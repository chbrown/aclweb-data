{"sections":[{"title":"Word Translation Based on Machine Learning Models Using Translation Memory and Corpora","paragraphs":["Kiyotaka Uchimotot, Satoshi Sekinet, Masaki Muratat, and Hitoshi Isaharat tCommunications Research Laboratory 2-2-2, Hikari-dai, Seika-cho, Soraku-gun,","Kyoto, 619-0289 Japan"]},{"title":"{uchimoto, murata, isahara}©crl.go.jp","paragraphs":[":j:New York University"]},{"title":"715","paragraphs":["Broadway, 7th floor New York, NY 10003, USA"]},{"title":"sekine@cs.nyu.edu","paragraphs":["Abstract SENSEVAL-2 was held in Spring, 2001. It con sisted of several tasks in various languages. In this paper, we describe our system used for one of these tasks: the Japanese translation task. With an accuracy of 63.4%, our system was the third best system in the contest among nine sys tems developed by seven groups. 1 Introduction In the Japanese translation task, the senses of a word were defined in terms of the word's trans lations. Given an input sentence and a target word in the sentence, our system first estimates the similarity between the input sentence and parallel example sets called \"Translation Mem ory\". It then selects an appropriate transla tion of the target word by using the example set with the highest similarity. The similarity is calculated using dynamic programming and a machine learning model, which assesses the similarity based on the similarity of a string, words to the left and to the right of the target word in the input sentence, content words in the input sentence and their translations, and co-occurrence of content words in bilingual and monolingual corpora in English and Japanese. 2 Japanese Translation Task In general, the definition of word senses depends on the goal of a task. The goal of the Japanese translation task is word selection in translation, where the target language is English. Therefore, word senses are defined as translations (trans lated words/ phrases).","Before the contest, a Japanese-English par allel phrase/sentence set (Translation Memory, henceforth referred to as TM) was given to the participants as training data. In the TM, for each Japanese headword, there was a set of pairs 155 of a Japanese expression including a headword and an English translation of the expression. We call these pairs examples. Some of the ex amples are shown in Figure 1.","<entry id= \"1\" headword= \".it,!j\" >","<sense id=\"l-1\"> <jexpression> ffl;~: .it,!j'T .Q </jexpression> <eexpression>to feel constrained for one's mother</ eexpression>","</sense>","<sense id= \"1-2\" > <jexpression> ffl:\"'-O).it,!j </jexpression> <eexpression>constraint toward one's mother</ eexpression> <transmemo> UC</transmemo>","</sense>","<sense id=\"1-3\"> <jexpression> Mk~ ~ .it,!j l-c b G -5 </jexpression> <eexpression>to request to refrain from donation</ eexpression>","</sense>","</entry> Figure 1: Examples in TM.","In the formal test (contest), the participants were given a set of texts each of which was marked by a target word. For each target word, the participants were required to submit either a sense id of the example (the number assigned to each example in the TM), which can be used to translate the target word, or a translation of the target word. In the latter case, a translation of the word itself, a translation of a sequence of words including the target word, or a transla tion of the whole sentence could be submitted.","Answers were prepared for each target word in the formal test. The answers could consist of one or more sense id's in the TM, or of pos sible translations. The output of each system was evaluated in terms of accuracy, defined as a percentage of answers identified correctly by the system. An answer was judged to have been identified correctly when a sense id or a trans lation selected by the system was found in the answer."]},{"title":"3 Word Translation Model","paragraphs":["Given an input sentence and a target word in the sentence, our model selects an appropriate translation of the target word or a sense id of examples appropriate for the translation of the target word by using examples with the high est similarity, estimated between the examples and the input sentence. In this paper, we call this model a word translation model. The source language is Japanese and the target language in translation is English. Henceforth we call a headword translation an English headword.","The similarity between an input sentence and examples is calculated by the following two methods:","1. A method based on the similarity of a string of characters (Method 1) : The similarity is defined as the amount of agreement between an input sentence and a Japanese example, ex pressed as a percentage.","2. A method based on machine learning models (Method 2) : The similarity is defined as the confidence or probability estimated by machine learning models. English headwords are used as classes (or categories) in machine learning mod els. Since the TM has examples with the same English headword, the similarity estimated by a model is the similarity between the input sen tence and a set of examples.","A model is prepared for each Japanese head word. Given an input sentence, the similarity between the input sentence and each example is calculated by a model using Method 1. If the similarity is equal to or greater than a certain threshold, the model returns either the sense id of the example with the highest similarity or an English headword of the example. Otherwise, a model in Method 2 selects and returns an En glish headword.","The following sections describe the two meth ods in greater detail. 3.1 Method Based on the Similarity of","A String of Characters (Method 1) When an example with the highest similarity is found, it is given the highest priority, and either the sense id or the English headword of the example is selected as an output.","When calculating the agreement rate between an input sentence and an example, the right most word of the Japanese example is stemmed. In other words, when the rightmost word is a function word or a auxiliary verb such as \"SURD (do)\", it is eliminated. When the right most word is a predicate, its inflectional part is also eliminated. For example, the stemmed examples in Figure 1 are"]},{"title":"\"f.J:","paragraphs":["~=ill\\\","]},{"title":"\"f.J:\"'-","paragraphs":["0)"]},{"title":"ill\\\" ,","paragraphs":["and \"mt~ ~"]},{"title":"ill\\\",","paragraphs":["respectively. The agreement rate is calculated as a percentage of characters in the Japanese example that cor respond to those in the input sentence. The correspondence is evaluated by comparing the Japanese example and the input sentence char acter by character. This can be done by using the UNIX command \"diff\" in a dynamic pro gramming method. 1 The similarity is calcu lated by using the following equation. Similarity ( the number of characters ) corresponding to characters in input sentence","--7----------.;- (1)","( the number of characters in ) stemmed Japanese example When several examples with the highest sim ilarity are found, the one having the longest Japanese example is selected except when the length of corresponding part is shorter than that of the Japanese headword.","However, it is unrealistic to expect that an example that is almost the same as the input sentence can be found because it is difficult to install all possible examples into the TM. So, when there is no example whose similarity is equal to or greater than the threshold, the method described in the next section is used. 3.2 Method Based on Machine","Learning Models (Method 2) 2 To select an appropriate example with the same usage as that of the input sentence, the sim ilarity must be calculated by extracting the most important information from various con flicting sources of information related to the in put sentence and examples. Since we want to avoid making complicated rules, we use machine learning models to calculate the similarity. In stead of all examples in the TM, English head words are used as classes in machine learning models. Therefore, examples having the same English headword are put into the same class and are considered to have the same similarity.","1","A description on how to use \"diff\" can be found in (Murata and Isahara, 2001).","2","Work on using machine learning methods for the tra!lslation of tenses, aspects, and modalities can be found'in {Murata et al., 2001a). 156","Classes identified by machine learning mod els are basically English headwords in TM, and they are detected manually. For example, En glish headwords of the examples in Figure 1 are \"feel constrained\", \"constraint\", and \"re frain\", respectively. When English headwords are verbs, they are represented by their basic forms. English words obtained when a Japanese headword is looked up in a Japanese-English dictionary are also used as classes.","For the training data, we use not only ex amples in the TM but also other data col lected from bilingual dictionaries or a par allel corpus. The collected data consist of Japanese-English parallel phrases/sentences in cluding both Japanese and English headwords, and they are used as complements of the train ing data.","For the machine learning models, we use SVM (Support Vector Machine), ME (Maximum En tropy), DL (Decision list), and SB (Simple Bayes). For each Japanese headword, the best model with the highest accuracy in 10-hold cross-validation on the training data is used for testing. The confidence of each class is esti mated by probability distribution"]},{"title":"p(a,","paragraphs":["b), where b is a context in a set of contexts, B, and a is a class in a set of classes,"]},{"title":"A.","paragraphs":["SVM is a classifier, and in this model, the confidence of each class cannot be represented by a probability distribu tion, but for the sake of convenience, we assign probability 1 to the most confident class esti mated by SVM, and 0 to all other classes. The parameters in each model follow those used in (Murata et al., 2001b). Context b is represented by a set of features, that is, information deriv able from the training data. The features used in our experiments were as follows:","1. Morphological information The string, basic form, major and minor parts of speech, and inflection type on six mor phemes, three morphemes to the left and three morphemes to the right of the target word in an input sentence.","2. Character n-gram Character n-grams in an input sentence. Each n-gram must include the target word.","3. Highest matching An English headword in the example that has the longest string matching that of the input sentence and its length are used as features.","4. Frequency of a content word and its translation candidates 157 We define a set of examples including the same English headword as an example set. For each English headword, we define the following six example sets: Example set 1 Japanese examples Example set 2 English examples Example set 3 Sentences similar to examples in","Example set 1. They are collected from a","Japanese monolingual corpus. Example set 4 Sentences similar to examples in","Example set 2. They are collected from an","English monolingual corpus. Example set 5 Union of Example sets 1 and 3 Example set 6 Union of Example sets 2 and 4","For each example set, Japanese-English par allel phrases/sentences including both Japanese and English headwords are collected from bilin gual dictionaries or parallel corpora, and are added to the example set.","Sentences similar to a certain example are de fined as sentences that include a substring of the example. The substring must include the headword of the example. In our model, we use sentences collected from a monolingual corpus because we want the model to reflect a real dis tribution of words, both headwords and words to the left and right of the headwords.","As content words, we used nouns, verbs, ad jectives, adverbs, and attributives, except head words, in the input sentence. For each content word in an input sentence and its translation candidates, the frequencies in each example set were used as features. The translation candi dates of a content word were obtained when the content word was looked up in a Japanese English dictionary. Each feature is represented by a combination of an example set, a head word, and the frequency of content words in the example set. When we find that the total fre quency of content words in an example set is n, we assume that every feature whose frequency is between 1 and n is observed. For example, when the content word found in the given sen tence is \"mother\", and it is found three times in the example set 1 for the headword \"buy\", the features \"Example set 1 : buy : 1,\" \"Example set 1 : buy : 2,\" and \"Example set 1 : buy : 3\" are assumed to be observed. By using these features, our model handles information about co-occurrence words of a headword in each cor pus as a clue to translating the headword."]},{"title":"4 Experiment","paragraphs":["4.1 Experimental conditions The input and evaluation of the systems fol lowed those of the Japanese translation task in SENSEVAL-2. A TM for 320 headwords was given to each participant in the middle of March, 2001. The average number of exam ples prepared for each headword was approxi mately 20. For the formal test, 40 target words (20 nouns and 20 verbs) were selected from the headwords. For each target word, 30 texts in cluding the target words were prepared. The total number of the target words was 1,200.","As a bilingual dictionary, we used \"EI JIRO\" available at the web site of NIFTY"]},{"title":"'","paragraphs":["a network provider. As monolingual corpora, we used MAINICHI newspapers from 1991 to 2000, NIKKEI newspapers from 1995 to 1999, SANKEI newspapers from 1994 to 1999, and LDC data collected in 1994 and 1995, which include English newspaper articles for several years published by the Wall Street Journal the Associated Press Writer, and the New York Times.","In the formal test, the threshold of similarity used in Method 1 was 1. JUMAN (Kurohashi and Nagao, 1999), a Japanese morphological an alyzer, was used for morphological analysis in Method 2. As sentences similar to a certain example in Method 2, sentences that included a string obtained by stemming Japanese exam ples were extracted for Japanese examples, and sentences that included English headwords were extracted for English examples. As for the rna chine learning models, we could not select the most appropriate set of models by cross vali dation because not all learning processes could be finished by the deadline for submission. The models finally selected for the formal test were as follows:","• SVM : 23 words (12 nouns and 11 verbs)","• DL : 12 words (8 nouns and 4 verbs)","• SB : 5 words (5 verbs) 4.2 Experimental Results and","Discussion The accuracy obtained by our system in the formal test was 63.4% (761/1,200). The accu racy obtained by Method 1 and 2 were 91.0% (91/100) and 60.9% (670/1,100), respectively. Based on our results, we can draw the following conclusions: 158","• The system performance was related to the amount of training data per class in Method 2.","• The accuracy obtained for words whose En glish headwords were general words was not high even though there were more training data for these words than for other headwords for which the accuracy was high. We believe that this is due to the quality of automatically col lected training data because general words ap pear in corpora quite frequently, and sometimes parallel sentences where Japanese and English headwords are not related to each other are collected. Therefore, we need to select auto matically collected parallel sentences by align ing Japanese and English headwords.","• Method 1 improved the accuracy, especially for idiomatic expressions that rarely appeared in the training data. We applied Method 2 to the target words to which Method 1 was applied in the formal test, and achieved an even lower accuracy of 34.0%(34/100).","• The accuracy obtained by the SB model was low. We speculate that the SB model is not suitable for the feature sets used in the test."]},{"title":"5 Conclusion","paragraphs":["This paper described our system used in SENSEVAL-2. Our model for word translation has the following characteristics: (1) It puts to gether examples having the same English head word into a set of examples, and selects a set of examples most similar to the input sentence by using machine learning models. (2) If an exam ple that is almost the same as the input sentence is found, our model gives it the highest priority. (3) It automatically collects training data and information used for training from other lan guage resources that are not only a bilingual corpus but also monolingual corpora of English an.d Japanese. We do not have to supervise any thmg except the detection of headword pairs in the examples."]},{"title":"References","paragraphs":["Sadao Kurohashi and Makoto Nagao, 1999. Japanese Mor phological Analysis System JUMAN Version 3.61. De partment of Informatics, Kyoto University.","Masaki Murata and Hitoshi !sahara. 2001. NLP using DIFF. In IPSJ~WGNL NL144-18, pages 127~134. (in Japanese).","Masaki Murata, Kiyotaka Uchimoto, Qing Ma, and Hi toshi !sahara. 2001a. Using a Support-Vector Machine for Japanese-to-English Translation of Tense, Aspect, and Modality. In ACL Workshop on the Data-Driven Machine Translation.","Masaki Murata, Masao Utiyama, Kiyotaka Uchimoto, Qing Ma, and Hitoshi !sahara. 2001b. Experiments on Word Sense Disambiguation Using Several Machine-leaning Metheds. In IEICE~WGNLC2001-2. (in Japanese)."]}]}