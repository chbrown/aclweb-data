{"sections":[{"title":"KUNLP system using Classification Information Model at SENSEVAL-2 Hee-Cheol Seo, Sang-Zoo Lee, Rae-Chang Rim Dept. of Computer Science and Engineering, Ho Lee Astronest Inc. Korea University 1, 5-ka, Anarn-dong Seongbuk-Gu, Seoul, 136-701, Korea {hcseo,zoo,rirn }@nlp.korea.ac.kr Abstract","paragraphs":["The classification information model or CIM classi fies instances by considering the discrimination abil ity of their features, which was proven to be useful for word sense disambiguation at SENSEVAL-1. But the CIM has a problem of information loss. KUNLP system at SENSEVAL-2 uses a modified version of the CIM for word sense disambiguation.","We used three types of features for word sense disambiguation: local, topical, and bigram context. Local and topical context are similar to Chodorow's context and refer to only unigram information. The window of a bigram context is similar to that of a local context but a bigram context refers to only bigram information.","We participated in the English lexical sample task and the Korean lexical sample task, where our sys tems ranked high."]},{"title":"1 Introduction","paragraphs":["The classification information model(Ho, 1997) is the model that classifies instances by considering the discrimination ability of their features. In the CIM, a feature with high discrimination ability con tributes to the classification more than one with low discrimination ability. Hence, we can omit the feature selection procedure. ·","The CIM has a kind of information loss problem due to the assumption that a feature contributes to only one class. We devised a modified version of the CIM where a feature can contribute to all classes.","\\Vord sense disambiguation task can be treated as a kind of classification process(Ho, 2000). When a classification technique is applied to word sense dis ambiguation, an instance corresponds to a context containing a polysemous word and its class to the proper sense of the word, and one of its features to a piece of context information. As a classifica tion problem, word sense disambiguation task can be solved by the CIM.","\\Ve used three types of features for word sense disambiguation: local, topical, and bigram context. Local and topical context are similar to Chodorow's context(Chodorow, 2000) and consist of only uni-"]},{"title":"135-090 3rd floor, Hanarn BD 157-18 Sarnsung-Dong Kangnarn-Gu, Seoul, Korea leeho@astronest.corn","paragraphs":["gram information. A bigram context has a similar window to a local context but consists of only bigram information."]},{"title":"2 KUNLP system","paragraphs":["To disambiguate senses, we did two phases: corpus preprocessing and sense disambiguation. Figure 1 shows the flow chart of our system. Corpus"]},{"title":"~","paragraphs":["Tokenizer","~ POS-Tagger Corpus Preprocessing"]},{"title":"~","paragraphs":["Phrase Filter","~","Sense Tagger using Modified CIM Sense Disambiguation"]},{"title":"~","paragraphs":["Sense-Tagged Corpus Figure 1: Flow chart of KUNLP system 2.1 Corpus preprocessing At the corpus preprocessing phase, we tokenized a corpus and then tagged it with parts-of-speech using Brill's Tagger(Brill, 1994). The tokenizer just sepa rates symbols from a word. For example, a sentence \"I'm straight, white, no longer middle class, anti IRA, have ... \" is tokenized to \"I 'm stright , white , no longer middle class , anti - IRA , have ... \". Un like other symbols, an apostrophe is not separated from the following characters."]},{"title":"147 2.2 Phrase filtering","paragraphs":["At the phrase filtering phase, we filtered senses using the satellite feature, which is marked with sat tag in training and test corpus given by the task organizer. For example, in a sentence This air of disengagement <head sats= \"carry_over. 067:0\"> carried</head> <sat id= \"carry_over. 067:0\"> over</sat> to his apparent attitude toward his things, carried over is a phrase and also a satellite feature.","Phrase filtering is applied to sense disambiguation as in Table 1 Table 1: phrase filtering and sense disambiguation if the number of filtered senses"]},{"title":"=","paragraphs":["1 then determine sense else if the number of filtered senses"]},{"title":"> 1","paragraphs":["then execute sense-tagger with the filtered senses","else if the number of filtered senses = 0 then execute sense-tagger with all senses","There are satellite features in the English lexical sample, but not in the Korean lexical sample. Hence, phrase filtering was applied only in the English lex ical sample task. 2.3 Classification Information Model","(CIM) The CIM is a kind of classification model based on the entropy theory. Given an input instance, the CIM decides the proper class of the instance by con sidering individual decisions made by each feature of the instance. In the model, the proper class of an instance,X, is determined by Equation 1. Class(X)"]},{"title":"~f","paragraphs":["arg max Rel(classj, X) (1) class; where classJ is the j-th class and Rel(classj, X) is the relevance between the j-th class and the instance X. Here, if we assume that features are independent of each other, the relevance can be defined as in Equation 2.","m Rel(classj, X)="]},{"title":"L","paragraphs":["x;W;j i=l (2) where m is the size of the feature set, xi is the value of the i-th feature and W;J is the weight of the i th feature for the j-th class. In Equation 2, x; has a binary value (1 if the feature occurs within the window, 0 otherwise) and W;j is defined in terms of classification information.","The classification information of a feature is com posed of two components. One is the discrimination"]},{"title":"148","paragraphs":["score (DS), which represents the discrimination abil ity of classifying instances. The other is the most probable class (MPC), which represents the most closely related class to the feature. Wij is defined by using these two components as follows:"]},{"title":"~","paragraphs":["{ DS; Wij ~ Q if classj = MPC; otherwise"]},{"title":"(3)","paragraphs":["In Equation 3, DS; and M PCi represent the DS and MPC of the i-th feature, respectively. In the CIM, DS and MPC are defined in terms of the con ditional probability of a class given a feature, which is normalized by the corpus size. The normalized conditional probability is defined as follows: clef"]},{"title":"=","paragraphs":["( l"]},{"title":"If)","paragraphs":["N(class) p C aSSj i N(class;) ';:-'n ( l"]},{"title":"If)","paragraphs":["N(class)","uk=l p c aSSk i N(classk) p(f;iclassj)"]},{"title":"(4)","paragraphs":["In Equation 4, Pii is a normalized conditional probability, N(classJ) is the number of instances belonging to the j-th class in the training data, N (class) is the average number of instances for each class and n is the number of classes. Given the normalized conditional probability distribution, DSs and MPCs are defined as follows: DS; clef MPC; clef log2 n ~"]},{"title":"H(pi)","paragraphs":["n log2 n"]},{"title":"+ ~","paragraphs":["PJi log2 PJi j=l","arg max PJi class;","arg max p(filclassj) class i"]},{"title":"(5) (6)","paragraphs":["In Equation 5,"]},{"title":"H(p;)","paragraphs":["is the entropy of the i-th feature over the normalized conditional probability distribution. 2.4 Modifying CIM The CIM has a problem caused by using MPCs, which is information loss. For example, let us con sider the situation in Table 2 and Table 3. Table 2 shows the normalized conditional probability distri bution, DSs and MPCs of features in an instance. Table 3 shows the weights and the relevance values at the CIM using Wij and at the modified CIM us ing 'Wij, for the instance of Table 2. The feature"]},{"title":"h","paragraphs":["co-occurred with class1 and class2 and the MPC of"]},{"title":"h","paragraphs":["is class1 at Table 2. In the CIM, this feature Table 2: A normalized conditional probability, DSs and MPCs of features of an instance","normalized conditional probability(pj;) feature class1 class2 class3 class4 DS MPC"]},{"title":"h","paragraphs":["0.7 0.3 0 0 1.1187 class1 fz 0 0.4 0.6 0 1.0290 class3"]},{"title":"h","paragraphs":["0 0.4 0.1 0.5 0.6390 class4 Table 3: The weights and the relevance values at the CIM using w;J and at the modified CIM using w;j, for the instance of Table 2 weight( W;J)"]},{"title":"II","paragraphs":["weight ( W;j) feature class1 class2 class3 class4"]},{"title":"II","paragraphs":["class1 class2 class3 class4"]},{"title":"h","paragraphs":["1.1187 0 0 0 0.7831 0.3356 0 0"]},{"title":"h","paragraphs":["0 0 1.0290 0 0 0.4116 0.6174 0"]},{"title":"h","paragraphs":["0 0 0 0.6390 0 0.2556 0.0639 0.3195 T"]},{"title":"I","paragraphs":["Rel(classj,X) 11.1187"]},{"title":"I","paragraphs":["0 1 1.o29o 1 o.639o 11 o.7831 1 1.oo28 1 o.6813 1 o.3195 1 contributes to only class1. Actually the feature"]},{"title":"h","paragraphs":["can contribute to distinguishing class2 from class3 if it consults the normalized conditional probability distribution. In the CIM, however, the feature can not distinguish them because their weights have the same value.","Another aspect of the problem is that the CIM fails to capture the minor contribution of features, which is crucial in the case where the sum of the minor contribution of features to a non-MPC class dominates that of the major contribution of fea tures to MPC classes. For example, at Table 2, all features,"]},{"title":"h, fz,","paragraphs":["and"]},{"title":"/3,","paragraphs":["have different MPCs: class1, class3 and class4, respectively. it is also ob vious that they have some minor contribution to the class2 . The CIM will classify the instance as class1 because Rel(class1,X)"]},{"title":"=","paragraphs":["1.1187 is the maximum number among the Rel(classj, X). However, if we consider the minor contribution of all the features, we prefer class2 to class1 because class2 intuitively gains the total contribution more than class1.","A solution to the problem may be not to use MPCs, but to use a measure of contribution of a feature to a class which is proportional to the dis crimination score of the feaure and the normalized conditional probability of the class given the feature. The modified CIM can be defined as follows:","m Rel(classj, X)="]},{"title":"L","paragraphs":["x;W;j"]},{"title":"(7)","paragraphs":["i=l","A def DS A","(","8) W;j = ; X PJi","As shown in Table 3, the"]},{"title":"·w","paragraphs":["12 is larger than tu 13 (0.3356"]},{"title":">","paragraphs":["0) and the instance is classified not as class1 but as class2 because Rei ( class2, X) ="]},{"title":"149","paragraphs":["1.0028"]},{"title":">","paragraphs":["Rel(class1 , X) = 0.7831, which is based on the modified CIM. 2.5 Feature Space We used three types of features for word sense dis ambiguation: local, topical and bigram context. In the preliminary experiment, we have observed that, when the CIM considered all these three types of features, it mostly achieved the best result. 2.5.1 Local context In a local context, there can be features of the fol lowing templates for all words within its window: • in the English lexical sample task - word_position : a word and its position - word_POS : a word and its part-of-speech","- POS_position : the part-of-speech and position of a word • in the Korean lexical sample task","- rnorpheme_position : a morpheme1 and its position.","- rnorpheme_POS : a morpheme and its part of-speech.","- POS_position : the part-of-speech and po sition of a morpheme","In the English lexical sample task, word is a sur face form and can be either one of open-class words whose POS is one of the noun, verb, adjective, and adverb; or one of closed-class words whose POS is 1","A Korean sentence is composed of one or more eojeols, which are separated by spaces, and an eojeol consists of one or more morphemes. one of the determiner, preposition, pronoun, and punctuation. The window size of ±3 words in the English lexical sample task and the window size from -2 to +3 word in the Korean lexical sample task were empirically chosen.","In the first phase of the experiments, we used just one complicated template, word_position_POS (in Korean morpheme_position_POS), which brought about data sparseness problem. So we split the tem plate into three simpler templates. 2.5.2 Topical context A topical context includes features of the following templates for all open-class words within its window: • in the English lexical sample task - word : an open-class word. • in the Korean lexical sample task - morpheme : an open-class morpheme.","The window size of ±1 sentences in the English lexical sample task and the window size of all sen tences in the Korean lexical sample task were em pirically chosen. 2.5.3 Bigram context In a bigrarn context, there can be features of the fol lowing templates for all word-pairs within its win dow: • in the English lexical sample task","- (word;, wordj) word (i>j) the i-th word and j-th (word;, POSj) : the i-th word and j-th part-of-speech ( i > j) • in the Korean lexical sample task","- (eojeol;, eojcolj) : the i-th eojeol and j-th eojeol (i>j)","\"Cnlike local and topical contexts, bigram contexts are composed of only bigrarn information surround ing the polysemous word. The window size of ±2 words in the English lexical sample task and the win dow size from -2 to +3 word in the Korean lexical sample task were empirically chosen."]},{"title":"3 Experimental Result","paragraphs":["The following tables show the results of our systems at SENSEVAL-2 (Table 4). For the Korean lexical sample task at SENSEVAL-2, only fine-grained sense distinction was made."]},{"title":"150","paragraphs":["Table 4: Results of KUNLP systems at SENSEVAL-2"]},{"title":"I","paragraphs":["task"]},{"title":"I","paragraphs":["prec."]},{"title":"I","paragraphs":["recall English Lexical Sample (fine g.) 0.629 0.629 English Lexical Sample (coarse g.) 0.697 0.697 Korean Lexical Sample (fine g.) 0.698 0.74"]},{"title":"4 Conclusion","paragraphs":["We have described the modified CIM used for word sense disambiguation at SENSEVAL-2. In the exper iments, three types of features; local, topical, and bigram context, are used. Our system ranked as the highest at the Korean lexical sample task and as the topmost group at the English lexical sample task among the supervised models at SENSEVAL-2. Consequently, the results back up the fact that the modified CIM and three types of features are useful for discriminating word senses."]},{"title":"References","paragraphs":["Eric Brill 1994. Some advances in rule-based part of speech tagging. In Proceedings of the Twelfth National Conference on Artificial Intel ligence ( AAAI-94}.","Martin Chodorow, Claudia Leacock and George A. Miller 2000. A Topical/Local Classifier for Word Sense Identification. In Computers and the Hu manities 34: 115-120.","Ro Lee, Dae-Ro Baek and Rae-Chang Rim 1997. Word Sense Disambiguation Based on The In formation Theory. In Proceedings of Research on Computational Linguisitcs Conference.","Ro Lee, Rae-Chang Rim and JungYun Seo 2000. Word Sense Disambiguation Using the Classifica tion Information Model. In Computers and the Humanities 34: 141-146."]}]}