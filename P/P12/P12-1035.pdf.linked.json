{"sections":[{"title":"","paragraphs":["Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 330–338, Jeju, Republic of Korea, 8-14 July 2012. c⃝2012 Association for Computational Linguistics"]},{"title":"A Joint Model for Discovery of Aspects in Utterances Asli Celikyilmaz Microsoft Mountain View, CA, USA asli@ieee.org Dilek Hakkani-Tur Microsoft Mountain View, CA, USA dilek@ieee.org Abstract","paragraphs":["We describe a joint model for understanding user actions in natural language utterances. Our multi-layer generative approach uses both labeled and unlabeled utterances to jointly learn aspects regarding utterance’s target domain (e.g. movies), intention (e.g., finding a movie) along with other semantic units (e.g., movie name). We inject information extracted from unstructured web search query logs as prior information to enhance the generative process of the natural language utterance understanding model. Using utterances from five domains, our approach shows up to 4.5% improvement on domain and dialog act performance over cascaded approach in which each semantic component is learned sequentially and a supervised joint learning model (which requires fully labeled data)."]},{"title":"1 Introduction","paragraphs":["Virtual personal assistance (VPA) is a human to machine dialog system, which is designed to perform tasks such as making reservations at restaurants, checking flight statuses, or planning weekend activities. A typical spoken language understanding (SLU) module of a VPA (Bangalore, 2006; Tur and Mori, 2011) defines a structured representation for utterances, in which the constituents correspond to meaning representations in terms of slot/value pairs (see Table 1). While target domain corresponds to the context of an utterance in a dialog, the dialog act represents overall intent of an utterance. The slots are entities, which are semantic constituents at the word or phrase level. Learning each component","Sample utterances on ’plan a night out’ scenario (I) Show me theaters in [Austin] playing [iron man 2]. (II)I’m in the mood for [indian] food tonight, show me the ones [within 5 miles] that have [patios].","Extracted Class and Labels Domain Dialog Act Slots=Values (I) Movie find Location=Austin","theater Movie-Name= iron man 2 (II) Restaurant find Rest-Cusine=indian","restaurant Location=within 5 miles","Rest-Amenities= patios Table 1: Examples of utterances with corresponding semantic components, i.e., domain, dialog act, and slots. is a challenging task not only because there are no a priori constraints on what a user might say, but also systems must generalize from a tractably small amount of labeled training data. In this paper, we argue that each of these components are interdependent and should be modeled simultaneously. We build a joint understanding framework and introduce a multi-layer context model for semantic representation of utterances of multiple domains.","Although different strategies can be applied, typically a cascaded approach is used where each semantic component is modeled separately/sequentially (Begeja et al., 2004), focusing less on interrelated aspects, i.e., dialog’s domain, user’s intentions, and semantic tags that can be shared across domains. Recent work on SLU (Jeong and Lee, 2008; Wang, 2010) presents joint modeling of two components, i.e., the domain and slot or dialog act and slot components together. Furthermore, most of these systems rely on labeled training utterances, focusing little on issues such as information sharing between the discourse and word level components across different domains, or variations in use of language. To deal with de-330 pendency and language variability issues, a model that considers dependencies between semantic components and utilizes information from large bodies of unlabeled text can be beneficial for SLU.","In this paper, we present a novel generative Bayesian model that learns domain/dialog-act/slot semantic components as latent aspects of text utterances. Our approach can identify these semantic components simultaneously in a hierarchical framework that enables the learning of dependencies. We incorporate prior knowledge that we observe in web search query logs as constraints on these latent aspects. Our model can discover associations between words within a multi-layered aspect model, in which some words are indicative of higher layer (meta) aspects (domain or dialog act components), while others are indicative of lower layer specific entities.","The contributions of this paper are as follows: (i) construction of a novel Bayesian framework for semantic parsing of natural language (NL) utterances in a unifying framework in §4, (ii) representation of seed labeled data and information from web queries as informative prior to design a novel utterance understanding model in §3 & §4, (iii) comparison of our results to supervised sequential and joint learning methods on NL utterances in §5. We conclude that our generative model achieves noticeable improvement compared to discriminative models when labeled data is scarce."]},{"title":"2 Background","paragraphs":["Language understanding has been well studied in the context of question/answering (Harabagiu and Hickl, 2006; Liang et al., 2011), entailment (Sammons et al., 2010), summarization (Hovy et al., 2005; Daumé-III and Marcu, 2006), spoken language understanding (Tur and Mori, 2011; Dinarelli et al., 2009), query understanding (Popescu et al., 2010; Li, 2010; Reisinger and Pasca, 2011), etc. However data sources in VPA systems pose new challenges, such as variability and ambiguities in natural language, or short utterances that rarely contain contextual information, etc. Thus, SLU plays an important role in allowing any sophisticated spoken dialog system (e.g., DARPA Calo (Berry et al., 2011), Siri, etc.) to take the correct machine actions.","A common approach to building SLU framework is to model its semantic components separately, as-suming that the context (domain) is given a priori. Earlier work takes dialog act identification as a classification task to capture the user’s intentions (Margolis et al., 2010) and slot filling as a sequence learning task specific to a given domain class (Wang et al., 2009; Li, 2010). Since these tasks are considered as a pipeline, the errors of each component are transfered to the next, causing robustness issues. Ideally, these components should be modeled simultaneously considering the dependencies between them. For example, in a local domain application, users may require information about a sub-domain (movies, hotels, etc.), and for each sub-domain, they may want to take different actions (find a movie, call a restaurant or book a hotel) using domain specific attributes (e.g., cuisine type of a restaurant, titles for movies or star-rating of a hotel). There’s been little attention in the literature on modeling the dependencies of SLU’s correlated structures.","Only recent research has focused on the joint modeling of SLU (Jeong and Lee, 2008; Wang, 2010) taking into account the dependencies at learning time. In (Jeong and Lee, 2008), a triangular chain conditional random fields (Tri-CRF) approach is presented to model two of the SLU’s components in a single-pass. Their discriminative approach represents semantic slots and discourse-level utterance labels (domain or dialog act) in a single structure to encode dependencies. However, their model requires fully labeled utterances for training, which can be time consuming and expensive to generate for dynamic systems. Also, they can only learn dependencies between two components simultaneously.","Our approach differs from the earlier work- in that- we take the utterance understanding as a multi-layered learning problem, and build a hierarchical clustering model. Our joint model can discover domain D, and user’s act A as higher layer latent concepts of utterances in relation to lower layer latent semantic topics (slots) S such as named-entities (”New York”) or context bearing non-named entities (”vegan”). Our work resembles the earlier work of PAM models (Mimno et al., 2007), i.e., directed acyclic graphs representing mixtures of hierarchical topic structures, where upper level topics are multinomial over lower level topics in a hierarchy. In an analogical way to earlier work, the D and A in our 331 approach represent common co-occurrence patterns (dependencies) between semantic tags S (Fig. 2). Concretely, correlated topics eliminate assignment of semantic tags to segments in an utterance that belong to other domains, e.g., we can discover that ”Show me vegan restaurants in San Francisco” has a low probably of outputting a movie-actor slot. Being generative, our model can incorporate unlabeled utterances and encode prior information of concepts."]},{"title":"3 Data and Approach Overview","paragraphs":["Here we define several abstractions of our joint model as depicted in Fig. 1. Our corpus mainly contains NL utterances (”show me the nearest dimsum places”) and some keyword queries (”iron man 2 trailers”). We represent each utterance u as a vector wu of Nu word n-grams (segments), wuj, each of which are chosen from a vocabulary W of fixed-size V. We use entity lists obtained from web sources (explained next) to identify segments in the corpus. Our corpus contains utterances from KD=4 main domains:∈ { movies, hotels, restaurants, events }, as well as out-of-domain other class. Each utterance has one dialog act (A) associated with it. We assume a fixed number of possible dialog actsKA for each domain. Semantic Tags, slots (S) are lexical units (segments) of an utterance, which we classify into two types: domain-independent slots that are shared across all domains, (e.g., location, time, year, etc.), and domain-dependent slots, (e.g. movie-name, actor-name, restaurant-name, etc.). For tractability, we consider a fixed number of latent slot typesKS. Our algorithm assigns domain/dialog-act/slot labels to each topic at each layer in the hierarchy using labeled data (explained in §4.)","We represent domain and dialog act components as meta-variables of utterances. This is similar to author-topic models (Rosen-Zvi et al., 2004), that capture author-topic relations across documents. In that case, words are generated by first selecting an author uniformly from an observed author list and then selecting a topic from a distribution over words that is specific to that author. In our model, each utterance u is associated with domain and dialog act topics. A word wuj in u is generated by first selecting a domain and an act topic and then slot topic over words of u. The domain-dependent slots in utterances are usually not dependent on the dialog act. For instance, while ”find [hugo] trailer” and ”show me where [hugo] is playing” have both a movie-name slot (”hugo”), they have different dialog acts, i.e., find-trailer and find-movie, respectively. We predict posterior probabilities for domain P̃ (d ∈ D|u) dialog act P̃ (a ∈ A|ud) and slots P̃ (sj ∈ S|wuj, d, sj−1) of words wuj in sequence.","To handle language variability, and hence discover correlation between hierarchical aspects of utterances1",", we extract prior information from two web resources as follows:","Web n-Grams (G). Large-scale engines such as Bing or Google log more than 100M search queries each day. Each query in the search logs has an associated set of URLs that were clicked after users entered a given query. The click information can be used to infer domain class labels, and there-fore, can provide (noisy) supervision in training domain classifiers. For example, two queries (”cheap hotels Las Vegas” and ”wine resorts in Napa”), which resulted in clicks on the same base URL (e.g., www.hotels.com) probably belong to the same domain (”hotels” in this case). movie rest. hotel event other ψG = P(d=hotel|wj=‘room’)d|wj","Given query logs, we compile sets of in-domain queries based on their base URLs2",". Then, for each vocabulary item wj ∈ W in our corpus, we calculate frequency of wj in each set of in-domain queries and represent each word (e.g., ”room”) as a discrete normalized probability distribution ψj","G over KD domains {ψd|j","G }∈ ψj","G. We inject them as nonuniform priors over domain and dialog act parameters in §4.","Entity Lists (E). We limit our model to a set of named-entity slots (e.g., movie-name, restaurant-name) and non-named entity slots (e.g., restaurant-cuisine, hotel-rating). For each entity slot, we extract a large collection of entity lists through the url’s on the web that correspond to our domains, such as movie-names listed on IMDB, restaurant-names on OpenTable, or hotel-ratings on tripadvisor.com. 1 Two utterances can be intrinsically related but contain no","common terms, e.g., ”has open bar” and ”serves free drinks”. 2 We focus on domain specific search engines such as","IMDB.com, RottenTomatoes.com for movies, Hotels.com and","Expedia.com for hotels, etc. 332","slot transition parameters slot topics dialog act topics !A domain specific act parameters n-gram prior from web query logs entity prior from web documents","domain topicsdomain parameters Utterance w w+1 wuj movie restaurant hotel menu 0.02 0.93 0.01 rooms 0.001 0.001 0.98 (G) Web N-Gram Context Prior(E) Entity List Prior V⨉D","wuj movie name restaurant name","hotel","name","hotel california 0.5 0.0 0.5","zucca 0.0 1.0 0.0 S w-1 S+1S-1 D A !D !S KS G","\"S KS topic-word parameters E MD MA MS Figure 1: Graphical model depiction of the MCM. D, A, S are domain, dialog act and slot in a hierarchy, each consisting of KD, KA, KS components. Shaded nodes indicate observed variables. Hyper-parameters are omitted. Sample informative priors over latent topics ψE and ψG are shown. Blue arrows indicate frequency of vocabulary terms sampled for each topic. We represent each entity list as observed nonuniform priors ψE and inject them into our joint learning process as V sparse multinomial distributions over latent topics D, and S to ”guide” the generation of utterances (Fig. 1 top-left table), explained in §4."]},{"title":"4 Multi-Layer Context Model - MCM","paragraphs":["The generative process of our multi-layer context model (MCM) (Fig. 1) is shown in Algorithm 1. Each utterance u is associated with d = 1..KD multinomial domain-topic distributions θd","D. Each domain d, is represented as a distribution over a = 1, .., KA dialog acts θda","A (θd","D → θda","A ). In our MCM model, we assume that each utterance is represented as a hidden Markov model with KS slot states. Each state generates n-grams according to a multinomial n-gram distribution. Once domain Du and act Aud topics are sampled for u, a slot state topic Sujd is drawn to generate each segment wuj of u by considering the word-tag sequence frequencies based on a simple HMM assumption, similar to the content models of (Sauper et al., 2011). Initial and transition probability distributions over the HMM states are sampled from Dirichlet distribution over slots θds","S . Each slot state s generates words according to multinomial word distribution φs","S. We also keep track of the frequency of vocabulary terms wj’s in a V ×KD matrix MD. Every time a wj is sampled for a domain d, we increment its count, a degree of domain bearing words. Similarly, we keep track of dialog act and slot bearing words in V × KA and V × KS matrices, MA and MS (shown as red arrows in Fig 1). Being Bayesian, each distribution θd","D, θad","A , and θds","S is sampled from a Dirichlet prior distribution with different parameters, described next.","Algorithm 1 Multi-Layer Context Model Generation","1: for each domain d ← 1, ..., KD","2: draw domain dist. θd","D ∼ Dir(α⋆","D)†",",","3: for each dialog-act a ← 1, ..., KA","4: draw dialog act dist. θda","A ∼ Dir(α⋆","A),","5: for each slot type s ← 1, ..., KS","6: draw slot dist. θds","S ∼ Dir(α⋆","S). 7: endfor 8: draw φs","S ∼ Dir(β) for each slot type s ← 1, ..., KS. 9: for each utterance u ← 1, ..., |U | do 10: Sample a domain Du∼Multi(θd","D) and, 11: and act topic Aud∼Multi(θda","A ). 12: for words wuj, j ← 1, ..., Nu do 13: - Draw Sujd∼Multi(θ","Du,Su(j−1)d","S )‡",".","14: - Sample wuj∼Multi(φSujd",").","15: end for","16: end for","† Dir(α⋆","D), Dir(α⋆ A), Dir(α⋆","S) are parameterized based on prior knowledge. ‡ Here HMM assumption over utterance words is used. In hierarchical topic models (Blei et al., 2003; Mimno et al., 2007), etc., topics are represented as distributions over words, and each document expresses an admixture of these topics, both of which have symmetric Dirichlet (Dir) prior distributions. Symmetric Dirichlet distributions are often used, since there is typically no prior knowledge favoring one component over another. In the topic model literature, such constraints are sometimes used to deterministically allocate topic assignments to known labels (Labeled Topic Modeling (Ramage et al., 2009)) or in terms of pre-learnt topics encoded as prior knowledge on topic distributions in documents (Reisinger and Pasça, 2009). Similar to previous work, we define a latent topic per each known semantic component label, e.g., five domain topics for five defined domains. Different from earlier work though, we also inject knowledge that we extract from several resources including entity lists from web search query click logs as well as seed labeled training utterances as prior information. We constrain the generation of the semantic components of our model by encoding prior knowledge in terms of 333 asymmetric Dirichlet topic priors α=(αm1,...,αmK ) where each kth topic has a prior weight αk=αmk, with varying base measure m=(m1,...,mk) 3",". We update parameter vectors of Dirichlet domain prior αu⋆","D ={(αD·ψu1","D ),..., αD·ψ","uKD","D }, where αD is","the concentration parameter for domain Dirichlet","distribution and ψu","D={ψud","D }","KD","d=1 is the base measure which we obtain from various resources. Because base measure updates are dependent on prior knowledge of corpus words, each utterance u gets a different base measure. Similarly, we update the parameter vector of the Dirichlet dialog act and slot priors αu⋆","A ={(αA·ψu1","A ),...,(αA·ψ uKA A )} and αu⋆ S ={(αS·ψu1","S ),...,(αS·ψ uKS S )} using base measures ψu A={ψua","A } KA a=1 and ψSu={ψus","S }","KS","s=1 respectively.","Before describing base measure update for domain, act and slot Dirichlet priors, we explain the constraining prior knowledge parameters below:","⋆ Entity List Base Measure(ψj","E): Entity features are indicative of domain and slots and MCM utilizes these features while sampling topics. For instance, entities hotel-name ”Hilton” and location ”New York” are discriminative features in classifying ”find nice cheap double room in New York Hilton” into correct domain (hotel) and slot (hotel-name) clusters. We represent entity lists corresponding to known domains as multinomial distributions ψ j E, where each ψ","d|j","E is the probability of entity-word wj used in the domain d. Some entities may belong to more than one domain, e.g., ”hotel California” can either be a movie, or song or hotel name. ⋆ Web n-Gram Context Base Measure (ψ","j","G): As explained in §3, we use the web n-grams as ad-ditional information for calculating the base measures of the Dirichlet topic distributions. Normalized word distributions ψ","j","G over domains were used","as weights for domain and dialog act base measure.","⋆ Corpus n-Gram Base Measure (ψ","j","C): Similar to other measures, MCM also encodes n-gram constraints as word-frequency features extracted from labeled utterances. Concretely, we calculate the frequency of vocabulary items given domain-act label pairs from the training labeled utterances and convert there into probability measures over domain-acts. We encode conditional 3 See (Wallach, 2008) Chapter 3 for analysis of hyper-priors","on topic models. probabilities {ψ ad|j C }∈ψ j C as multinomial distribu-","tions of words over domain-act pairs, e.g., ψ","ad|j","C =","P(d=”restaurant”, a=”make-reservation”|”table”).","Base measure update: The α-base measures are","used to shape Dirichlet priors αu⋆","D , αu⋆","A and αu⋆","S . We","update the base measures of each sampled domain","Du = d given each vocabulary wj as: ψ dj D = { ψ d|j E , ψ d|j E > 0 ψ d|j G , otherwise (1) In (1) we assume that entities (E) are more indicative of the domain compared to other n-grams (G) and should be more dominant in sampling decision for domain topics. Given an utterance u, we calculate its base measure ψud","D =(","∑Nu j ψ","dj","D )/Nu.","Once the domain is sampled, we update the prior","weight of dialog acts Aud = a: ψ aj A = ψ ad|j C ∗ ψ d|j G (2)","and slot components Sujd = s: ψ sj S = ψ","d|j","E (3)","Then we update their base measures for a given u as:","ψua","A =(∑Nu","j ψ aj A )/Nu and ψus","S =(","∑Nu j ψ sj S )/Nu. 4.1 Inference and Learning The goal of inference is to predict the domain, user’s act and slot distributions over each segment given an utterance. The MCM has the following set of parameters: domain-topic distributions θd","D for each u, the act-topic distributions θda","A for each domain topic d of u, local slot-topic distributions for each domain θS",", and φs","S for slot-word distributions. Previous work (Asuncion et al., 2009; Wallach et al., 2009) shows that the choice of inference method has negligible effect on the probability of testing documents or inferred topics. Thus, we use Markov Chain Monte Carlo (MCMC) method,specifically Gibbs sampling, to model the posterior distribution PMCM(Du, Aud, Sujd|αu⋆","D , αu⋆","A , αu⋆","S , β) by obtaining samples (Du, Aud, Sujd) drawn from this distribution. For each utterance u, we sample a domain Du and act Aud and hyper-parameters αD and αA and their base measures ψud","D , ψua","A (from Eq. 1,2): θd D =","N d u + αDψud","D Nu + αu⋆","D","; θda A =","Na|ud + αA ψud D","Nud + αu⋆ A (4) The N d","u is the number of occurrences of domain topic d in utterance u, Na|ud is the number of occurrences of act a given d in u. During sampling of a 334 slot state Sujd, we assume that utterance is generated by the HMM model associated with the assigned domain. For each segment wuj in u, we sample a slot state Sujd given the remaining slots and hyper-parameters αS, β and base measure ψus","S (Eq. 3) by:","p(Sujd = s|w, Du, S−(ujd)αu⋆ S , β) ∝ N k ujd + β N k (.) + V β ∗ (N Du,Su(j−1)d s + αSψus","S )∗ N Du,s Su(j+1)d + I(Suj−1, s) + I(Suj+1, s) + αSψus","S N Du,s (.) + I(Suj−1, s) + KDαu⋆","S (5) The N k","ujd is the number of times segment wuj is generated from slot state s in all utterances assigned to domain topic d, N","Du,s1","s2 is the num-","ber of transitions from slot state s1 to s2, where","s1 ∈{Su(j−1)d,Su(j+1)d}, I(s1, s2)=1 if slot s1=s2. 4.2 Semantic Structure Extraction with MCM During Gibbs sampling, we keep track of the frequency of draws of domain, dialog act and slot in-dicating n-grams wj, in MD, MA and MS matrices, respectively. These n-grams are context bearing words (examples are shown in Fig.1.). For given u the predicted domain d∗","u is determined by: d∗ u = arg maxd P̃ (d|u) = arg max","d[θd D ∗","∏Nu j=1 Mjd D MD ]","and predicted dialog act by arg maxa P̃ (a|ud∗","):","a∗","u = arg maxa[θd∗","a","A ∗","∏Nu j=1 Mja A MA ] (6) For each segment wuj in u, its predicted slot are determined by arg maxs P (sj|wuj, d∗",", sj−1): s∗ uj = arg maxs[p(Sujd∗ = s|.) ∗","∏Nu j=1 Zjs S ZS ] (7)"]},{"title":"5 Experiments","paragraphs":["We performed several experiments to evaluate our proposed approach. Before presenting our results, we describe our datasets as well as two baselines. 5.1 Datasets, Labels and Tags Our dataset contains utterances obtained from dialogs between human users and our personal assistant system. We use the transcribed text forms of","Domain Sample Dialog Acts (DAs) & Slots","movie DAs: find-movie/director/actor,buy-ticket Slots: name, mpaa-rating (g-rated), date, director/actor-name, award(oscar winning)...","hotel DAs: find-hotel, book-hotel, Slots: name, room-type(double), amenities, smoking, reward-program(platinum elite)...","restaurant DAs: find-restaurant, make-reservation, Slots: opening-hour, amenities, meal-type,...","event DAs: find-event/ticket/performers, get-info.. Slots: name, type(concert), performer.... Table 2: List of domains, dialog acts and semantic slot tags of utterance segments. Examples for some slots values are presented in parenthesis as italicized. the utterances obtained from (acoustic modeling engine) to train our models 4",". Thus, our dataset contains 18084 NL utterances, 5034 of which are used for measuring the performance of our models. The dataset consists of five domain classes, i.e, movie, restaurant, hotel, event, other, 42 unique dialog acts and 41 slot tags. Each utterance is labeled with a domain, dialog act and a sequence of slot tags corresponding to segments in utterance (see examples in Table 1). Table 2 shows sample dialog act and slot labels. Annotation agreement, Kappa measure (Cohen, 1960), was around 85%.","We pulled a month of web query logs and extracted over 2 million search queries from the movie, hotel, event, and restaurant domains. We also used generic web queries to compile a set of ’other’ domain queries. Our vocabulary consists of n-grams and segments (phrases) in utterances that are extracted using web n-grams and entity lists of §3. We extract distributions of n-grams and entities to inject as prior weights for entity list base (ψ j E) and web n-gram context base measures (ψ j G) (see §4). 5.2 Baselines and Experiment Setup We evaluated two baselines and two variants of our joint SLU approach as follows: ⋆ Sequence-SLU: A traditional approach to SLU extracts domain, dialog act and slots as semantic components of utterances using three sequential models. Typically, domain and dialog act detection models are taken as query classification, where a given NL query is assigned domain and act labels. Among supervised query classification meth-","4","We submitted sample utterances used in our models as ad-ditional resource. Due to licensing issues, we will reveal the full train/test utterances upon acceptance of our paper. 335 movie restaurant movie, theater, ticket, matinee, fandango menu, table, dinner, togo kids-friendly chinese, coffee","D1 D2 find-movieA1 find-reviewA2 reservationA3 check-menuA4 movie-nameS1 actor-nameS2 iron man 2, hugo, muppets descendants rest-nameS3 cuisineS4 Sk tom hanks, angelina jolie, cameron reviews, critics ratings, mpaa, breath-taking scary, ticket iron-man 2, oscar winner kid-friendly reserve, table wait-time menu, list, vine list, check, hotpot nearest, city center, Vancouver, New York amici, zucca new york bagel starbucks chinese, vietnamese, italian, fast food DO M AIN DIAL O G  A CTS location SL O TS domain in-","dependent slots Figure 2: Sample topics discovered by Multi-Layer Context Model (MCM). Given samples of utterances, MCM is able to infer a meaningful set of dialog act (A) and slots (S), falling into broad categories of domain classes (D). ods, we used the Adaboost, utterance classification method that starts from a set of weak classifiers and builds a strong classifier by boosting the weak classifiers. Slot discovery is taken as a sequence labeling task in which segments in utterances are labeled (Li, 2010). For segment labeling we use Semi-Markov Conditional Random Fields (Semi-CRF) (Sarawagi and Cohen, 2004) method as a benchmark in evaluating semantic tagging performance. ⋆ Tri-CRF: We used Triangular Chain CRF (Jeong and Lee, 2008) as our supervised joint model base-line. It is a state-of-the art method that learns the sequence labels and utterance class (domain or dialog act) as meta-sequence in a joint framework. It encodes the inter-dependence between the slot sequence s and meta-sequence label (d or a) using a triangular chain (dual-layer) structure. ⋆ Base-MCM: Our first version injects an informative prior for domain, dialog act and slot topic distributions using information extracted from only labeled training utterances and inject as prior constraints (corpus n-gram base measure ψ j C) during topic assignments. ⋆ WebPrior-MCM: Our full model encodes distributions extracted from labeled training data as well as structured web logs as asymmetric Dirichlet priors. We analyze performance gain by the information from web sources (ψ j G and ψ","j","E) when injected into our approach compared to Base-MCM.","We inject dictionary constraints as features to train supervised discriminative methods, i.e., boosting and Semi-CRF in Sequence-SLU, and Tri-CRF models. For semantic tagging, dictionary constraints apply to the features between individual segments and their labels, and for utterance classification (to predict domain and dialog acts) they apply to the features between utterance and its label. Given a list of dictionaries, these constraints specify which label is more likely. For discriminative methods, we use several named entities, e.g., Movie-Name, Restaurant-Name, Hotel-Name, etc., non-named entities, e.g., Genre, Cuisine, etc., and domain independent dictionaries, e.g., Time, Location, etc.","We train domain and dialog act classifiers via Icsiboost (Favre et al., 2007) with 10K iterations using lexical features (up to 3-n-grams) and constraining dictionary features (all dictionaries). For feature templates of sequence learners, i.e., Semi-CRF and Tri-CRF, we use current word, bi-gram and dictionary features. For Base-MCM and WebPrior-MCM, we run Gibbs sampler for 2000 iterations with the first 500 samples as burn-in. 5.3 Evaluations and Discussions We evaluate the performance of our joint model on two experiments using two metrics. For domain and dialog act detection performance we present results in accuracy, and for slot detection we use the F1 pairwise measure.","Experiment 1. Encoding Prior Knowledge: A common evaluation method in SLU tasks is to measure the performance of each individual semantic model, i.e., domain, dialog act and semantic tagging (slot filling). Here, we not only want to demonstrate the performance of each component of MCM but also their performance under limited amount of labeled data. We randomly select subsets of labeled training data U i","L ⊂ UL with different samples sizes, ni L ={γ ∗ nL}, where nL represents the sample size of UL and γ={10%,25%,..} is the subset percentage. At each random selection, the rest of the utterances are used as unlabeled data to boost the performance of MCM. The supervised baselines do not leverage the unlabeled utterances.","The results reported in Figure 3 reveal both the strengths and some shortcomings of our approach. When the number of labeled data is small (ni","L ≤25%*nL), our WebPrior-MCM has a better performance on domain and act predictions compared to the two baselines. Compared to Sequence-SLU, we observe 4.5% and 3% performance improvement on the domain and dialog act 336 10 25 50 75 100 919293949596 % Labeled Data Accurac y % Utterance Domain Performance 20 40 60 80 100 82838485868788 % Labeled Data Accurac y % Dialog Act Performance 20 40 60 80 100 65 70 75 80 85 % Labeled Data F - Measure Semantic Tag (Slot) Performance Sequence-SLU Tri-CRF Base-MCM WebPrior-MCM Figure 3: Semantic component extraction performance measures for various baselines as well as our approach with different priors. models, whereas our gain is 2.6% and 1.7% over Tri-CRF models. As the percentage of labeled utterances in training data increase, Tri-CRF performance increases, however WebPrior-MCM is still comparable with Sequence-SLU. This is because we utilize domain priors obtained from the web sources as supervision during generative process as well as unlabeled utterances that enable handling language variability. Adding labeled data improves the performance of all models however supervised models benefit more compared toMCM models.","Although WebPrior-MCM’s domain and dialog act performances are comparable (if not better than) the other baselines, it falls short on the semantic tagging model. This is partially due to the HMM assumption compared to the supervised conditional model’s used in the other baselines, i.e., Semi-CRF in Sequence-SLU and Tri-CRF). Our work can be extended by replacing HMM assumption with CRF based sequence learner to enhance the capability of the sequence tagging component of MCM.","Experiment 2. Less is More? Being Bayesian, our model can incorporate unlabeled data at training time. Here, we evaluate the performance gain on domain, act and slot predictions as more unlabeled data is introduced at learning time. We use only 10% of the utterances as labeled data in this experiment and incrementally add unlabeled data (90% of labeled data are treated as unlabeled).","The results are shown in Table 3. n% (n=10,25,..) unlabeled data indicates that the WebPrior-MCM is trained using n% of unlabeled utterances along with training utterances. Adding unlabeled data has a positive impact on the performance of all three se-","Table 3: Performance evaluation results of","WebPrior-MCM using different sizes of unlabeled","utterances at learning time.","Unlabeled Domain Dialog Act Slot % Accuracy Accuracy F-Measure 10% 94.69 84.17 52.61 25% 94.89 84.29 54.22 50% 95.08 84.39 56.58 75% 95.19 84.44 57.45 100% 95.28 84.52 58.18 mantic components when WebPrior-MCM is used. The results show that our joint modeling approach has an advantage over the other joint models (i.e., Tri-CRF) in that it can leverage unlabeled NL utterances. Our approach might be usefully extended into the area of understanding search queries, where an abundance of unlabeled queries is observed."]},{"title":"6 Conclusions","paragraphs":["In this work, we introduced a joint approach to spoken language understanding that integrates two properties (i) identifying user actions in multiple domains in relation to semantic units, (ii) utilizing large amounts of unlabeled web search queries that suggest the user’s hidden intentions. We proposed a semi-supervised generative joint learning approach tailored for injecting prior knowledge to enhance the semantic component extraction from utterances as a unifying framework. Experimental results using the new Bayesian model indicate that we can effectively learn and discover meta-aspects in natural language utterances, outperforming the supervised baselines, especially when there are fewer labeled and more unlabeled utterances. 337"]},{"title":"References","paragraphs":["A. Asuncion, M. Welling, P. Smyth, and Y. W. Teh. 2009. On smoothing and inference for topic models. UAI.","S. Bangalore. 2006. Introduction to special issue of spoken language understanding in conversational systems. In Speech Conversation, volume 48, pages 233–238.","L. Begeja, B. Renger, Z. Liu D. Gibbon, and B. Shahraray. 2004. Interactive machine learning techniques for improving slu models. In Proceedings of the HLT-NAACL 2004 Workshop on Spoken Language Understanding for Conversational Systems and Higher Level Linguistic Information for Speech Processing.","Pauline M. Berry, Melinda Gervasio, Bart Peintner, and Neil Yorke-Smith. 2011. Ptime: Personalized assistance for calendaring. In ACM Transactions on Intelligent Systems and Technology, volume 2, pages 1–40.","D. Blei, A. Ng, and M. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research.","J. Cohen. 1960. A coefficient of agreement for nominal scales. In Educational and Psychological Measure-ment, volume 20, pages 37–46.","H. Daumé-III and D. Marcu. 2006. Bayesian query focused summarization.","M. Dinarelli, A. Moschitti, and G. Riccardi. 2009. Reranking models for spoken language understanding. Proc. European Chapter of the Annual Meeting of the Association of Computational Linguistics (EACL).","B. Favre, D. Hakkani-Tür, and Sebastien Cuendet. 2007. Icsiboost. http://code.google.come/ p/icsiboost.","S. Harabagiu and A. Hickl. 2006. Methods for using textual entailment for question answering. pages 905– 912.","E. Hovy, C.Y. Lin, and L. Zhou. 2005. A be-based multidocument summarizer with query interpretation. Proc. DUC.","M. Jeong and G. G. Lee. 2008. Triangular-chain conditional random fields. EEE Transactions on Audio, Speech and Language Processing (IEEE-TASLP).","X. Li. 2010. Understanding semantic structure of noun phrase queries. Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL).","P. Liang, M. I. Jordan, and D. Klein. 2011. Learning dependency based compositional semantics.","A. Margolis, K. Livescu, and M. Osterdorf. 2010. Domain adaptation with unlabeled data for dialog act tagging. In Proc. Workshop on Domain Adaptation for Natural Language Processing at the the Annual Meeting of the Association of Computational Linguistics (ACL).","D. Mimno, W. Li, and A. McCallum. 2007. Mixtures of hierarchical topics with pachinko allocation. Proc. ICML.","A. Popescu, P. Pantel, and G. Mishne. 2010. Semantic lexicon adaptation for use in query interpretation. 19th World Wide Web Conference (WWW-10).","D. Ramage, D. Hall, R. Nallapati, and C. D. Manning. 2009. Labeled lda: A supervised topic model for credit attribution in multi-labeled corpora. Proc. EMNLP.","J. Reisinger and M. Pasça. 2009. Latent variable models of concept-attribute attachement. Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL).","J. Reisinger and M. Pasca. 2011. Fine-grained class label markup of search queries. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL).","M. Sammons, V. Vydiswaran, and D. Roth. 2010. Ask not what textual entailment can do for you... In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL), Uppsala, Sweden, 7.","S. Sarawagi and W. W. Cohen. 2004. Semimarkov conditional random fields for information extraction. Proc. NIPS.","C. Sauper, A. Haghighi, and R. Barzilay. 2011. Content models with attitude. In Proc. of the Annual Meeting of the Association of Computational Linguistics (ACL).","G. Tur and R. De Mori. 2011. Spoken language understanding: Systems for extracting semantic information from speech. Wiley.","H. Wallach, D. Mimno, and A. McCallum. 2009. Rethinking lda: Why priors matter. NIPS.","H. Wallach. 2008. Structured topic models for language. Ph.D. Thesis, University of Cambridge.","Y.Y. Wang, R. Hoffman, X. Li, and J. Syzmanski. 2009. Semi-supervised learning of semantic classes for query understanding from the web and for the web. In The 18th ACM Conference on Information and Knowledge Management.","Y-Y. Wang. 2010. Strategies for statistical spoken language understanding with small amount of data - an emprical study. Proc. Interspeech 2010. 338"]}],"references":[{"authors":[{"first":"A.","last":"Asuncion"},{"first":"M.","last":"Welling"},{"first":"P.","last":"Smyth"},{"first":"Y.","middle":"W.","last":"Teh"}],"year":"2009","title":"On smoothing and inference for topic models"},{"authors":[{"first":"S.","last":"Bangalore"}],"year":"2006","title":"Introduction to special issue of spoken language understanding in conversational systems"},{"authors":[{"first":"L.","last":"Begeja"},{"first":"B.","last":"Renger"},{"first":"Z.","middle":"Liu D.","last":"Gibbon"},{"first":"B.","last":"Shahraray"}],"year":"2004","title":"Interactive machine learning techniques for improving slu models"},{"authors":[{"first":"Pauline","middle":"M.","last":"Berry"},{"first":"Melinda","last":"Gervasio"},{"first":"Bart","last":"Peintner"},{"first":"Neil","last":"Yorke-Smith"}],"year":"2011","title":"Ptime: Personalized assistance for calendaring"},{"authors":[{"first":"D.","last":"Blei"},{"first":"A.","last":"Ng"},{"first":"M.","last":"Jordan"}],"year":"2003","title":"Latent dirichlet allocation"},{"authors":[{"first":"J.","last":"Cohen"}],"year":"1960","title":"A coefficient of agreement for nominal scales"},{"authors":[{"first":"H.","last":"Daumé-III"},{"first":"D.","last":"Marcu"}],"year":"2006","title":"Bayesian query focused summarization"},{"authors":[{"first":"M.","last":"Dinarelli"},{"first":"A.","last":"Moschitti"},{"first":"G.","last":"Riccardi"}],"year":"2009","title":"Reranking models for spoken language understanding"},{"authors":[{"first":"B.","last":"Favre"},{"first":"D.","last":"Hakkani-Tür"},{"first":"Sebastien","last":"Cuendet"}],"year":"2007","title":"Icsiboost"},{"authors":[{"first":"S.","last":"Harabagiu"},{"first":"A.","last":"Hickl"}],"year":"2006","title":"Methods for using textual entailment for question answering"},{"authors":[{"first":"E.","last":"Hovy"},{"first":"C.","middle":"Y.","last":"Lin"},{"first":"L.","last":"Zhou"}],"year":"2005","title":"A be-based multidocument summarizer with query interpretation"},{"authors":[{"first":"M.","last":"Jeong"},{"first":"G.","middle":"G.","last":"Lee"}],"year":"2008","title":"Triangular-chain conditional random fields"},{"authors":[{"first":"X.","last":"Li"}],"year":"2010","title":"Understanding semantic structure of noun phrase queries"},{"authors":[{"first":"P.","last":"Liang"},{"first":"M.","middle":"I.","last":"Jordan"},{"first":"D.","last":"Klein"}],"year":"2011","title":"Learning dependency based compositional semantics"},{"authors":[{"first":"A.","last":"Margolis"},{"first":"K.","last":"Livescu"},{"first":"M.","last":"Osterdorf"}],"year":"2010","title":"Domain adaptation with unlabeled data for dialog act tagging"},{"authors":[{"first":"D.","last":"Mimno"},{"first":"W.","last":"Li"},{"first":"A.","last":"McCallum"}],"year":"2007","title":"Mixtures of hierarchical topics with pachinko allocation"},{"authors":[{"first":"A.","last":"Popescu"},{"first":"P.","last":"Pantel"},{"first":"G.","last":"Mishne"}],"year":"2010","title":"Semantic lexicon adaptation for use in query interpretation"},{"authors":[{"first":"D.","last":"Ramage"},{"first":"D.","last":"Hall"},{"first":"R.","last":"Nallapati"},{"first":"C.","middle":"D.","last":"Manning"}],"year":"2009","title":"Labeled lda: A supervised topic model for credit attribution in multi-labeled corpora"},{"authors":[{"first":"J.","last":"Reisinger"},{"first":"M.","last":"Pasça"}],"year":"2009","title":"Latent variable models of concept-attribute attachement"},{"authors":[{"first":"J.","last":"Reisinger"},{"first":"M.","last":"Pasca"}],"year":"2011","title":"Fine-grained class label markup of search queries"},{"authors":[{"first":"M.","last":"Sammons"},{"first":"V.","last":"Vydiswaran"},{"first":"D.","last":"Roth"}],"year":"2010","title":"Ask not what textual entailment can do for you"},{"authors":[{"first":"S.","last":"Sarawagi"},{"first":"W.","middle":"W.","last":"Cohen"}],"year":"2004","title":"Semimarkov conditional random fields for information extraction"},{"authors":[{"first":"C.","last":"Sauper"},{"first":"A.","last":"Haghighi"},{"first":"R.","last":"Barzilay"}],"year":"2011","title":"Content models with attitude"},{"authors":[{"first":"G.","last":"Tur"},{"first":"R.","last":"De Mori"}],"year":"2011","title":"Spoken language understanding: Systems for extracting semantic information from speech"},{"authors":[{"first":"H.","last":"Wallach"},{"first":"D.","last":"Mimno"},{"first":"A.","last":"McCallum"}],"year":"2009","title":"Rethinking lda: Why priors matter"},{"authors":[{"first":"H.","last":"Wallach"}],"year":"2008","title":"Structured topic models for language"},{"authors":[{"first":"Y.","middle":"Y.","last":"Wang"},{"first":"R.","last":"Hoffman"},{"first":"X.","last":"Li"},{"first":"J.","last":"Syzmanski"}],"year":"2009","title":"Semi-supervised learning of semantic classes for query understanding from the web and for the web"},{"authors":[{"first":"Y-Y.","last":"Wang"}],"year":"2010","title":"Strategies for statistical spoken language understanding with small amount of data - an emprical study"}],"cites":[{"authors":[{"last":"Bangalore"}],"year":"2006","style":0,"reference":{"authors":[{"first":"S.","last":"Bangalore"}],"year":"2006","title":"Introduction to special issue of spoken language understanding in conversational systems"}},{"authors":[{"last":"Tur"},{"last":"Mori"}],"year":"2011","style":0},{"authors":[{"last":"Begeja"},{"last":"al."}],"year":"2004","style":0,"reference":{"authors":[{"first":"L.","last":"Begeja"},{"first":"B.","last":"Renger"},{"first":"Z.","middle":"Liu D.","last":"Gibbon"},{"first":"B.","last":"Shahraray"}],"year":"2004","title":"Interactive machine learning techniques for improving slu models"}},{"authors":[{"last":"Jeong"},{"last":"Lee"}],"year":"2008","style":0,"reference":{"authors":[{"first":"M.","last":"Jeong"},{"first":"G.","middle":"G.","last":"Lee"}],"year":"2008","title":"Triangular-chain conditional random fields"}},{"authors":[{"last":"Wang"}],"year":"2010","style":0,"reference":{"authors":[{"first":"Y-Y.","last":"Wang"}],"year":"2010","title":"Strategies for statistical spoken language understanding with small amount of data - an emprical study"}},{"authors":[{"last":"Harabagiu"},{"last":"Hickl"}],"year":"2006","style":0,"reference":{"authors":[{"first":"S.","last":"Harabagiu"},{"first":"A.","last":"Hickl"}],"year":"2006","title":"Methods for using textual entailment for question answering"}},{"authors":[{"last":"Liang"},{"last":"al."}],"year":"2011","style":0,"reference":{"authors":[{"first":"P.","last":"Liang"},{"first":"M.","middle":"I.","last":"Jordan"},{"first":"D.","last":"Klein"}],"year":"2011","title":"Learning dependency based compositional semantics"}},{"authors":[{"last":"Sammons"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"M.","last":"Sammons"},{"first":"V.","last":"Vydiswaran"},{"first":"D.","last":"Roth"}],"year":"2010","title":"Ask not what textual entailment can do for you"}},{"authors":[{"last":"Hovy"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"E.","last":"Hovy"},{"first":"C.","middle":"Y.","last":"Lin"},{"first":"L.","last":"Zhou"}],"year":"2005","title":"A be-based multidocument summarizer with query interpretation"}},{"authors":[{"last":"Daumé-III"},{"last":"Marcu"}],"year":"2006","style":0,"reference":{"authors":[{"first":"H.","last":"Daumé-III"},{"first":"D.","last":"Marcu"}],"year":"2006","title":"Bayesian query focused summarization"}},{"authors":[{"last":"Tur"},{"last":"Mori"}],"year":"2011","style":0},{"authors":[{"last":"Dinarelli"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"M.","last":"Dinarelli"},{"first":"A.","last":"Moschitti"},{"first":"G.","last":"Riccardi"}],"year":"2009","title":"Reranking models for spoken language understanding"}},{"authors":[{"last":"Popescu"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"A.","last":"Popescu"},{"first":"P.","last":"Pantel"},{"first":"G.","last":"Mishne"}],"year":"2010","title":"Semantic lexicon adaptation for use in query interpretation"}},{"authors":[{"last":"Li"}],"year":"2010","style":0,"reference":{"authors":[{"first":"X.","last":"Li"}],"year":"2010","title":"Understanding semantic structure of noun phrase queries"}},{"authors":[{"last":"Reisinger"},{"last":"Pasca"}],"year":"2011","style":0,"reference":{"authors":[{"first":"J.","last":"Reisinger"},{"first":"M.","last":"Pasca"}],"year":"2011","title":"Fine-grained class label markup of search queries"}},{"authors":[{"last":"Berry"},{"last":"al."}],"year":"2011","style":0,"reference":{"authors":[{"first":"Pauline","middle":"M.","last":"Berry"},{"first":"Melinda","last":"Gervasio"},{"first":"Bart","last":"Peintner"},{"first":"Neil","last":"Yorke-Smith"}],"year":"2011","title":"Ptime: Personalized assistance for calendaring"}},{"authors":[{"last":"Margolis"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"A.","last":"Margolis"},{"first":"K.","last":"Livescu"},{"first":"M.","last":"Osterdorf"}],"year":"2010","title":"Domain adaptation with unlabeled data for dialog act tagging"}},{"authors":[{"last":"Wang"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"Y.","middle":"Y.","last":"Wang"},{"first":"R.","last":"Hoffman"},{"first":"X.","last":"Li"},{"first":"J.","last":"Syzmanski"}],"year":"2009","title":"Semi-supervised learning of semantic classes for query understanding from the web and for the web"}},{"authors":[{"last":"Li"}],"year":"2010","style":0,"reference":{"authors":[{"first":"X.","last":"Li"}],"year":"2010","title":"Understanding semantic structure of noun phrase queries"}},{"authors":[{"last":"Jeong"},{"last":"Lee"}],"year":"2008","style":0,"reference":{"authors":[{"first":"M.","last":"Jeong"},{"first":"G.","middle":"G.","last":"Lee"}],"year":"2008","title":"Triangular-chain conditional random fields"}},{"authors":[{"last":"Wang"}],"year":"2010","style":0,"reference":{"authors":[{"first":"Y-Y.","last":"Wang"}],"year":"2010","title":"Strategies for statistical spoken language understanding with small amount of data - an emprical study"}},{"authors":[{"last":"Jeong"},{"last":"Lee"}],"year":"2008","style":0,"reference":{"authors":[{"first":"M.","last":"Jeong"},{"first":"G.","middle":"G.","last":"Lee"}],"year":"2008","title":"Triangular-chain conditional random fields"}},{"authors":[{"last":"Mimno"},{"last":"al."}],"year":"2007","style":0,"reference":{"authors":[{"first":"D.","last":"Mimno"},{"first":"W.","last":"Li"},{"first":"A.","last":"McCallum"}],"year":"2007","title":"Mixtures of hierarchical topics with pachinko allocation"}},{"authors":[{"last":"Rosen-Zvi"},{"last":"al."}],"year":"2004","style":0},{"authors":[{"last":"Sauper"},{"last":"al."}],"year":"2011","style":0,"reference":{"authors":[{"first":"C.","last":"Sauper"},{"first":"A.","last":"Haghighi"},{"first":"R.","last":"Barzilay"}],"year":"2011","title":"Content models with attitude"}},{"authors":[{"last":"Blei"},{"last":"al."}],"year":"2003","style":0,"reference":{"authors":[{"first":"D.","last":"Blei"},{"first":"A.","last":"Ng"},{"first":"M.","last":"Jordan"}],"year":"2003","title":"Latent dirichlet allocation"}},{"authors":[{"last":"Mimno"},{"last":"al."}],"year":"2007","style":0,"reference":{"authors":[{"first":"D.","last":"Mimno"},{"first":"W.","last":"Li"},{"first":"A.","last":"McCallum"}],"year":"2007","title":"Mixtures of hierarchical topics with pachinko allocation"}},{"authors":[{"last":"Ramage"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"D.","last":"Ramage"},{"first":"D.","last":"Hall"},{"first":"R.","last":"Nallapati"},{"first":"C.","middle":"D.","last":"Manning"}],"year":"2009","title":"Labeled lda: A supervised topic model for credit attribution in multi-labeled corpora"}},{"authors":[{"last":"Reisinger"},{"last":"Pasça"}],"year":"2009","style":0,"reference":{"authors":[{"first":"J.","last":"Reisinger"},{"first":"M.","last":"Pasça"}],"year":"2009","title":"Latent variable models of concept-attribute attachement"}},{"authors":[{"last":"Wallach"}],"year":"2008","style":0,"reference":{"authors":[{"first":"H.","last":"Wallach"}],"year":"2008","title":"Structured topic models for language"}},{"authors":[{"last":"Asuncion"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"A.","last":"Asuncion"},{"first":"M.","last":"Welling"},{"first":"P.","last":"Smyth"},{"first":"Y.","middle":"W.","last":"Teh"}],"year":"2009","title":"On smoothing and inference for topic models"}},{"authors":[{"last":"Wallach"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"H.","last":"Wallach"},{"first":"D.","last":"Mimno"},{"first":"A.","last":"McCallum"}],"year":"2009","title":"Rethinking lda: Why priors matter"}},{"authors":[{"last":"Cohen"}],"year":"1960","style":0,"reference":{"authors":[{"first":"J.","last":"Cohen"}],"year":"1960","title":"A coefficient of agreement for nominal scales"}},{"authors":[{"last":"Li"}],"year":"2010","style":0,"reference":{"authors":[{"first":"X.","last":"Li"}],"year":"2010","title":"Understanding semantic structure of noun phrase queries"}},{"authors":[{"last":"Sarawagi"},{"last":"Cohen"}],"year":"2004","style":0,"reference":{"authors":[{"first":"S.","last":"Sarawagi"},{"first":"W.","middle":"W.","last":"Cohen"}],"year":"2004","title":"Semimarkov conditional random fields for information extraction"}},{"authors":[{"last":"Jeong"},{"last":"Lee"}],"year":"2008","style":0,"reference":{"authors":[{"first":"M.","last":"Jeong"},{"first":"G.","middle":"G.","last":"Lee"}],"year":"2008","title":"Triangular-chain conditional random fields"}},{"authors":[{"last":"Favre"},{"last":"al."}],"year":"2007","style":0,"reference":{"authors":[{"first":"B.","last":"Favre"},{"first":"D.","last":"Hakkani-Tür"},{"first":"Sebastien","last":"Cuendet"}],"year":"2007","title":"Icsiboost"}}]}
