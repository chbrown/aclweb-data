{"sections":[{"title":"","paragraphs":["Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 104–109, Sofia, Bulgaria, August 4-9 2013. c⃝2013 Association for Computational Linguistics"]},{"title":"Joint Inference for Heterogeneous Dependency Parsing Guangyou Zhou and Jun Zhao National Laboratory of Pattern Recognition Institute of Automation, Chinese Academy of Sciences 95 Zhongguancun East Road, Beijing 100190, China {gyzhou,jzhao}@nlpr.ia.ac.cn Abstract","paragraphs":["This paper is concerned with the problem of heterogeneous dependency parsing. In this paper, we present a novel joint inference scheme, which is able to leverage the consensus information between heterogeneous treebanks in the parsing phase. Different from stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008), which process the dependency parsing in a pipelined way (e.g., a second level uses the first level outputs), in our method, multiple dependency parsing models are coordinated to exchange consensus information. We conduct experiments on Chinese Dependency Treebank (CDT) and Penn Chinese Treebank (CTB), experimental results show that joint inference can bring significant improvements to all state-of-the-art dependency parsers."]},{"title":"1 Introduction","paragraphs":["Dependency parsing is the task of building dependency links between words in a sentence, which has recently gained a wide interest in the natural language processing community and has been used for many problems ranging from machine translation (Ding and Palmer, 2004) to question answering (Zhou et al., 2011a). Over the past few years, supervised learning methods have obtained state-of-the-art performance for dependency parsing (Yamada and Matsumoto, 2003; McDonald et al., 2005; McDonald and Pereira, 2006; Hall et al., 2006; Zhou et al., 2011b; Zhou et al., 2011c). These methods usually rely heavily on the manually annotated treebanks for training the dependency models. However, annotating syntac- (with) (eyes) (cast) (Hongkong) BA NN VV NR (with) (eyes) (cast) (Hongkong) p n v ns Figure 1: Different grammar formalisms of syntactic structures between CTB (upper) and CDT (below). CTB is converted into dependency grammar based on the head rules of (Zhang and Clark, 2008). tic structure, either phrase-based or dependency-based, is both time consuming and labor intensive. Making full use of the existing manually annotated treebanks would yield substantial savings in data-annotation costs.","In this paper, we present a joint inference scheme for heterogenous dependency parsing. This scheme is able to leverage consensus information between heterogenous treebanks during the inference phase instead of using individual output in a pipelined way, such as stacked learning methods (Nivre and McDonald, 2008; Martins et al., 2008). The basic idea is very simple: although heterogenous treebanks have different grammar formalisms, they share some consensus information in dependency structures for the same sentence. For example in Figure 1, the dependency structures actually share some partial agreements for the same sentence, the two words “eyes” and “Hongkong” depend on “cast” in both Chinese Dependency Treebank (CDT) (Liu et al., 2006) and Penn Chinese Treebank (CTB) (Xue et al., 2005). Therefore, we would like to train the dependency parsers on individual heterogenous treebank and jointly parse the same sentences with consensus information exchanged between them.","The remainder of this paper is divided as fol-104 Treebank1 Treebank2","Parser1 Parser2","consensus information exchange Joint inference test data Figure 2: General joint inference scheme of heterogeneous dependency parsing. lows. Section 2 gives a formal description of the joint inference for heterogeneous dependency parsing. In section 3, we present the experimental results. Finally, we conclude with ideas for future research."]},{"title":"2 Our Approach","paragraphs":["The general joint inference scheme of heterogeneous dependency parsing is shown in Figure 2. Here, heterogeneous treebanks refer to two Chinese treebanks: CTB and CDT, therefore we have only two parsers, but the framework is generic enough to integrate more parsers. For easy explanation of the joint inference scheme, we regard a parser without consensus information as a baseline parser, a parser incorporates consensus information called a joint parser. Joint inference provides a framework that accommodates and coordinates multiple dependency parsing models. Similar to Li et al. (2009) and Zhu et al. (2010), the joint inference for heterogeneous dependency parsing consists of four components: (1) Joint Inference Model; (2) Parser Coordination; (3) Joint Inference Features; (4) Parameter Estimation. 2.1 Joint Inference Model For a given sentence x, a joint dependency parsing model finds the best dependency parsing tree y∗ among the set of possible candidate parses Y(x) based on a scoring function Fs:","y∗","= arg max","y∈Y(x) Fs(x, y) (1) Following (Li et al., 2009), we will use dk to denote the kth joint parser, and also use the notation Hk(x) for a list of parse candidates of sentence x determined by dk. The sth joint parser can be written as: Fs(x, y) = Ps(x, y) + ∑ k,k̸=s Ψk(y, Hk(x)) (2) where Ps(x, y) is the score function of the sth baseline model, and each Ψk(y, Hk(x)) is a partial consensus score function with respect to dk and is defined over y and Hk(x): Ψk(y, Hk(x)) = ∑ l λk,lfk,l(y, Hk(x)) (3) where each fk,l(y, Hk(x)) is a feature function based on a consensus measure between y and Hk(x), and λk,l is the corresponding weight parameter. Feature index l ranges over all consensus-based features in equation (3). 2.2 Parser Coordination Note that in equation (2), though the baseline score function Ps(x, y) can be computed individually, the case of Ψk(y, Hk(x)) is more complicated. It is not feasible to enumerate all parse candidates for dependency parsing. In this paper, we use a bootstrapping method to solve this problem. The basic idea is that we can use baseline models’ n-best output as seeds, and iteratively refine joint models’ n-best output with joint inference. The joint inference process is shown in Algorithm 1.","Algorithm 1 Joint inference for multiple parsers Step1: For each joint parser dk, perform inference with a baseline model, and memorize all dependency parsing candidates generated during inference in Hk(x); Step2: For each candidate in Hk(x), we extract subtrees and store them in H′","k(x). First, we extract bigram-subtrees that contain two words. If two words have a dependency relation, we add these two words as a subtree into H′","k(x). Similarly, we can extract trigram-subtrees. Note that the dependency direction is kept. Besides, we also store the “ROOT” word of each candidate in H′","k(x); Step3: Use joint parsers to re-parse the sentence x with the baseline features and joint inference features (see sub-section 2.3). For joint parser dk, consensus-based features of any dependency parsing candidate are computed based on current setting of H′","s(x) for all s but k. New dependency parsing candidates generated by dk in re-parsing are cached in H′′","k(x); Step4: Update all Hk(x) with H′′","k(x); Step5: Iterate from Step2 to Step4 until a preset iteration limit is reached.","In Algorithm 1, dependency parsing candidates of different parsers can be mutually improved. For example, given two parsers d1 and d2 with candidates H1 and H2, improvements on H1 enable d2 to improve H2, and H1 benefits from improved H2, and so on.","We can see that a joint parser does not enlarge the search space of its baseline model, the only change is parse scoring. By running a complete inference process, joint model can be applied to re-parsing all candidates explored by a parser. 105 Thus Step3 can be viewed as full-scale candidates reranking because the reranking scope is beyond the limited n-best output currently cached in Hk. 2.3 Joint Inference Features In this section we introduce the consensus-based feature functions fk,l(y, Hk(x)) introduced in equation (3). The formulation can be written as: fk,l(y, Hk(x)) = ∑ y′ ∈H","k(x)","P (y′ |dk)Il(y, y′",") (4) where y is a dependency parse of x by using parser ds (s ̸= k), y′","is a dependency parse in Hk(x)","and P (y′ |d k) is the posterior probability of depen-","dency parse y′","parsed by parser d","k given sentence x. Il(y, y′",") is a consensus measure defined on y and y′","using different feature functions. Dependency parsing model P (y′","|dk) can be predicted by using the global linear models (GLMs) (e.g., McDonald et al. (2005); McDonald and Pereira (2006)). The consensus-based score functions Il(y, y′",") include the following parts: (1) head-modifier dependencies. Each head-modifier dependency (denoted as “edge”) is a tuple t =< h, m, h → m >, so Iedge(y, y′",") =∑ t∈y δ(t, y′","). (2) sibling dependencies: Each sibling de-","pendency (denoted as “sib”) is a tuple t =<","i, h, m, h ← i → m >, so Isib(y, y′",") =∑ t∈y δ(t, y′","). (3) grandparent dependencies: Each grand-","parent dependency (denoted as “gp”) is a tuple","t =< h, i, m, h → i → m >, so Igp(y, y′",") =∑","<h,i,m,h→i→m>∈y δ(t, y′",").","(4) root feature: This feature (denoted as “root”) indicates whether the multiple dependency parsing trees share the same “ROOT”, so Iroot(y, y′",") = ∑","<ROOT >∈y δ(< ROOT >, y′",").","δ(·, ·) is a indicator function–δ(t, y′",") is 1 if t ∈ y′","and 0 otherwise, feature index l ∈ {edge, sib, gp, root} in equation (4). Note that < h, m, h → m > and < m, h, m → h > are two different edges.","In our joint model, we extend the baseline features of (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007) by conjoining with the consensus-based features, so that we can learn in which kind of contexts the different parsers agree/disagree. For the third-order features (e.g., grand-siblings and tri-siblings) described in (Koo et al., 2010), we will discuss it in future work. 2.4 Parameter Estimation The parameters are tuned to maximize the dependency parsing performance on the development set, using an algorithm similar to the average perceptron algorithm due to its strong performance and fast training (Koo et al., 2008). Due to limited space, we do not present the details. For more information, please refer to (Koo et al., 2008)."]},{"title":"3 Experiments","paragraphs":["In this section, we describe the experiments to evaluate our proposed approach by using CTB4 (Xue et al., 2005) and CDT (Liu et al., 2006). For the former, we adopt a set of headselection rules (Zhang and Clark, 2008) to convert the phrase structure syntax of treebank into a dependency tree representation. The standard data split of CTB4 from Wang et al. (2007) is used. For the latter, we randomly select 2,000 sentences for test set, another 2,000 sentences for development set, and others for training set.","We use two baseline parsers, one trained on CTB4, and another trained on CDT in the experiments. We choose the n-best size of 16 and the best iteration time of four on the development set since these settings empirically give the best performance. CTB4 and CDT use two different POS tag sets and transforming from one tag set to another is difficult (Niu et al., 2009). To over-come this problem, we use Stanford POS Tagger1 to train a universal POS tagger on the People’s Daily corpus,2","a large-scale Chinese corpus (approximately 300 thousand sentences and 7 million words) annotated with word segmentation and POS tags. Then the POS tagger produces a universal layer of POS tags for both the CTB4 and CDT. Note that the word segmentation standards of these corpora (CTB4, CDT and People’s Daily) slightly differs; however, we do not consider this problem and leave it for future research.","The performance of the parsers is evaluated using the following metrics: UAS, DA, and CM, which are defined by (Hall et al., 2006). All the metrics except CM are calculated as mean scores per word, and punctuation tokens are consistently excluded.","We conduct experiments incrementally to evaluate the joint features used in our first-order and second-order parsers. The first-order parser","1","http://nlp.stanford.edu/software/tagger.shtml","2","http://www.icl.pku.edu.cn 106","– Features CTB4 CDT UAS CM UAS CM dep1 baseline 86.6 42.5 75.4 16.6 + edge 88.01 (↑1.41) 44.28 (↑1.78) 77.10 (↑1.70) 17.82 (↑1.22) + root 87.22 (↑0.62) 43.03 (↑0.53) 75.83 (↑0.43) 16.81 (↑0.21) + both 88.19 (↑1.59) 44.54 (↑2.04) 77.16 (↑1.76) 17.90 (↑1.30)","CTB4 + CDT 87.32 43.08 75.91 16.89 dep2 baseline 88.38 48.81 77.52 19.70 + edge 89.17 (↑0.79) 49.73 (↑0.92) 78.44 (↑0.92) 20.85 (↑1.15) + sib 88.94 (↑0.56) 49.26 (↑0.45) 78.02 (↑0.50) 20.13 (↑0.43) + gp 88.90 (↑0.52) 49.11 (↑0.30) 77.97 (↑0.45) 20.06 (↑0.36) + root 88.61 (↑0.23) 48.88 (↑0.07) 77.65 (↑0.13) 19.88 (↑0.18) + all 89.62 (↑1.24) 50.15 (↑1.34) 79.01 (↑1.49) 21.11 (↑1.41)","CTB4 + CDT 88.91 49.13 78.03 20.12 Table 1: Dependency parsing results on the test set with different joint inference features. Abbreviations: dep1/dep2 = first-order parser and second-order parser; baseline = dep1 without considering any joint inference features; +* = the baseline features conjoined with the joint inference features derived from the heterogeneous treebanks; CTB4 + CDT = we simply concatenate the two corpora and train a dependency parser, and then test on CTB4 and CDT using this single model. Improvements of joint models over baseline models are shown in parentheses. Type Systems ≤ 40 Full D","dep2 90.86 88.38 MaltParser 87.1 85.8","Wang et al. (2007) 86.6 - C","MSTMalt† 90.55 88.82 Martins et al. (2008)† 90.63 88.84 Surdeanu et al. (2010)† 89.40 86.63","H Zhao et al. (2009) 88.9 86.1","Ours 91.48 89.62","S Yu et al. (2008) - 87.26 Chen et al. (2009) 92.34 89.91 Chen et al. (2012) - 91.59 Table 2: Comparison of different approach on CTB4 test set using UAS metric. MaltParser = Hall et al. (2006); MSTMalt=Nivre and McDonald (2008). Type D = discriminative dependency parsers without using any external resources; C = combined parsers (stacked and ensemble parsers); H = discriminative dependency parsers using external resources derived from heterogeneous treebanks, S = discriminative dependency parsers using external unlabeled data. † The results on CTB4 were not directly reported in these papers, we implemented the experiments in this paper. (dep1) only incorporates head-modifier dependency part (McDonald et al., 2005). The second-order parser (dep2) uses the head-modifier and sibling dependency parts (McDonald and Pereira, 2006), as well as the grandparent dependency part (Carreras, 2007; Koo et al., 2008). Table 1 shows the experimental results.","As shown in Table 1, we note that adding more joint inference features incrementally, the dependency parsing performance is improved consistently, for both treebanks (CTB4 or CDT). As a final note, all comparisons between joint models and baseline models in Table 1 are statistically significant.3","Furthermore, we also present a baseline method called “CTB4 + CDT” for comparison. This method first tags both CTB4 and CDT with the universal POS tagger trained on the People’s Daily corpus, then simply concatenates the two corpora and trains a dependency parser, and finally tests on CTB4 and CDT using this single model. The comparisons in Table 1 tell us that very limited information is obtained without consensus features by simply taking a union of the dependencies and their contexts from the two treebanks.","To put our results in perspective, we also compare our second-order joint parser with other best-performing systems. “≤ 40” refers to the sentence with the length up to 40 and “Full” refers to all the sentences in test set. The results are shown in Table 2, our approach significantly outperforms many systems evaluated on this data set. Chen et al. (2009) and Chen et al. (2012) reported a very high accuracy using subtree-based features and dependency language model based features derived from large-scale data. Our systems did not use such knowledge. Moreover, their technique is orthogonal to ours, and we suspect that combin-ing their subtree-based features into our systems might get an even better performance. We do not present the comparison of our proposed approach 3 We use the sign test at the sentence level. All the com-","parisons are significant at p < 0.05. 107 Type Systems UAS DA D","Duan et al. (2007) 83.88 84.36 Huang and Sagae (2010) 85.20 85.52 Zhang and Nivre (2011) 86.0 -","C Zhang and Clark (2008) - 86.21 Bohnet and Kuhn (2012) 87.5 -","H Li et al. (2012) 86.44 -","Ours 85.88 86.52","S Chen et al. (2009) - 86.70 Table 3: Comparison of different approaches on CTB5 test set. Abbreviations D, C, H and S are as in Table 2. Treebanks #Sen # Better # NoChange # Worse CTB4 355 74 255 26 CDT 2,000 341 1,562 97 Table 4: Statistics on joint inference output on CTB4 and CDT development set. with the state-of-the-art methods on CDT because there is little work conducted on this treebank.","Some researchers conducted experiments on CTB5 with a different data split: files 1-815 and files 1,001-1,136 for training, files 886-931 and 1,148-1,151 for development, files 816-885 and files 1,137-1,147 for testing. The development and testing sets were also performed using goldstandard assigned POS tags. We report the experimental results on CTB5 test set in Table 4. Our results are better than most systems on this data split, except Zhang and Nivre (2011), Li et al. (2012) and Chen et al. (2009). 3.1 Additional Results To obtain further information about how dependency parsers benefit from the joint inference, we conduct an initial experiment on CTB4 and CDT. From Table 4, we find that out of 355 sentences on the development set of CTB4, 74 sentences benefit from the joint inference, while 26 sentences suffer from it. For CDT, we also find that out of 2,000 sentences on the development set, 341 sentences benefit from the joint inference, while 97 sentences suffer from it. Although the overall dependency parsing results is improved, joint inference worsens dependency parsing result for some sentences. In order to obtain further information about the error sources, it is necessary to investigate why joint inference gives negative results, we will leave it for future work."]},{"title":"4 Conclusion and Future Work","paragraphs":["We proposed a novel framework of joint inference, in which multiple dependency parsing models were coordinated to search for better dependency parses by leveraging the consensus information between heterogeneous treebanks. Experimental results showed that joint inference significantly outperformed the state-of-the-art baseline models.","There are some ways in which this research could be continued. First, recall that the joint inference scheme involves an iterative algorithm by using bootstrapping. Intuitively, there is a lack of formal guarantee. A natural avenue for further research would be the use of more powerful algorithms that provide certificates of optimality; e.g., dual decomposition that aims to develop decod-ing algorithms with formal guarantees (Rush et al., 2010). Second, we would like to combine our heterogeneous treebank annotations into a unified representation in order to make dependency parsing results comparable across different annotation guidelines (e.g., Tsarfaty et al. (2011))."]},{"title":"Acknowledgments","paragraphs":["This work was supported by the National Natural Science Foundation of China (No. 61070106, No. 61272332 and No. 61202329), the National High Technology Development 863 Program of China (No. 2012AA011102), the National Basic Re-search Program of China (No. 2012CB316300), We thank the anonymous reviewers and the prior reviewers of ACL-2012 and AAAI-2013 for their insightful comments. We also thank Dr. Li Cai for providing and preprocessing the data set used in this paper."]},{"title":"References","paragraphs":["B. Bohnet and J. Kuhn. 2012. The best of both worlds-a graph-based completion model for transition-based parsers. In Proceedings of EACL.","X. Carreras. 2007. Experiments with a Higher-order Projective Dependency Parser. In Proceedings of EMNLP-CoNLL, pages 957-961.","W. Chen, D. Kawahara, K. Uchimoto, and Torisawa. 2009. Improving Dependency Parsing with Subtrees from Auto-Parsed Data. In Proceedings of EMNLP, pages 570-579.","W. Chen, M. Zhang, and H. Li. 2012. Utilizing dependency language models for graph-based dependency parsing models. In Proceedings of ACL.","Y. Ding and M. Palmer. 2004. Synchronous dependency insertion grammars: a grammar formalism for syntax based statistical MT. In Proceedings of 108 the Workshop on Recent Advances in Dependency Grammar, pages 90-97.","X. Duan, J. Zhao, and B. Xu. 2007. Probabilistic Models for Action-based Chinese Dependency Parsing. In Proceedings of ECML/PKDD.","J. M. Eisner. 2000. Bilexical Grammars and Their Cubic-Time Parsing Algorithm. Advanced in Probabilistic and Other Parsing Technologies, pages 29-62.","J. Hall, J. Nivre, and J. Nilsson. 2006. Discriminative Classifier for Deterministic Dependency Parsing. In Proceedings of ACL, pages 316-323.","L. Huang and K. Sagae. 2010. Dynamic Programming for Linear-Time Incremental Parsing. In Proceedings of ACL, pages 1077-1086.","T. Koo, X. Carreras, and M. Collins. 2008. Simple Semi-Supervised Dependency Parsing. In Proceedings of ACL.","T. Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Sontag. 2010. Dual Decomposition for Parsing with Non-Projective Head Automata. In Proceedings of EMNLP.","M. Li, N. Duan, D. Zhang, C.-H. Li, and M. Zhou. 2009. Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus Between Decoders. In Proceedings of ACL, pages 585-592.","Z. Li, T. Liu, and W. Che. 2012. Exploiting multiple treebanks for parsing with Quasi-synchronous grammars. In Proceedings of ACL.","T. Liu, J. Ma, and S. Li. 2006. Building a Dependency Treebank for Improving Chinese Parser. Journal of Chinese Languages and Computing, 16(4):207-224.","A. F. T. Martins, D. Das, N. A. Smith, and E. P. Xing. 2008. Stacking Dependency Parsers. In Proceedings of EMNLP, pages 157-166.","R. McDonald and F. Pereira. 2006. Online Learning of Approximate Dependency Parsing Algorithms. In Proceedings of EACL, pages 81-88.","R. McDonald, K. Crammer, and F. Pereira. 2005. Online Large-margin Training of Dependency Parsers. In Proceedings of ACL, pages 91-98.","Z. Niu, H. Wang, and H. Wu. 2009. Exploiting Heterogeneous Treebanks for Parsing. In Proceedings of ACL, pages 46-54.","J. Nivre and R. McDonld. 2008. Integrating Graph-based and Transition-based Dependency Parsing. In Proceedings of ACL, pages 950-958.","A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola. 2010. On Dual Decomposition and Linear Programming Relation for Natural Language Processing. In Proceedings of EMNLP.","M. Surdeanu and C. D. Manning. 2010. Ensemble Models for Dependency Parsing: Cheap and Good? In Proceedings of NAACL.","R. Tsarfaty, J. Nivre, and E. Andersson. 2011. Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation. In Proceedings of EMNLP.","J.-N Wang, J-.S. Chang, and K.-Y. Su. 1994. An Automatic Treebank Conversion Algorithm for Corpus Sharing. In Proceedings of ACL, pages 248-254.","Q. I. Wang, D. Lin, and D. Schuurmans. 2007. Simple Training of Dependency Parsers via Structured Boosting. In Proceedings of IJCAI, pages 1756-1762.","N. Xue, F. Xia, F.-D. Chiou, and M. Palmer. 2005. The Penn Chinese Treebank: Phrase Structure An-notation of a Large Corpus. Natural Language Engineering, 10(4):1-30.","Yamada and Matsumoto. 2003. Statistical Sependency Analysis with Support Vector Machines. In Proceedings of IWPT, pages 195-206.","D. H. Younger. 1967. Recognition and Parsing of Context-Free Languages in Time n3",". Information and Control, 12(4):361-379, 1967.","K. Yu, D. Kawahara, and S. Kurohashi. 2008. Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures. In Proceedings of COLING, pages 1049-1056.","Y. Zhang and S. Clark. 2008. A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search. In Proceedings of EMNLP, pages 562-571.","Y. Zhang and J. Nivre. 2011. Transition-based Dependency Parsing with Rich Non-local Features. In Proceedings of ACL, pages 188-193.","H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross Language Dependency Parsing Using a Bilingual Lexicon. In Proceedings of ACL, pages 55-63.","G. Zhou, L. Cai, J. Zhao, and K. Liu. 2011. Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives. In Proceedings of ACL, pages 653-662.","G. Zhou, J. Zhao, K. Liu, and L. Cai. 2011. Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing. In Proceedings of ACL, pages 1556-1565.","G. Zhou, L. Cai, K. Liu, and J. Zhao. 2011. Improving Dependency Parsing with Fined-Grained Features. In Proceedings of IJCNLP, pages 228-236.","M. Zhu, J. Zhu, and T. Xiao. 2010. Heterogeneous Parsing via Collaborative Decoding. In Proceedings of COLING, pages 1344-1352. 109"]}],"references":[{"authors":[{"first":"B.","last":"Bohnet"},{"first":"J.","last":"Kuhn"}],"year":"2012","title":"The best of both worlds-a graph-based completion model for transition-based parsers"},{"authors":[{"first":"X.","last":"Carreras"}],"year":"2007","title":"Experiments with a Higher-order Projective Dependency Parser"},{"authors":[{"first":"W.","last":"Chen"},{"first":"D.","last":"Kawahara"},{"first":"K.","last":"Uchimoto"},{"last":"Torisawa"}],"year":"2009","title":"Improving Dependency Parsing with Subtrees from Auto-Parsed Data"},{"authors":[{"first":"W.","last":"Chen"},{"first":"M.","last":"Zhang"},{"first":"H.","last":"Li"}],"year":"2012","title":"Utilizing dependency language models for graph-based dependency parsing models"},{"authors":[{"first":"Y.","last":"Ding"},{"first":"M.","last":"Palmer"}],"year":"2004","title":"Synchronous dependency insertion grammars: a grammar formalism for syntax based statistical MT"},{"authors":[{"first":"X.","last":"Duan"},{"first":"J.","last":"Zhao"},{"first":"B.","last":"Xu"}],"year":"2007","title":"Probabilistic Models for Action-based Chinese Dependency Parsing"},{"authors":[{"first":"J.","middle":"M.","last":"Eisner"}],"year":"2000","title":"Bilexical Grammars and Their Cubic-Time Parsing Algorithm"},{"authors":[{"first":"J.","last":"Hall"},{"first":"J.","last":"Nivre"},{"first":"J.","last":"Nilsson"}],"year":"2006","title":"Discriminative Classifier for Deterministic Dependency Parsing"},{"authors":[{"first":"L.","last":"Huang"},{"first":"K.","last":"Sagae"}],"year":"2010","title":"Dynamic Programming for Linear-Time Incremental Parsing"},{"authors":[{"first":"T.","last":"Koo"},{"first":"X.","last":"Carreras"},{"first":"M.","last":"Collins"}],"year":"2008","title":"Simple Semi-Supervised Dependency Parsing"},{"authors":[{"first":"T.","last":"Koo"},{"first":"A.","middle":"M.","last":"Rush"},{"first":"M.","last":"Collins"},{"first":"T.","last":"Jaakkola"},{"first":"D.","last":"Sontag"}],"year":"2010","title":"Dual Decomposition for Parsing with Non-Projective Head Automata"},{"authors":[{"first":"M.","last":"Li"},{"first":"N.","last":"Duan"},{"first":"D.","last":"Zhang"},{"first":"C.","middle":"-H.","last":"Li"},{"first":"M.","last":"Zhou"}],"year":"2009","title":"Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus Between Decoders"},{"authors":[{"first":"Z.","last":"Li"},{"first":"T.","last":"Liu"},{"first":"W.","last":"Che"}],"year":"2012","title":"Exploiting multiple treebanks for parsing with Quasi-synchronous grammars"},{"authors":[{"first":"T.","last":"Liu"},{"first":"J.","last":"Ma"},{"first":"S.","last":"Li"}],"year":"2006","title":"Building a Dependency Treebank for Improving Chinese Parser"},{"authors":[{"first":"A.","middle":"F. T.","last":"Martins"},{"first":"D.","last":"Das"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"E.","middle":"P.","last":"Xing"}],"year":"2008","title":"Stacking Dependency Parsers"},{"authors":[{"first":"R.","last":"McDonald"},{"first":"F.","last":"Pereira"}],"year":"2006","title":"Online Learning of Approximate Dependency Parsing Algorithms"},{"authors":[{"first":"R.","last":"McDonald"},{"first":"K.","last":"Crammer"},{"first":"F.","last":"Pereira"}],"year":"2005","title":"Online Large-margin Training of Dependency Parsers"},{"authors":[{"first":"Z.","last":"Niu"},{"first":"H.","last":"Wang"},{"first":"H.","last":"Wu"}],"year":"2009","title":"Exploiting Heterogeneous Treebanks for Parsing"},{"authors":[{"first":"J.","last":"Nivre"},{"first":"R.","last":"McDonld"}],"year":"2008","title":"Integrating Graph-based and Transition-based Dependency Parsing"},{"authors":[{"first":"A.","middle":"M.","last":"Rush"},{"first":"D.","last":"Sontag"},{"first":"M.","last":"Collins"},{"first":"T.","last":"Jaakkola"}],"year":"2010","title":"On Dual Decomposition and Linear Programming Relation for Natural Language Processing"},{"authors":[{"first":"M.","last":"Surdeanu"},{"first":"C.","middle":"D.","last":"Manning"}],"year":"2010","title":"Ensemble Models for Dependency Parsing: Cheap and Good? In Proceedings of NAACL"},{"authors":[{"first":"R.","last":"Tsarfaty"},{"first":"J.","last":"Nivre"},{"first":"E.","last":"Andersson"}],"year":"2011","title":"Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation"},{"authors":[{"first":"J.","middle":"-N","last":"Wang"},{"first":"J-.S.","last":"Chang"},{"first":"K.","middle":"-Y.","last":"Su"}],"year":"1994","title":"An Automatic Treebank Conversion Algorithm for Corpus Sharing"},{"authors":[{"first":"Q.","middle":"I.","last":"Wang"},{"first":"D.","last":"Lin"},{"first":"D.","last":"Schuurmans"}],"year":"2007","title":"Simple Training of Dependency Parsers via Structured Boosting"},{"authors":[{"first":"N.","last":"Xue"},{"first":"F.","last":"Xia"},{"first":"F.","middle":"-D.","last":"Chiou"},{"first":"M.","last":"Palmer"}],"year":"2005","title":"The Penn Chinese Treebank: Phrase Structure An-notation of a Large Corpus"},{"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","title":"Statistical Sependency Analysis with Support Vector Machines"},{"authors":[]},{"authors":[]},{"authors":[{"first":"K.","last":"Yu"},{"first":"D.","last":"Kawahara"},{"first":"S.","last":"Kurohashi"}],"year":"2008","title":"Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures"},{"authors":[{"first":"Y.","last":"Zhang"},{"first":"S.","last":"Clark"}],"year":"2008","title":"A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search"},{"authors":[{"first":"Y.","last":"Zhang"},{"first":"J.","last":"Nivre"}],"year":"2011","title":"Transition-based Dependency Parsing with Rich Non-local Features"},{"authors":[{"first":"H.","last":"Zhao"},{"first":"Y.","last":"Song"},{"first":"C.","last":"Kit"},{"first":"G.","last":"Zhou"}],"year":"2009","title":"Cross Language Dependency Parsing Using a Bilingual Lexicon"},{"authors":[{"first":"G.","last":"Zhou"},{"first":"L.","last":"Cai"},{"first":"J.","last":"Zhao"},{"first":"K.","last":"Liu"}],"year":"2011","title":"Phrase-Based Translation Model for Question Retrieval in Community Question Answer Archives"},{"authors":[{"first":"G.","last":"Zhou"},{"first":"J.","last":"Zhao"},{"first":"K.","last":"Liu"},{"first":"L.","last":"Cai"}],"year":"2011","title":"Exploiting Web-Derived Selectional Preference to Improve Statistical Dependency Parsing"},{"authors":[{"first":"G.","last":"Zhou"},{"first":"L.","last":"Cai"},{"first":"K.","last":"Liu"},{"first":"J.","last":"Zhao"}],"year":"2011","title":"Improving Dependency Parsing with Fined-Grained Features"},{"authors":[{"first":"M.","last":"Zhu"},{"first":"J.","last":"Zhu"},{"first":"T.","last":"Xiao"}],"year":"2010","title":"Heterogeneous Parsing via Collaborative Decoding"}],"cites":[{"authors":[{"last":"Nivre"},{"last":"McDonald"}],"year":"2008","style":0},{"authors":[{"last":"Martins"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"A.","middle":"F. T.","last":"Martins"},{"first":"D.","last":"Das"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"E.","middle":"P.","last":"Xing"}],"year":"2008","title":"Stacking Dependency Parsers"}},{"authors":[{"last":"Ding"},{"last":"Palmer"}],"year":"2004","style":0,"reference":{"authors":[{"first":"Y.","last":"Ding"},{"first":"M.","last":"Palmer"}],"year":"2004","title":"Synchronous dependency insertion grammars: a grammar formalism for syntax based statistical MT"}},{"authors":[{"last":"Zhou"},{"last":"al."}],"year":"2011a","style":0},{"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","style":0,"reference":{"authors":[{"last":"Yamada"},{"last":"Matsumoto"}],"year":"2003","title":"Statistical Sependency Analysis with Support Vector Machines"}},{"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"K.","last":"Crammer"},{"first":"F.","last":"Pereira"}],"year":"2005","title":"Online Large-margin Training of Dependency Parsers"}},{"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"F.","last":"Pereira"}],"year":"2006","title":"Online Learning of Approximate Dependency Parsing Algorithms"}},{"authors":[{"last":"Hall"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"J.","last":"Hall"},{"first":"J.","last":"Nivre"},{"first":"J.","last":"Nilsson"}],"year":"2006","title":"Discriminative Classifier for Deterministic Dependency Parsing"}},{"authors":[{"last":"Zhou"},{"last":"al."}],"year":"2011b","style":0},{"authors":[{"last":"Zhou"},{"last":"al."}],"year":"2011c","style":0},{"authors":[{"last":"Zhang"},{"last":"Clark"}],"year":"2008","style":0,"reference":{"authors":[{"first":"Y.","last":"Zhang"},{"first":"S.","last":"Clark"}],"year":"2008","title":"A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search"}},{"authors":[{"last":"Nivre"},{"last":"McDonald"}],"year":"2008","style":0},{"authors":[{"last":"Martins"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"A.","middle":"F. T.","last":"Martins"},{"first":"D.","last":"Das"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"E.","middle":"P.","last":"Xing"}],"year":"2008","title":"Stacking Dependency Parsers"}},{"authors":[{"last":"Liu"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"T.","last":"Liu"},{"first":"J.","last":"Ma"},{"first":"S.","last":"Li"}],"year":"2006","title":"Building a Dependency Treebank for Improving Chinese Parser"}},{"authors":[{"last":"Xue"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"N.","last":"Xue"},{"first":"F.","last":"Xia"},{"first":"F.","middle":"-D.","last":"Chiou"},{"first":"M.","last":"Palmer"}],"year":"2005","title":"The Penn Chinese Treebank: Phrase Structure An-notation of a Large Corpus"}},{"authors":[{"last":"Li"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"M.","last":"Li"},{"first":"N.","last":"Duan"},{"first":"D.","last":"Zhang"},{"first":"C.","middle":"-H.","last":"Li"},{"first":"M.","last":"Zhou"}],"year":"2009","title":"Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus Between Decoders"}},{"authors":[{"last":"Zhu"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"M.","last":"Zhu"},{"first":"J.","last":"Zhu"},{"first":"T.","last":"Xiao"}],"year":"2010","title":"Heterogeneous Parsing via Collaborative Decoding"}},{"authors":[{"last":"Li"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"M.","last":"Li"},{"first":"N.","last":"Duan"},{"first":"D.","last":"Zhang"},{"first":"C.","middle":"-H.","last":"Li"},{"first":"M.","last":"Zhou"}],"year":"2009","title":"Collaborative Decoding: Partial Hypothesis Re-ranking Using Translation Consensus Between Decoders"}},{"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"K.","last":"Crammer"},{"first":"F.","last":"Pereira"}],"year":"2005","title":"Online Large-margin Training of Dependency Parsers"}},{"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"F.","last":"Pereira"}],"year":"2006","title":"Online Learning of Approximate Dependency Parsing Algorithms"}},{"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"K.","last":"Crammer"},{"first":"F.","last":"Pereira"}],"year":"2005","title":"Online Large-margin Training of Dependency Parsers"}},{"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"F.","last":"Pereira"}],"year":"2006","title":"Online Learning of Approximate Dependency Parsing Algorithms"}},{"authors":[{"last":"Carreras"}],"year":"2007","style":0,"reference":{"authors":[{"first":"X.","last":"Carreras"}],"year":"2007","title":"Experiments with a Higher-order Projective Dependency Parser"}},{"authors":[{"last":"Koo"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"T.","last":"Koo"},{"first":"A.","middle":"M.","last":"Rush"},{"first":"M.","last":"Collins"},{"first":"T.","last":"Jaakkola"},{"first":"D.","last":"Sontag"}],"year":"2010","title":"Dual Decomposition for Parsing with Non-Projective Head Automata"}},{"authors":[{"last":"Koo"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"T.","last":"Koo"},{"first":"X.","last":"Carreras"},{"first":"M.","last":"Collins"}],"year":"2008","title":"Simple Semi-Supervised Dependency Parsing"}},{"authors":[{"last":"Koo"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"T.","last":"Koo"},{"first":"X.","last":"Carreras"},{"first":"M.","last":"Collins"}],"year":"2008","title":"Simple Semi-Supervised Dependency Parsing"}},{"authors":[{"last":"Xue"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"N.","last":"Xue"},{"first":"F.","last":"Xia"},{"first":"F.","middle":"-D.","last":"Chiou"},{"first":"M.","last":"Palmer"}],"year":"2005","title":"The Penn Chinese Treebank: Phrase Structure An-notation of a Large Corpus"}},{"authors":[{"last":"Liu"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"T.","last":"Liu"},{"first":"J.","last":"Ma"},{"first":"S.","last":"Li"}],"year":"2006","title":"Building a Dependency Treebank for Improving Chinese Parser"}},{"authors":[{"last":"Zhang"},{"last":"Clark"}],"year":"2008","style":0,"reference":{"authors":[{"first":"Y.","last":"Zhang"},{"first":"S.","last":"Clark"}],"year":"2008","title":"A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search"}},{"authors":[{"last":"Wang"},{"last":"al."}],"year":"2007","style":0,"reference":{"authors":[{"first":"Q.","middle":"I.","last":"Wang"},{"first":"D.","last":"Lin"},{"first":"D.","last":"Schuurmans"}],"year":"2007","title":"Simple Training of Dependency Parsers via Structured Boosting"}},{"authors":[{"last":"Niu"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"Z.","last":"Niu"},{"first":"H.","last":"Wang"},{"first":"H.","last":"Wu"}],"year":"2009","title":"Exploiting Heterogeneous Treebanks for Parsing"}},{"authors":[{"last":"Hall"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"J.","last":"Hall"},{"first":"J.","last":"Nivre"},{"first":"J.","last":"Nilsson"}],"year":"2006","title":"Discriminative Classifier for Deterministic Dependency Parsing"}},{"authors":[{"last":"Wang"},{"last":"al."}],"year":"2007","style":0,"reference":{"authors":[{"first":"Q.","middle":"I.","last":"Wang"},{"first":"D.","last":"Lin"},{"first":"D.","last":"Schuurmans"}],"year":"2007","title":"Simple Training of Dependency Parsers via Structured Boosting"}},{"authors":[{"last":"Martins"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"A.","middle":"F. T.","last":"Martins"},{"first":"D.","last":"Das"},{"first":"N.","middle":"A.","last":"Smith"},{"first":"E.","middle":"P.","last":"Xing"}],"year":"2008","title":"Stacking Dependency Parsers"}},{"authors":[{"last":"Surdeanu"},{"last":"al."}],"year":"2010","style":0},{"authors":[{"last":"Zhao"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"H.","last":"Zhao"},{"first":"Y.","last":"Song"},{"first":"C.","last":"Kit"},{"first":"G.","last":"Zhou"}],"year":"2009","title":"Cross Language Dependency Parsing Using a Bilingual Lexicon"}},{"authors":[{"last":"Yu"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"K.","last":"Yu"},{"first":"D.","last":"Kawahara"},{"first":"S.","last":"Kurohashi"}],"year":"2008","title":"Chinese Dependency Parsing with Large Scale Automatically Constructed Case Structures"}},{"authors":[{"last":"Chen"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"W.","last":"Chen"},{"first":"D.","last":"Kawahara"},{"first":"K.","last":"Uchimoto"},{"last":"Torisawa"}],"year":"2009","title":"Improving Dependency Parsing with Subtrees from Auto-Parsed Data"}},{"authors":[{"last":"Chen"},{"last":"al."}],"year":"2012","style":0,"reference":{"authors":[{"first":"W.","last":"Chen"},{"first":"M.","last":"Zhang"},{"first":"H.","last":"Li"}],"year":"2012","title":"Utilizing dependency language models for graph-based dependency parsing models"}},{"authors":[{"last":"Hall"},{"last":"al."}],"year":"2006","style":0,"reference":{"authors":[{"first":"J.","last":"Hall"},{"first":"J.","last":"Nivre"},{"first":"J.","last":"Nilsson"}],"year":"2006","title":"Discriminative Classifier for Deterministic Dependency Parsing"}},{"authors":[{"last":"MSTMalt=Nivre"},{"last":"McDonald"}],"year":"2008","style":0},{"authors":[{"last":"McDonald"},{"last":"al."}],"year":"2005","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"K.","last":"Crammer"},{"first":"F.","last":"Pereira"}],"year":"2005","title":"Online Large-margin Training of Dependency Parsers"}},{"authors":[{"last":"McDonald"},{"last":"Pereira"}],"year":"2006","style":0,"reference":{"authors":[{"first":"R.","last":"McDonald"},{"first":"F.","last":"Pereira"}],"year":"2006","title":"Online Learning of Approximate Dependency Parsing Algorithms"}},{"authors":[{"last":"Carreras"}],"year":"2007","style":0,"reference":{"authors":[{"first":"X.","last":"Carreras"}],"year":"2007","title":"Experiments with a Higher-order Projective Dependency Parser"}},{"authors":[{"last":"Koo"},{"last":"al."}],"year":"2008","style":0,"reference":{"authors":[{"first":"T.","last":"Koo"},{"first":"X.","last":"Carreras"},{"first":"M.","last":"Collins"}],"year":"2008","title":"Simple Semi-Supervised Dependency Parsing"}},{"authors":[{"last":"Chen"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"W.","last":"Chen"},{"first":"D.","last":"Kawahara"},{"first":"K.","last":"Uchimoto"},{"last":"Torisawa"}],"year":"2009","title":"Improving Dependency Parsing with Subtrees from Auto-Parsed Data"}},{"authors":[{"last":"Chen"},{"last":"al."}],"year":"2012","style":0,"reference":{"authors":[{"first":"W.","last":"Chen"},{"first":"M.","last":"Zhang"},{"first":"H.","last":"Li"}],"year":"2012","title":"Utilizing dependency language models for graph-based dependency parsing models"}},{"authors":[{"last":"Duan"},{"last":"al."}],"year":"2007","style":0,"reference":{"authors":[{"first":"X.","last":"Duan"},{"first":"J.","last":"Zhao"},{"first":"B.","last":"Xu"}],"year":"2007","title":"Probabilistic Models for Action-based Chinese Dependency Parsing"}},{"authors":[{"last":"Huang"},{"last":"Sagae"}],"year":"2010","style":0,"reference":{"authors":[{"first":"L.","last":"Huang"},{"first":"K.","last":"Sagae"}],"year":"2010","title":"Dynamic Programming for Linear-Time Incremental Parsing"}},{"authors":[{"last":"Zhang"},{"last":"Nivre"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Y.","last":"Zhang"},{"first":"J.","last":"Nivre"}],"year":"2011","title":"Transition-based Dependency Parsing with Rich Non-local Features"}},{"authors":[{"last":"Zhang"},{"last":"Clark"}],"year":"2008","style":0,"reference":{"authors":[{"first":"Y.","last":"Zhang"},{"first":"S.","last":"Clark"}],"year":"2008","title":"A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing Using Beam-Search"}},{"authors":[{"last":"Bohnet"},{"last":"Kuhn"}],"year":"2012","style":0,"reference":{"authors":[{"first":"B.","last":"Bohnet"},{"first":"J.","last":"Kuhn"}],"year":"2012","title":"The best of both worlds-a graph-based completion model for transition-based parsers"}},{"authors":[{"last":"Li"},{"last":"al."}],"year":"2012","style":0,"reference":{"authors":[{"first":"Z.","last":"Li"},{"first":"T.","last":"Liu"},{"first":"W.","last":"Che"}],"year":"2012","title":"Exploiting multiple treebanks for parsing with Quasi-synchronous grammars"}},{"authors":[{"last":"Chen"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"W.","last":"Chen"},{"first":"D.","last":"Kawahara"},{"first":"K.","last":"Uchimoto"},{"last":"Torisawa"}],"year":"2009","title":"Improving Dependency Parsing with Subtrees from Auto-Parsed Data"}},{"authors":[{"last":"Zhang"},{"last":"Nivre"}],"year":"2011","style":0,"reference":{"authors":[{"first":"Y.","last":"Zhang"},{"first":"J.","last":"Nivre"}],"year":"2011","title":"Transition-based Dependency Parsing with Rich Non-local Features"}},{"authors":[{"last":"Li"},{"last":"al."}],"year":"2012","style":0,"reference":{"authors":[{"first":"Z.","last":"Li"},{"first":"T.","last":"Liu"},{"first":"W.","last":"Che"}],"year":"2012","title":"Exploiting multiple treebanks for parsing with Quasi-synchronous grammars"}},{"authors":[{"last":"Chen"},{"last":"al."}],"year":"2009","style":0,"reference":{"authors":[{"first":"W.","last":"Chen"},{"first":"D.","last":"Kawahara"},{"first":"K.","last":"Uchimoto"},{"last":"Torisawa"}],"year":"2009","title":"Improving Dependency Parsing with Subtrees from Auto-Parsed Data"}},{"authors":[{"last":"Rush"},{"last":"al."}],"year":"2010","style":0,"reference":{"authors":[{"first":"A.","middle":"M.","last":"Rush"},{"first":"D.","last":"Sontag"},{"first":"M.","last":"Collins"},{"first":"T.","last":"Jaakkola"}],"year":"2010","title":"On Dual Decomposition and Linear Programming Relation for Natural Language Processing"}},{"authors":[{"last":"Tsarfaty"},{"last":"al."}],"year":"2011","style":0,"reference":{"authors":[{"first":"R.","last":"Tsarfaty"},{"first":"J.","last":"Nivre"},{"first":"E.","last":"Andersson"}],"year":"2011","title":"Evaluating Dependency Parsing: Robust and Heuristics-Free Cross-Annotation Evaluation"}}]}
