{"sections":[{"title":"Parsing for Semidirectional Lambek Grammar is NP-Complete Jochen Dfrre","paragraphs":["Institut ffir maschinelle Sprachverarbeitung University of Stuttgart"]},{"title":"Abstract","paragraphs":["We study the computational complexity of the parsing problem of a variant of Lambek Categorial Grammar that we call"]},{"title":"semidirectional.","paragraphs":["In semidirectional Lambek calculus SD[ there is an additional nondirectional abstraction rule allowing the formula abstracted over to appear any-where in the premise sequent's left-hand side, thus permitting non-peripheral extraction. SD[ grammars are able to generate each context-free language and more than that. We show that the parsing problem for semidireetional Lambek Grammar is NP-complete by a reduction of the 3-Partition problem. Key words: computational complexity, Lambek Categorial Grammar 1"]},{"title":"Introduction","paragraphs":["Categorial Grammar (CG) and in particular Lambek Categorial Grammar (LCG) have their well-known benefits for the formal treatment of natural language syntax and semantics. The most outstanding of these benefits is probably the fact that the specific way, how the complete grammar is encoded, namely in terms of 'combinatory potentials' of its words, gives us at the same time recipes for the construction of meanings, once the words have been combined with others to form larger linguistic entities. Although both frameworks are equivalent in weak generative capacity -- both derive exactly the context-free languages --, LCG is superior to CG in that it can cope in a natural way with extraction and unbounded dependency phenomena. For instance, no special category assignments need to be stipulated to handle a relative clause containing a trace, because it is analyzed, via hypothetical reasoning, like a traceless clause with the trace being the hypothesis to be discharged when combined with the relative pronoun. Figure 1 illustrates this proof-logical behaviour. Notice that this natural-deduction-style proof in the type logic corresponds very closely to the phrasestructure tree one would like to adopt in an analysis with traces. We thus can derive Bill misses ~ as an s from the hypothesis that there is a \"phantom\""]},{"title":"np","paragraphs":["in the place of the trace. Discharging the hypothesis, indicated by index 1, results in Bill"]},{"title":"misses","paragraphs":["being analyzed as an"]},{"title":"s/np","paragraphs":["from zero hypotheses. Observe, however, that such a bottom-up synthesis of a new unsaturated type is only required, if that type is to be consumed (as the antecedent of an implication) by another type. Otherwise there would be a simpler proof without this abstraction. In our example the relative pronoun has such a complex type triggering an extraction. A drawback of the pure Lambek Calculus !_ is that it only allows for so-called 'peripheral extraction', i.e., in our example the trace should better be initial or final in the relative clause. This inflexibility of Lambek Calculus is one of the reasons why many researchers study richer systems today. For instance, the recent work by Moortgat (Moortgat 94) gives a systematic in-depth study of mixed Lambek systems, which integrate the systems L, NL, NLP, and LP. These ingredient systems are obtained by varying the Lambek calculus along two dimensions: adding the permutation rule (P) and/or dropping the assumption that the type combinator (which forms the sequences the systems talk about) is associative (N for"]},{"title":"non-associative).","paragraphs":["Taken for themselves these variants of I_ are of little use in linguistic descriptions. But in Moortgat's mixed system all the different resource management modes of the different systems are left intact in the combination and can be exploited in different parts of the grammar. The relative pronoun which would, for instance, receive category"]},{"title":"(np\\np)/(np --o s)","paragraphs":["with --o being implication in LP, 1 i.e., it requires","1The Lambek calculus with permutation I_P is also called the \"nondirectional Lambek calculus\" (Benthem 88). In it the leftward and rightward implication"]},{"title":"95","paragraphs":["(the book)","which (np\\np)/(s/np) misses e"]},{"title":"(n;\\8)/n;","paragraphs":["Bill ~~ np np\\s 8"]},{"title":"I","paragraphs":["s/npl np\\np Figure 1: Extraction as resource-conscious hypothetical reasoning as an argument \"an s lacking an np somewhere\" .2. The present paper studies the computational complexity of a variant of the Lambek Calculus that lies between / and tP, the Semidirectional Lambek Calculus SDk. 3 Since tP derivability is known to be NP-complete, it is interesting to study restrictions on the use of the I_P operator -o. A restriction that leaves its proposed linguistic applications intact is to admit a type B -o A only as the argument type in functional applications, but never as the functor. Stated prove-theoretically for Gentzen-style systems, this amounts to disallowing the left rule for -o. Surprisingly, the resulting system SD[. can be stated without the need for structural rules, i.e., as a monolithic system with just one structural connective, because the ability of the abstracted-over formula to permute can be directly encoded in the right rule for --o. 4 Note that our purpose for studying SDI_ is not that it might be in any sense better suited for a theory of grammar (except perhaps, because of its simplicity), but rather, because it exhibits a core of logical behaviour that any richer system also needs to include, at least if it should allow for non-peripheral extraction. The sources of complexity uncovered here are thus a forteriori present in all these richer systems as well. collapse.","2Morrill (Morrill 94) achieves the same effect with a permutation modality /k apphed to the np gap: (s/Anp)","SThis name was coined by Esther K6nig-Baumer, who employs a variant of this calculus in her LexGram system (KSnig 95) for practical grammar development.","4It should be pointed out that the resource management in this calculus is very closely related to the handhng and interaction of local valency and unbounded dependencies in HPSG. The latter being handled with set-valued features SLASH, QUE and KEL essentially emulates the permutation potential of abstracted categories in semidirectional Lambek Grammar. A more detailed analysis of the relation between HPSG and SD[ is given in (KSnig 95)."]},{"title":"2 Semidirectional Lambek Grammar","paragraphs":["2.1 Lambek calculus The semidirectional Lambek calculus (henceforth SDL) is a variant of J. Lambek's original (Lambek 58) calculus of syntactic types. We start by defining the Lambek calculus and extend it to obtain SDL. Formulae (also called \"syntactic types\") are built from a set of propositional variables (or \"primitive types\") B = {bl, b2,...} and the three binary connectives • , \\,/, called product, left implication, and right implication. We use generally capital letters A, B, C,... to denote formulae and capitals towards the end of the alphabet T, U, V, ... to denote sequences of formulae. The concatenation of sequences U and V is denoted by (U, V). The (usual) formal framework of these logics is a Gentzen-style sequent calculus. Sequents are pairs (U, A), written as U =~ A, where A is a type and U is a sequence of types. 5 The claim embodied by sequent U =~ A can be read as \"formula A is derivable from the structured database U\". Figure 2 shows Lambek's original calculus t. First of all, since we don't need products to obtain our results and since they only complicate matters, we eliminate products from consideration in the sequel. In Semidirectional Lambek Calculus we add as additional connective the [_P implication --% but equip it only with a right rule. U, B, V :=~ A (-o R) if T = (U, Y) nonempty. T :~ B --o A","5In contrast to Linear Logic (Girard 87) the order of types in U is essential, since the structural rule of permutation is not assumed to hold. Moreover, the fact that only a single formula may appear on the right of ~, make the Lambek calculus an intuitionistic fragment of the multiplicative fragment of non-commutative propositional Linear Logic."]},{"title":"96","paragraphs":["(Ax) T~B U,A,V=~C U, A/B, T, V =~ C (/L) U,B ~A U ::~ A/B (/1~) if U nonempty T ::v B U,A, V =v C U, T, B\\A, V =~ C (\\L) B,U~A U =~ B\\A (\\R) if U nonempty U,A,B, V =~ C (.L) U, AoB, V =~ C UsA V~B (.R) U,V =~ A.B T~A"]},{"title":"U,A,V=¢,C (Cut)","paragraphs":["U, T, V =~ U Figure 2: Lambek calculus L Let us define the polarity of a subformula of a sequent A1, • •., Am ::~ A as follows: A has positive polarity, each of Ai have negative polarity and if B/C or C\\B has polarity p, then B also has polarity p and C has the opposite polarity of p in the sequent. A consequence of only allowing the (-o R) rule, which is easily proved by induction, is that in any derivable sequent --o may only appear in positive polarity. Hence, -o may not occur in the (cut) formula A of a (Cut) application and any subformula B -o A which occurs somewhere in the prove must also occur in the final sequent. When we assume the final sequent's RHS to be primitive (or --o-less), then the (-o R) rule will be used exactly once for each (positively) occuring -o-subformula. In other words, (-o R) may only do what it is supposed to do: extraction, and we can directly read off the category assignment which extractions there will be. We can show Cut Elimination for this calculus by a straight-forward adaptation of the Cut elimination proof for L. We omit the proof for reasons of space."]},{"title":"Proposition 1 (Cut Elimination)","paragraphs":["Each SDL-derivable sequent has a cut-free proof. The cut-free system enjoys, as usual for Lambek-like logics, the Subformula Property: in any proof only subformulae of the goal sequent may appear. In our considerations below we will make heavy use of the well-known count invariant for Lambek systems (Benthem 88), which is an expression of the resource-consciousness of these logics. Define #b(A) (the b-count of A), a function counting positive and negative occurrences of primitive type b in an arbi-"]},{"title":"97","paragraphs":["trary type A, to be if A= b if A primitive and A ~ b #b(A)= #b(B)-#b(C)ifA=B/CorA=V\\B","or A=C-o B [.#b(B) + #b(C) ifA = B. C The invariant now states that for any primitive b, the b-count of the RHS and the LHS of any derivable sequent are the same. By noticing that this invariant is true for (Ax) and is preserved by the rules, we immediately can state:"]},{"title":"Proposition 2 (Count Invariant)","paragraphs":["If"]},{"title":"I-sb L","paragraphs":["U ==~ A, then #b(U) = #b(A) fo~ any b ~ t~. Let us in parallel to SDL consider the fragment of it in which (/R) and (\\R) are disallowed. We call this fragment SDL-. Remarkable about this fragment is that any positive occurrence of an implication must be --o and any negative one must be / or \\. 2.2 Lambek"]},{"title":"Grammar Definition","paragraphs":["3 We define a Lambek grammar to be a quadruple (E, ~r, bs, l) consisting of the finite alphabet of terminals E, the set jr of all Lambek formulae generated from some set of propositional variables which includes the distinguished variable s, and the lezical map l : ~, --* 2 7 which maps each terminal to a finite subset off. We extend the lexical map l to nonempty strings of terminals by setting l(wlw2...w~) := l(wl) × l(w~) x ... x l(w,) for wlw2...wn E ~+. The language generated by a Lambek grammar G = (~,~',bs,l) is defined as the set of all strings wlw~...wn E ~+ for which there exists a sequence x==~x x==~x B~, B2, C~, C2, c n+l, b n+l => y (*) B~, B2, C~, C2, c n, b n ~ c --o (b --o y) A2, B[, B2, C~, C2, c n, b n =* x","n--1 A 1 , A2, B~, B2, C~, C2, c, b =v x A~ -1, A2, B~', B2, C~, C2 =~ c -0 (b -0 x) A?, A2, B~, B2, C{ ~, C2 ==> x Figure 3: Proof of A~, A2, B~, B2, C~, C2 =~ z 2x(-on) (]L) 2x(--on) (/L) of types U E l(wlw2...wn) and k k U ~ bs. We denote this language by L(G). An SDL-grammar is defined exactly like a Lambek grammar, except that kSD k replaces kl_. Given a grammar G and a string w = WlW2... wn, the parsing (or recognition) problem asks the question, whether w is in L(G). It is not immediately obvious, how the generative capacity of SDL-grammars relate to Lambek grammars or nondirectional Lambek grammars (based on calculus LP). Whereas Lambek grammars generate exactly the context-free languages (modulo the missing empty word) (Pentus 93), the latter generate all permutation closures of context-free languages (Benthem 88). This excludes many context-free or even regular languages, but includes some context-sensitive ones, e.g., the permutation closure of a n b n c n . Concerning SD[, it is straightforward to show that all context-free languages can be generated by SDL-grammars• Proposition 4 Every context-free language is generated by some SDL-grammar. Proof. We can use a the standard transformation of an arbitrary cfr. grammar G = (N, T, P, S) to a categorial grammar G'. Since -o does not appear in G' each SDl_-proof of a lexical assignment must be also an I_-proof, i.e. exactly the same strings are judged grammatical by SDL as are judged by L. D Note that since the {(Ax), (/L), (\\L)} subset of I_ already accounts for the cfr. languages, this observation extends to SDL-. Moreover, some languages which are not context-free can also be generated. Example. Consider the following grammar G for the language anbnc n. We use primitive types B = {b, c, x, y, z} and define the lexical map for E ="]},{"title":"98","paragraphs":["{a, b, c} as follows:","l(a) := { x/(c ---o (b -o x)), xl(c ---o (b -o y)) } = )41 = A2"]},{"title":"----CI","paragraphs":["= C2 The distinguished primitive type is x• To simplify the argumentation, we abbreviate types as indicated above• Now, observe that a sequent U =~ x, where U is the image of some string over E, only then may have balanced primitive counts, if U contains exactly one occurrence of each of A2, B2 and C2 (accounting for the one supernumerary x and balanced y and z counts) and for some number n >_ 0, n occurrences of each of A1, B1, and C1 (because, resource-oriented speaking, each Bi and Ci \"consume\" a b and c, resp., and each Ai \"provides\" a pair b, c). Hence, only strings containing the same number of a's, b's and c's may be produced. Furthermore, due to the Subformula Property we know that in a cut-free proof of U ~ x, the mMn formula in abstractions (right rules) may only be either c -o (b --o X) or b -o X, where X E {x,y}, since all other implication types have primitive antecedents. Hence, the LHS of any sequent in the proof must be a subsequence of U, with some additional b types and c types interspersed. But then it is easy to show that U can only be of the form","Anl, A2, B~, B2, C~, C2, since any / connective in U needs to be introduced via (/L). It remains to be shown, that there is actually a proof for such a sequent• It is given in Figure 3. The sequent marked with * is easily seen to be derivable without abstractions. A remarkable point about SDL's ability to cover this language is that neither L nor LP can generate it. Hence, this example substantiates the claim made in (Moortgat 94) that the inferential capacity of mixed Lambek systems may be greater than the sum of its component parts. Moreover, the attentive reader will have noticed that our encoding also extends to languages having more groups of n symbols, i.e., to languages of the form n n n al a2 ... a k • Finally, we note in passing that for this grammar the rules (/R) and (\\R) are irrelevant, i.e. that it is at the same time an SOL- grammar."]},{"title":"3 NP-Completeness of the Parsing Problem","paragraphs":["We show that the Parsing Problem for SDL-grammars is NP-complete by a reduction of the 3-Partition Problem to it. 6 This well-known NP-complete problem is cited in (GareyJohnson 79) as follows. Instance: Set ,4 of 3m elements, a bound N E Z +, and a size s(a) E Z + for each a E 4̀ such that ~ < s(a) < ~- and"]},{"title":"~o~ s(a) = mN.","paragraphs":["Question: Can 4̀ be partitioned into m disjoint sets 4̀1,4̀2,...,Am such that, for 1 < i < m, ~ae.a s(a) = N (note that each 4̀i must 'therefore contain exactly 3 elements from 4̀)?","Comment: NP-complete in the strong sense. Here is our reduction. Let F = (4̀, m,N,s) be a given 3-Partition instance. For notational convenience we abbreviate (...((A/BI)/B~)/...)/Bn by A/B~ •...• B2 • B1 and similarly B, -o (... (B1 --o A)...) by Bn •... • B2 • B1 --o A, but note that this is just an abbreviation in the product-free fragment. Moreover the notation A k stands for","AoAo ...oA k t~mes We then define the SDL-grammar Gr = (~, ~, bs, l) as follows: p, :="]},{"title":"{v, wl,..., warn}","paragraphs":["5 t\" := all formulae over primitive types m b"]},{"title":"B = {a,d}UUi=,{ i,c,:}","paragraphs":["bs"]},{"title":":--=","paragraphs":["a • for l<i<3rn-l: l(wi) :="]},{"title":"UJ.<./<m","paragraphs":["d/d • bj • c: (~')","6A similar reduction has been used in (LincolnWinkler 94) to show that derivability in the multiplicative fragment of propositional Linear Logic with only the connectives --o and @ (equivalently Lambek calculus with permutation LP) is NP-complete."]},{"title":"99","paragraphs":["The word we are interested in is v wl w2...w3m. We do not care about other words that might be generated by Gr. Our claim now is that a given 3-Partition problem F is solvable if and only if v wl ... w3m is in L(Gr). We consider each direction in turn. Lemma 5 (Soundness) If a 3-Partition problem F = (A,m,N,s) has a solution, then vwl...w3m is in/(Gr). Proof. We have to show, when given a solution to F, how to choose a type sequence U ~ l(vwl...wzm) and construct an SDL proof for U ==~ a. Suppose 4̀ = {al,a2,...,a3m}. From a given solution (set of triples) A1,4̀~,... ,-Am we can compute in polynomial time a mapping k that sends the index of an element to the index of its solution triple, i.e., k(i) = j iff ai e 4̀j. To obtain the required sequence U, we simply choose for the wi terminals the type","• cS(a3\"~) • c ~(\"~) (resp. d/bk(3m) k(3m) for W3m). did • bk(i) k(i) Hence the complete sequent to solve is:","N d) a/(b 3 •b 3 •...•b3m ac N •c N •...•c m -o did • bko) • %(1) cS(a3,.-1) (*) did • bk(3m-1) • k(am-1) dlb • cS(a3\") / k(3m) k(zm) Let a/Bo, B1,...B3m ~ a be a shorthand for (*), and let X stand for the sequence of primitive types"]},{"title":"c~(,,~,.) c~(,~.,,-~) c~(,~,)","paragraphs":["bk(3m), k(3m),bk(3m-l), k(3,~_l),...bko), k(1)\" Using rule (/L) only, we can obviously prove B1, . . . B3m , X ::~ d. Now, applying (--o R) 3m + N m times we can obtain B1,...B3m =~ B0, since there are in total, for each i, 3 bi and N ci in X. As final step we have BI,...B3m ~ B0 a ~ a a/Bo, BI,... B3m ~ a (/L) which completes the proof. [] Lemma 6 (Completeness) Let F = (.4, m, N, s) be an arbitrary 3-Partition problem and Gr the corresponding SDL-grammar as defined above. Then F has a solution, if v wl... w3m is in L(Gr). Proof. Let v wl... W3m 6 L(Gr) and N d), B1,. • • Bsm ~ a a/(b? .....em -o be a witnessing derivable sequent, i.e., for 1 < i < 3m, Bi E l(wi). Now, since the counts of this sequent must be balanced, the sequence B1,...B3m must contain for each 1 _< j < m exactly 3"]},{"title":"bj","paragraphs":["and exactly N cj as subformulae. Therefore we can read off the solution to F from this sequent by including in"]},{"title":"Aj","paragraphs":["(for 1 < j < m) those three ai for which Bi has an occurrence of"]},{"title":"bj,","paragraphs":["say these are"]},{"title":"aj(1), aj(2)","paragraphs":["and aj(3). We verify, again via balancedness of the primitive counts, that"]},{"title":"s(aj(1))","paragraphs":["÷"]},{"title":"s(aj(2))","paragraphs":["+ s(aj(3)) ="]},{"title":"N","paragraphs":["holds, because these are the numbers of positive and negative occurrences of cj in the sequent. This completes the proof. [] The reduction above proves NP-hardness of the parsing problem. We need strong NP-completeness of 3-Partition here, since our reduction uses a unary encoding. Moreover, the parsing problem also lies within NP, since for a given grammar G proofs are linearly bound by the length of the string and hence, we can simply guess a proof and check it in polynomial time. Therefore we can state the following: Theorem 7"]},{"title":"The parsing problem for","paragraphs":["SDI_"]},{"title":"is NP- complete.","paragraphs":["Finally, we observe that for this reduction the rules"]},{"title":"(/R)","paragraphs":["and (\\R) are again irrelevant and that we can extend this result to SDI_-. 4 Conclusion We have defined a variant of Lambek's original calculus of types that allows abstracted-over categories to freely permute. Grammars based on SOl- can generate any context-free language and more than that. The parsing problem for SD[, however, we have shown to be NP-complete. This result indicates that efficient parsing for grammars that allow for large numbers of unbounded dependencies from within one node may be problematic, even in the categorial framework. Note that the fact, that this problematic case doesn't show up in the correct analysis of normal NL sentences, doesn't mean that a parser wouldn't have to try it, unless some arbitrary bound to that number is assumed. For practical grammar engineering one can devise the motto"]},{"title":"avoid accumulation of unbounded dependencies by whatever means.","paragraphs":["On the theoretical side we think that this result for S01 is also of some importance, since SDI_ exhibits a core of logical behaviour that any (Lambek-based) logic must have which accounts for non-peripheral extraction by some form of permutation. And hence, this result increases our understanding of the necessary computational properties of such richer systems. To our knowledge the question, whether the Lambek calculus itself or its associated parsing problem are NP-hard, are still open. References J. van Benthem. The Lambek Calculus. In R. T. O. et al. (Ed.),"]},{"title":"Categorial Grammars and Natural Lan- guage Structures,","paragraphs":["pp. 35-68. Reidel, 1988. M. R. Garey and D. S. Johnson."]},{"title":"Computers and Intractability--A Guide to the Theory of NP- Completeness.","paragraphs":["Freeman, San Francisco, Cal., 1979. J.-Y. Girard. Linear Logic."]},{"title":"Theoretical Computer Science,","paragraphs":["50(1):1-102, 1987. E. Khnig. LexGram - a practical categorial grammar formalism. In"]},{"title":"Proceedings of the Workshop on Computational Logic for Natural Language Process- ing. A Joint COMPULOGNET/ELSNET/EAGLES Workshop,","paragraphs":["Edinburgh, Scotland, April 1995. J. Lambek. The Mathematics of Sentence Structure."]},{"title":"American Mathematical Monthly,","paragraphs":["65(3):154-170, 1958. P. Lincoln and T. Winkler. Constant-Only Multiplicative Linear Logic is NP-Complete."]},{"title":"Theoretical Computer Science,","paragraphs":["135(1):155-169, Dec. 1994. M. Moortgat. Residuation in Mixed Lambek Systems. In M. Moortgat (Ed.),"]},{"title":"Lambek Calculus. Mul- timodal and Polymorphic Extensions, DYANA-2 de- liverable RI.I.B.","paragraphs":["ESPRIT, Basic Research Project 6852, Sept. 1994. G. Morrill."]},{"title":"Type Logical Grammar: Categorial Logic of Signs.","paragraphs":["Kluwer, 1994. M. Pentus. Lambek grammars are context free. In"]},{"title":"Proceedings of Logic in Computer Science,","paragraphs":["Montreal, 1993."]},{"title":"100","paragraphs":[]}]}
