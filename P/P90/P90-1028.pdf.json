{"sections":[{"title":"ALGORITHMS FOR GENERATION IN LAMBEK THEOREM PROVING Erik-Jan van der Linden * Guido Minnen Institute for Language Technology and Artificial Intelligence Tilburg University PO Box 90153, 5000 LE Tilburg, The Netherlands E-maih vdlindenOkub.nl ABSTRACT","paragraphs":["We discuss algorithms for generation within the Lambek Theorem Proving Framework. Efficient algorithms for generation in this framework take a semantics-driven strategy. This strategy can be modeled by means of rules in the calculus that are geared to generation, or by means of an algorithm for the Theorem Prover. The latter possibility enables processing of a bidirectional calculus. Therefore Lambek Theorem Proving is a natural candidate for a 'uniform' architecture for natural language parsing and generation. Keywords: generation algorithm; natural language generation; theorem proving; bidirectionality; categorial grammar."]},{"title":"1 INTRODUCTION","paragraphs":["Algorithms for tactical generation are becoming an increasingly important subject of research in computational linguistics (Shieber, 1988; Shieber et al., 1989; Calder et al., 1989). In this paper, we will discuss generation algorithms within the Lambek Theorem Proving (LTP) framework (Moortgat, 1988; Lambek, 1958; van Benthem, 1988). In section (2) we give an introduction to a categorial calculus that is extended towards bidirectionality. The naive top-down control strategy in this section does not suit the needs of efficient generation. Next, we discuss two ways to implement a semantics-driven strategy. Firstly, we add inference rules and cut rules geared to generation to the calculus (3). Secondly, since these changes in the calculus do not support bidirectionality, we *We would llke to thank Gosse Bouma, Wietske Si~tsma and Marianne Sanders for their comments on an earlier draft of the paper.","220 introduce a second implementation: a bottom-up algorithm for the theorem prover (4)."]},{"title":"2 EXTENDING THE CAL- CULUS","paragraphs":["Natural Language Processing as deduction The architectures in this paper resemble the uniform architecture in Shieber (1988) because language processing is viewed as logical deduction, in analysis and generation: \"The generation of strings matching some criteria can equally well be thought of as a deductive process, namely a process of constructive proof of the existence of a string that matches the criteria.\" (Shieber, 1988, p. 614). In the LTP framework a categorial reduction system is viewed as a logical calculus where parsing a syntagm is an attempt to show that it follows from a set of axioms and inference rules. These inference rules describe what the processor does in assembling a semantic representation (representational non-autonomy: Crain and Steedman, 1982; Ades and Steedman, 1982). Derivation trees represent a particular parse process (Bouma, 1989). These rules thus seem to be nondeclarative, and this raises the question whether they can be used for generation. The answer to this question will emerge throughout this paper. Lexical information As in any categorial grammar, linguistic information in LTP is for the larger part represented with the signs in the lexicon and not with the rules of the calculus (signs are denoted by prosody:syntax:semantlcs). A generator using a categorial grammar needs lexical information about the syntactic form of a functor that is connected to some semantic functot in order to syntactically correctly generate the semantic arguments of this functor. For a parser, the reverse is true. In order to fulfil both needs, lexical information is made available to the theorem prover in the form of in~t6aces of o~ionu. I Axioms then truely represent what should be axiomatic in a lexicalist description of a language: the ]exical items, the connections between form and meaning. 2","I* sliainationrules */","(U,[Pros_Fu:X/Y:Functor],[TIR],V)=>[Z] <- [Pros_Fu:X/Y:Functor] =>","[Pros_Fu:X/Y:Functor] k [TIR] => [Pros Arg:Y:Ar~ k"]},{"title":"(U,[(Pros_Fu*l~os_Arg):X:Functor@Arg],V)","paragraphs":["=>"]},{"title":"[z].","paragraphs":["(U,[T[R],[Pros_Fu:Y\\X:Functor],V) => [Z] <- [Pros_Fu:Y\\X:Functor] =>","[Pros_Fu:Y\\X:Functor] k [TIR] => [Pros_arg:Y:krg] k (U,[(Pros_krg*Pros_Fu):X:FunctorQArg],V) =>","[z]. Rules Whenever inference rules are applied, an attempt is made to axiomatize the functor that participates in the inference by the first subsequent of the elimination rules. This way, lexical information is retrieved from the lexicon. /* introduction rulss */ [T[R]=>[Pros:Y\\X:Var_Y'Tsra_X] <- nogsnvar(Y\\X) k ([id:Y:Var_Y],[T[R]) =>"]},{"title":"[(id*Pros):X:Tarm_X].","paragraphs":["A prosodic operator connects prosodic elements. A prosodic identity element, id, is necessary because introduction rules are prosodical]y vacuous. In order to avoid unwanted matching between axioms and id-elements, one special axiota is added for id-elements. Meta-logical checks are included in the rules in order to avoid vsriables occuring in the final derivation, nogenv,2r reeursively checks whether any part of an expression is a variable. A sequent in the calculus is denoted with P => T, where P, called the antecedent, and T, the succedent, are finite sequences of signs. The calculus is presented in (1) . In what follows, X and ¥ are categories; T and Z, are signs; R, U and V are possibly empty sequences of signs; @ denotes functional application, a caret denotes ~- abstraction, s"]},{"title":"(i)","paragraphs":["/* axioms */ [Pros:X:¥] => [Pros:X:Y] <- [Pros:l:Y] =i> [Pros:X:Y] k true. [Pros:X:Y] => [Pros:X:Y] <-"]},{"title":"(nossnvar(X),","paragraphs":["nonvar(Y)) k 1;rue. [TIR] => [Pros:X/Y:Var_Y'Tsrm_X] <- nogsnvar(X/Y) k ([T[R],Cid:Y:Var_Y]) ->"]},{"title":"[(Pros*id):l:Term_X].","paragraphs":["/* axiom for prosodic id-element */ [id:X:Y] =i> [id:X:Y] <-","isvs.r(Y). /* lexicon, lexioms */ [john:np:john] =1> [john:np:john]. [mary:np:mexy] =1> [maxy:np:maxy]. [loves:(np\\s)/np:lovn] =1>","[loves:(np\\s)/np:lows]. In order to initiate analysis, the theorem prover is presented with sequents like (2). Inference rules are applied recursively to the antecedent of the sequent until axioms are found. This regime can be called top-down from the point of view ofprob- ]em solving and bottom-up from a \"parsing\" point of view. For generation, a sequent like (3) is presented to the theorem prover. Both analysis and generation result in a derivation like (4). Note that generation not only results in a sequence of lexical signs, but also in a peosodic pl~rasing that could be helpful for speech generation."]},{"title":"(2)","paragraphs":["lVem der Linden and Minnen (submitted) contains a more elaborate comparison of the extended cedcu]tm with the origins] calculus as proposed in Moortgat (1988).","2A suggestion similar to this proposal was made by K~nig (1989) who stated that lexicsI items are to be seen as axioms, but did not include them as such in her description of the L-calculus.","SThroughout this paper we will use a Prolog notation because the architectures presented here depend partly on the Prolog un[i~cstlon mechanism.","221 [john:A:B,lovss:C:D,msxy:E:F] => [Pros:s:Ssm]"]},{"title":"(3)","paragraphs":["U => [Pros:s:loves@maryQjohn]"]},{"title":"Although both (2) and (3) result (4), in the","paragraphs":["case of generation, (4) does not represent the"]},{"title":"(4)","paragraphs":["john:np:john 1or*s: (np\\s)/np:loves ma~ry:np:mary => john*(loves*mary):s:lovesQaary@john <-","loves: (np\\s)/np:loves => loves: (np\\s)/np:1oves <- loves: (np\\s)/np:loves =I> loves:(np\\s)/np:1oves <- true","aary:np:aary => aary:np:aary <- ms.ry:np:aa~ry =I> aary:np:aary <- true","john: np: J olm loves*mary : np\\s : lovea@aary => j ohn* (loves*mary) : s : loves@aary@j olm <- loves*aary : np\\s : loves@mary => loves*aary :np\\s : loves@mary <- true john:np:john => john:np:john <-","john:np:john -1> john:np:john <- true john* (loves*aary) :s : lovss@aaryQj ohn => john* (loves*mary) : s : loves@aary@j ohn: <- true exact proceedings of the theorem prover. It starts applying rules, matching them with the antecedent, without making use of the original semantic information, and thus resulting in an in-efficient and nondeterministic generation process: all possible derivations including all hxical items are generated until some derivation is found that results in the succedent. 4 We conclude that the algorithm normally used for parsing in LTP is in-efficient with respect to generation."]},{"title":"3 CALCULI DESIGNED FOR GENERATION","paragraphs":["A solution to the ei~ciency problem raised in the previous section is to start from the origihal semantics. In this section we discuss calculi that make explicit use of the original semantics. Firstly, we present Lambek-like rules especially designed for generation. Secondly, we introduce a Cut-rule for generation with sets of categorial reduction rules. Both entail a variant of the crucial starting-point of the semantic-he~d-driven algorithms described in Calder et al. (1989) and Shieber et al. (1989): if the functor of a semantic representation can be identified, and can be refated to a lexical representation containing syntactic information, it is possible to generate the arguments syntactically. The efficiency of this strategy stems from the fact that it is guided by the known semantic and syntactic information, and lexical information is retrieved as soon as possible.","In contrast to the semantic-head-driven al>- proach, our semantic representations do not allow for immediate recognition of semantic heads: these can only be identified after all arguments","4ef. Shleber et el. (1989) on top-down generation algorithms. 2 2 2 have been stripped of the functor recursively (loves@mary@john =:> loves@mary => loves). Calder et al. conjecture that their algorithm \"(...) extends naturally to the rules of composition, division and permutation of Combinatory Categorial Grammar (Steedman, 1987) and the Lambek Calculus (1958)\" (Calder et al., 1989, p."]},{"title":"23 ).","paragraphs":["This conjecture should be handled with care. As we have stated before, inference rules in LTP describe ho~ a processor operates. An important difference with the categorial reduction rules of Calder et al. is that inference.rules in LTP implicitly initiate the recursion of the parsing and generation process. Technically speaking, Lambek rules cannot be arguments of the rule-predicate of Calder et al. (1989, p. 237). The gist of our strategy is similar to theirs, but the algorithms dilTer. Lambek-llke generation Rules are presented in (5) that explicitly start from the known information during generation: the syntax and semantics of the succedent. Literally, the inference rule states that a sequent consisting of an antecedent that unifies with two sequences of signs U and Y, and a succedent that unifies with a sign with semantics Sem_FuQSem_Arg is a theorem of the calculus if Y reduces to a syntactic functor looking for an argument on its left side with the functor-meaning of the original semantics, and U reduces to its argument. This rule is an equivalent of the second elimination rule in (I)."]},{"title":"(5)","paragraphs":["/* el~inationrule */ ~,v] =>","[(Pros_krg*Pros_Fu):X:Sem_Fu@Sea_krg] <- V =>[Pros_Fu:Y\\X:Sen_Fu] t U =>[Pros_Arg:Y:Sen_krg].","/* introduction-rule */","[T[R] => [Pros:Y\\l:Var_Y'Tera_X] <- nogenvsr(Y\\X) k (CCid:Y:Vnur_Y]],CTIR]) =>","[(id*Pros):X:Tora_l]."]},{"title":"4 A COMBINED BOT- TOM-UP/TOP-DOWN REGIME","paragraphs":["In this section, we describe an algorithm for the theorem prover that proceeds in a combined bottom-up/top-down fashion from the problem solving point of view. It maintains the same semantics-driven strategy, and enables efficient generation with the bidirectional calculus in (I). The algorithm results in derivations like (4), in the same theorem prover architecture, be it along another path. A Cut-rule for generation A"]},{"title":"Cut-rule","paragraphs":["is a structural rule that can be used within the L-calculus to include partial proofs derived with categorial reduction rules into other proofs. In (6) a generation Cut-rule is presented together with the AB-system."]},{"title":"(6)","paragraphs":["/* Cut-rule for generation */ [U.V] => [Pros_Z:Z:Su_Z] <-"]},{"title":"[Pros_X:X:Sem_X,","paragraphs":["Pros_Y:Y:Sem_Y] =*>","[Pros_g:z:sem_Z]","U => [Pros_Z:X:Sem_Z]","V ffi> [Proe_Y:Y:Sem_Y]. /* reduction rules, system AB */ [Pros_Fu:X/Y:Functor. lhcos_Arg:Y:lrg] =*>","(Pros_FU*Pros_Arg):X:Functor@Arg].","[Pros_Arg:Y:Arg, Pros_Fu:Y\\l:Functor] =*> (Pros.Arg*Pros_Fu):X:Functor@ArS]. The generator regimes presented in this section are semantics-driven: they start from a semantic representation, assume that it is part of the uppermost sequent within a derivation, and work towards the lexical items, axioms, with the recursive application of inference rules. From the point of view of theorem proving, this process should be described as a top-down problem solving strategy. The rules in this section are, however, geared towards generation. Use of these rules for parsing would result in massive non-determinism. Elficient parsing and generation require different rules: the calculus is not"]},{"title":"bidirectioaal.","paragraphs":["223 Bidirectionality There are two reasons to avoid duplication of grammars for generation and interpretation. Firstly, it is theoretically more elegant and simple to make use of one grammar. Secondly, for any language processing system, human or machine, it is more economic (Bunt, 1987, p. 333). Scholars in the area of language generation have therefore pleaded in favour of the"]},{"title":"bidirectionalit~","paragraphs":["of linguistic descriptions (Appelt, 1987).","Bidirectionality might in the first place be implemented by using one grammar and two separate algorithms for analysis and generation (Jacobs, 1985; Calder et el., 1989). However, apart from the desirability to make use of one and the same grammar for generation and analysis, it would be attractive to have one and the same"]},{"title":"processiag architecture","paragraphs":["for both analysis and generation. Although attempts to find such architectures (Shieber, 1988) have been termed \"looking for the fountain of youth', s it is a stimulating question to what extent it is possible to use the same architecture for both tasks. Example An example will illustrate how our algorithm proceeds. In order to generate from a sign, the theorem prover assumes that it is the succedent of one of the"]},{"title":"subsequeats","paragraphs":["of one of the inference rules (7-1/2). (In case of an introduction rule the sign is matched with the succedent of the"]},{"title":"headseq~en~;","paragraphs":["this implies a top-down step.) If unification with one of these subsequents can be established, the other subsequents and the headsequent can be partly instantiated. These sequents can then serve as starting points for further bottom-up processing. Firstly, the headsequent is subjected to bottom-up process-","SRon Kaplan during discussion of the $hieber presentation at Coling 1988. Generation of nounphrase ~he ~abie. Start with sequent P => [Pros :np: the@table] l- Assume suecedent is part of an axiom: [Pros : np: the0t able] => [Pros :np: the@table] 2- Match axiom with last subsequent of an inference rule:","(U, [Pros_Fu:X/Y:Functor], [T[I~,V) => [Z] <- [Pros_Fu:X/Y:Functor] => [Pros_Fu:X/Y:Functor] & [T [ R] => [Pros_krg : Y : Arg] & (U, [ (Pros_Fu*Pros_Arg) : X: Functor@~g], V) => [Z]. Z = Pros:np:the@table; Functor : the; Arg = table; X = np; U = [ ]; V = [ ]. 3- Derive instantiated head sequent: [Pros_Fu: np/Y: the], [T [ R] => [Pros :rip: the0table] 4- No more applications in head sequent: Prove (bottom-up) first instantiated subsequent: [Pros_Fu: np/Y: the] ,,> [Pros_Fu :np/Y : the] Unifies with the axiom for \"the\": Pros_Fu = the; Y = n. 5- Prove (bottom-up) second instantiated subsequent: [T[ R] => [Pros_Arg: n: \"~ able] Unifies with axiom for \"table\": Pros_Arg = table; T = table:n:table; R = [ ] 6- Prove (bottum-up) last subsequent: is a nonlexical ax/om. [ (the*t able) :np : the@table] => [ (the*table) : np: theQtable]. 7- Final derivation:","the:np/n:the table:n:table => the*table:np.the@table <- the:np/n:the => the:np/n:the <-","the:np/n:the =1> the:np/n:the <- true table:n:table => table:n:table <-","table:n:table =i> tabls:n:table <- true the*table :np:the@table => the*table :np:the@table <- true 224 ing (7-3), in order to axiomatize the head functor as soon as possible. Bottom-up processing stops when no more application operators can be eliminsted from the head sequent (7-4). Secondly, working top-down, the other subsequents (7-4/5) are made subject to bottom-up processing, and at last the last subsequent"]},{"title":"(7-6). (7)","paragraphs":["presents generation of a nounphrsse, the ~able. Non-determinism A source for non-determinism in the semantics-driven strategy is the fact that the theorem prover forms hypotheses about the direction a functor seeks its arguments, and then checks these against the lexicon. A possibility here would be to use a calculus where dorainance and precedence are taken apart. We will pursue rids suggestion in future research."]},{"title":"5 CONCLUDING REMARKS","paragraphs":["Implementation The algorithms and calculi presented here have been implemented with the use of modified versions of the categorial calculi interpreter described in Moortgat (1988). Conclusion Efl]cient, bidirectional use of categorial calculi is possible if extensions are made with respect to the calculus, and if s combined bottom-up/top-down algorithm is used for generation. Analysis and generation take place within the same processing architecture, with the same linguistics descriptions, be it with the use of different algorithms. LTP thus serves as a natural candidate for a uniform architecture of parsing and generation. Semantic non-monotonieity A constraint on grammar formalisms that can be dealt with in current generation systems is semantic monotonicity (Shieber, 1988; but cf. Shieber et al., 1989). The algorithm in Calder et al. (1989) requires an even stricter constaint. Firstly, in van der Linden and Minnen (submitted) we describe how the addition of a unification-based semantics to the calculus described here enables processing of non-monotonic phenomena such as noncompositional verb particles and idioms. Identity semantics (cf. Calder et al. p. 235) should be no problem in this respect. Secondly, unary rules and type-raising (ibid.) are part of the L-calculus, and are neither fundamental problems. Inverse E-reduction A problem that exists for all generation systems that include some form of ~-semantics is that generation necessitates the inverse operation of~-reduction. Although we have implemented algorithms for inverse E-reduction, these are not computationally tractable, e A way out could be the inclusion of a unification based semantics. 7 SBunt (1987) states that an expression with n constants results in 2 n - 1 possible inverse ~-reductlons. 7As proposed in van der Linden and Minnen (submitted) for the calculus in (2). 225"]},{"title":"6 REFERENCES","paragraphs":["Ades, A., and Steedman, M., 1982 On the order of words. Linguistics and Pkilosoph~/, 4, pp. 517-558. Appelt, D.E., 1987 Bidirectional Grammars and the Design of Natural Language Systems. In Wilks, Y. (Ed.), Theoretical Issues in Natural Language Processing. Las Cruces, New Mexico: New Mexico State University, January 7-9, pp. 185-191. Van Benthem, J., 1988 Categorial Grammar. Chapter 7 in Van Benthem, J., Essays in Logical Semantics. Reidel, Dordrecht. Boums, G., 1989 Emcient Processing of Flexible Categorial Grammar. In Proceedings of the EACL 1989, Manchester. pp. 19-26. Bunt, H., 1987 Utterance generation from semantic representations augmented with pragmatic information. In Kempen 1987. Calder, J., Reape M., and Zeevat, H., 1989 An algorithm for generation in Unification Categorial Grammar. In Proceedings of the EACL 1989, Manchester. pp. 233-240. Crain, S., and Steedman, M., 1982 On not being led up the garden path. In Dowry, Karttunen and Zwicky (Eds.) Natu~l language pQrsing. Cambridge: Cambridge University Press. Jacobs, P., 1985 PHRED, A generator for Natural Language Interfaces. Computational Linguistics 11, 4, pp. 219-242. Kempen , G., (Ed.) 1987 Natural language generation: new results in artificial intelligence, pay. cttology and linouiatics. Dordrecht: Nijhoff. K6nig, E., 1989 Parsing as natured deduction. In Proceedings of the ACL 1989, Vancouver. Lsmbek, J., 1958 The mathematics of sentence structure. Am. Math Monthly, 85, 154-169. Linden, E. van der, and Minnen, G., (submitted) An account of Non-monotonous phenomena in bidirectional Lambek Theorem Proving. Moortgat, M., 1988 Categorial Inueatigetions. Logical and Hnguistic ¢apects of the Lambek calculus. Disseration, University of Amsterdam. Shieber, S., 1988 A uniform architecture for Parsing and Generation. In Proceedings of Coling 1988, Budapest, pp. 614-619. Shieber, S., van Noord, G., Moore, R., and Pereira, P., 1989 A semantic-Head-Driven Generation Algorithm for Unification-Based Formallsms. In Proceedings of ACL 1989 Vancouver. Steedman, M., 1987 Combinatory Grammars and Parasitic Gaps Natural Language and Linguistic Theory, 5, pp. 403-439. 226"]}]}
