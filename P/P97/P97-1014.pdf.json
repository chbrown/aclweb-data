{"sections":[{"title":"Centering in-the-Large: Computing Referential Discourse Segments Udo Hahn & Michael Strube","paragraphs":["Computational Linguistics Research Group","Freiburg University, Werthmannplatz 1","D-79085 Freiburg, Germany","http://www.coling.uni-freiburg.de/"]},{"title":"Abstract","paragraphs":["We specify an algorithm that builds up a hierarchy of referential discourse segments from local centering data. The spatial extension and nesting of these discourse segments constrain the reachability of potential antecedents of an anaphoric expression beyond the local level of adjacent center pairs. Thus, the centering model is scaled up to the level of the global referential structure of discourse. An empirical evaluation of the algorithm is supplied."]},{"title":"1 Introduction","paragraphs":["The centering model (Grosz et al., 1995) has evolved as a major methodology for computational discourse analysis. It provides simple, yet powerful data structures, constraints and rules for the"]},{"title":"local","paragraphs":["coherence of discourse. As far as anaphora resolution is concerned, e.g., the model requires to consider those discourse entities as potential antecedents for anaphoric expressions in the current utterance Ui, which are available in the forward-looking centers of the"]},{"title":"immediately preceding","paragraphs":["utterance Ui- 1. No constraints or rules are formulated, however, that account for anaphoric relationships which spread out over non-adjacent utterances. Hence, it is unclear how discourse elements which appear in utterances preceding utterance Ui-1 are taken into consideration as potential antecedents for anaphoric expressions in"]},{"title":"Ui.","paragraphs":["The extension of the search space for antecedents is by no means a trivial enterprise. A simple linear backward search of all preceding centering structures, e.g., may not only turn out to establish illegal references but also contradicts the cognitive principles underlying the limited attention constraint (Walker, 1996b). The solution we propose starts from the observation that additional constraints on valid antecedents are placed by the"]},{"title":"global","paragraphs":["discourse structure previous utterances are embedded in. We want to emphasize from the beginning that our proposal considers only the"]},{"title":"referential","paragraphs":["properties underlying the global discourse structure. Accordingly, we define the"]},{"title":"extension","paragraphs":["of referential discourse segments (over several utterances) and a"]},{"title":"hierarchy","paragraphs":["of referential discourse segments (structuring the entire discourse). 1 The algorithmic procedure we propose for creating and manag-ing such segments receives local centering data as input and generates a sort of superimposed index structure by which the reachability of potential antecedents, in particular those prior to the immediately preceding utterance, is made explicit. The adequacy of this definition is judged by the effects centered discourse segmentation has on the validity of anaphora resolution (cf. Section 5 for a discussion of evaluation results)."]},{"title":"2 Global Discourse Structure","paragraphs":["There have been only few attempts at dealing with the recognition and incorporation of discourse structure beyond the level of immediately adjacent utterances within the centering framework. Two recent studies deal with this topic in order to relate attentional and intentional structures on a larger scale of global discourse coherence. Passonneau (1996) proposes an algorithm for the generation of referring expressions and Walker (1996a) integrates centering into a cache model of attentional state. Both studies, among other things, deal with the supposition whether a correlation exists between particular centering transitions (which were first introduced by Brennan et al. (1987); cf. Table 1) and intention-based discourse segments. In particular, the role of SHIFT-type transitions is examined from the perspective of whether they not only indicate a shift of the topic between two immediately successive utterances but also signal (intention-based) segment boundaries. The data in both studies reveal that only a weak correlation between the SHIFT transitions and segment boundaries can be observed. This finding precludes a reliable predic-tion of segment boundaries based on the occurrence of 1 Our notion of"]},{"title":"referential","paragraphs":["discourse segment should not be confounded with the"]},{"title":"intentional","paragraphs":["one originating from Grosz & Sidner (1986), for reasons discussed in Section 2."]},{"title":"104","paragraphs":["SHIFTS and"]},{"title":"vice versa.","paragraphs":["In order to accommodate to these empirical results divergent solutions are proposed. Passonneau suggests that the centering data structures need to be modified appropriately, while Walker concludes that the local centering data should be left as they are and further be complemented by a cache mechanism. She thus intends to extend the scope of centering in accordance with cognitively plausible limits of the attentional span. Walker, finally, claims that the content of the cache, rather than the intentional discourse segment structure, determines the accessibility of discourse entities for anaphora resolution."]},{"title":"c~(v.) = cdu.-~) c~(u.) #","paragraphs":["OR"]},{"title":"Cb(Vn-1)","paragraphs":["undef."]},{"title":"Cb(Vn-1) Cb(Un)","paragraphs":["= CONTINUE (C) SMOOTH-SHIFT (SS)"]},{"title":"c~(u.) cb(u.) #","paragraphs":["RETAIN (R) ROUGH-SHIFT"]},{"title":"(RS) c~(u.)","paragraphs":["Table h Transition Types","As a working hypothesis, for the purposes of anaphora resolution we subscribe to Walker's model, in particular to that part which casts doubt on the hypothesized dependency of the attentional from the intentional structure of discourse (Grosz & Sidner, 1986, p. 180). We diverge from Walker (1996a), however, in that we propose an alternative to the caching mechanism, which we consider to be methodologically more parsimonious and, at least, to be equally effective (for an elaboration of this claim, cf. Section 6).","The proposed extension of the centering model builds on the methodological framework"]},{"title":"of functional center- ing","paragraphs":["(Strube & Hahn, 1996). This is an approach to centering in which issues such as thematicity or topicality are already inherent. Its linguistic foundations relate the ranking"]},{"title":"of the forward-looking centers and the functional information structure","paragraphs":["of the utterances, a notion originally developed by Dane~ (1974). Strube & Hahn (1996) use the centering data structures to redefine Dane~'s trichotomy between"]},{"title":"given information, theme and rheme","paragraphs":["in terms of the centering model. The"]},{"title":"Cb(Un),","paragraphs":["the most highly ranked element of"]},{"title":"C! (Un-1)","paragraphs":["realized in"]},{"title":"Un,","paragraphs":["corresponds to the element which represents the"]},{"title":"given","paragraphs":["in-formation. The"]},{"title":"theme","paragraphs":["of"]},{"title":"Un","paragraphs":["is represented by the preferred center"]},{"title":"Cp (Un),","paragraphs":["the most highly ranked element of"]},{"title":"C! ( Un ). The theme/rheme hierarchy","paragraphs":["of"]},{"title":"Un","paragraphs":["corresponds to the ranking in the C! s. As a consequence, utterances without any anaphoric expression do not have any"]},{"title":"given","paragraphs":["elements and, therefore, no"]},{"title":"Cb.","paragraphs":["But independent of the use of anaphoric expressions, each utterance must have a theme and a"]},{"title":"C! as","paragraphs":["well. The identification of the"]},{"title":"preferred center","paragraphs":["with the"]},{"title":"theme","paragraphs":["implies that it is of major relevance for determin-ing the thematic progression of a text. This is reflected in our reformulation of the two types of thematic progression (TP) which can be directly derived from centering data (the third one requires to refer to conceptual generalization hierarchies and is therefore beyond the scope of this paper, cf. Dane~ (1974) for the original statement):"]},{"title":"1. TP with a constant theme:","paragraphs":["Successive utterances continuously share the same Cp."]},{"title":"2. TP with linear thematization of rhemes:","paragraphs":["An element of the"]},{"title":"C! (Ui- 1 )","paragraphs":["which is not the Cp (Ui- 1 ) appears in"]},{"title":"Ui","paragraphs":["and becomes the Cp(Ui) after the processing of this utterance. Cf(Vi-1) : [ c 1 ..... ej ..... cs ]"]},{"title":"C~(Vi) : [","paragraphs":["Cl ..... ck ..... et"]},{"title":"]","paragraphs":["Cf(Ui-1): [el ..... cj ..... cs] l<j<s Cf(Vd: [el ..... ek ..... e~l Table 2: Thematic Progression Patterns Table 2 visualizes the abstract schemata of"]},{"title":"TP pat- terns.","paragraphs":["In our example (cf. Table 8 in Section 4), U1 to Ua illustrate the"]},{"title":"constant theme,","paragraphs":["while U7 to U10 illustrate the"]},{"title":"linear thematization of rhemes.","paragraphs":["In the latter case, the theme changes in each utterance, from"]},{"title":"\"Handbuch\" (manual)","paragraphs":["via"]},{"title":"\"Inhaltsverzeichnis\" (table of contents)","paragraphs":["to"]},{"title":"\"Kapitel\" (chapter)","paragraphs":["etc. Each of the new themes are introduced in the immediately preceding utterance so that local coherence between these utterances is established.","Daneg (1974) also allows for the combination and recursion of these basic patterns; this way the global thematic coherence of a text can be described by recurrence to these structural patterns. These principles allow for a major extension of the original centering algorithm. Given a reformulation of the TP constraints in centering terms, it is possible to determine referential segment boundaries and to arrange these segments in a nested, i.e., hierarchical manner on the basis of which reachability constraints for antecedents can be formulated. According to the segmentation strategy of our approach, the Cp of the end point (i.e., the last utterance) of a discourse segment provides the major theme of the whole segment, one which is particularly salient for anaphoric reference relations. Whenever a relevant new theme is established, however, it should reside in its own discourse segment, either embedded or in parallel to another one. Anaphora resolution can then be performed"]},{"title":"(a)","paragraphs":["with the forward-looking centers of the linearly immediately preceding utterance,"]},{"title":"(b)","paragraphs":["with the forward-looking centers of the end point of the hierarchically immediately reachable discourse segment, and"]},{"title":"(c)","paragraphs":["with the preferred center of the end point of any hierarchically reachable discourse segment (for a formalization of this constraint, cf. Table 4)."]},{"title":"105 3 Computing Global Discourse Structure","paragraphs":["Prior to a discussion of the algorithmic procedure for hypothesizing discourse segments based on evidence from local centering data, we will introduce its basic build-ing blocks. Let x denote the anaphoric expression under consideration, which occurs in utterance Ui associated with segment level s. The function"]},{"title":"Resolved(x, s, Us)","paragraphs":["(cf. Table 3) is evaluated in order to determine the proper antecedent"]},{"title":"ante","paragraphs":["for x. It consists of the evaluation of a teachability predicate for the antecedent on which we will concentrate here, and of the evaluation of the predicate"]},{"title":"lsAnaphorFor","paragraphs":["which contains the linguistic and conceptual constraints imposed on a (pro)nominal anaphor"]},{"title":"(viz.","paragraphs":["agreement, binding, and sortal constraints) or a textual ellipsis (Hahn et al., 1996), not an issue in this paper. The predicate"]},{"title":"lsReachable","paragraphs":["(cf. Table 4) requires"]},{"title":"ante","paragraphs":["to be reachable from the utterance Us associated with the segment level s. 2 Reachability is thus made dependent on the segment structure"]},{"title":"DS","paragraphs":["of the discourse as built up by the segmentation algorithm which is specified in Table 6. In Table 4, the symbol \"=str\" denotes string equality, N the natural numbers. We also introduce as a notational convention that a discourse segment is identified by its index s and its opening and closing utterance, viz."]},{"title":"DS[s.beg]","paragraphs":["and"]},{"title":"DS[s.end],","paragraphs":["respectively. Hence, we may either identify an utterance"]},{"title":"Ui","paragraphs":["by its linear text index, i, or, if it is accessible, with respect to its hierarchical discourse segment index, s (e.g., cf. Table 8 where U3 ="]},{"title":"UDs[1.end]","paragraphs":["or U13 = UDs[3.end])."]},{"title":"The","paragraphs":["discourse segment"]},{"title":"index","paragraphs":["is always identical to the currently valid segment"]},{"title":"level,","paragraphs":["since the algorithm in Table 6 implements a stack behavior. Note also that we attach the discourse segment index s to center expressions, e.g.,"]},{"title":"Cb(s, Us). Resolved(x, s, Ui)","paragraphs":[":="]},{"title":"l ante if IsReachable(ante, s,","paragraphs":["Ui)"]},{"title":"A IsAnaphorFor(x, ante) under else","paragraphs":["Table 3: Resolution of Anaphora"]},{"title":"IsReachable(ante, s, Ui ) if ante","paragraphs":["6"]},{"title":"C/(s, Ui-1) else if ante","paragraphs":["E"]},{"title":"C/(s - 1, Uosts_,.~,a]) else if (3v E N : ante =~tr Cp(v, UDsI .... a])","paragraphs":["̂v < (s - 1)) A (-~Sv' 6 N:"]},{"title":"ante","paragraphs":["=,t,-"]},{"title":"Cp(v',UDst~,.~ndl)","paragraphs":["A v < v') Table 4: Reachability of the Anaphoric Antecedent Finally, the function"]},{"title":"Lift(s, i)","paragraphs":["(cf. Table 5) determines the appropriate discourse segment level, s, of an utter-2The Cf lists in the functional centering model are"]},{"title":"totally","paragraphs":["ordered (Strobe & Hahn, 1996, p.272) and we here implicitly assume that they are accessed in the total order given. ance"]},{"title":"Ui","paragraphs":["(selected by its linear text index,"]},{"title":"i). Lift","paragraphs":["only applies to structural configurations in the centering lists in which themes continuously shift at three different consecutive segment levels and associated preferred centers at least (cf. Table 2, lower box, for the basic pattern)."]},{"title":"Lift(s, i)","paragraphs":[":="]},{"title":"Lift(s- 1, i-","paragraphs":["1)"]},{"title":"if","paragraphs":["s>2Ai>3 ̂c.(s,u,_~) # c~(~ -","1,u,_~) ̂c~(s - I, u,_~) # c.(s - 2, u,_~) ̂c~(s,u,_,) • cj(s- 1,u,_~)","8 else Table 5: Lifting to the Appropriate Discourse Segment","Whenever a discourse segment is created, its starting and closing utterances are initialized to the current position in the discourse. Its end point gets continuously incremented as the analysis proceeds until this discourse segment DS is"]},{"title":"ultimately closed,","paragraphs":["i.e., whenever another segment"]},{"title":"DS'","paragraphs":["exists at the"]},{"title":"same","paragraphs":["or a"]},{"title":"hierarchically higher","paragraphs":["level of embedding such that the end point of"]},{"title":"DS'","paragraphs":["exceeds that of the end point of"]},{"title":"DS.","paragraphs":["Closed segments are inaccessible for the antecedent search. In Table 8, e.g., the first two discourse segments at level 3 (ranging from U5 to U5 and Us to Ull ) are closed, while those at level 1 (ranging from U1 to U3), level 2 (ranging from U4 to"]},{"title":"UT)","paragraphs":["and level 3 (ranging from U12 to U13) are open. The main algorithm (see Table 6) consists of three major logical blocks (s and Ui denote the current discourse segment level and utterance, respectively). 1. Continue Current Segment. The"]},{"title":"Cp(s, Ui-1)","paragraphs":["is taken over for"]},{"title":"Ui.","paragraphs":["If Ui-1 and Ui indicate the end of a sequence in which a series of thematizations of rhemes have occurred, all embedded segments are lifted by the function"]},{"title":"Lift","paragraphs":["to a higher level s'. As a result of lifting, the entire sequence (including the final two utterances) forms a single segment. This is trivially true for cases of a constant theme.","2. Close Embedded Segment(s). (a)"]},{"title":"Close the embedded segment(s) and continue another, already existing segment:","paragraphs":["If"]},{"title":"Ui","paragraphs":["does not include any anaphoric expression which is an element of the"]},{"title":"Cf (s, Ui-O,","paragraphs":["then match the antecedent in the hierarchically reachable segments. Only the Cp of the utterance at the end point of any of these segments is considered a potential antecedent. Note that, as a side effect, hierarchically lower segments are ultimately closed when a match at higher segment levels succeeds.","(b)"]},{"title":"Close the embedded segment and open a new, parallel one:","paragraphs":["If none of the anaphoric expressions under consideration co-specify the"]},{"title":"106","paragraphs":["Cp(8 -"]},{"title":"1, U[8_l.end]),","paragraphs":["then the entire"]},{"title":"C!","paragraphs":["at this segment level is checked for the given utterance. If an antecedent matches, the segment which contains"]},{"title":"Ui- 1","paragraphs":["is ultimately closed, since Ui opens a parallel segment at the"]},{"title":"same","paragraphs":["level of embedding. Subsequent anaphora checks exclude any of the preceding parallel segments from the search for a valid antecedent and just visit the currently open one.","(c)"]},{"title":"Open new, embedded segment:","paragraphs":["If there is no","matching antecedent in hierarchically reach-","able segments, then for utterance Ui a new, em-","bedded segment is opened.","3. Open New, Embedded Segment. If none of the above cases applies, then for utterance Ui a new, embedded segment is opened. In the course of processing the following utterances, this decision may be retracted by the function"]},{"title":"Lift.","paragraphs":["It serves as a kind of \"garbage collector\" for globally insignificant discourse segments which, nevertheless, were reasonable from a local perspective for reference resolution purposes. Hence, the centered discourse segmentation procedure works in an incremental way and revises only locally relevant, yet globally irrelevant segmentation decisions on the fly. s:=l i:=1"]},{"title":"DS[s.be9]","paragraphs":[":= i"]},{"title":"DS[s.end]","paragraphs":[":= i while --"]},{"title":"end of text","paragraphs":["i:=i+1"]},{"title":"n := {Resolved(x,s, Ui) lx E U~}","paragraphs":["if3r • T~ : r ~---str Cp(s, Ui-1) (1)","then s' 1= s i' := i"]},{"title":"DS[Lift(s', i').end]","paragraphs":[":= i else if~3r"]},{"title":"E Tt : r • Cl(s, Ui_l )","paragraphs":["(2a) then"]},{"title":"found","paragraphs":[":="]},{"title":"FALSE","paragraphs":["k:~s","while-,found A (k > 1) k:=k-1 i_f3r • 7?.: r =s,r Cp(k, Utk.~,,~) then s := k"]},{"title":"DS[s.end]","paragraphs":[":= i"]},{"title":"found","paragraphs":[":="]},{"title":"TRUE else","paragraphs":["if k = s - 1 (2b) then if3r •~:r•"]},{"title":"Cs(k, Utk.o,,,~)","paragraphs":["then"]},{"title":"DS[s.beg]","paragraphs":[":= i"]},{"title":"DS[s.end]","paragraphs":[":= i"]},{"title":"found := TRUE if -,found","paragraphs":["(2e) then s := s + 1"]},{"title":"DS[s.beg]","paragraphs":[":= i"]},{"title":"DS[s.end]","paragraphs":[":= i else s := s q- 1 (3)"]},{"title":"DS[s.beg]","paragraphs":[":= i"]},{"title":"DS[s.end]","paragraphs":[":= i Table 6: Algorithm for Centered Segmentation"]},{"title":"4 A Sample Text Segmentation","paragraphs":["The text with respect to which we demonstrate the working of the algorithm (see Table 7) is taken from a German computer magazine"]},{"title":"(c't,","paragraphs":["1995, No.4, p.209). For ease of presentation the text is somewhat shortened. Since the method for computing levels of discourse segments depends heavily on different kinds of anaphoric expressions, (pro)nominal anaphors and textual ellipses are marked by italics, and the (pro)nominal anaphors are underlined, in addition. In order to convey the influence of the German word order we provide a rough phrase-to-phrase translation of the entire text.","The centered segmentation analysis of the sample text is given in Table 8. The first column shows the linear text index of each utterance. The second column contains the centering data as computed by functional centering (Strube & Hahn, 1996). The first element of the"]},{"title":"C I,","paragraphs":["the"]},{"title":"preferred center, Cp,","paragraphs":["is marked by bold font. The third column lists the centering transitions which are derived from the"]},{"title":"Cb/C!","paragraphs":["data of immediately successive utterances (cf. Table 1 for the definitions). The fourth column depicts the levels of discourse segments which are computed by the algorithm in Table 6. Horizontal lines indicate the beginning of a segment (in the algorithm, this corresponds to a value assignment to"]},{"title":"DS[s.beg]).","paragraphs":["Verti-cal lines show the extension of a segment (its end is fixed by an assignment to"]},{"title":"DS[s.end]). The","paragraphs":["fifth column indicates which block of the algorithm applies to the current utterance (cf. the right margin in Table 6). The computation starts at U1, the headline. The"]},{"title":"C1(Ux )","paragraphs":["is set to"]},{"title":"\"1260\"","paragraphs":["which is meant as an abbreviation of"]},{"title":"\"Brother HL-1260\".","paragraphs":["Upon initialization, the beginning as well as the ending of the initial discourse segment are both set to \"1\". U2 and Ua simply continue this segment (block (1) of the algorithm), so"]},{"title":"Lift","paragraphs":["does not apply. The"]},{"title":"C v","paragraphs":["is set to"]},{"title":"\"1260\"","paragraphs":["in all utterances of this segment. Since U4 does neither contain any anaphoric expression which co-specifies the"]},{"title":"Cv(1 ,","paragraphs":["Ua) (block (1)) nor any other element of the 67/( 1, U3) (block (2a)), and as there is no hierarchically preceding segment, block (2c) applies. The segment counter s is incremented and a new segment at level 2 is opened, set-ting the beginning and the ending to \"4\". The phrase"]},{"title":"\"das diinne Handbiichlein\" (the thin leaflet)","paragraphs":["in U5 does not co-specify the"]},{"title":"C v","paragraphs":["(2, U4) but co-specifies an element of the"]},{"title":"C!","paragraphs":["(2, U4) instead"]},{"title":"(viz. \"Handbuch\" (manual)).","paragraphs":["Hence, block (3) of the algorithm applies, leading to the creation of a new segment at level 3. The anaphor"]},{"title":"\"Handbuch\" (manual)","paragraphs":["in U6 co-specifies the"]},{"title":"Cv(3 , Us).","paragraphs":["Hence block (1) applies (the occurrence of"]},{"title":"\"1260\"","paragraphs":["in"]},{"title":"CI(U5 )","paragraphs":["is due to the assumptions specified by Strube & Hahn (1996)). Given this configuration, the function"]},{"title":"Lift","paragraphs":["lifts the embedded segment one level, so the 107 (1) (2) (3)"]},{"title":"(4)","paragraphs":["(5) (6) (7) Brother HL- 1260 Ein Detail fiillt schon beim ersten Umgang mit dem grogen Brother auf: One particular - is already noticed - in the first approach to - the big Brother. Im Betrieb macht e._gr durch ein kr~iftiges Arbeitsger~usch auf sich aufmerksam, das auch im Stand-by-Modus noch gut vemehmbar ist. In operation - draws - it - with a heavy noise level - attention to itself- which - also - in the stand-by mode - is still well audible. F~r Standard-InstaUationen kommt man gut ohne Handbuch aus. As far as standard installations are concerned- gets - one - well - by - without any manual. Zwar ed~iutert das dSnne Handbiichlein die Bedienung der Hardware anschaulich und gut illustriert. Admittedly, gives - the thin leaflet- the operation of the hardware- a clear description of - and - well illustrated. Die Software-Seite wurde im Handbuch dagegen stiefmSttedich behandelt: The software part - was - in the manual- however - like a stepmother- treated: bis auf eine karge Seite mit einem Inhaltsverzeichnis zum HP-Modus sucht man vergebens weitere Informationen. except for one meagre page- containing the table of contents for the HP mode - seeks- one- in vain- for further information.","(8) Kein Wander: unter dem lnhaltsverzeichnis steht der lapidare Hinweis, man m6ge sich die Seiten dieses Kapitels doch bitte yon Diskette ausdrucken- Frechheit. No wonder: beneath the table of contents - one finds the terse instruction, one should - oneself- the pages of this section - please - from disk - print out - - impertinence.","(9) Ohne diesen Ausdruck sucht man vergebens nach einem Hinweis darauf, warum die Auto-Continue-Funktion in der PostScript-Emulation nicht wirkt. Without this print-out, looks - one - in vain - for a hint - why - the auto-continue-function - in the PostScript emulation - does not work.","(10) Nach dem Einschalten zeigt das LC-Display an, dab diese praktische Hilfsfunktion nicht aktiv ist; After switching on - depicts - the LC display - that - this practical help function - not active - is;","(11) si__.ge tiberwacht den Dateientransfer vom Computer. it monitors the file transfer from the computer.","(12) Viele der kleinen Macken verzeiht man dem HL-1260 wenn man erste Ausdrucke in H~inden h~ilt. Many of the minor defects - pardons - one - the HL-1260, when - one - the first print outs - holds in [one' s] hands. (13) Gerasterte Grauflftchen erzeugt der Brother sehr homogen Raster-mode grey-scale areas - generates - the Brother-very homogeneously... Table 7: Sample Text segment which ended with U4 is now continued up to U6 at level 2. As a consequence, the centering data of U5 are excluded from further consideration as far as the co-specification by any subsequent anaphoric expression is concerned. Uz simply continues the same segment, since the textual ellipsis \"Seite\" (page) refers to \"Handbuch\" (manual). The utterances U8 to U10 exhibit a typical thematization-of-the-rhemes pattern which is quite common for the detailed description of objects. (Note the sequence of SHIFT transitions.) Hence, block (3) of the algorithm applies to each of the utterances and, correspondingly, new segments at the levels 3 to 5 are created. This behavior breaks down at the occurrence of the anaphoric expression \"sie\" (it) in Uxl which co-specifies the Cp ( 5, Ul o ), viz. \"auto-continue function\", denoted by another anaphoric expression, namely \"Hilfsfunktion\" (help function) in U10. Hence, block (1) applies. The evaluation of Lift succeeds with respect to two levels of embedding. As a result, the whole sequence is lifted up to level 3 and continues this segment which started at the discourse element \"lnhaltsverzeichhis\" (list of contents). As a result of applying Lift, the whole sequence is captured in one segment. U12 does not contain any anaphoric expression which co-specifies an element of the C! (3, U11), hence block (2) of the algorithm applies. The anaphor \"HL-1260\" does not co-specify the Cp of the utterance which represents the end of the hierarchically preceding discourse segment (UT), but it co-specifies an element of the C! (2, UT). The immediately preceding segment is ultimately closed and a parallel segment is opened at UI~ (cf. block (2b)). Note also that the algorithm does not check the C! (3, U10) despite the fact that it contains the antecedent of \"1260\". However, the occurrences of \"1260\" in the Cfs of U9 and Ux0 are mediated by textual ellipses. If these utterances contained the expression \"1260\" itself, the algorithm would have built a different discourse structure and, therefore, \"1260\" in U10 were reachable for the anaphor in Ulz. Segment 3, finally, is continued by Ulz. 5 Empirical Evaluation In this section, we present some empirical data concern-ing the centered segmentation algorithm. Our study was based on the analysis of twelve texts from the informa-tion technology domain (IT), of one text from a Ger-"]},{"title":"108","paragraphs":["U~ (1) Cb: Cf.\" (2) Cb: Cf: (3) Cb: Cf: (4) Cb: Cf.\" (5) Cb: Cf: (6) Cb: Cf: (7) Cb: Cf: (8) Cb: Cf: (9) Cb: Cf:","(10) Cb:","Cf:","(11) Cb:","Cf:","(12) Cb:","Cf:","(13) Cb:","Cf: Centering Data Trans. [1260] 1260 C [1260, Umgang, Detail] 1260 C [1260, Betrieb, Arbeitsger~usch, Stand-by-Modus] [Standard-Installation, Handbuch] Handbuch C [Handbueh, 1260, Hardware, Bedienung] Handbuch C [Handbuch, 1260, Software] Handbuch C [Handbueh, Seite, 1260, HP-Modus, Inhaltsverzeichnis, Informationen] Inhaltsverzeichnis SS [Inhaltsverzeiehnis, Hinweis, Seiten, Kapitel, Diskette, Frechheit] Kapitel SS [Kapitel, Ausdmck, Hinweis, 1260, Auto-Continue-Funktion, PostScript-Emulation] 1260 RS [Auto-Continue-Funktion, 1260, LC-Display] Auto-Continue-Funktion SS [Auto-Continue-Funktion, Dateien-Transfer, Computer] [1260, Macken, Ausdmck] 1260 C [1260, Graufl~ichen] man news magazine (Spiegel) 3, and of two literary texts 4 (Lit). Table 9 summarizes the total numbers of anaphors, textual ellipses, utterances, and words in the test set. Levels of Discourse Segments 1 2 3 4 5 E 496 240 547 8319 IT Spiegel anaphors 197 101 198 ellipses 195 22 23 utterances 336 84 127 words 5241 1468 1610 Block 1 1 2e 3 1, Lift 1 I 3 1, Lift 2b Table 8: Sample of a Centered Text Segmentation Analysis neither specified for anaphoric antecedents in Ui, not an issue here, nor for anaphoric antecedents beyond Ui-1. In the test set, 139 anaphors (28%) and 116 textual ellipses (48,3%) fall out of the (intersentential) scope of Lit those common algorithms. So, the problem we consider is not a marginal one. U~ Ui-2 Ui-a Ui-4 Ui-5 Table 9: Test Set","Table 10 and Table 11 consider the number of anaphoric and text-elliptical expressions, respectively, and the linear distance they have to their corresponding antecedents. Note that common centering algorithms (e.g., the one by Brennan et al. (1987)) are specified only for the resolution of anaphors in Ui-1. They are","3japan - Der Neue der alten Garde. In Der Spiegel, Nr. 3, 1996.","4The first two chapters of a short story by the German writer Heiner MOiler (Liebesgeschichte. In Heiner MOiler. Geschichten aus der Produktion 2. Berlin: Rotbuch Verlag, 1974, pp.57-63) and the first chapter of a novel by Uwe Johnson (ZweiAnsichten. Frankfurt/Main: Suhrkamp Verlag, 1965.) 10 117 28 18 6 6 Lit E 7 32 49 70 121 308 14 24 66 5 10 33 1 5 12 0 1 7 1 3 12 1 1 5 2 1 4 Ui-~ to Ui-lO 8 Ui-l, to Ui-15 3 Ui-l~ to U,-2o 1 Table 10: Anaphoric Antecedent in Utterance U~","Table 12 and Table 13 give the success rate of the centered segmentation algorithm for anaphors and textual ellipses, respectively. The numbers in these tables indicate at which segment level anaphors and textual ellipses were correctly resolved. The category of errors"]},{"title":"109","paragraphs":["U/-1"]},{"title":"Ui-2","paragraphs":["Ui-3"]},{"title":"Ui-4 Ui-5","paragraphs":["Ui-6 to Ui-lo Ui-u to Ui-15 IT Spiegel Lit E 94 15 15 124 42 6 8 56 16 0 0 16 14 0 0 14 8 0 0 8 14 1 0 15 7 0 0 7 Table 11: Elliptical Antecedent in Utterance U covers erroneous analyses the algorithm produces, while the one for false positives concerns those resolution results where a referential expression was resolved with the hierarchically most recent antecedent but not with the linearly most recent (obviously, the targeted) one (both of them denote the same discourse entity). The categories Cy(s, Ui-1) in Tables 12 and 13 contain more elements than the categories Ui-1 in Tables 10 and 11, respectively, due to the mediating property of textual ellipses in functional centering (Strube & Hahn, 1996). U~"]},{"title":"cI(~,U~-,)","paragraphs":["Cp(s - 1, UDS[,--L,,d]) C/(s - 1, UDsls--l.end])"]},{"title":"Cp(s","paragraphs":["-"]},{"title":"2, UDS[8-2...~)","paragraphs":["Cp(s -","3, UDS[~-3.,,~) Cp(s - 4, UDSl,--4.,,d]) c~( ~ - s, uo s[,-~.,,~l) errors false positives"]},{"title":"~m","paragraphs":["10 7 32 49 161 78 125 364 14 9 24 47 7 5 9 21 1 0 1 2 1 0 1 2 0 0 1 1 0 1 0 I 3 1 5 9 (I) (3) (7) (11) Table 12: Anaphoric Antecedent in Center~"]},{"title":"cl (s, U~-i )","paragraphs":["Cp(s - 1, UDSi,-1.,,~d]) CI(s - 1, Uosls-~.*,a]) Cp(s - 2, Uosts-~.~,,~l) Cp(s - 3, UDats-Z.ena]) errors IT","Spiegel Lit 156 18 17 18 0 4 10 1 2 7 1 0 3 0 0 1 2 0 (2) (0) (3) E 191 22 13 8 3 3"]},{"title":"(5)","paragraphs":["Table 13: Elliptical Antecedent in Centerx","The centered segmentation algorithm reveals a pretty good performance. This is to some extent implied by the structural patterns we find in expository texts, viz. their single-theme property (e.g., \"1260\" in the sample text). In contrast, the literary texts in the test exhibited a much more difficult internal structure which resembled the multiple thread structure of dialogues discussed by Ros6 et al. (1995). The good news is that the segmentation procedure we propose is capable of dealing even with these more complicated structures. While only one antecedent of a pronoun was not reachable given the superimposed text structure, the remaining eight errors are characterized by full definite noun phrases or proper names. The vast majority of these phenomena can be considered informationally redundant utterances in the terminology of Walker (1996b) for which we currently have no solution at all. It seems to us that these kinds of phrases may override text-grammatical structures as evidenced by referential discourse segments and, rather, trigger other kinds of search strategies.","Though we fed the centered segmentation algorithm with rather long texts (up to 84 utterances), the antecedents of only two anaphoric expressions had to bridge a hierarchical distance of more than 3 levels. This coincides with our supposition that the overall structure computed by the algorithm should be rather fiat. We could not find an embedding of more than seven levels."]},{"title":"6 Related Work","paragraphs":["There has always been an implicit relationship between the local perspective of centering and the global view of focusing on discourse structure (cf. the discussion in Grosz et al. (1995)). However, work establishing an explicit account of how both can be joined in a computational model has not been done so far. The efforts of Sidner (1983), e.g., have provided a variety of different focus data structures to be used for reference resolution. This multiplicity and the on-going growth of the number of different entities (cf. Suri & McCoy (1994)) mirrors an increase in explanatory constructs that we consider a methodological drawback to this approach because they can hardly be kept control of. Our model, due to its hierarchical nature implements a stack behavior that is also inherent to the above mentioned proposals. We refrain, however, from establishing a new data type (even worse, different types of stacks) that has to be managed on its own. There is no need for extra computations to determine the \"segment focus\", since that is implicitly given in the local centering data already available in our model.","A recent attempt at introducing global discourse no-tions into the centering framework considers the use of a cache model (Walker, 1996b). This introduces an additional data type with its own management principles for data storage, retrieval and update. While our proposal for centered discourse segmentation also requires a data structure of its own, it is better integrated into centering than the caching model, since the cells of segment structures simply contain \"pointers\" that implement a direct link to the original centering data. Hence, we avoid extra operations related to feeding and updating the cache. The relation between our centered segmentation algorithm and Walker's (1996a) integration of centering into the cache model can be viewed from two different angles. On the one hand, centered segmentation may be a part of the cache model, since it provides an elaborate, non-linear ordering of the elements within the cache. Note, however, that our model does not require any prefixed size corresponding to the limited attention constraint. On the other hand, centered segmentation may replace the"]},{"title":"110","paragraphs":["cache model entirely, since both are competing models of the attentional state. Centered segmentation has also the additional advantage of restricting the search space of anaphoric antecedents to those discourse entities actually referred to in the discourse, while the cache model allows unrestricted retrieval in the main or long-term memory.","Text segmentation procedures (more with an informa-tion retrieval motivation, rather than being related to reference resolution tasks) have also been proposed for a coarse-grained partitioning of texts into contiguous, nonoverlapping blocks and assigning content labels to these blocks (Hearst, 1994). The methodological basis of these studies are lexical cohesion indicators (Morris & Hirst, 1991) combined with word-level co-occurrence statistics. Since the labelling is one-dimensional, this approximates our use of preferred centers of discourse segments. These studies, however, lack the fine-grained informa-tion of the contents of Cf lists also needed for proper reference resolution.","Finally, many studies on discourse segmentation highlight the role of cue words for signaling segment boundaries (cf., e.g., the discussion in Passonneau & Litman (1993)). However useful this strategy might be, we see the danger that such a surface-level description may actually hide structural regularities at deeper levels of investigation illustrated by access mechanisms for centering data at different levels of discourse segmentation."]},{"title":"7 Conclusions","paragraphs":["We have developed a proposal for extending the centering model to incorporate the global referential structure of discourse for reference resolution. The hierarchy of discourse segments we compute realizes certain constraints on the reachability of antecedents. Moreover, the claim is made that the hierarchy of discourse segments implements an intuitive notion of the limited attention constraint, as we avoid a simplistic, cognitively implausible linear backward search for potentional discourse referents. Since we operate within a functional framework, this study also presents one of the rare formal accounts of thematic progression patterns for full-fledged texts which were informally introduced by Dane~ (1974).","The model, nevertheless, still has several restrictions. First, it has been developed on the basis of a small corpus of written texts. Though these cover diverse text sorts (viz. technical product reviews, newspaper articles and literary narratives), we currently do not account for spoken monologues as modelled, e.g., by Passonneau & Litman (1993) or even the intricacies of dyadic conversations Ros6 et al. (1995) deal with. Second, a thorough integration of the referential and intentional description of discourse segments still has to be worked out. Acknowledgments. We like to thank our colleagues in the CLIF group for fruitful discussions and instant support, Joe Bush who polished the text as a native speaker, the three anonymous reviewers for their critical comments, and, in particular, Bonnie Webber for supplying invaluable comments to an earlier draft of this paper. Michael Strube is supported by a postdoctoral grant from DFG (Str 545/1-1)."]},{"title":"References","paragraphs":["Brennan, S. E., M. W. Friedman & C. J. Pollard (1987). A centering approach to pronouns. In Proc. of the 25 th Annual Meeting of the Association for Computational Linguistics; Stanford, Cal., 6-g July 1987, pp. 155-162.","Dane~, E (1974). Functional sentence perspective and the organization of the text. In E Dane~ (Ed.), Papers on Functional Sentence Perspective, pp. 106-128. Prague: Academia.","Grosz, B. J., A. K. Joshi & S. Weinstein (1995). Centering: A framework for modeling the local coherence of discourse. Computational Linguistics, 21 (2):203-225.","Grosz, B. J. & C. L. Sidner (1986). Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3): 175-204.","Hahn, U., K. Markert & M. Strube (1996). A conceptual reasoning approach to textual ellipsis. In Proc. of the 12 th European Conference on Artificial Intelligence (ECAI '96); Budapest, Hungary, 12-16 August 1996, pp. 572-576. Chichester: John Wiley.","Hearst, M. A. (1994). Multi-paragraph segmentation of expos-","nd itory text. In Proc. of the 32 Annual Meeting of the Association for Computational Linguistics; Las Cruces, N.M., 27-30June 1994, pp. 9-16.","Morris, J. & G. Hirst (1991). Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Computational Linguistics, 17(1):21-48.","Passonneau, R. J. (1996). Interaction of discourse structure with explicitness of discourse anaphoric noun phrases. In M. Walker, A. Joshi & E. Prince (Eds.), Centering in Discourse. Preprint.","Passonneau, R. J. & D. J. Litman (1993). Intention based segmentation: Human reliability and correlation with linguistic cues. In Proc. of the 318t Annual Meeting of the Association for Computational Linguistics; Columbus, Ohio, 22-26 June 1993, pp. 148-155.","Ros6, C. E, B. Di Eugenio, L. S. Levin & C. Van Ess-Dykema (1995). Discourse processing of dialogues with multiple","rd threads. In Proc. of the 33 Annual Meeting of the Association for Computational Linguistics; Cambridge, Mass., 26-30June 1995, pp. 31-38.","Sidner, C. L. (1983). Focusing in the comprehension of definite anaphora. In M. Brady & R. Berwick (Eds.), Computational Models of Discourse, pp. 267-330. Cambridge, Mass.: MIT Press.","Strobe, M. & U. Hahn (1996). Functional centering. In Proc. of the 34 th Annual Meeting of the Association for Computational Linguistics; Santa Cruz, Cal., 23-28 June 1996, pp. 270-277.","Suri, L. Z. & K. E McCoy (1994). RAFT/RAPR and centering: A comparison and discussion of problems related to processing complex sentences. Computational Linguistics, 20(2):301-317.","Walker, M. A. (1996a). Centering, anaphora resolution, and discourse structure. In M. Walker, A. Joshi & E. Prince (Eds.), Centering in Discourse. Preprint.","Walker, M. A. (1996b). Limited attention and discourse structure. Computational Linguistics, 22(2):255-264. 111"]}]}
