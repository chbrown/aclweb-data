{"sections":[{"title":"Rich Prior Knowledge in Learning for NLP Gregory Druck, Kuzman Ganchev, João Graça Why Incorporate Prior Knowledge?","paragraphs":["have: unlabeled data option: hire linguist annotators"]},{"title":"Why Incorporate Prior Knowledge?","paragraphs":["have: unlabeled data option: hire linguist annotators This approach does not scale to every task and domain of interest. However, we already know a lot about most problems of interest."]},{"title":"Example: Document Classification •","paragraphs":["Prior Knowledge:"]},{"title":"•","paragraphs":["labeled features: information about the label distribution when word w is present --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," Documents Labels newsgroups classification baseball Mac politics ... hit Apple senate ... Braves Macintosh taxes ... runs Powerbook liberal ... sentiment polarity positive negative memorable terrible perfect boring exciting mess"]},{"title":"Example: Information Extraction •","paragraphs":["Prior Knowledge:"]},{"title":"•","paragraphs":["labeled features:"]},{"title":"•","paragraphs":["the word ACM should be labeled either journal or booktitle most of the time"]},{"title":"•","paragraphs":["non-Markov (long-range) dependencies:"]},{"title":"•","paragraphs":["each reference has at most one segment of each type W. H. Enright. Improving the efficiency of matrix operations in the numerical solution of stiff ordinary differential equations. ACM Trans. Math. Softw., 4(2), 127-136, June 1978. extraction from research papers:"]},{"title":"Example: Part-of-speech Induction •","paragraphs":["Prior Knowledge:"]},{"title":"•","paragraphs":["linguistic knowledge: each sentence should have a verb"]},{"title":"•","paragraphs":["posterior sparsity: the total number of different POS tags assigned to each word type should be small Tags A career with the European institutions must become more attractive. To o many young, new... Text"]},{"title":"Example: Dependency Grammar Induction •","paragraphs":["Prior Knowledge:"]},{"title":"•","paragraphs":["linguistic rules: nouns are usually dependents of verbs"]},{"title":"•","paragraphs":["noisy labeled data: target language parses should be similar to aligned parses in a resource-rich source language"]},{"title":"Example: Word Alignment •","paragraphs":["Prior Knowledge:"]},{"title":"•","paragraphs":["Bijectivity: alignment should be mostly one-to-one"]},{"title":"•","paragraphs":["Symmetry: source→target and target→source alignments should agree A career with the European institutions must become more attractive. Uma carreira nas instituições europeias têm de se tornar mais atractiva."]},{"title":"This Tutorial In general, how can we leverage such knowledge and an unannotated corpus during learning? Notation & Models","paragraphs":["input variables (documents, sentences): structured output variables (parses, sequences): unstructured output variables (labels): input / output variables for entire corpus: probabilistic model parameters: generative models: discriminative models: model feature function:"]},{"title":"p","paragraphs":["θ"]},{"title":"(y|x) p","paragraphs":["θ"]},{"title":"(x, y) x y θ f (x, y)","paragraphs":["X Y y"]},{"title":"Learning Scenarios •","paragraphs":["Unsupervised:"]},{"title":"•","paragraphs":["unlabeled data + prior knowledge"]},{"title":"•","paragraphs":["Lightly Supervised:"]},{"title":"•","paragraphs":["unlabeled data + “informative” prior knowledge"]},{"title":"•","paragraphs":["i.e. provides specific information about labels"]},{"title":"•","paragraphs":["Semi-Supervised:"]},{"title":"•","paragraphs":["labeled data + unlabeled data + prior knowledge"]},{"title":"Running Example #1: Document Classification •","paragraphs":["model: Maximum Entropy Classifier (Logistic Regression)"]},{"title":"•","paragraphs":["setting: lightly supervised; no labeled data"]},{"title":"•","paragraphs":["prior knowledge:"]},{"title":"•","paragraphs":["labeled features: information about the label distribution when word w is present"]},{"title":"•","paragraphs":["label is often hockey or baseball when game is present pθ (y|x)=","1 Z (x) exp(θ · f (x,y))"]},{"title":"Running Example #2: Word Alignment •","paragraphs":["model: first-order Hidden Markov Model (HMM)"]},{"title":"•","paragraphs":["setting: unsupervised"]},{"title":"•","paragraphs":["prior knowledge:"]},{"title":"•","paragraphs":["Bijectivity: alignment should be mostly one-to-one 1 1 2 3 we know the way sabemos el camino null1 2 3 0 pθ (y, x)=pθ (y0) N∏ i=1 pθ (yi|yi−1)pθ (xi|yi)"]},{"title":"Problem ","paragraphs":["This ou t pu t doe s no t agree with prior knowledge!"]},{"title":"•","paragraphs":["six target words align to source word animada"]},{"title":"•","paragraphs":["five source words do not align with any target word gameconvivialvery,animatedanwasit cordialmuyyanimadamaneraunadejugaban"]},{"title":"model data output","paragraphs":["x1 x2 x3 y1 y2 y3"]},{"title":"+ Limited Approach: Labeling Data","paragraphs":["limitation: Often unclear how to do conversion"]},{"title":"•","paragraphs":["Example #1: often (not always) game → {hockey,baseball}"]},{"title":"•","paragraphs":["Example #2: alignment should be mostly one-to-one","prior knowledge --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --","","--- --- -----","-- -- --- ----","--- --- --- --- ","-- ---------","------- ---- -- --- --- -----","-- -- --- ----","--- --- --- ---","","-- ---------","------- ---- --","","--- --- -----","-- -- --- ----","--- --- --- --- ","-- ---------","------- ---- --  --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," approach: Convert prior knowledge to labeled data. Prototypes (+ cluster features):"]},{"title":"•","paragraphs":["[Haghighi & Klein 06] Others:"]},{"title":"•","paragraphs":["[Raghavan & Allan 07]"]},{"title":"•","paragraphs":["[Schapire et al. 02]"]},{"title":"Limited Approach: Bayesian Approach","paragraphs":["approach: Encode prior knowledge with a prior on parameters. limitation: Our prior knowledge is not about parameters! Parameters are difficult to interpret; hard to get desired effect."]},{"title":"•","paragraphs":["Example #1: often (not always) game → {hockey,baseball}"]},{"title":"•","paragraphs":["Example #2: alignment should be mostly one-to-one natural: “ should be small (or sparse)”θ ( informat i ve prior )possible: “ should be close to ”θi θ̃i p(θ)specifying x1 x2 x3 y1 y2 y3 θα [Dayanik et al. 06] [Johnson 07], among many others"]},{"title":"Limited Approach: Augmenting Model","paragraphs":["limitation: can be difficult to get desired effect"]},{"title":"•","paragraphs":["Example #1: often (not always) game → {hockey,baseball} limitation: may make exact inference intractable"]},{"title":"•","paragraphs":["Example #2: Bijectivity makes inference #P-complete x1 x2 x3 y1 y2 y3 z1 approach: Encode prior knowledge with additional variables and dependencies."]},{"title":"This Tutorial","paragraphs":["develop:"]},{"title":"•","paragraphs":["a language for directly encoding prior knowledge"]},{"title":"•","paragraphs":["methods for learning with knowledge in this language"]},{"title":"•","paragraphs":["( approximations to modeling this language directly )"]},{"title":"•","paragraphs":["(loosely) these methods perform mappings for us:"]},{"title":"•","paragraphs":["encoded prior knowledge parameters"]},{"title":"•","paragraphs":["encoded prior knowledge labeling"]},{"title":"θ","paragraphs":["--- --- ----- -- -- --- ---- --- --- --- --- --- ----- -- -- --- ---- --- --- --- --- --- ----- -- -- --- ---- --- --- ---"]},{"title":"⇝⇝ A Language for Encoding Prior Knowledge","paragraphs":["Our prior knowledge is about distributions over latent output variables. (output variables are interpretable) Specifically, we know some properties of this distribution:"]},{"title":"•","paragraphs":["Example #1: often (not always) game→{hockey,baseball} Formulation: know about the expectations of some functions under distribution over latent output variables"]},{"title":"Constraint Features •","paragraphs":["constraint feature function:"]},{"title":"•","paragraphs":["Example #1:"]},{"title":"•","paragraphs":["for document x, returns a vector with a 1 in the lth position if y is the lth label and the word w is in x"]},{"title":"•","paragraphs":["Example #2:"]},{"title":"•","paragraphs":["returns a vector with mth value = number of target words in sentence x that align with source word m"]},{"title":"φ(x, y)","paragraphs":["φw (x,y)=1(y = l)1(w ∈ x) φ(x, y)= N∑ i=1 1(yi = m)"]},{"title":"Expectations of Constraint Features •","paragraphs":["Example #1: Corpus expectation:"]},{"title":"•","paragraphs":["vector with expected distribution over labels for documents that contain w ( is the count of w)"]},{"title":"•","paragraphs":["Example #2: Per-example expectation:"]},{"title":"•","paragraphs":["vector with mth value = expected number of target words that align with source word m Epθ [φ(X, Y)] = 1 cw ∑ x ∑ y pθ (y|x)φw (x,y) Epθ [φ(x, y)] = ∑ y pθ (y|x)φ(x, y) cw"]},{"title":"Expressing Preferences •","paragraphs":["express preferences using target values:"]},{"title":"• Example #1: •","paragraphs":["label distribution for game is close to [40% 40% 20%]"]},{"title":"• Example #2: •","paragraphs":["expected number of target words that align with each source word is at most one φ̃ Epθ [φw (X, Y)] ≈ φ̃ Epθ [φ(x, y)] ≤ φ̃"]},{"title":"Preview: Labeled Features","paragraphs":["User Experiments [Druck et al. 08] 0 100 200 300 400 500 600 700 8000.4 0.5 0.6 0.7 0.8 0.9 1 labeling time in seconds testing accuracy   GE ER ~2 minutes, 100 features labeled (or skipped): 82% accuracy ~15 minutes, 100 documents labeled (or skipped): 78% accuracy PC vs. Mac complete set of labeled features PC Mac dos mac ibm apple hp quadra dx targets set with simple heuristic: majority label gets","90% of mass"]},{"title":"Preview: Word Alignment","paragraphs":["[Graça et al. 10] 60 68.75 77.5 86.25 95 En-Pt Pt-En En-Es Es-En HMM HMM + Bijectivity Constraint"]},{"title":"Overview of the Frameworks Running Example Mode l Family: conditional exponential models are model features p","paragraphs":["θ"]},{"title":"(Y|X)= exp(θ · f (X, Y)) Z(X) Z(X)=∑","paragraphs":["Y"]},{"title":"exp(θ · f (X, Y)) f (X, Y) Choosing parameters Mode l Family: conditional exponential models Obje c t i ve: maximize observed data likelihood Note: Frameworks also suitable for generative models (no labeled data necessary) θ p","paragraphs":["θ"]},{"title":"(Y|X)= exp(θ · f (X, Y)) Z(X) max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y","paragraphs":["L"]},{"title":"|X","paragraphs":["L"]},{"title":") + log p(θ)","paragraphs":["def"]},{"title":"= L(θ; D","paragraphs":["L"]},{"title":") Visual Example: Maximum Likelihood Mode l: Object i ve: - + o o o o o o o o max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y","paragraphs":["L"]},{"title":"|X","paragraphs":["L"]},{"title":") − 0.1∥θ∥","paragraphs":["2 2"]},{"title":"p(Y|X)=∏","paragraphs":["i"]},{"title":"exp(y","paragraphs":["i"]},{"title":"x","paragraphs":["i"]},{"title":"· θ) Z (x","paragraphs":["i"]},{"title":") A language for prior information The expectations of user-defined constraint features are close to some value φ(X, Y) φ̃ E[φ(X, Y)] ≈ φ̃ Running Example: Want to ensure that 25% of unlabeled documents are about politics • constraint features  • preferred expected value • Expectation w.r.t. unlabeled data φ(x, y)= { 1ify is “politics” 0 otherwise φ̃ =0.25 Constraint-Driven Learning Mo t i vat ion: Hard EM algorithm with preferences Hard EM: Cons t rain t Dr i ve n Le ar ning: M-Step: set θ = arg max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"( Ŷ|X) E-Step: set Ŷ = arg max","paragraphs":["Y"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y|X)−penalty(Y) M-Step: set θ = arg max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"( Ŷ|X) E-Step: set Ŷ = arg max","paragraphs":["Y"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y|X)","paragraphs":["M. Chang, L. Ratinov, D. Roth (2007)."]},{"title":"Constraint-Driven Learning Mo t i vat ion: Hard EM algorithm with preferences Cons t raint Dri ve n Le arning: • penalties encode similar information as * more on this later * • E-Step can be hard; use beam search E-Step: set Ŷ = arg max","paragraphs":["Y"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y|X)−penalty(Y) M-Step: set θ = arg max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"( Ŷ|X) E[φ] ≈ φ̃ Visual Example: Constraint Driven Learning where are “imagined” labels andŶ - + o o o o o o o o φ[ Ŷ] = count(+, Ŷ) max","paragraphs":["θ, Ŷ"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y","paragraphs":["L"]},{"title":"|X","paragraphs":["L"]},{"title":") − 0.1∥θ∥","paragraphs":["2 2"]},{"title":"s.t. φ( Ŷ)=2 Posterior Regularization Mo t i vat ion: EM algorithm with sane posteriors EM: Cons t raine d EM: E-Step: set q(Y)=argmin","paragraphs":["q"]},{"title":"D","paragraphs":["KL"]},{"title":"(q(Y)||p","paragraphs":["θ"]},{"title":"(Y|X)) M-Step: set θ = arg max","paragraphs":["θ"]},{"title":"E","paragraphs":["q(Y)"]},{"title":"[p","paragraphs":["θ"]},{"title":"(Y|X)] E-Step: set q(Y)=argmin","paragraphs":["q∈Q"]},{"title":"D","paragraphs":["KL"]},{"title":"(q(Y)||p","paragraphs":["θ"]},{"title":"(y|x)) M-Step: set θ = arg max","paragraphs":["θ"]},{"title":"E","paragraphs":["q(Y)"]},{"title":"[p","paragraphs":["θ"]},{"title":"(Y|X)]","paragraphs":["J. Graça, K. Ganchev, B. Taskar (2007)."]},{"title":"Posterior Regularization Mo t i vat ion: EM algorithm with sane posteriors Ide a: provide constraints Object i ve: E[φ] ≈ φ̃ define Q: set of q such that E","paragraphs":["q"]},{"title":"[φ] ≈ φ̃ max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − D","paragraphs":["KL"]},{"title":"(Q||p","paragraphs":["θ"]},{"title":"(Y|X)) run EM-like procedure but use proposal q ∈ Q where D","paragraphs":["KL"]},{"title":"is Kullback-Leibler divergence X = D","paragraphs":["U"]},{"title":"are the input variables for unlabeled corpus Y is label for entire unlabeled corpus Posterior Regularization Hard cons t raints: Sof t cons t raints: max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − min","paragraphs":["q∈Q"]},{"title":"D","paragraphs":["KL"]},{"title":"(q(Y)|| p","paragraphs":["θ"]},{"title":"(Y|X)) Q = { q(Y):∥∥∥E","paragraphs":["q"]},{"title":"[φ(Y)] = φ̃∥∥∥","paragraphs":["2 2"]},{"title":"≤ ε } max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − min","paragraphs":["q"]},{"title":"( D","paragraphs":["KL"]},{"title":"(q(Y)|| p","paragraphs":["θ"]},{"title":"(Y|X)) + α ∥∥∥E","paragraphs":["q"]},{"title":"[φ(Y)] = φ̃∥∥∥","paragraphs":["2 2"]},{"title":") Visual Example: Posterior Regularization where: - + o o o o o o o o max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y","paragraphs":["L"]},{"title":"|X","paragraphs":["L"]},{"title":") − 0.1∥θ∥","paragraphs":["2 2"]},{"title":"− D","paragraphs":["KL"]},{"title":"(Q||p","paragraphs":["θ"]},{"title":") D","paragraphs":["KL"]},{"title":"(Q||p","paragraphs":["θ"]},{"title":")=min","paragraphs":["q"]},{"title":"D","paragraphs":["KL"]},{"title":"(q||p","paragraphs":["θ"]},{"title":")s.t.E","paragraphs":["q"]},{"title":"[φ]=2 Generalized Expectation Constraints Mo t i vat ion: augment log-likelihood with cost for “bad” posteriors. Object i ve: where is short-hand Op t imizat ion: gradient descent on max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − ∥∥∥E","paragraphs":["pθ (Y|X)"]},{"title":"[φ] − φ̃∥∥∥","paragraphs":["β"]},{"title":"E","paragraphs":["pθ (Y|X)"]},{"title":"[φ]=E","paragraphs":["pθ (Y|X)"]},{"title":"[φ(X, Y)] = ∑","paragraphs":["Y"]},{"title":"p","paragraphs":["θ"]},{"title":"(Y|X)φ(X, Y) θ","paragraphs":["G. Mann, A. McCallum (2007)."]},{"title":"A visual comparison of the frameworks Object i ve: Generalized Expectation Constraints - + o o o o o o o o max","paragraphs":["θ"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y","paragraphs":["L"]},{"title":"|X","paragraphs":["L"]},{"title":") − 0.1∥θ∥","paragraphs":["2 2"]},{"title":"− 500∥E","paragraphs":["pθ"]},{"title":"[φ] − 2∥","paragraphs":["2 2"]},{"title":"Types of constraints Cons t raint Dri ve n Le arning: Penalized Viterbi • Easy if decompose as the model. and • Otherwise: • Beam search • Integer linear program p(Y|X)=∏","paragraphs":["c"]},{"title":"p","paragraphs":["c"]},{"title":"(y","paragraphs":["c"]},{"title":"|X) arg max","paragraphs":["Y"]},{"title":"log p","paragraphs":["θ"]},{"title":"(Y|X) −∥φ(X, Y) − φ̃∥","paragraphs":["β"]},{"title":"∥φ(X, Y) − φ̃∥","paragraphs":["β"]},{"title":"∥φ(X, Y) − φ̃∥","paragraphs":["β"]},{"title":"= ∑","paragraphs":["c"]},{"title":"δ","paragraphs":["c"]},{"title":"(X, y","paragraphs":["c"]},{"title":") Types of constraints Pos terior Regularizat ion: KL projection • Usually easy if decompose as the model: and • Otherwise: Sample","paragraphs":["(e.g. K. Bellare, G. Druck, and A. McCallum, 2009)"]},{"title":"φ(Y, X)","paragraphs":["p(Y|X)=∏ c pc(yc|X) q(Y|X)=∏ c qc(yc|X) φ(X, Y)=∑ c φc(X, yc)"]},{"title":"⇒ min","paragraphs":["q"]},{"title":"D","paragraphs":["KL"]},{"title":"(q||p","paragraphs":["θ"]},{"title":")s.t.∥E","paragraphs":["q"]},{"title":"[φ] − φ̃∥","paragraphs":["β"]},{"title":"≤ ε Types of constraints Ge neralize d Expectat ion Cons t raints: Direct gradient • Usually easy if: • decomposes as the model • Can compute * more on this later * • Unstructured • Sequence, Grammar (semiring trick) • Otherwise: sample or approximate the gradient. φ(Y, X) max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − ∥∥∥E","paragraphs":["pθ (Y|X)"]},{"title":"[φ] − φ̃∥∥∥","paragraphs":["β φ(X, Y)=∑ c φc(X, yc)"]},{"title":"E[φ × f ] A Bayesian View: Measurements Object i ve: mode of given observations","paragraphs":["XL θ X YL Y φ(X, Y) b Figure 4.1: The model used by Liang et al. [2009], using our notation. We have separated treatment of the labeled data (XL, YL) from treatment of the unlabeled data X. and produce some value φ(X, Y), which is never observed directly. Instead, we observe some noisy version b ≈ φ(X, Y). The measured values b are distributed according to some noise model pN (b|φ(X, Y)). Liang et al. [2009] note that the optimization is convex for log-concave noise and use box noise in their experiments, giving b uniform probability in some range near φ(X, Y). In the Bayesian setting, the model parameters θ as well as the observed measurement values b are random variables. Liang et al. [2009] use the mode of p(θ|XL, YL, X, b) as a point estimate for θ:","arg max θ","p(θ|XL, YL, X, b) = arg max θ ∑ Y p(θ, Y, b|X, XL, YL), (4.6) with equality because p(θ|XL, YL, X, b) ∝ p(θ, b|XL, YL, X)= ∑","Y p(θ, Y, b|X, XL, YL). Liang et al. [2009] focus on computing p(θ, Y, b|X, XL, YL). They define their model for this quantity as follows: p(θ, Y, b|X, XL, YL)=p(θ|XL, YL) pθ(Y|X) pN (b|φ(X, Y)) (4.7) where the Y and X are particular instantiations of the random variables in the entire unlabeled corpus X. Equation 4.7 is a product of three terms: a prior on θ, the model probability pθ(Y|X), and a noise model pN (b|φ). The noise model is the probability that we observe a value, b, of the measurement features φ, given that its actual value was φ(X, Y). The idea is that we model errors in the estimation of the posterior probabilities as noise in the measurement process. Liang et al. [2009] use a uniform distribution over φ(X, Y) ± ε, which they call “box noise”. Under this model, observing b farther than ε from φ(X, Y) has zero probability. In log space, the exact MAP objective, becomes: maxθ L(θ) + log Epθ(Y|X) [ pN (b|φ(X, Y))] . (4.8) 31 maxθ log p(θ)+ ∑ (x,y)∈DL log pθ(y|x)=L(θ; DL) θ P. Liang, M. Jordan, D. Klein (2009)"]},{"title":"Object i ve: mode of given observations A Bayesian View: Measurements","paragraphs":["XL θ X YL Y φ(X, Y) b Figure 4.1: The model used by Liang et al. [2009], using our notation. We have separated treatment of the labeled data (XL, YL) from treatment of the unlabeled data X. and produce some value φ(X, Y), which is never observed directly. Instead, we observe some noisy version b ≈ φ(X, Y). The measured values b are distributed according to some noise model pN (b|φ(X, Y)). Liang et al. [2009] note that the optimization is convex for log-concave noise and use box noise in their experiments, giving b uniform probability in some range near φ(X, Y). In the Bayesian setting, the model parameters θ as well as the observed measurement values b are random variables. Liang et al. [2009] use the mode of p(θ|XL, YL, X, b) as a point estimate for θ:","arg max θ","p(θ|XL, YL, X, b) = arg max θ ∑ Y p(θ, Y, b|X, XL, YL), (4.6) with equality because p(θ|XL, YL, X, b) ∝ p(θ, b|XL, YL, X)= ∑","Y p(θ, Y, b|X, XL, YL). Liang et al. [2009] focus on computing p(θ, Y, b|X, XL, YL). They define their model for this quantity as follows: p(θ, Y, b|X, XL, YL)=p(θ|XL, YL) pθ(Y|X) pN (b|φ(X, Y)) (4.7) where the Y and X are particular instantiations of the random variables in the entire unlabeled corpus X. Equation 4.7 is a product of three terms: a prior on θ, the model probability pθ(Y|X), and a noise model pN (b|φ). The noise model is the probability that we observe a value, b, of the measurement features φ, given that its actual value was φ(X, Y). The idea is that we model errors in the estimation of the posterior probabilities as noise in the measurement process. Liang et al. [2009] use a uniform distribution over φ(X, Y) ± ε, which they call “box noise”. Under this model, observing b farther than ε from φ(X, Y) has zero probability. In log space, the exact MAP objective, becomes: maxθ L(θ) + log Epθ(Y|X) [ pN (b|φ(X, Y))] . (4.8) 31 maxθ L(θ; DL) + log Epθ(Y|X) [ p( φ̃|φ(X, Y))] θ"]},{"title":"What's wrong with this picture? Object i ve: mode of given observations Example: Exactly 25% of articles are “politics” What is the probability exactly 25% of the articles are labeled `̀politics''? How do we optimize this with respect to ? max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") + log E","paragraphs":["pθ (Y|X)"]},{"title":"[ p( φ̃|φ(X, Y))] θ θ p( φ̃|φ(X, Y)) = 1 ( φ̃ = φ(X, Y) ) E","paragraphs":["pθ (Y|X)"]},{"title":"[ 1( φ̃ = φ(X, Y)) ] What's wrong with this picture? Example: Compute prob: 25% of docs are “politics”. Naively: in this case we can use a DP, but if there are many constraints, that doesn’t work. Easier: What is the expected number of “politics” articles? Article p(“politics”) 1 0.2 2 0.4 3 0.1 4 0.6 0.2+0.4+0.1+0.6","paragraphs":["0.2 × (1 − 0.4) × (1 − 0.1) × (1 − 0.6) + ...+ +(1 − 0.2) × (1 − 0.4) × (1 − 0.1) × 0.6"]},{"title":"Probabilities and Expectations difficult to compute expectations of arbitrary functions but... Usually: decomposes as a sum e .g. 25% of articles are “politics” Ide a: approximate","paragraphs":["φ(X, Y) φ(X, Y)= ∑ instances φ(x, y) Epθ(Y|X) [ p ( φ̃"]},{"title":"|","paragraphs":["φ(X, Y) )] ≈ p ( φ̃"]},{"title":"|","paragraphs":["E pθ(Y|X) [φ(X, Y)])"]},{"title":"Probabilities and Expectations Approximat ion: Object i ve: Example: is Gaussian is so for appropriate this is identical to GE!","paragraphs":["Epθ(Y|X) [ p ( φ̃"]},{"title":"|","paragraphs":["φ )] ≈ p ( φ̃"]},{"title":"|","paragraphs":["E pθ(Y|X) [φ] )"]},{"title":"max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") + log p ( φ̃ | E","paragraphs":["pθ (Y|X)"]},{"title":"[φ] ) log p ( φ̃ | E[φ] ) ⇒","paragraphs":["p ( φ̃"]},{"title":"|","paragraphs":["E[φ] ) log p ( φ̃"]},{"title":"|","paragraphs":["E[φ] )"]},{"title":"⇓","paragraphs":["∥∥∥E[φ] − φ̃∥∥∥ 2 2"]},{"title":"Optimizing GE objective GE Object i ve: • Gradient involves covariance this can be hard because and the usual dynamic programs (inside outside, forward backward) can’t compute this. Cov(φ, f )=E[φ × f ] − E[φ] × E[f ] E[φ × f ]=∑","paragraphs":["Y"]},{"title":"p(Y)φ(Y) × f (Y) O","paragraphs":["GE"]},{"title":"= max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − ∥∥∥E","paragraphs":["pθ (Y|X)"]},{"title":"[φ(X, Y)] − φ̃∥∥∥","paragraphs":["β"]},{"title":"Optimizing GE Objective Maintaining both and in the DP is expensive * Semiring trick can help for some problems *","paragraphs":["x1 x2 x3 x3 y1 y2 y3 y4 E[φ × f ]=∑ Y p(Y)φ(Y) × f (Y) φ(Y) × f (Y)= [ ∑ i φ(yi) ] ×   ∑ j f (yj )  "]},{"title":"y","paragraphs":["i"]},{"title":"y","paragraphs":["j "]},{"title":"E.g. if inference is a hypergraph problem. A Variational Approximation GE Object i ve: • Can be hard to compute in gradient. Ide a: use variational approximation * Note: this is the PR objective * q(Y) ≈ p","paragraphs":["θ"]},{"title":"(Y|X)","paragraphs":["maxθ,q(Y) L(θ; DL)−DKL ( q(Y)"]},{"title":"||","paragraphs":["pθ(Y|X) ) − ∥∥∥Eq [φ(X, Y)] − φ̃∥∥∥ β"]},{"title":"Cov(φ, f ) O","paragraphs":["GE"]},{"title":"= max","paragraphs":["θ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") − ∥∥∥ φ̃ − E","paragraphs":["pθ (Y|X)"]},{"title":"[φ(X, Y)]∥∥∥","paragraphs":["β"]},{"title":"Approximating with the mode PR Object i ve: sometimes minimizing the KL is hard. Ide a: use hard assignment : • becomes • becomes • use EM-like procedure to optimize Cons t raint Dri ve n Le arning Object i ve:","paragraphs":["maxθ,q(Y) L(θ; DL)−DKL ( q(Y)"]},{"title":"||","paragraphs":["pθ(Y|X) ) − ∥∥∥Eq [φ(X, Y)] − φ̃∥∥∥ β"]},{"title":"q(Y) ≈ 1(Y = Ŷ) ∥∥∥E","paragraphs":["q"]},{"title":"[φ(X, Y)] − φ̃∥∥∥","paragraphs":["β"]},{"title":"log p( Ŷ)D","paragraphs":["KL"]},{"title":"( q(Y) || p","paragraphs":["θ"]},{"title":"(Y|X) ) log p( φ̃ | φ(X, Ŷ)) max","paragraphs":["θ, Ŷ"]},{"title":"L(θ; D","paragraphs":["L"]},{"title":") + log p","paragraphs":["θ"]},{"title":"( Ŷ) + log p( φ̃|φ(X, Ŷ)) Visual Summary","paragraphs":["Measurements Generalized Expectation Distribution Matching","Posterior Regularization","Coupled Semi-Supervised Learning Constraint Driven Learning Distribution Matching","variational approximation; Jensen’s inequality","variational approximation","MAP approximation","MAP approximation log E[pN ( φ̃|φ)] ≈ log pN ( φ̃|E[φ])"]},{"title":"Applications •","paragraphs":["Unstructured problems:"]},{"title":"•","paragraphs":["Document Classification"]},{"title":"•","paragraphs":["Sequence problems:"]},{"title":"•","paragraphs":["Information Extraction"]},{"title":"•","paragraphs":["Pos-Induction"]},{"title":"•","paragraphs":["Word Alignment"]},{"title":"•","paragraphs":["Tree problems:"]},{"title":"•","paragraphs":["Grammar Induction"]},{"title":"Document Classification •","paragraphs":["Model: Max. Entropy Classifier (Logistic Regression)"]},{"title":"•","paragraphs":["Challenge: What if we have no labeled data?"]},{"title":"•","paragraphs":["cannot use standard unsupervised learning: --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," --- --- ----- -- -- --- ---- --- --- --- ---"," -- --------- ------- ---- --"," Documents Labels pθ (y|x)= exp(θ · f (x,y))∑ y exp(θ · f (x,y)) ∑ y pθ (y|x)=1"]},{"title":"Labeled Features •","paragraphs":["often we can still provide some light supervision"]},{"title":"•","paragraphs":["prior knowledge: labeled features"]},{"title":"•","paragraphs":["formally: have an estimate of the distribution over labels for documents that contain word w: φ̃w newsgroups classification baseball Mac politics ... hit Apple senate ... Braves Macintosh taxes ... runs Powerbook liberal ... sentiment polarity positive negative memorable terrible perfect boring exciting mess"]},{"title":"Leveraging Labeled Features with GE","paragraphs":["[Mann & McCallum 07], [Druck et al. 08]"]},{"title":"•","paragraphs":["constraint feature:"]},{"title":"•","paragraphs":["for a document x, returns a vector with a 1 in the lth position if y is the lth label and the word w is in x"]},{"title":"•","paragraphs":["expectation: label distribution for docs that contain w"]},{"title":"•","paragraphs":["GE penalty: KL divergence from target distribution φw (x,y)=1(y = l)1(w ∈ x) 1 cw ∑ x Epθ(y|x)[φw (x,y)] DKL ( φ̃w || 1 cw ∑ x Epθ(y|x)[φw (x,y)])"]},{"title":"User Experiments with Labeled Features","paragraphs":["[Druck et al. 08] 0 100 200 300 400 500 600 700 8000.4 0.5 0.6 0.7 0.8 0.9 1 labeling time in seconds testing accuracy   GE ER ~2 minutes, 100 features labeled (or skipped): 82% accuracy ~15 minutes, 100 documents labeled (or skipped): 78% accuracy PC vs. Mac complete set of labeled features PC Mac dos mac ibm apple hp quadra dx targets set with simple heuristic: majority label gets","90% of mass"]},{"title":"Experiments with Labeled Features","paragraphs":["[Druck et al. 08] 60 65 70 75 80 sentiment (50) webkb (100) newsgroups (500) GE (model contains only labeled features) GE (model also contains unlabeled features) 15x 3.5x 6.5x","learning about “unlabeled features” through covariance improves generalization","estimated speed-up over labeling documents"]},{"title":"Information Extraction: Example Tasks •","paragraphs":["citation extraction:"]},{"title":"•","paragraphs":["apartment listing extraction: Detached single family house. 3 bedrooms 1 1/2 baths. Almost 1000 square feet in living area. 1 car garage. New pergo floor and tile kitchen floor. New interior/exterior paint. Close to shopping mall and bus stop. Near 101/280. Available July 1, 2004. If you are interested, email for more details. Cousot, P. and Cousot, R. 1978. Static determination of dynamic properties of recursive procedures. In Proceedings of the IFIP Conference on Programming Concepts, E. Neuhold, Ed. North-Holland Pub. Co., 237-277."]},{"title":"Information Extraction: Markov Models •","paragraphs":["models for sequence labeling based IE"]},{"title":"•","paragraphs":["Hidden Markov Model (HMM):"]},{"title":"•","paragraphs":["Conditional Random Field (CRF): pθ (y, x)=pθ (y0) N∏ i=1 pθ (yi|yi−1)pθ (xi|yi) pθ (y|x)=","1 Z (x) exp( N∑ i=1 θ · f (x,yi−1,yi)) expectation: label distribution when q is true model: Linear Chain CRF note: Semiring trick makes GE O(L2) instead of O(L3) as in [Mann & McCallum 08]"]},{"title":"Information Extraction: Labeled Features","paragraphs":["[Mann & McCallum 08], [Liang et al. 09] ROOMMATES respectful CONTACT *phone* FEATURES laundry","apartments example labeled features: 1 cq ∑ x ∑ i Epθ(yi|x)[φq (x,yi,i)] constraint features: vector with a 1 in the lth position if y is the lth label and predicate q is true (i.e. w is present at i) φq (x,yi,i)=1(yi = l)q(x,i)"]},{"title":"Information Extraction: Labeled Features","paragraphs":["[Haghighi & Klein 06], [Mann & McCallum 08], [Liang et al. 09] apartment listing extraction Prototype GE (KL) Measurements/PR 650 700 750 800 850 0 labeled 10 labeled 100 labeled supervised CRF (100) [MM08]"]},{"title":"•","paragraphs":["accurate with constraints alone"]},{"title":"•","paragraphs":["outperform fully supervised with constraints and labeled data"]},{"title":"Limitations of Markov Models •","paragraphs":["predicted:"]},{"title":"•","paragraphs":["prediction has two author and two title segments:"]},{"title":"•","paragraphs":["error #1: Neuhold, Ed. should be editor"]},{"title":"•","paragraphs":["error #2: North-Holland Pub. Co., should be publisher"]},{"title":"•","paragraphs":["A Markov model cannot represent that at most one segment of each type appears in each reference. Cousot, P. and Cousot, R. 1978. Static determination of dynamic properties of recursive procedures. In Proceedings of the IFIP Conference on Programming Concepts, E. Neuhold, Ed. North-Holland Pub. Co., 237-277."]},{"title":"Long-Range Constraints","paragraphs":["[Chang et al. 07] [Bellare et al. 09]"]},{"title":"•","paragraphs":["“Each field is a contiguous sequence of tokens and appears at most once in a citation.”"]},{"title":"•","paragraphs":["constraint feature: counts the number of segments of each type"]},{"title":"•","paragraphs":["constrained to be ≤ 1 using PR or CODL"]},{"title":"•","paragraphs":["additional constraints: 10 labeled features such as:"]},{"title":"•","paragraphs":["pages→pages"]},{"title":"•","paragraphs":["proc.→booktitle"]},{"title":"Long-Range Constraints","paragraphs":["[Chang et al. 07] [Bellare et al. 09] constraints improve both CRF (PR) and HMM (CODL) 50 60 70 80 90 5 labeled 20 labeled CRF CRF + PR HMM HMM + CODL citation model method description [Mann et al. 07] MaxEnt GE constraints on label marginals [Druck et al. 09] CRF GE","actively labeled features","[Bellare & McCallum 09]","alignment CRF GE labeled features [Singh et al. 10]","semi-Markov CRF PR labeled gazetteers [Druck et al. 10] HMM PR constraints derived from labeled data"]},{"title":"Other Applications in Information Extraction Pos Induction Low Tag Ambiguity","paragraphs":["[Graça et al. 09] JJ VB NN car object romantic offensive being E[degree] = 1.5E[degree] = 10000 0 2 4 6 8 10 0 200 400 600 800 1000 1200 1400 1600 1800 L 1 L ! rank of word by L1L!","Supervised HMM Distribution of word ambiguity N V ADJ Prep ADV 0.9 0.1 0 0 0 0.7 0.1 0.1 0 0.1 0.1 0.3 0 0.6 0 0.3 0.6 0 0 0.1 0.3 0.7 0 0 0"]},{"title":"•","paragraphs":["Pick a particular word type: run"]},{"title":"•","paragraphs":["Stack all occurrences"]},{"title":"•","paragraphs":["Calculate posterior probability"]},{"title":"•","paragraphs":["Take the maximum for each tag"]},{"title":"•","paragraphs":["Sum the maxes a run into town. of the mile run. run gold. run errands. run for mayor. Sum 1 Sum 1 1 1 1 1 0.9 0.7 0.1 0.6 0.2"]},{"title":"Max Sum","paragraphs":["2.5"]},{"title":"Measuring Tag Ambiguity","paragraphs":["[Graça et al. 09]"]},{"title":"φ","paragraphs":["wti :Word type w has hidden state t at occurrence i"]},{"title":"min","paragraphs":["cwt"]},{"title":"E","paragraphs":["q(y)"]},{"title":"[φ","paragraphs":["wti"]},{"title":"] ≤ c","paragraphs":["wt"]},{"title":"l","paragraphs":["1"]},{"title":"/l","paragraphs":["∞"]},{"title":"= ∑","paragraphs":["wt"]},{"title":"c","paragraphs":["wt"]},{"title":"Tag Sparsity","paragraphs":["[Graça et al. 09] 0 1.25 2.5 3.75 5 En Pt Es Ambi g ui ty d i ff er ence HMM L1LMax","Average ambiguity difference 0 2 4 6 8 10 0 200 400 600 800 1000 1200 1400 1600 1800 L 1 L ! rank of word by L1L! Supervised","HMM HMM+Sp Distribution of word ambiguity"]},{"title":"Results","paragraphs":["[Graça et al. 09] 50 57.5 65 72.5 80 En Pt Bg Es Dk Tr HMM HMM+Sp 3.8 6.7 7.4 7.6 9.6 3.8"]},{"title":"6.5 % Average Improvement Word Alignments","paragraphs":["[Graça et al. 10]"]},{"title":"•","paragraphs":["Bijectivity constraints"]},{"title":": •","paragraphs":["Each word should align to at most one other word"]},{"title":"•","paragraphs":["Symmetry constraints:"]},{"title":"•","paragraphs":["Directional models should agree"]},{"title":"Bijectivity Constraints","paragraphs":["[Graça et al. 10] Bijective Constraints","012345678","0 jugaban ∑","≤ 1","1 de ∑","≤ 1","2 una ∑","≤ 1","3 manera ∑","≤ 1","4 animada ∑","≤ 1","5 y ∑","≤ 1","6 muy ∑","≤ 1","7 cordial ∑","≤ 1","8 . ∑","≤ 1","it wa","s an anim","at","e","d,","very c on v i v i a lga m e. 50/74 Bijective Constraints - After projection","012345678","0 jugaban ∑","≤ 1","1 de ∑","≤ 1","2 una ∑","≤ 1","3 manera ∑","≤ 1","4 animada ∑","≤ 1","5 y ∑","≤ 1","6 muy ∑","≤ 1","7 cordial ∑","≤ 1","8 . ∑","≤ 1","it","wa","s an anim at e d",", very c","on v i v i a lga m e. 51/74Feature: Constraint: φ(x, y)= N∑ i=1 1(yi = m) Eq [φ(x, y)] ≤ 1"]},{"title":"Symmetry Constraints","paragraphs":["[Graça et al. 10] Feature: Constraint: Symmetric - Original posteriors 01234 −→ p θt","(z | x) 0 no 1 hay 2 estadı́sticas 3 .","01234 ←− p θt","(z | x) 0 no 1 hay 2 estadı́sticas 3 .","no sta","tistica l","data exi sts. pθt q ←−pθt −→pθt 55 / 74"]},{"title":"E","paragraphs":["q"]},{"title":"[φ(x, y)] = 0 φ(x, y)=    +1 y ∈ −→ y and −→ y","paragraphs":["i"]},{"title":"= j −1 y ∈ ←− y and ←− y","paragraphs":["j"]},{"title":"= i 0 otherwise","paragraphs":["−→ p θ (y|x) ←− p θ (y|x)"]},{"title":"Symmetry Constraints","paragraphs":["[Graça et al. 10] Before projection: After projection:"]},{"title":"Symmetric - After projection","paragraphs":["E-Step qs (z )=argmin q(z)∈Qs KL [qs (z) || pθt (z | xs )] 01234 −→p θt (z | x) 0 no 1 hay 2 estadı́sticas 3 .","01234 ←−p θt (z | x) 0 no 1 hay 2 estadı́sticas 3 .","no sta","tistica l","data exi sts. 01234 0 no","−→q (z)1 hay 2 estadı́sticas 3 . 01234 0 no","←−q (z)1 hay 2 estadı́sticas 3 .","no sta","tistica l","data exi sts. M-Step Does not change 56 / 74 −→ p θ (y|x) ←− p θ (y|x)"]},{"title":"−→ q (y) ←− q (y) Results","paragraphs":["[Graça et al. 10] 50 60 70 80 90 100 1000 10000 100000 1e+06 precision size S-HMM B-HMM HMM","50 60 70 80 90 100 1000 10000 100000 1e+06 precision size S-HMM B-HMM HMM Evolution with data size 50 60 70 80 90 100 1000 10000 100000 1e+06 precision size S-HMM B-HMM M4 HMM","50 60 70 80 90 100 1000 10000 100000 1e+06 precision size S-HMM B-HMM M4 HMM ▶ Specially useful for low data situations 61 / 74 Evolution with data size 50 60 70 80 90 100 1000 10000 100000 1e+06 precision size S-HMM B-HMM M4 HMM","50 60 70 80 90 100 1000 10000 100000 1e+06 precision size S-HMM B-HMM M4 HMM ▶ Specially useful for low data situations 61 / 74"]},{"title":"Results","paragraphs":["[Graça et al. 10] 60 65 70 75 80 85 90 95","En-Pt Pt-En Pt-Fr Fr-Pt En-Es Es-En Es-Fr Fr-Es Pt-Es Es-Pt En-Fr Fr-En Languages HMM 70.5 67.5 73.0 77.6","75.7 74.9 80.9 84.0 82.4 79.8 76.3 78.3 B-HMM 85.0 74.4 71.3 86.3 88.4","87.2 87.2","86.5 82.5","90.1 90.8","91.6 S-HMM 86.2 85.0 82.4 87.9 82.7 84.6","89.1 88.9 84.6 91.8 93.4 94.6"]},{"title":"Dependency Parsing DMV Model","paragraphs":["[Graça et al. 04] Dependency model with valence (Klein and Manning, ACL 2004) x y RegularizationN createsV sparseADJ grammarsN","pθ(x, y)=θroot(V )","·θstop(nostop|V ,right,false) · θchild(N|V ,right)","·θstop(stop|V ,right,true) · θstop(nostop|V ,left,false) · θchild(N|V ,left)","... 3/9"]},{"title":"Dependency Parsing • Transfer annotations from another language •","paragraphs":["[Ganchev et al. 09]"]},{"title":"• Constrain the number of child/parent relations •","paragraphs":["[Gillenwater et al. 11]"]},{"title":"• Use linguistic rules •","paragraphs":["[Druck et al. 09] [Naseem et al. 10]"]},{"title":"Dependency Parsing Transfer annotations","paragraphs":["[Ganchev et al. 09]"]},{"title":"• Use information from a resource rich language • Make the annotation transfer robust • Preserve n % of the edges Dependency Parsing Transfer annotations","paragraphs":["[Ganchev et al. 09]"]},{"title":"Eq [φ(x, y)] = 1 |Cx | ∑ y∈C","paragraphs":["x"]},{"title":"q(y|x) Eq [φ(x, y)] ≥ b Dependency Parsing Transfer annotations","paragraphs":["[Ganchev et al. 09] 66 67 68 69 70 ES BG DMV PR-Transfer"]},{"title":"Dependency Parsing Posterior Sparsity","paragraphs":["[Graça et al. 10]"]},{"title":"• ML learns very ambiguous grammars • all productions have some probability • constrain the number of possible productions Dependency Parsing Posterior Sparsity","paragraphs":["[Gillenwater et al. 11] Measuring ambiguity on distributions over trees N → N V → N AD J → N N → V V → V AD J → V N → AD J V → AD J AD J → AD J SparsityN isV workingV 0.4 0.6","010 SparsityN isV workingV 0.4","0.6 .4 .6 0 UseV goodADJ grammarsN0.7 0.3 0 .7 .3 UseV goodADJ grammarsN0.40.6 .4 .6 0","max ↓ sum = 3.3 ← 0 1 .3 .4 .6 0 .4 .6 0 7/9"]},{"title":"Dependency Parsing Posterior Sparsity","paragraphs":["[Gillenwater et al. 11] GILLENWATER,GANCHEV,GRAÇA,PEREIRA,TASKAR Una d","papelera nc es vs un d objeto nc","civilizado aq Una d","papelera nc es vs un d objeto nc","civilizado aq 1.00","1.00 1.00","0.49 0.51 1.00 0.57 0.43 Una d","papelera nc es vs un d objeto nc","civilizado aq 1.00 0.83 0.75 0.990.92 0.35 0.48","Figure 14: Posterior edge probabilities for an example sentence from the Spanish test corpus. Top is Gold, middle is EM, and bottom is PR. since then it does not have to pay the cost of assigning a parent with a new tag to cover each noun that does not come with a determiner.","Table 4 contrasts the most frequent types of errors EM, SDP, and PR make on several test sets where PR does well. The “acc” column is accuracy and the “errs” column is the absolute number of errors of the key type. Accuracy for the key “parent POS truth/guess → child POS” is computed as a function of the true relation. So, if the key is pt/pg → c, then accuracy is: acc = # of pt → c in Viterbi parses # of pt → c in gold parses . (25) In the following subsections we provide some analysis of the results from Table 4. 7.1 English Corrections Considering English first, there are several notable differences between EM and PR errors. Similar to the example for Spanish, the direction of the noun-determiner relation is corrected by PR. This is reflected by the VB/DT → NN key, the NN/VBZ → DT key, the NN/IN → DT key, the IN/DT → NN key, the NN/VBD → DT key, the NN/VBP → DT key, and the NN/VB → DT key, which for EM and SDP have accuracy 0. PR corrects these errors.","A second correction PR makes is reflected in the VB/TO → VB key. One explanation for the reason PR is able to correctly identify VBs as the parents of other VBs instead of mistakenly making TO the parent of VBs is that “VB CC VB” is a frequently occurring sequence. For example, “build and hold” and “panic and bail” are two instances of the “VB CC VB” pattern from the test corpus. Presented with such scenarios, where there is no TO present to be the parent of VB, PR chooses the first VB as the parent of the second. It maintains this preference for making the first VB a parent of the second when encountered with “VB TO VB” sequences, such as “used to eliminate”, because it would have to pay an additional penalty to make TO the parent of the second VB. In this manner, PR corrects the VB/TO → VB key error of EM and SDP. 26 Gold: DVM: DMV+Sparsity:"]},{"title":"Dependency Parsing Posterior Sparsity","paragraphs":["[Gillenwater et al. 11] 0 17.5 35 52.5 70 English Bulgarian Portuguese Checz Spanish German DMV DMV+Sparsity"]},{"title":"Dependency Parsing Linguistic Rules","paragraphs":["[Naseem et al. 10] Using Universal Linguistic Knowledge to Guide Grammar Induction Tahira Naseem, Harr Chen, Regina Barzilay","Computer Science and Artificial Intelligence Laboratory","Massachusetts Institute of Technology {tahira, harr, regina} @csail.mit.edu","Mark Johnson Department of Computing Macquarie University","mark.johnson@mq.edu.au Abstract We present an approach to grammar induction that utilizes syntactic universals to improve dependency parsing across a range of languages. Our method uses a single set of manually-specified language-independent rules that identify syntactic dependencies between pairs of syntactic categories that commonly occur across languages. During inference of the probabilistic model, we use posterior expectation constraints to require that a minimum proportion of the dependencies we infer be instances of these rules. We also automatically refine the syntactic categories given in our coarsely tagged input. Across six languages our approach outperforms state-of-the-art unsupervised methods by a significant margin.1 1 Introduction Despite surface differences, human languages exhibit striking similarities in many fundamental as-pects of syntactic structure. These structural correspondences, referred to as syntactic universals, have been extensively studied in linguistics (Baker, 2001; Carnie, 2002; White, 2003; Newmeyer, 2005) and underlie many approaches in multilingual parsing. In fact, much recent work has demonstrated that learning cross-lingual correspondences from corpus data greatly reduces the ambiguity inherent in syntactic analysis (Kuhn, 2004; Burkett and Klein, 2008; Cohen and Smith, 2009a; Snyder et al., 2009; Berg-Kirkpatrick and Klein, 2010).","1","The source code for the work presented in this paper is available at http://groups.csail.mit.edu/rbg/code/dependency/ Root → Auxiliary Noun → Adjective Root → Verb Noun → Article Verb → Noun Noun → Noun Verb → Pronoun Noun → Numeral Verb → Adverb Preposition → Noun Verb → Verb Adjective → Adverb Auxiliary → Verb Table 1: The manually-specified universal dependency rules used in our experiments. These rules specify headdependent relationships between coarse (i.e., unsplit) syntactic categories. An explanation of the ruleset is provided in Section 5.","In this paper, we present an alternative grammar induction approach that exploits these structural correspondences by declaratively encoding a small set of universal dependency rules. As input to the model, we assume a corpus annotated with coarse syntactic categories (i.e., high-level part-of-speech tags) and a set of universal rules defined over these categories, such as those in Table 1. These rules incorporate the definitional properties of syntactic categories in terms of their interdependencies and thus are universal across languages. They can potentially help disambiguate structural ambiguities that are difficult to learn from data alone — for example, our rules prefer analyses in which verbs are dependents of auxiliaries, even though analyz-ing auxiliaries as dependents of verbs is also consistent with the data. Leveraging these universal rules has the potential to improve parsing performance for a large number of human languages; this is particularly relevant to the processing of low-resource"]},{"title":"Small set of universal rules = 1 if edge in rule set Eq [φ(x, y)] ≥ b φ(x, y) Dependency Parsing Linguistic Rules","paragraphs":["[Naseem et al. 10] 0 20 40 60 80 English Danish Portuguese Slovene Spanish Swedish DMV DMV+Rules"]},{"title":"Dependency Parsing: Applications using Other Models • Tree CRF •","paragraphs":["[Druck et al. 09]"]},{"title":"• MST Parser •","paragraphs":["[Ganchev et al. 09]"]},{"title":"Other Applications • Multi view learn i ng: •","paragraphs":["[Ganchev et al. 08]"]},{"title":"• Relation extraction: •","paragraphs":["[Chen et al. 11]"]},{"title":"Implementation Tips and Tricks Off-the-Shelf Tools: MALLET http://mallet.cs.umass.edu •","paragraphs":["off-the-shelf support for labeled features"]},{"title":"•","paragraphs":["models: MaxEnt Classifier, Linear Chain CRF (one and two label constraints)"]},{"title":"•","paragraphs":["methods: GE and PR"]},{"title":"•","paragraphs":["constraints on label distributions for input features"]},{"title":"•","paragraphs":["GE penalties: KL divergence, (+ soft inequalities)"]},{"title":"•","paragraphs":["PR penalties: (+ soft inequalities)"]},{"title":"•","paragraphs":["in development: Tree CRF, and other penalties l 2 2 l 2 2 l1"]},{"title":"Off-the-Shelf Tools: MALLET http://mallet.cs.umass.edu •","paragraphs":["import data in SVMLight-like or CoNLL03-like formats"]},{"title":"•","paragraphs":["import constraints in a simple text format:"]},{"title":"•","paragraphs":["easily specify method options (i.e. SimpleTagger): positive interesting:2 film:1 ... negative tired:1 sequel:1 ... positive best:1 recommend:2 ... U.N. NNP B-NP B-ORG official NN I-NP O heads VBZ B-VP O tired negative:0.8 positive:0.2 best positive:0.9 negative:0.1 U.N. B-ORG:0.7,0.9 B-VP O:0.95, java cc.mallet.fst.semi_supervised.tui.SemiSupSimpleTagger \\ --train true --test lab --loss l2 --learning ge \\ unlabeled.txt test.txt constraints.txt"]},{"title":"New GE Constraints: MALLET http://mallet.cs.umass.edu •","paragraphs":["Java Interfaces for implementing new GE constraints"]},{"title":"•","paragraphs":["covariance computation implemented (MaxEnt, CRF)"]},{"title":"•","paragraphs":["primarily need to write methods to:"]},{"title":"•","paragraphs":["restriction: constraints must factor with model"]},{"title":"•","paragraphs":["restriction: GE objective must be differentiable compute constraint features and expectations compute GE objective value compute GE objective gradient (but not covariance)"]},{"title":"New PR Constraints: MALLET http://mallet.cs.umass.edu •","paragraphs":["Java Interfaces for implementing new PR constraints"]},{"title":"•","paragraphs":["inference algorithms implemented (MaxEnt, CRF)"]},{"title":"•","paragraphs":["primarily need to write methods for E-step (projection):"]},{"title":"•","paragraphs":["restriction: constraints must factor with model compute constraint features and expectations compute scores under q for E-step compute objective function for E-step compute gradient for E-step"]},{"title":"GE Implementation Advice •","paragraphs":["computing covariance (required for gradient):"]},{"title":"•","paragraphs":["trick: compute cov. of composite constraint feature"]},{"title":"•","paragraphs":["e xample: penalty:"]},{"title":"•","paragraphs":["re sult: only need to store vectors of size in computation, rather than covariance matrix"]},{"title":"•","paragraphs":["trick: efficient gradient computation in hypergraphs"]},{"title":"•","paragraphs":["use semiring algorithms of [Li & Eisner 09]"]},{"title":"•","paragraphs":["re sult: same time complexity as supervised (w. both) φc(x, y)=∑","φ 2( φ̃ − E[φ])φ(x, y)l2 2 dim(f )"]},{"title":"GE Implementation Advice •","paragraphs":["parameter regularization:"]},{"title":"•","paragraphs":["regularization encourages bootstrapping by penalizing very large parameter values:"]},{"title":"•","paragraphs":["optimization: non-convex"]},{"title":"•","paragraphs":["usually L-BFGS still preferable (use “restart trick”)"]},{"title":"•","paragraphs":["zero initialization usually works well"]},{"title":"•","paragraphs":["other init: supervised, MaxEnt, GE in simpler model l 2 2"]},{"title":"> Off-the-Shelf Tools: PR Toolkit http://code.google.com/p/pr-toolkit/ •","paragraphs":["off-the-shelf support for PR"]},{"title":"•","paragraphs":["models:"]},{"title":"•","paragraphs":["MaxEnt Classifier, HMM,DMV"]},{"title":"•","paragraphs":["applications:"]},{"title":"•","paragraphs":["Word Alignment, Pos Induction, Grammar Induction"]},{"title":"•","paragraphs":["constraints: posterior sparsity, bijectivity, agreement"]},{"title":"•","paragraphs":["No command line mode"]},{"title":"•","paragraphs":["Smaller support base"]},{"title":"PR Implementation example: Word Alignment - Bijectivity •","paragraphs":["Learning: EM, PR • void eStep(counts, lattices); • void mStep(counts); • lattice constraint.project(lattice);"]},{"title":"•","paragraphs":["Model: HMM • lattice computePosteriors(lattice); • void addCount(lattice, counts); • void updateParameters(counts);"]},{"title":"•","paragraphs":["Constraints: Bijectivity • lattice project(lattice);"]},{"title":"PR Implementation example: EM","paragraphs":["class EM { model;  void em(n){ lattices= model.getLattices(); counts = model.counts(); for(i=0; i< n; i++) { eStep(counts, lattices); mStep(counts); } }  void eStep(counts, lattices) { counts.clear(); for(l : lattices) { model.computePosterior(l); model.addCount(l,counts); } } void mStep(counts) { model.updateParameters(counts); } ...... }"]},{"title":"PR Implementation example: PR","paragraphs":["class PR { model; constraint;  void em(n){ lattices= model.getLattices(); counts = model.counts(); for(i=0; i< n; i++) { eStep(counts, lattices); mStep(counts); } }  void eStep(counts, lattices) { counts.clear(); for(l : lattices){ model.computePosterior(l); constraint.project(l); model.addCount(l,counts); } } void mStep(counts) { model.updateParameters(counts); } ...... }"]},{"title":"PR Implementation example: HMM","paragraphs":["class HMM { obsProb, transProbs,initProbs;  lattice computerPosteriors(lattice){ “Run forward backward” }  void addCount(lattice,counts){ “Add posteriors to count table” } void updateParams(counts){ “Normalize counts” “Copy counts to params table” } void getCounts(){ “return copy of params structures” } void getLattices(){ “return structure of all lattices in the corpus” } ...... }"]},{"title":"PR Implementation example: Bijective constraints •","paragraphs":["Constraint: returns a vector with mth value = number of target words in sentence x that align with source word m φ(x, y)= N∑ i=1 1(yi = m) Q = {q : Eq [φ(x, y)] ≤ 1}"]},{"title":"•","paragraphs":["Primal: Hard DKL(Q|pθ ) = arg min","q DKL(q|pθ )"]},{"title":"•","paragraphs":["Dual: Easy arg max","λ≥0 −b T · λ − log Z (λ) − ||λ||2 Z (λ)=∑ y pθ (y|x)exp(−λ · φ(x, y))"]},{"title":"PR Implementation example: Bijective Constraints","paragraphs":["class BijectiveConstraints { model; lattice project(lattice){ obj = BijectiveObj(model,lattice); Optimizer.optimize(obj); }  } class BijectiveObj { lattice;  void updateModel(newLambda){ lattice_ = lattice*exp(newLambda); computerPosteriors(lattice) } double getObj(){ obj = -dot(lambda,b); obj -= lattice.likelihood; obj -= l2Norm(lambda); } double[] getGrad(){ grad = lattice.posteriors - b; grad -= norm(lambda); return grad; }"]},{"title":"Other Software Packages •","paragraphs":["Learning Based Java:"]},{"title":"•","paragraphs":["http://cogcomp.cs.illinois.edu/page/software_view/11"]},{"title":"•","paragraphs":["support for Constraint-Driven Learning"]},{"title":"•","paragraphs":["Factorie:"]},{"title":"•","paragraphs":["http://code.google.com/p/factorie/"]},{"title":"•","paragraphs":["support for GE and PR in development"]},{"title":"Rich Prior Knowledge in Learning for Natural Language Processing","paragraphs":["Bibliography","For a more up-to-date bibliography as well as additional information about these methods, point your browser to: http://sideinfo.wikkii.com/ 1 Constraint-Driven Learning Constraint driven learning (CoDL) was first introduced in Chang et al. [2007], and has been used also in Chang et al. [2008]. A further paper on the topic is in submission [Chang et al., 2010]. 2 Generalized Expectation Generalized Expectation (GE) constraints were first introduced by Mann and McCallum [2007]1","and were used to incorporate prior knowledge about the label distribution into semi-supervised classification. GE constraints have also been used to leverage “labeled features” in document classification [Druck et al., 2008] and information extraction [Mann and McCallum, 2008, Druck et al., 2009b, Bellare and McCallum, 2009], and to incorporate linguistic prior knowledge into dependency grammar induction [Druck et al., 2009a]. 3 Posterior Regularization The most clearly written overview of Posterior Regularization (PR) is Ganchev et al. [2010]. PR was first introduced in Graca et al. [2008], and has been applied to dependency grammar induction [Ganchev et al., 2009, Gillenwater et al., 2009, 2011, Naseem et al., 2010], part of speech induction [Graça et al., 2009a], multi-view learning [Ganchev et al., 2008], word alignment [Graca et al., 2008, Ganchev et al., 2009, Graça et al., 2009b], and cross-lingual semantic alignment [Platt et al., 2010]. The framework was independently discovered by Bellare et al. [2009] as an approximation to GE constraints, under the name Alternating Projections, and used under that name also by Singh et al. [2010] and Druck and McCallum [2010] for information extraction. The framework was also independently discovered by Liang et al. [2009] as an approximation to","1","In Mann and McCallum [2007] the method was called Expectation Regularization. a Bayesian model motivated by modeling prior information as measurements, and applied to information extraction. 4Closelyrelatedframeworks Quadrianto et al. [2009] introduce a distribution matching framework very closely related to GE constraints, with the idea that the model should predict the same feature expectations on labeled and undlabeled data for a set of features, formalized as a kernel.","Carlson et al. [2010] introduce a framework for semi-supervised learning based on constraints, and trained with an iterative update algorithm very similar to CoDL, but introducing only confident constraints as the algorithm progresses.","Gupta and Sarawagi [2011] introduce a framework for agreement that is closely related to the PR-based work in Ganchev et al. [2008], with a slightly different objective and a different training algorithm. References","K. Bellare, G. Druck, and A. McCallum. Alternating projections for learning with expectation constraints. In Proc. UAI, 2009.","Kedar Bellare and Andrew McCallum. Generalized expectation criteria for bootstrapping extractors using record-text alignment. In EMNLP, pages 131–140, 2009.","Andrew Carlson, Justin Betteridge, Richard C. Wang, Estevam R. Hruschka Jr., and Tom M. Mitchell. Coupled Semi-Supervised Learning for Information Extraction. In Proceedings of the Third ACM International Conference on Web Search and Data Mining (WSDM), 2010.","M. Chang, L. Ratinov, and D. Roth. Guiding semi-supervision with constraint-driven learning. In Proc. ACL, 2007.","Ming-Wei Chang, Lev Ratinov, and Dan Roth. Structured learning with constrained conditional models. 2010. In submission.","M.W. Chang, L. Ratinov, N. Rizzolo, and D. Roth. Learning and inference with constraints. In Proceedings of the National Conference on Artificial Intelligence (AAAI). AAAI, 2008.","G. Druck, G. Mann, and A. McCallum. Learning from labeled features using generalized expectation criteria. In Proc. SIGIR, 2008.","G. Druck, G. Mann, and A. McCallum. Semi-supervised learning of dependency parsers using generalized expectation criteria. In Proc. ACL-IJCNLP, 2009a.","Gregory Druck and Andrew McCallum. High-performance semi-supervised learning using discriminatively constrained generative models. In Proceedings of the International Conference on Machine Learning (ICML 2010), pages 319–326, 2010.","Gregory Druck, Burr Settles, and Andrew McCallum. Active learning by labeling features. In EMNLP, pages 81–90, 2009b.","K. Ganchev, J. Graça, J. Blitzer, and B. Taskar. Multi-view learning over structured and non-identical outputs. In Proc. UAI, 2008.","K. Ganchev, J. Gillenwater, and B. Taskar. Dependency grammar induction via bitext projection constraints. In Proc. ACL-IJCNLP, 2009.","Kuzman Ganchev, Joo Graa, Jennifer Gillenwater, and Ben Taskar. Posterior sparsity in unsupervised dependency parsing. Journal of Machine Learning Research, 11:2001–2049, July 2010. URL http://jmlr.csail.mit.edu/ papers/v11/ganchev10a.html.","Jennifer Gillenwater, Kuzman Ganchev, Joo Graa, Ben Taskar, and Fernando Pereira. Sparsity in grammar induction. In NIPS Workshop on Grammar Induction, Representation of Language and Language Learning, 2009.","Jennifer Gillenwater, Kuzman Ganchev, Joo Graa, Fernando Pereira, and Ben Taskar. Posterior sparsity in unsupervised dependency parsing. Journal of Machine Learning Research, 12:455–490, February 2011. URL http://jmlr. csail.mit.edu/papers/v12/gillenwater11a.html.","Joao Graca, Kuzman Ganchev, and Ben Taskar. Expectation maximization and posterior constraints. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 569– 576. MIT Press, Cambridge, MA, 2008.","J. Graça, K. Ganchev, F. Pereira, and B. Taskar. Parameter vs. posterior sparisty in latent variable models. In Proc. NIPS, 2009a.","J. Graça, K. Ganchev, and B. Taskar. Postcat - posterior constrained alignment toolkit. In The Third Machine Translation Marathon, 2009b.","Rahul Gupta and Sunita Sarawagi. Joint training for open-domain extraction on the web: exploiting overlap when supervision is limited. In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining (WSDM), 2011.","P. Liang, M. I. Jordan, and D. Klein. Learning from measurements in exponential families. In Proc. ICML, 2009.","G. S. Mann and A. McCallum. Simple, robust, scalable semi-supervised learning via expectation regularization. In Proc. ICML, 2007.","G. S. Mann and A. McCallum. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Proc. ACL, 2008.","Tahira Naseem, Harr Chen, Regina Barzilay, and Mark Johnson. Using universal linguistic knowledge to guide grammar induction. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1234–1244, Cambridge, MA, October 2010. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/D10-1120.","John Platt, Kristina Toutanova, and Wen-tau Yih. Translingual document representations from discriminative projections. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 251–261, Cambridge, MA, October 2010. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/D10-1025.","Novi Quadrianto, James Petterson, and Alex Smola. Distribution matching for transduction. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 1500–1508. MIT Press, 2009.","Sameer Singh, Dustin Hillard, and Chris Leggetter. Minimally-supervised extraction of entities from text advertisements. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 73–81, Los Angeles, California, June 2010. Association for Computational Linguistics. URL http://www.aclweb.org/anthology/N10-1009."]}]}