{"sections":[{"title":"A tabular interpretation of a class of 2-Stack Automata","paragraphs":["Eric Villemonte de la Clergerie INRIA - Rocquencourt- B.P. 105 78153 Le ChesnayCedex, FRANCE Eric.De_La_Clergerie@inria.fr Miguel Alonso Pardo Universidad de La Corufia Campus de Elvifia s/n 15071 La Corufia, SPAIN alonso©dc, fi. udc. es"]},{"title":"Abstract","paragraphs":["The paper presents a tabular interpretation for a kind of 2-Stack Automata. These automata may be used to describe various parsing strategies, ranging from purely top-down to purely bottom-up, for LIGs and TAGs. The tabular interpretation ensures, for all strategies, a time complexity in O(n 6) and space complexity in"]},{"title":"O(n 5)","paragraphs":["where n is the length of the input string. Introduction 2-Stack automata [2SA] have been identified as possible operational devices to describe parsing strategies for Linear Indexed Grammars [LIG] or Tree Adjoining Grammars [TAG] (mirroring the traditional use of Push-Down Automata [PDA] for Context-Free Grammars [CFG]). Different variants of 2SA (or not so distant Embedded Push-Down Automata) have been proposed, some to describe top-down strategies (Vijay-Shanker, 1988; Becker, 1994), some to describe bottom-up strategies (Rambow, 1994; Nederhof, 1998; Alonso Pardo et al., 1997), but none (that we know) that are able to describe both kinds of strategies.","The same dichotomy also exists in the different tabular algorithms that has been proposed for specific parsing strategies with complexity ranging from O(n 6) for bottom-up strategies to"]},{"title":"O(n 9)","paragraphs":["for prefix-valid top-down strategies (with the exception of a O(n 6) tabular interpretation of a prefix-valid hybrid strategy (Nederhof, 1997)). It must also be noted that the different tabular algorithms may be difficult to understand and it is often unclear to know if the algorithms still hold for different strategies.","This paper overcomes these problems by (a) introducing"]},{"title":"strongly-driven 2SA","paragraphs":["[SD-2SA] that may be used to describe parsing strategies for TAGs and LIGs, ranging from purely top-down to purely bottom-up, and (b) presenting a tabular interpretation of these automata in time complexity O(n 6) and space complexity"]},{"title":"O(nS).","paragraphs":["The tabular interpretation follows the principles of Dynamic Programming: the derivations are broken into elementary sub-derivations that may (a) be combined in different contexts to retrieve all possible derivations and (b) be represented in a compact way by"]},{"title":"items,","paragraphs":["allowing tabulation.","The strongly-driven 2SA are introduced and motivated in Section 1. We illustrate in Sections 2 and 3 their power by describing several parsing strategies for LIGs and TAGs. Items are presented in Section 4. Section 5 lists the rules to combine items and transitions and establishes correctness theorems. 1 Strongly-driven 2-Stack Automata 2SA are natural extensions of Push-Down Automata working on a pair of stacks. However, it is known that unrestricted 2SA have the power of a Turing Machine. The remedy is to consider asymmetric stacks, one being the Master Stack MS where most of the work is done and the other being the Auxiliary Stack AS mainly used for restricted \"bookkeeping\".","The following remarks are intended to give an idea of the restrictions we want to enforce. The first ones are rather standard and may be found under different forms in the literature. The last one justifies the qualification of \"strongly-driven\" for our automata. [Session] AS should actually be seen as a stack of"]},{"title":"session stacks,","paragraphs":["each one being associated to a"]},{"title":"session.","paragraphs":["Only the topmost session stack may be consulted or modified. This idea is closely related to the notion of"]},{"title":"Embedded Push-Down Automata","paragraphs":["(Rambow, 1994, 96-102).","[Linearity] A session starts in mode write w and switches at some point in mode erase e. In mode w (resp. e), no element can be popped from (resp. pushed to) the master stack MS. Switching back from e to w is not allowed. This requirement is related to linearity because it means that a same session stack is never used twice by \"descendants\" of an element in MS.","[Soft Session Exit] Exiting a session is only possible when reaching back, with an empty session stack and in mode erase, the MS element that initiated the session.","[Driving] Each pushing on MS done in write mode leaves some mark in MS about the action that 1333 <"]},{"title":"/zW \\W /ZE \\E I I I I","paragraphs":["--*W ~W Write Mode 11"]},{"title":"-~E ~E I I I I I I I I I I I I I I I •","paragraphs":["Master stack Figure 1: Representation of transitions and derivations took place on the session stack. The popping of this mark (in erase mode) will guide which action should take place on the session stack. In other words, we want the erasing actions to faithfully retrace the writing actions.","Formally, a SD-2SA .A is specified by a tuple (~, .M, X, $0, $l, O) where ~ denotes the finite set of terminals, .M the finite set of master stack elements and X the finite set of auxiliary stack elements. The init symbol $0 and final symbol $y are distinguished elements of Ad. O is a finite set of transitions.","The master stack MS is a word in (D.M)* where 2) denotes the set {/~, x.~, ---% ~} of action marks used to remember which action (w.r.t. the auxiliary stack AS) takes place when pushing the next master stack element. The empty master stack is noted e and a non-empty master stack ~1A1 ... ~nAn where A,~ denotes the topmost element.","The meaning of the action marks is: /2 Pushing of an element on AS. \"x~ Popping of the topmost element of AS. --* No action on AS. Creation of a new session (with a new empty session stack on AS).","The auxiliary stack AS is a word of (K:X*)* where K: = {~w,~e} is a set of two elements used to delimit session stacks in AS. Delimiter ~w (resp. ~e) is used to start a new session from a session which is in writing (resp. erasing) mode. The empty auxiliary stack is noted e.","Given some input string xl ... xi E E*, a configuration of .A is a tuple (m, u, ~, ~) where m E {w, e} denotes a mode (writing or erasing), u a string position in [0, f], -- the master stack and ~ the auxiliary stack. Modes are ordered by w -~ e to capture the fact that no switching from e to w is possible. The initial configuration of ,4 is (w, 0, ~$0, ~w) and the final one (e, f,"]},{"title":"~$f, ~W).","paragraphs":["A transition is given as a pair (p, --, ~), z (q, O, 0) where p, q are modes (or, with some abuse, variables ranging over modes), z in E*, .-- and O suffixes of master stacks in .M(2)Ad)*, and ~,0 suffixes of auxiliary stacks in"]},{"title":"X*(~gX*)*","paragraphs":["= (XUK:)*. Such a transition applies on any configuration (p, u, k~--, ~b~) such that xu+l ... x, = z and returns (q, v, ~0, ¢0). We restrict the kind of allowed transitions:","SWAP (p, A, ~), z (q, B, ~) with p _ q and either","e K: (\"session bottom check\") or ~ = e (\"no AS consultation\") . /-WRITE (w,A, e), z (w,"]},{"title":"ATB, b)","paragraphs":["/-ERASE (e,"]},{"title":"A/ZB,a) , z (e, D, e)","paragraphs":["--*-WRITE (w, A, e), ~ , (w,"]},{"title":"A-*B, e)","paragraphs":["--*-ERASE (e,"]},{"title":"A-+B, e) , ~ ~","paragraphs":["(e, C, e) ~-WRITE (m, A, e), z, (w,"]},{"title":"A~B, ~m)","paragraphs":["~-ERASE (e,"]},{"title":"A~B, ~m) ~i~ (m, C, e)","paragraphs":["x,~-WRITE (w, A, a), ~, (w,"]},{"title":"A'x~B, e)","paragraphs":["\"~-ERASE (e,"]},{"title":"A\"~B, e) , ~ , (e, C, c)","paragraphs":["Figure 1 graphically outlines the different kinds of transitions using a 2D representation where the X-axis (Y-axis) is related to the master (resp. auxiliary) stack. Figure 1 also shows the two forms of derivations we encounter (during a same session). 2","Using 2SA to parse LIGs Indexed Grammars (Aho, 1968) are an extension of Context-free Grammars in which a stack of indices is associated with each non-terminal symbol. Linear Indexed Grammars (Gazdar, 1987) are a restricted form of Indexed Grammars in which the index stack of at most one body non-terminal (the"]},{"title":"child)","paragraphs":["is related with the stack of the head non-terminal (the"]},{"title":"father).","paragraphs":["The other stacks of the production must","have a bounded stack size. Formally, a LIG G is a 5-tuple"]},{"title":"(VT, VN, S, VI,P)","paragraphs":["where"]},{"title":"VT","paragraphs":["is a finite set of terminals,"]},{"title":"VN","paragraphs":["is a finite set of non-terminals,"]},{"title":"S E VN","paragraphs":["is the start symbol, VI is a finite set of indices and P is a finite set of productions. Following (Gazdar, 1987) we consider productions in which at most one element can be pushed on or popped from a stack of indices: 1334 [Terminal] Ak,o[] --+ ak where ak • VT U {•}, [POP] Ak,o [oo] --. Ak,t []... Ak,d[oo'y]... Ak,.~ [] [PUSH] Ak,0[ooT]--* Ak,1 []... Ak,d[OO]... Ak,,~ [] [HOR] Ak,0[oo] ~ ak,1 [1... Ak,d[OO]... a~,,~ [1","To each production k of type PUSH, POP or HOR, we associate a characteristic tuple t(k) = (d, 5, a,/3) where d is the position of the child and the other arguments given by the following table: Type 5 a PUSH /z e 7 POP ~ 7 e HOR ---* e • We introduce symbols ~'k,i as a shortcut for dotted productions [Ak,0~Ak,1 ... Ak,i • Ak,i+ l ... Ak,,~ ].","In order to design a broad class of parsing strategies ranging from pure top-down to pure bottom-up, we parameterize the automaton to be presented by a call projection -'* from 12 to )2 cart and a return projection *'-\" from 12 to \"W et where ~ = VN U VI and ]2 cart and V ret are two sets of elements. We require ]2 cart N ]2 ret = 0 and (\"-*, +'-) to be invertible, i.eVX, rev, (X,*X) = (V, ~) =:~ x = r","The projections extend to sequences by taking X1... X: = X-~I ... ~ and \"~ =e (similarly for +-).","Given a LIG G and a choice of projections, we define the 2SA .A(G, -~, = ~-) (Vr, M, X, -~, ~, O) where M = {Vk,i}U~TU~TT, X = ~//U~//, and whose transitions are built using the following rules. • Call/Return of a non child CALL: (m, Vk,i,e)* , (w, Vk,i~,~ rn) RET: (e, , (m, Vk,i+,,e) • Call/Return of a child for t(k) = (i + 1,5, a,/3). CALL(5) : (w, Vk,i, W), ~_~ (w, Vk,iSAk,-~+l, \"-~) RET(5) : (e, Vk,iSAk,i++'-'-';1, /3) , , (e, Vk.i+l, W) • Production Selection SEL: (w,A---~,0, e), , (w, Vk,0, e) • Production Publishing PUB: (e, Vk,n~,e), , (e, ~0k,0, e) • Scanning (for terminal productions) SCAN : (w, ' m a~ ~ m Ak,0, ~ )~---*(e, Ak,0, ~ )","The reader may easily check that A(G,-'-*, ~-'-) recognizes L(G). The choice of the call and return elements for the MS (A~k,i and Ak,i) and the AS ('-~ and ~') defines a parsing strategy, by controlling how information flow between the phases of prediction and propagation. The following table lists the choices corresponding to the main parsing strategies (but others are definable). Strategy ~ ~- -~ ~- Top-Down A _l_ 7 .l_ Bottom-Up 2. A' _l_ 7 Earley A A' 7 7'","It is also worth to note that the description of A(G,-*, +--) could be simplified. In-deed, for every configuration (m,u,E,~) derivable with .A(G, \"--*,*-\"), we can show that --- = ~Vkl,ilSt... Vk.,i,,SnX, and that 5t only depends on Vk~,i~. That means that we could use a master stack without action marks, these marks being implicitly given by the elements XTk,i. 3 Using 2SA to parse TAGs Tree Adjoining Grammars are a extension of CFG introduced by Joshi in (Joshi, 1987) that use trees instead of productions as primary representing structure. Formally, a TAG is a 5-tuple G = (VN,VT, S,I,A), where VN is a finite set of non-terminal symbols, VT a finite set of terminal symbols, S the axiom of the grammar, I a finite set of initial trees and A a finite set of auxiliary trees. IUA is the set of elementary trees. Internal nodes are labeled by non-terminals and leaf nodes by terminals or e, except for exactly one leaf per auxiliary tree (the foot) which is labeled by the same non-terminal used as label of its root node.","New trees are derived by adjoining: let be a a tree containing a node u labeled by A and let be fl an auxiliary tree whose root and foot nodes are also labeled by A. Then, the adjoining of/3 at the adjunction node u is obtained by excising the subtree a~ of a with root u, attaching/3 to u and attaching the excised subtree to the foot of/3 (See Fig. 2). pine Figure 2: Traversal of an adjunction","An elementary tree a may be represented by a set P(a) of context free productions, each one being either of the form","• Yk,O ---4 Pk,1... Pk,n~, where Yk,o denotes some non-leaf node k of a and uk,i the i th son of k. 1335","• vk,0 --* al¢, where vk,0 denotes some leaf node k of c~ with terminal label ak.","As done for LIGs, we introduce symbols Vk,i to denote dotted productions and consider projections \"* and ~ to define the parameterized 2SA .A(G, -'-*, *\") ="]},{"title":"(VT, At, At,","paragraphs":["v0,0, ~0,0, O) where At = {Vk,i) U {vk,i} U {v~,/). The transitions are given by the following rules (and illustrated in Figure 2). • Call / Return for a node not on a spine. The","call starts a new session, exited at return. CALL : (m, Vk,i,e) , , (w,","m RET: (e, Vk,/~vk.i+l,~ )' ' (m, Vk,i+l,e) • Call / Return for a node"]},{"title":"vk,i+l","paragraphs":["on a spine. The adjunction stack is propagated un-modified along the spine.","SCALL : (w, Vk,i,e), ,"]},{"title":"(w, Vk,i---*vk,i+~,e) SRET :","paragraphs":["(e,"]},{"title":"Vk,i--*bk,i+l, e) , ~ (e,","paragraphs":["Vk,i+l,e)","• Call / Return for an adjunction on node uk,0. The computation is diverted to parse some acceptable auxiliary tree ~ (with root node rh), and a continuation point is stored on the auxiliary stack.","ACALL : (w, vk,0,e) , ,"]},{"title":"Vk,o/Zr~,Vk,o) ARET:","paragraphs":["(e,v~,o/ZF3Z,Vk,,~), , (e, ~-\" e) /]k,0, • Call / Return for a foot node f~. The continu-","ation stored by the adjunction is used to parse","the excised subtree. FCALL : (w, f~,A) ,- , (w, f-'-~\"~A, e) FRET : (e,"]},{"title":"f~'%A,~) , , (e, ]~,A)","paragraphs":["Note: These two transitions use a variable A over At. This is a slight extension of 2SA that preserves correctness and complexity.","• Production Selection SEL: (w, vk.~,e), , (w, Vk,0,e)","• Production Publishing PUB: (m, Vk,n~,e), (e,~ e) /]k,0, • Scanning SCAN: (w, v~,0, ~m), ~,(e, ~---","Different parsing strategies can be obtained by choosing the call (vk,i) and return (vk,i) elements:","Strategy prefix-valid Top-Down v _l_ Bottom-Up _L v' prefix-valid Earley v v'","Non prefix-valid variants of the top-down and Earley-like strategies can also be defined, by taking ~ = _L and ~ = r~ for every root node r~ of an auxiliary tree j3 (the projections being unmodified on the other elements). In other words, we get a full prediction on the context-free backbone of G but no prediction on the adjunctions. 4","Items We identify two kinds of elementary derivations, namely Context-Free [CF] and escaped Context-Free [xCF] derivations, respectively represented by CF and xCF items. An item keeps the pertinent information relative to a derivation, which allows to apply the sequence of transitions associated with the derivation in different contexts.","Before presenting these items, we introduce the following classification about derivations.","A derivation"]},{"title":"(p,u, EA,~)[--~7 / (q,v,O,O)","paragraphs":["is said rightward if no element of E is accessed (even for consultation) during the derivation and if A is only consulted. Then F~A is a prefix of O.","Similarly, a derivation (p, u, E, ~)1-~\" (q, v, O, 0) is said upward if no element of ~ is accessed (even for consultation). Then ~ is a prefix of 0.","We also note"]},{"title":"w[q/p]","paragraphs":["the prefix substitution of p by q for all words"]},{"title":"w,p, q","paragraphs":["on some vocabulary such that p is prefix of w. 4.1 Context-Free Derivations A Context-Free [CF] derivation only depends on the topmost element A of the initial stack MS. That means that no element of the initial AS and no element of MS below element A is needed: (o, u,-A, ~)l-~l (w,"]},{"title":"v, OB, 0)1-~2 (m, w, OBhC, ~c)","paragraphs":["where • dl and"]},{"title":"did2","paragraphs":["are both rightward and upward. • d 2 is rightward.","• either (5 # ~, o = w, and c e A') or (5 = ~, and c = ~o). For such a derivation, we have: Proposition 4.1"]},{"title":"For all prefix stacks","paragraphs":["E',~',"]},{"title":"(o,u,E'A,(')","paragraphs":["I-~, (w,v, O'B,8') (re, w, O'B6C,(c) where O' = and o' = O[gl ].","The proposition suggests representing the CF derivation by a CF item of the form"]},{"title":"ABh(7, m","paragraphs":["where A = (u, A) and B = (v, B) are micro configurations and (7 = (w, C, c) a mini configuration. 1336"]},{"title":"B ~c","paragraphs":["A .t~.--. \" \""]},{"title":"CF(-*)","paragraphs":["Item"]},{"title":"CF(7)","paragraphs":["or"]},{"title":"CF(~)","paragraphs":["Item B"]},{"title":"CF(X~)","paragraphs":["Item B • : : : • : : :"]},{"title":"xCF(--*)","paragraphs":["Item r~ I I I I I I I I : : :"]},{"title":"xCF(/z)","paragraphs":["Item r~ \"-~ I I I I I I Figure 3: Items Shapes"]},{"title":"A xCF('x~)Item r~ I I I I I I I ,","paragraphs":["4.2 Escaped Context-Free Derivations An escaped Context-Free [xCF] derivation is al-most a CF derivation, except for an"]},{"title":"escape","paragraphs":["sub-derivation that accesses deep elements of AS. where (w, u, EA, ~)"]},{"title":"I~","paragraphs":["(w,v, eB, e) [ *--\"- (w, s, @D, ~d) d~"]},{"title":"I*-- (e,t,@DX,~E,¢)","paragraphs":["dx"]},{"title":"I-~; (e, w, OBSC, ¢c)","paragraphs":["• dl and"]},{"title":"did2","paragraphs":["are both rightward and upward• • d2 and"]},{"title":"dx","paragraphs":["are rightward• • d3 is upward• • 5# ~ and d, cE X. Proposition 4.2"]},{"title":"For all prefix stacks ~ and ~', stack ¢~, and rightward derivation","paragraphs":["(w,"]},{"title":"s, @'D, ~'d)l~x , (e, t, @'DX,~E,","paragraphs":["¢')"]},{"title":"where","paragraphs":["~' = ¢[~'/E],"]},{"title":"we have","paragraphs":["(w, u, E'A, ~')[-~-"]},{"title":"I~*","paragraphs":["d2"]},{"title":"I~*","paragraphs":["d3"]},{"title":"(w, v, e[='/--]B, e[~'/~]) (w, s, ¢[-' lZ] D, ~' d) . ( e, t, ¢[E' /E]DX~E,","paragraphs":["¢')"]},{"title":"(e, w, O[~-'/Z]BSC, ¢'c)","paragraphs":["The proposition suggests representing the xCF derivation by an xCF item of the form"]},{"title":"ABS[i:) E]Ce","paragraphs":["where A = (u,A), B -- (v,B/, /~ = (s,D,d/, E = (t, E / and C -- (w, C, c/.","In order to homogenize notations, we also use the alternate notation"]},{"title":"ABS[oo]Cm","paragraphs":["to represent CF item"]},{"title":"ABSC'rn,","paragraphs":["introducing a dummy symbol o. The specific forms taken by CF and xCF items for","the different actions 5 are outlined in Figure 3."]},{"title":"5 Combining items and transitions","paragraphs":["We provide the rules to combine items and transitions in order to retrieve all possible 2SA derivations.","These rules do not explicit the scanning constraints and suppose that the string z may be read between positions w and k of the input string• They use holes * to denote slots that not need be consulted. For any mini configuration A = (u, A, a), we note ~o = (u, A) its micro projection• [--*-WRITE] r = (w, C, e), ~, (w,"]},{"title":"C--*F, e)","paragraphs":["A**[oo]Cw =~ AC°~[oo]~'w where C = <w, C, c>, and F = (k, F, c). [/-WRITE] r = (w, C, e), ~, (w,"]},{"title":"C/ZF, f)","paragraphs":["(1) A**[oo] Cw ==~ G ° G °/z [oo] Fw where C = (w, C, c), and F = (k, F, f). [~-WRITE] r = (m, C, e) vz. \" (w,"]},{"title":"C~F, ~\"~)","paragraphs":["(2)"]},{"title":"A**[oo]Cm ==~","paragraphs":["C°C°~[o¢]Fw where C = (w, C, c), and F = {k, F, ~m). iX-WRITE] T = (W, C, c): z (w,"]},{"title":"CX~F,e)","paragraphs":["(3) ]i°**[°°]CWM**[oo]Aw }~ MC°\\[°°]Fw (4) where C = (w,C,c), A = (u,A,a), and F = <k,F,a). [--*-ERASE] r = (e,"]},{"title":"B--*C, e) , ~ , (e, F, e)","paragraphs":["A°MA[°°] ]~w'4°]~°~[DE]Oe }~ A°MA[DE]Fe (5) where C = (w, C, c), b = (v, B, b), ~' = (k, F, c/, and (when D # o) D = (s,D,b). 1337 [x,~-ERASE] ~- = (e,"]},{"title":"Bx~C,e),","paragraphs":["z (e,f, f) 21° B°\"~[D*]C'e"]},{"title":"}","paragraphs":["~I°*A [oo]-~lw =~ -/V/° O#[]~C°] ~'e (6)"]},{"title":"f~°o~[oolBw","paragraphs":["where C' = (w,C,c), /~ = (v,B,b), M = (/,M,m), ~' = (k,F,f), and (when D ~ o) D = (*,*,m). IF-ERASE] ~- = (e,"]},{"title":"B~C, ~'~) ~ (m, F, e) /~°B~[oo]Ce }~ MNA[DE]Fm","paragraphs":["(7)"]},{"title":"MNA[DE]Bm","paragraphs":["where C = (w~C,~m),"]},{"title":"B = (v,B,b),","paragraphs":["and ~' ="]},{"title":"(k,F,a)","paragraphs":["[/Z-ERASE] r = (e,"]},{"title":"B/ZC, c) ,","paragraphs":["= ~"]},{"title":"(e, F, e)","paragraphs":["MNA[~]l~w/~°]~/°/Z[°°]Ce }==~ MNA[°°]/ae (S) where (~7 = (w,C,c/, B = (v,B,b/, and ~' = (k, F, b)"]},{"title":".B°B°/Z[DE°]Ce }","paragraphs":["MNA[oolBw"]},{"title":"~ MNA[OPI~'e","paragraphs":["(9)"]},{"title":"MD°x,~[OP]E,e","paragraphs":["where C' = (w, C, c), /~ = (v, B, b), ~' = {k, F, b), and (when O # o) O = <l, O, b). [SWAP] r = (p, C,~), z (q, F,~)"]},{"title":"AB6[DE]Cm ~ AB6[DEI~'m (10)","paragraphs":["where C? = (w, C, c), ~' = (k, F, c), and either"]},{"title":"c=~=~°or~=e.","paragraphs":["The best way to apprehend these rules is to visualize them graphically as done for the two most complex ones (Rules 6 and 9) in Figures 4 and 5. A \"--L Figure 4: Application of Rule 6 N C D ~M P \"~'-\"~ Figure 5: Application of Rule 9 5.1 Reducing the complexity An analysis of the time complexity to apply each rule gives us polynomial complexities"]},{"title":"O(n\")","paragraphs":["with u <_ 6 except for Rule 9 where u = 8. However, by adapt-ing an idea from (Nederhof, 1997), we replace Rule 9 by the alternate and equivalent Rule 11."]},{"title":"\"B°*/[b'E°]C'e } ,D° x,,~[OP]~'e","paragraphs":["MNA[oo]l~w"]},{"title":"~ MNA[OPI~e","paragraphs":["(11)"]},{"title":"M .'%[O P]*e","paragraphs":["where C7 : (w,C,c), B = (v,B,b), ~' = (k,F,b), and (when O ¢ v) O = (l, O, b).","Rule 11 has same complexity than Rule 9, but may actually be split into two rules of lesser complexity"]},{"title":"O(n6),","paragraphs":["introducing an intermediary pseudo-item"]},{"title":"BB/Z[[OP]]Ce","paragraphs":["(intuitively assimilable to a \"deeply escaped\" CF derivation).","Rule 12 collects these pseudo-items (independently from any transition) while Rule 13 combines them with items (given a/Z-ERASE transition ~-). BB/Z[/)E°]C'e }===~"]},{"title":"BB/Z[[OP]](3'e","paragraphs":["(12)"]},{"title":"*D°\\[OP]E,e","paragraphs":["1~° ]~°/Z[[OP]]Ce } MNA[c~]I~w"]},{"title":"~ MNA[OP]Fe","paragraphs":["(13)"]},{"title":"M* ~,~[OP]*e","paragraphs":["where C7 = (w,C,c}, B = (v,B,b), ~' = (k,F,b), and (when"]},{"title":"O ¢ o) O = (l, O, b).","paragraphs":["Theorem 5.1"]},{"title":"The worst time complexity of the ap- plication rules (1,2,3,4,5,6,7,8,10,12,13) is O(n 6) where n is the length of the input string. The worst space complexity is O(nS).","paragraphs":["5.2 Correctness results Two main theorems establish the correctness of derivable items w.r.t, derivable configurations.","A derivable item is either the initial item or an item resulting from the application of a combination rules on derivable items. The initial item (0, e)(0, e)~[oo] <0, $0, ~w> w stands for the virtual derivation step (w, 0, e, e)[- (w, 0, ~$0, ~w). Theorem 5.2 (Soundness)For"]},{"title":"every derivable item Z = AB6[£IE]Cm, there exists a derivation on configurations (o, e) I-D--- Ul~- v such that H[-~- V is a CF or xCF derivation repre- sentable by I. Proof:","paragraphs":["By induction on the item derivation length and by case analysis. I 1338 Theorem 5.3 (Completeness) For all derivable configuration (m, w, EC , ~c), there exists a derivable item AB~[DE]Cm such that C = (w, C, c}. Proof: By induction on the configuration derivation length and by case analysis of the different application rules. We also need the following \"Extrac-tion Lemma\". | Proposition 5.1 From any derivation"]},{"title":"(0, e)I--~- (m, w, EC, ~c)","paragraphs":["may be extracted a suffix CF or xCF sub-derivation U[~ (m, .,, ~.C, ~c) for some configuration U. 5.3 Illustration In the context of TAG parsing (Sect. 3), we can provide some intuition of the items that are built with .A(G, \"-*, +-), using some characteristic points encountered during the traversal of an adjunction (Fig. 6).","on ADJ","on SPINE","on FOOT after CALL A1A1/[oo]RIw AI SI'--'~[oO]Fl W Bi Fl\"N[oo]Aaw before RET","AIAI/[F1A4]R2e"]},{"title":"AI S1---+[FI A4]F2e","paragraphs":["B1 F1 \",.~ [G, B4]A4 e Figure 6: Adjunction and Items 6","Conclusion This paper unifies different results about TAGs and LIGs in an uniform setting and illustrates the advantages of a clear distinction between the use of an operational device and the evaluation of this device. The operational device (here SD-2SA) helps us to focus on the description of parsing strategies (for LIGs and TAGs), while, independently, we design an efficient evaluation mechanism for this device (here tabular interpretation with complexity O(n6)).","Besides illustrating a methodology, we believe our approach also opens new axes of research.","For instance, even if the tabular interpretation we have presented has (we believe) the best possible complexity, it is still possible (using techniques outside the scope of this paper, (Barth61emy and Villemonte de la Clergerie, 1996)) to improve its efficiency by refining what information should be kept in each kind of items (hence increasing computation sharing and reducing the number of items).","To handle TAGs or LIGs with attributes, we also plan to extend SD-2SA to deal with first-order terms (rather than just symbols) using unification to apply transitions and subsumption to check items.","References","Alfred V. Aho. 1968. Indexed grammars -- an extension of context-free grammars. Journal of the ACM, 15(4):647-671, October.","Miguel Angel Alonso Pardo, Eric de la Clergerie, and Manuel Vilares Ferro. 1997. Automata-based parsing in dynamic programming for Linear Indexed Grammars. In A. S. Narin'yani, editor, Proc. of DIALOGUE'97 Computational Linguistics and its Applications International Workshop, pages 22-27, Moscow, Russia, June.","F. P. Barth~lemy and E. Villemonte de la Clergerie. 1996. Information flow in tabular interpretations for generalized push-down automata. To appear in journal of TCS.","Tilman Becker. 1994. A new automaton model for TAGs: 2-SA. Computational Intelligence, 10(4):422-430.","Gerald Gazdar. 1987. Applicability of indexed grammars to natural languages. In U. Reyle and C. Rohrer, editors, Natural Language Parsing and Linguistic Theories, pages 69-94. D. Reidel Publishing Company.","Aravind K. Joshi. 1987. An introduction to tree adjoining grammars. In Alexis Manaster-Ramer, editor, Mathematics of Language, pages 87-115. John Benjamins Publishing Co., Amsterdam/Philadelphia.","Mark-Jan Nederhof. 1997. Solving the correct-prefix property for TAGs. In T. Becker and H.-V. Krieger, editors, Proc. of MOL'97, pages 124-130, Schloss Dagstuhl, Germany, August.","Mark-Jan Nederhof. 1998. Linear indexed automata and tabulation of TAG parsing. In Proc. of First Workshop on Tabulation in Parsing and Deduc-tion (TAPD'98), pages 1-9, Paris, France, April.","Owen Rambow. 1994. Formal and Computational Aspects of Natural Language Syntax. Ph.D. thesis, University of Pennsylvania.","K. Vijay-Shanker. 1988. A Study of Tree Adjoining Grammars. Ph.D. thesis, University of Pennsylvania, January. 1339"]}]}
