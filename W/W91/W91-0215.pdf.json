{"sections":[{"title":"A model for the interaction of lexical and non-lexical knowledge in the determination of word meaning Peter","paragraphs":["Gerstl","IBM Germany, Scientific Center","Institute for Knowledge Based Systems","Schloflstr. 70","7000 Stuttgart 1 e-mail: gersti @ dsOiilog.bitnet","Abstract The lexicon of a natural language understanding system that is not restricted to one single application but should be adaptable to a whole range of different tasks has to provide a flexible mechanism for the determination of word meaning. The reason for such a mechanism is the semantic variability of words, i.e. their potential to denote different things in different contexts. The goal of our project is a model that makes these phenomena explicit. We approach this goal by defining word meaning as a complex function resulting from the interaction of processes operating on knowledge elements. In the following we characterize the range of phenomena our model is intended to describe and give an outline of the way in which the interpretation process may determine the referential potential of words by the integration and evaluation of a variety of factors."]},{"title":"1 Introduction","paragraphs":["A system with the capability of natural language understanding typically relies on knowledge about a restricted domain of application. For example, as a natural language component of an information system, it needs to be able to identify the relevant linguistic patterns. In case of an information system for flight scheduling words such as \"plane\", \"departure\", \"late\", ...will typically be more relevant than for example: \"pahn\", \"this-tle\", \"pine\" which might be appropriate for a different domain. In any event, there will be a whole range of words that are commonly used in conversation and, thus, are independent from the choice of a specific domain. It is therefore desirable to have a multi-level architecture which can be adapted to different domains without being forced to redesign the whole system. A text understanding system based on this kind of architecture would provide the kernel functionality that allows it to couple principles and mechanisms not immediately dependent on the domain a specific implementation of the system will be used for. The main problem of such a modular architecture is how and where to draw the boundary between domain-independent and domain-specific knowledge. There are at least two more reasons which motivate a domain-oriented design strategy:","With regard to knowledge representation, the history in artificial intelligence research has lead from early enthusiastic plans of 'general problem solving capabilities' to more realistic applications of expert systems. One reason was the huge amount of data that would have to be represented together with a large set of regularities introducing a level of complexity which could not, be handeled in a realistic manner by the systems currently 165 available. Another problem is the inconsistency of data that would necessarily arise once a lot of different and sometimes conflicting information had to be integrated into a single knowledge base. Under this perspective task- and domain-orientation is a matter of rendering the knowledge base manageable and to allow reasoning processes to draw meaningful inferences on the basis of consistent data.","The second argument in favour of a domain-oriented design strategy comes from the area of lexical semantics. It is a well known fact that the meaning of a word depends on a multitude of contextual influences. In a very broad notion of context the task and the domain of a text understanding system may be considered a part of the context that licences an effective restriction of the 'semantic scope' of a single word. This again is mainly an argument of tractability which in this case helps to minimize the amount of lexical information needed. In our example it is a natural design decision to assume that the lexicon of a language understanding system as part of an information system about flight schedules does not have to account for the 'plant'-reading of \"plane\"."]},{"title":"2 The variability of words","paragraphs":["The way in which a word might contribute to the determination of the meaning of linguistic expressions is indeterminate in different ways. W. Labov calls the semantic potential of words enabling them to constitute various links between linguistic expressions and elements of the domain (semantic) variability. It is this potential which is responsible for the already mentioned context dependence of word meaning. An important goal of our model is to classify types of variability according to a set of more or less specific properties. The questions guiding this classification are: Which kind of representation does the variability affect; by which means are the variants related and, how can the referential potential be restricted in order to single out the intended meaning? In the linguistic tradition, these variability phenomena fall into one of four classes which we will sketch out below. 2.1 Morphological ambiguity This class represents cases of identical surface representations of words extracted from a discourse. Depending on the kind of representation in which the natural language input is encoded (i.e. orthographic, phonetic, ... form) cases of homography or homophony may belong to this class or not. Homonymy as a specific instance of morphological ambiguity results from the identity of lexical base forms. In a lexicon using orthographic representations as is normally the case in dictionaries (singular nouns, infinitive forms of verbs, ... ) there are for example two homonymous entries for \"firm\" (the adjective and the noun variant). In addition, morphological ambiguity captures the more general case of an inflected form that is identical to a base form or to another inflected form. An example is the occurence of \"saw\" which depending on the context can be understood as noun, as base form of the verb \"saw\" or as inflected form derived from the base form \"see\".","It is a notorious problem in lexical semantics [Kooij 71] to justify the distinction between coincidental identity of forms (morphologicM ambiguity) and semantic variants of a single lexical item (chapter 2.2). In our approach it depends on the purpose of the system and, thus, is a design decision comparable to modelling conventions for the domain knowledge. Identical basic word forms which are in no relevant and transparent"]},{"title":"166","paragraphs":["way related to the representation of knowledge about the domain will be represented by different lexical items. The question whether two identical forms 'collapse' into a single entry is then directed by the choice of the domain and the task analogous to the way in which drawing a boundary between elements of the domain is motivated. Defining two word forms as being homonymous yields the consequence that once the occurence in a discourse has been morphologically identified and thus mapped onto the corresponding lexical item it is no more possible to skip to a different homonymous variant. Words which shall not expose this behaviour should not be modelled as homonymous hut as semantic variants of a single lexical item. 2.2 Polysemy and polyfunctionality In the preceding chapter we outlined the situation where two lexical items realize the same word form. The potential of semantic variation encoded in a single lexical item is known"]},{"title":"as polysemy.","paragraphs":["It remains in effect once the appropriate lexical item has been identified by means of morphological processes. A special case of polysemy is what [Weber 74] calls"]},{"title":"polyfuaclionalily","paragraphs":["refering to the situation where two variants of a lexical item belong to different syntactic categories. Polyfunctionality occurs very frequently since many lexical items allow identical realizations which belong to different syntactic categories being related by means of conversion or other morphological processes which do not affect the word stem. Examples are the nominal and verbal reading of \"point\" and the variants of \"clean\" which are categorized as adjective, adverb and verb. The comparison with variants in a dictionary is not as effective as it was in chapter 2.1 because the entries in a dictionary tend to conflate phenomena we call polysemy and cases of variability outlined in chapter 2.3. 2.3 Metonymy and change of semantic type In the previous chapter we mentioned that a polyfunctional expression can be the analyzed as the realization of different categories in different contexts. The difference in semantic potential that arises from this variability sometimes not only involves the transition to a different semantic type in the sense of Montague grammar but it may be paralleled by a more or less extensive shift in conceptual interpretation (cf. the one-place versus two-place predicate reading of \"drink\"). Apart from ambiguities which are reflected by morphosyntactic properties of a lexical item (eg. its argument structure) there are instances of semantic variation allowing to change the interpretation of a class of linguistic items in a systematic manner. The crucial question is if this class should be characterized by lexical information or on the basis of regularities found in the domain."]},{"title":"Metonymy","paragraphs":["is a specific instance of this type of variability where the different readings are related by elements of a set of fundamental relationships such as 'part-whole', 'cause-effect', etc. [Nunberg 78] investigates more general mechanisms that licence the use of a word in place of another in cases where both of them are related by means of a context-specific relation. The phenomena range from eases of systematic correspondence such as in the 'newspaper-example '1 to more ideosyncratic ones as the famous 'ham-sandwhich-case '2. As Nunberg notes these are not cases of linguistic ambiguity because pointing to the sandwhich would 1 The word \"newspaper\" eazl be used to refer either to the publisher or to the publication. 2A waiter might apply the expression \"the ham sandwhich is sitting at table 20\" in order to identify","a unique guest who ordered a ham sandwhich."]},{"title":"167","paragraphs":["serve the same purpose as the utterance of the complex phrase. Nevertheless, it is not clear if the relations are considered as instances of lexical or encyclopaedic knowledge.","An example similar to the 'newspaper-case' is the potential of words such as \"school\", \"opera\", ... to select one of the alternative meaning variants 'building', 'process', 'institution', etc. The approach outlined in [Bierwisch 82] derives this potential from systematic relationships between"]},{"title":"concepts","paragraphs":["representing entities of the domain. The conceptual knowledge about social instutions has to provide the background information that \"the parliament is at the end of the street\" is semantically well-formed though \"?the government is at the end of the street\" is not. Since the iexical specifications of \"parliament\" and \"government\" cannot account for the fact that it is naturally assumed that the former can be associated with a specific building whereas a similar assignment is not possible for the latter. A comparable argument may be found for the 'substance'-reading of words naming trees. The iil-formedness of \"?this table is made of plane\" in contrast to \"this table is made of oak\" results from the non-verifiability in the common-sense model of the domain. If an expert would affirm that is quite common to use the wood from palm trees for the construction of tables we would probably change our model of the domain and licence the acceptability of the first sentence. This example is different from the 'school'/'newspaper'-cases since in addition to the conceptual shift it involves a modification of semantic properties of the underlying lexical items. This in turn is an argument in favour of a lexicalist position which would classify this type of variability as cases of polysemy. [Pustejovsky 90] shows that a lexicalist approach to event structure allows to systematically characterize a whole range of type-shifting phenomena together with their consequences with respect to well-formedness conditions.","As a consequence of seeking the portability of domain specific knowledge we follow the lines of Bierwisch in distinguishing lexical and conceptual information. Yet we do not reject the lexicalist position since we consider semantic type-shifting effects as driven by regularities of the conceptual structure. In the following section, we generalize this position to a systematic distinction between"]},{"title":"linguistic","paragraphs":["and"]},{"title":"non.lingustic knowledge.","paragraphs":["This allows us to keep variants introduced by linguistic ambiguities systematically apart from those cases we classify as non-linguistic variations.","Following [Binnick 70] we define polysemous variants of a word as those cases of variability which are (at least in principle) distinguishable on the basis of linguistic properties of the corresonding lexical item. Polysemous variants of a lexical item thus differ in at least one morphosyntactie or semantic property. For non-linguistic variants introduced by means of metonymy or type-shifting linguistic properties of a lexical item do not help to identify the intended reading because the variants have exactly the same linguistic properties. This situation calls for the disambiguation potential of contextual information in order to reduce the 'semantic scope '3. 2.4 Contextual relativity"]},{"title":"Vagueness","paragraphs":["and"]},{"title":"indexicality","paragraphs":["also belong to the class of variability phenomena. They are usually associated with specific groups of linguistic expressions (graduable predicates in ease of vagueness and deietie expressions in case of indexieality). In contrast to the effects introduced so far, in these eases the class of potential referents cannot simply","3We consider the 'semantic scope' of a word as the possible range of interpretation implied by the literal use of a word. The more general notion of 'referential potential' additionally accounts for cases of conceptual shift as in the 'ham-sandwich' example."]},{"title":"168","paragraphs":["be characterized by an enumeration of alternatives. As [Pinkal 80] points out it is an inherent property of vague predicates to provide a 'grey area' where the decision whether the predicate is applicable or not depends on the discourse context. It is even impossible to precisely delimit the area of positive or negative applicability. Following the lines of [Bosch 83] we do not consider vagueness as an isolated semantic property of a specific class of words but as an instance of the more general notion of"]},{"title":"context-dependence 4.","paragraphs":["Since this is an aspect of the referential potential of words our model has to cover theses phenomena as well.","Indexicality is the potential of deictic expressions to select their meaning by exploiting peculiarities of the discourse situation. It is similar to vagueness since the implied referential indeterminacy cannot be resolved independently from the specific discourse context. Yet, even deictie expressions are not immune to other types of variability. For example, the pronoun 'T' may be used to refer to an entity which is somehow related to the speaker in a certain discourse situation. An example is the utterance of \"I am over there\" with the speaker pointing to a desk. The expression 'T' in this case can be used to refer to the place, where the speaker usually works. This is an example of a systematic shift in meaning motivated by a conceptual relation. It thus belongs to the phenomena described in the previous chapter.","Another instance of context relativity occurs in cases of"]},{"title":"privative opposition.","paragraphs":["This relativity results from the lack of semantic information for a specific word which could be provided by the use of a different word. According to [Zwicky/Sadock 75] \"dog\" is ambiguous between the readings 'male dog' and 'female dog' because it can be forced to provide both readings in sentences like \"that is a dog, but it isn't a dog\". In contrast to \"?that is a lion, but it isn't a lion\" it seems that a meaningful interpretation can be found for the former (the one which forces the selection of different variants for both occurences of \"dog\") whereas the latter leads to a contradiction. The choice of a variant could be forced by the use of \"bitch\" instead of dog which is not possible for \"lion\" since there is not regular lexical specification for something like \"lioness\". This illustrates the fact that lack of semantic information for a lexical item can under certain circumstances yield the same effect as a disjunction of alternative readings. This may occur whenever the semantic 'gap' can be filled by one of a small set of possible alternatives."]},{"title":"3 A classification of knowledge types","paragraphs":["In order to have a precise representational basis for our model of word meaning, this chapter is intended to introduce the basic notions used to classify the relevant phenomena. The distinction between linguistic and non-linguistic knowledge mentioned in the preceding section constitutes the methodical basis of our model. Up to a certain degree, this distinction allows an independent examination of properties characteristic for only one type of knowledge. By assuming this distinction we do not claim that linguistic and non-linguistic knowledge are in a way fundamentally different. We use this distinction as a methodological tool that makes it possible to isolate certain aspects of word meaning not directly involving the whole range of both types of knowledge. In the course of stepwise extending the complexity of interrelations between linguistic and non-linguistic knowledge we will have to carefully analyze the tenability of this distinction.","4 In general the notion of context dependence applies to referential expressions such as definite nominal phrases. We will restrict our attention to cases of context-dependence which apply to single words."]},{"title":"169","paragraphs":["We account for possible similarities between both types of knowledge by using the same formalism for the representation of linguistic and non-linguistic knowledge. It is a variant of order-sorted predicate logic [Nebel/Smolka 89] which combines properties of the KL-ONE family of knowledge representation languages with properties of feature based unification grammars such as HPSG [Pollard/Sag 87]. In order to concentrate on the description of our model we will not go into the details of our formalism here s.","The central components of our model are the"]},{"title":"iezicon","paragraphs":["on the linguistic side and the"]},{"title":"ontology","paragraphs":["on the non-linguistic side. The lexicon and the ontology provide the 'basic building blocks' of linguistic and non-linguistic knowledge respectively. The elements of the lexicon are called"]},{"title":"categories;","paragraphs":["the elements of the ontology"]},{"title":"concepts.","paragraphs":["It is important to","note that the lexicon in our model integrates specifications of syntactic categories (i.e N,","V, ..., N', ..., AP .... ) with lexical items.","The formal means for the description of categories and concepts are"]},{"title":"sorts","paragraphs":["which are related by means of"]},{"title":"attributes","paragraphs":["and"]},{"title":"rules.","paragraphs":["Attributes may be used to express characteristic properties or relationships motivating the choice of a specific distinction between sorts. Rules on the other hand are not considered as tools for the description of inherent and permanent properties but as representations of regularities which might arise under certain circumstances. Apart from that, the collection of attributive characterizations has to be consistent. That is not necessarily required for the system of rules as a whole. The fundamental organizational principle of subsumption relates categories and concepts are licencing the inheritance of attributes between sorts. The subsumption order does only apply between elements of one and the same type of knowledge. The notation used for the description of sorts is a feature-logic as in [Shieber 86] for categories and a simple relational notation for concepts. We represent the fact that A subsumes B as A C B. Rules of grammar and rules of inference are represented by using simple predicate logic notion. Sorts, attributes and rules will be called"]},{"title":"knowledge elements.","paragraphs":["All of them put together constitute the"]},{"title":"knowledge base","paragraphs":["of our system.","According to our argument in favour of a design strategy specifically tailored to the domain and the task the system is intended for, the structure of the ontology must be covered by an appropriate theory about entities of the domain, their inherent properties and the diverse aspects in which they are related. We reiterate this methodological claim here since a similar argument can be applied to the organization of the lexicon. The typical task of a text understanding system is to facilitate the"]},{"title":"analysis","paragraphs":["and"]},{"title":"production","paragraphs":["of textual input. It depends on the capabilities required whether certain aspects of this task involve restrictions on the set of relevant linguistic phenomena 6. The choice of lexical items depends on the domain at issue since the lexical inventory should cover at least the range of non-linguistic phenomena represented in the non-linguistic component of the system.","Categorial knowledge provided by the lexicon together with the"]},{"title":"rules off grammar","paragraphs":["constitutes the descriptional apparatus for the classification of"]},{"title":"expressions.","paragraphs":["On the one hand expressions serve as input for linguistic processing and on the other hand they represent sequential patterns of written or spoken language. This intermediate status makes them","5 Most of our assumptions about the representation of linguistic and non-linguistic knowledge are based on experiences gained from work in the LILOG-project at IBM Stuttgart. A description of formalisms and methods applied in this project can be found in [Geurts 90].","6 One can for example reduce the computational complexity by limiting the relevant sentence-level constructions to simple propositional clauses if the system is not meant to deal with other types of modality. Even if this argument sounds quite trivial the determination of a set of requirements for the linguistic component are as important as they are for the representation of domain knowledge."]},{"title":"170","paragraphs":["elements of discourse knowledge. Expressions belong to the type of knowledge which serves as a kind of record for the registration of linguistic interactions together with their spatio-temporal specifications. It directly corresponds to episodic knowledge on the non-linguistic side. Episodic knowledge has the same intermeditate status as discourse knowledge since on the one hand it serves as a record of 'statements' and other 'experiences' with respect to the domain and on the other hand it is used to characterize entities from the domain as individuals on the basis of conceptual knowledge. Conceptual knowledge combines the structural information conveyed by the ontology with the additional information expressed by rules of inference. Individuals which result from the processing of certain linguistic expressions are called referents since they are open to further reference by linguistic means. The figure below shows the whole classification assumed as the basis of our model."]},{"title":"/ g~eral / Categorial / \\ elements ruleJ / \\","paragraphs":["Lexical Grammatical Knowledge Linguistic"]},{"title":"\\ indlvldual \\ Discourse Non-linguistic / $~nera!","paragraphs":["/ Conceptual"]},{"title":"/ \\ elemeuts ruleJ / \\ Ontological Inferential \\ individu61 \\ Episodic Expressions","paragraphs":["Referents Figure 1: The classification of knowledge types."]},{"title":"4 Word meaning","paragraphs":["The task of our model is an approach to the various aspects of word meaning which are responsible for the variability effects described in section 2. In order to reduce the complexity of the linguistic domain we restrict the relevant linguistic expressions to those representing simple word forms which cannot be further decomposed by mophological processes other than inflection. As a consequence, the granularity for the representation of linguistic knowledge treats basic morphemes as minimal elements. Another consequence is the width of the temporal grid which specifies the minimal 'temporal distance' between elements of discourse knowledge. We introduce temporal indices, allowing to subdivide the linguistic input into a chain of word-level segments. Each index uniquely identifies a gap between two words and directly corresponds to a set of intermediate results in the course of processing the input. These results are what we call the context. Formally speaking, a context is a set of factors marked by a temporal index specific to a certain stage of processing at which the system is observed. Factors are functions between knowledge elements or between instances thereof. They are elements of specific contexts and therefore differ from attributes because their existence is strictly tied to a certain stage of processing associated with a temporal index. As a result of iterated forwarding a factor may remain applicable during a sequence of processing steps. Factors may be classified according 171 to their origin. Factors which are directly derived from knowledge elements are called"]},{"title":"primitive factors.","paragraphs":["Depending on the type of knowledge elements involved we distinguish two modes of origin. Primitive factors can be ..."]},{"title":"Â• selected as","paragraphs":["instances of attributes or"]},{"title":"Â• established","paragraphs":["by the application of rules."]},{"title":"Complex factors","paragraphs":["are derived from primitive ones by one of the following operations: Â• the"]},{"title":"restriction","paragraphs":["of the domain and/or range of a primitve factor Â• the application of set-theoretical operations on primitive factors Â• the"]},{"title":"functional composition","paragraphs":["of primitive factors","We present this classification because our analysis of word meaning crucially depends on the notion of contextual factors. It is the main goal of our project to reconstruct word meaning as the result of the interaction of processes with cope with an effective integration of various linguistic and non-linguistic factors primitive and complex in nature. Since we investigate word meaning under the aspect of the potential of words to refer to representations of entities of the domain, word meaning in our terminology is a complex factor which links elements from discourse knowledge (expressions representing words) to elements from episodical knowledge (referents). The temporary status of factors is responsible for the fact that for the identification of the referential meaning of a word the whole context has to be taken into account. The linguistic notion of 'word meaning' therefore derives from the analysis of subsets of factors that result from the intersection of contexts present in a sufficiently large group of different uses of the same word. 4.1 The constituents of reference In order to characterize the interrelation between factors introducing variability effects"]},{"title":"(productive factors)","paragraphs":["and those limiting the 'semantic search space'"]},{"title":"(restrictive factors)","paragraphs":["we need to examine the way in which word meaning can be decomposed into a small number of factors 7. A segmentation of the interpretation process according to our classification of knowledge types leads to three"]},{"title":"components","paragraphs":["which by application of functional composition constitute word meaning. Since components are derived by functional decomposition of a complex factor (word meaning) they are factors as well. Components may be further analyzed as the results of set-theoretic operations on basic factors some of which limit and some of which extend the 'semantic scope' of a word form s. Factors extending the scope of interpretation are directly responsible for the variability effects described in section 2. Factors constraining the scope of interpretation are the topic of chapter 4.2. The following list introduces the three components of meaning together with examples of the relevant productive factors. An interesting criterion for the classification of productive factors is whether they are established by the application of rules or selected from attributes between knowledge elements.","7We do not assume contexts to be finite but our approach relies on the fact that a finite subset of the context sumces to describe word meaning precisely enough to demonstrate the requirements a system with reasonable disambiguation capabilities has to fulfil.","8 In fact the same function may in one stage of the interpretatio process serve as productive factor and in another as a restrictive factor. Thus, the property of productivity or restrictivity cannot definitively assigned to specific factors. More precisely speaking, it is property of factors dependent on the current stage of processing represented by the temporal index."]},{"title":"172 (1) Categorization","paragraphs":["Categorization as the first component of the chain maps expressions representing words onto lexical items. Its relevant productive factor is established by the application of morphological rules in some cases involving morphological ambiguity.","The following categorization of \"saw\" is selected from the lexicon because of the identity of phonological forms: PHON SYN carl4 V SEM","t sawt MAJOR V TENSE PRESENT SUBCAT ~ ... ~ v...v ~ ... TENSE PRESENT SUBCAT ,~","conc54","A morphological rule establishes the categorization of \"saw\" as an inflected form derived from the lexical base form for \"see\": carl6 PHON f3rdsng(' see')","[MAJOR V ] SYN TENSE PAST","SUBCAT ~ ... ~ v...v ~ ... SEM c0nc75"]},{"title":"(2) Lexical","paragraphs":["meaning","The semantic specification of a lexical item and the properties of the corresponding concept are related by means of the sEi value. Two basic factors which contribute to the relevant productive factor of lexical meaning originate from attributes in the knowledge base by means of selection. The linguistic constituent of lexical meaning may involve polysemy or polyfunctionality if it provides a range of semantic alternatives and the corresponding morphosyntactic properties for a single lexical item. (2a) The linguistic constituent of lexical meaning The subcategorization entry of the lexical item selects the following three s polysemous","readings for cat14: Â• . . SUBCAT","SYN NP[NOM] ]","SEM cone 8 ~\"","[ SYN NP[ACC] ] [ SYN NP[NOM] ]","V < SEM conclo ' SEM cone s >","V < ([ SYN PP[WITH] 1)[ SYN NP[ACC] ] [ SYN NP[NOM] ] ~","SEM c0nc35 ~ SEM cOnCl3 ~ SEM cone 8","The non-linguistic constituent of iexical meaning is responsible for variabilities originating from systematic relationships between different concepts related to a single lexical","9As a matter of illustration the subcategorization frame does not exhaust the range of alternative readings. It again depends on the task of the linguistic component wether the lexlcal item has to provide further polysemous variants such as the intransitive reading of \"see\"."]},{"title":"173","paragraphs":["item by means of the semantic specification. (2b) The non-linguistic constituent of lexical meaning","conc75 SITUITIO| E ...","time :","conc5","location : cone3","conc23 PERCEPTIO| E SITUATIO| actor : concs theme : cone13"]},{"title":"instrument : conc35","paragraphs":["conc34 REALIZATIO| E SITUATIO| actor : concs proposition : conc19","conc39 VISTI|G~ITUATIO| visitor visited"]},{"title":"(3) Indlvlduation","paragraphs":["spatio-temporal properties The filler of the actor role visually perceives the filler of the theme role by using the filler of the instrument role The filler of the actor role realizes the filler of the proposition role SITUATIO| conc2 The filler of the visitor role conc 4 .",". .","This last factor in the chain of meaning components becomes established by the application of rules of inference. It maps concepts onto referents. The productive factor of individuation is referentiality extending the range of possible referents a concept can be individuated to. Referentiality here serves as cover term for the phenomena described in chapter 2.4 together with cases of conceptual variation which qualify as 'ad-hoc-anaphora' because they succeed to identify a unique referent in a specific context but cannot be characterized as instances of general principles guiding a shift in conceptual interpretation lÂ°.","Additional parameters of the discourse situation (the time and location of the utterance as well as a proposition rl) allow to establish an individuation which maps conc34 onto a referent r2 with the following properties:"]},{"title":"actor(r2)","paragraphs":["= rspeaker ̂ proposition(r2) : rl ̂ location(r2) = r a ̂r3 C Sdiscourse ̂ time(r2) = r4 A r4 < tdi,Â¢our,e","The three components of word meaning can be considered intermediate steps of the interpretation process. They may be analyzed and described in isolation since their interaction results from the way in which the range of the preceding component fits to the domain of the following. The task of the interpretation process on this background is to find a 'path' leading from an expression to an individual which under consideration of all the available contextual factors qualifies as plausible candidate for the referential meaning of the expression. 4.2 How the semantic scope can be restricted The crucial question now is how the diverse components interact in order to reduce the range of word meaning by the exclusion of implausible variants. Here we pick out three lÂ°Nunberg's ham-sandwich is an example instance of this kind of context specific ad-hoc-anaphora."]},{"title":"174","paragraphs":["example groups of factors which in a typical situation may support the reductive factors of meaning components and such help to reduce the referential potential of a word."]},{"title":"(1) Word-specific factors","paragraphs":["The first group are factors which result from structural relationships expressed by morphosyntaxtic attributes and rules of grammar. As we mentioned in chapter 2.3 these factors only Mfect variabilities which are introduced by the linguistic part of our knowledge base. Factors of this group thus may help to resolve cases of morphological ambiguity, polysemy or polyfunctionality but they have no effect on variants that result from metonymy, change of semantic type or other instances of contextual relativity.","Consider the following part of discourse: \"I tried to find a possibility to escape. Then I saw a hole in the fence.\"","We'll give a sketch of an analysis of the meaning of \"saw\" in this example on the basis of the knowledge elements introduced in the previous section. The rules of grammar suppress the nominal reading of \"saw\" since the principles of X-syntax require the constituent \"a hole in the wall\" to be 'absorbed'. Morphological rules do not support the disambiguation process. On the contrary, their productive potential causes the in-troduction of the variant derived from the base form \"see\". The variant cat56 is ruled out because of incompatibilities between its subcategorization frame and the syntactic environment of \"saw\" in our example. caÂ¢56 PHON SYN V SEM MAJOR TENSE SUBCAT V t sawt","v","PRESENT","[ SYN NP[NOMI ]","SEM concl8 ~>","[ SYN NP[ACC] I [ SYN NP[NOM] ]","SEM conc42 ' SEM cone18 TENSE PRESENT SUBCAT ~","c0nc75","The intransitive polysemous variant fails because of the same reasons as the nominal homonymous variant. The transitive reading of cat56 would force an optional prepositional argument to be headed by \"into \"11. Thus, the polysemous variant conc42 can be singled out purely on the basis of word-specific factors if the rules of grammar do not account for the adjunction of a locative PP with the head \"in\". In case the grammar licences the existence of a prepositional adjunct, our model of the domain would have to contribute the restrictive factor that the concept associated with \"the fence\" does not fit with conditions on 'sawing'-events. Since the reductive influence of word-specific factors ends with the selection of polysemous variants we cannot expect a further restriction of the 'semantic scope' without additionally considering other types of factors. 11 In order to simplify the example this alternative does not occur in the feature structure of cat56."]},{"title":"175 (2) Selectional","paragraphs":["restrictions","A different group of factors belongs to the semantic level 12 of our model. Factors in this group neither are clear instances of linguistic regularities nor of non-linguistic ones. They are partially linguistic and partially non-linguistic in nature and therefore considered as complex factors derived by the integration of elements from both types of knowledge. They may help to reduce variabilities affecting categorization or lexical meaning. Yet, like word-secific factors they do not constrain contextual relativity.","Consider the following part of discourse: a piece of wood"]},{"title":"}","paragraphs":["\"I saw in the bathroom.\" a cup of coffee","The semantic specification for the internal argument of \"saw\" leads to a concept conc4~ representing a class of entities which qualify as fillers of the corresponding role in the conceptual representation of the 'sawing'-event.","conc75 BAWl]l(] C SITUATIO]I actor"]},{"title":":","paragraphs":["concls obj ect : conc42 instrument"]},{"title":": conc29","paragraphs":["for example: a human beeing for example: a concrete object for example: a set of tools","The compatibility between the semantic specification of the internal argument of the two polysemous readings of \"saw\" and the type specification of a role belonging to the correspondint SEM-value account for the existence of selectional restrictions. The conceptual representation of '% piece of wood\" must be compatible with conc42 in order to establish the lexical meaning leading to the concept SaWI]IG.EVE]IT. In the case of \"this hand-saw saws well\" the external argument would because of requirements on fillers of conceptual roles have to be mapped on the instruemt role of conc75. The situation is more tricky if we compare the instances of the external argument of cat23 in the following example: (1) The policeman saw an accident. (2) *The ball saw an accident. (3) The automatic traffic control camera saw an accident. (4) ?The morning saw an accident.","An interesting aspect of this phenomena is that selectional restrictions may be can-celled by contextual factors or by means of rhetoric devices. The example sentences show how difficult it might be to identify an obligatory set of selectional restrictions. Comparing (1) with (2) suggests being an instance of the concept PERS0]I as a reasonable choice. Example (3) however shows that the critical property is something like 'having an optical sensoring mechanism capable of detecting objects'. Sentence (4) might imply a metaphorical interpretation in spite of its apparent semantic illformedness. This again yields an argument in favour of a domain-driven design strategy for the semantic level linking between categories and concepts.","12 The semantic level is the 'interface' between linguistic and non-linguistic knowledge represented by the SEM values in |exical items together with a set of rules which attune semantic specifications of argument structure to attributes of the corresponding conceptual definitions."]},{"title":"176 (3) The set of","paragraphs":["possible referents","The last group of factors exemplified here are the only means available to reduce the semantic scope resulting from contextual relativity. As we saw in chapter 2.4 contextual relativity is a fundamental property all referential expressions have in common. Since the 'semantic scope' introduced by variabilities of this type cannot be subdivided into a set of alternative readings neither lexical nor conceptual information does help to restrict the range of indiviuation.","The only way out of this dilemma is to derive a set of possible referents from knowledge about the domain and from information occuring in the preceding part of discourse. The latter calls for an investigation of discourse properties on the basis of pragmatic devices such as the Gricean conversation principles. Bridging phenomena 13 as generalizations of anaphoric binding are promising candidates for an approach to the determination of possible referents. C. Sidner emphasizes: \"anaphor interpretation can be studied as a computational process that uses the already existing specification of a noun phrase to find the specification of an anaphor\" [Sidner 83, p.269]. The actual limits of a set of possible referents thus very much depend on the inferential capabilities of our system to reconstruct the conceptual relationships undelying text coherence. The notion of focus presented in the work of Sidner certainly plays a crucial role in the reducion of the computational complexity a computation of all possible bindings would involve if realistic discourse situations were to be considered."]},{"title":"5 Conclusion","paragraphs":["Up to now we merely picked a collection of phenomena with an impact on the referential potential of words ranging from lexical properties to 'genuine' discourse phenomena. We presented a moderately general framework designed in a way that each of these phenomena has a place to fit in. The example analysis of \"saw\" illustrated the interaction of elements of our model and thereby pointed to problematic aspects that yet have to be resoved. A crucial problem is to distinguish between linguistic aspects of lexical meaning which the lexicon has to account for from non-linguistic aspects which derive from relations in conceptual structure. The next step in the evaluation of our model requires the determination of criteria which help to keep linguistic and non-linguistic aspects of the semantic level apart. The ultimate goal of this distinction is to narrow down the flow of information that passes through the semantic 'interface' between linguistic and non-linguistic knowledge. If this strategy succeeds it should be possible to adapt the conceptual knowledge to different domains of application not affecting linguistic knowledge as the basis for capabilities of discourse understanding."]},{"title":"References","paragraphs":["[Bierwisch 82] M. Bierwisch, \"Semantische und konzeptuelle Repr/isentation lexikalischer Einheiten\", R. RfiSi~ka / W. Motsch (eds.), Untersuchungen zur Semantik, Studia Grammatica XXII, Berlin, 1982. 13 In the terminology of [Clark/Haviland 77]."]},{"title":"177 [Binnick 70] [Bosch 83] [Clark/Haviland 77] [Geurts 90] [Kooij 71] [Nebel/Smolka 89] [Nunberg 78] [Pinkal 80] [Pollard/Sag 87] [Pustejovsky 90] [Shieber 86] [Sidner 83] [Weber 74] [Zwieky/Sadock 75] R. I. Binnick, \"Ambiguity and vagueness\", Papers from the Sixth Regional Meeting of the Chicago Linguistic Society, Chicago, 1970, pp. 147-153. P. Bosch, \"Vagueness is Context-Dependance: A solution to the sorites paradox\", T. T. Bailmer / M. Pinkal (eds.), Approaching Vagueness, Elsevier Science Publishers B.v. (North-Holland), 1983, pp. 189-210. H. H. Clark and S. E. Haviland, \"Comprehension and the given-new contract\", R. O. Freedle (ed.), Discourse Production and Comprehension, Norwood, New Jersey, 1977. Bart Geurts (ed.), \"Natural Language Understanding in LILOG: An Intermediate Overview\", IWBS Report 187, IBM Germany GmbH, Scientific Center, 1990. J. G. Kooij. \"Ambiguity in Natural Language. An investigation of certain problems in its linguistic description\", Amsterdam, London, 1971. B. Nebel / G. Smolka, \"Representation and Reasoning with Attributive Descriptions\", IWBS Report 81, IBM Germany GmbH, Scientific Center, 1989. G. D. Nunberg. \"The Pragmatics of Reference\", PhD Thesis, Reproduced by the Indiana University Linguistics Club, 1978. M. Pinkal, \"Semantische Vagheit: Phiinomen und Theorien: Teil I\" Linguistische Berichte, 1980. C. Pollard / E. A. Sag, \"Information-based Syntax and Semantics: Volume r', CSLI Lecture Notes Number 13 Stanford, 1987. J. Pustejovsky, \"Semantic Function and Lexical Decomposition\", Schmitz / Schuetz / Kunz (eds.), Linguistic Approaches to Artificial Intelligence, Lang, 1990, pp. 243-303. S. M. Shieber. \"An Introduction to Unification-BasedApproaches to Grammar\", CLSI Lecture Notes Number 4, Stanford, 1986. C. L. Sidner. \"Focusing in the comprehension of definite anaphora\", M. Brady / Robert C. Berwick, (eds.), Computational Models of Disourse, Cambridge, Mass. and London, 1983. H. J. Weber, \"Mehrdeutige Wortformen im heutigen Deutsch: Studien zu ihrer grammatischen Beschreibung und lexikographischen Erfassung\", Tiibingen, 1974. A. M. Zwicky and J. M. Sadock, \"Ambiguity tests and how to fail them\", J. P. Kimball (ed.) ,Syntax and Semantics, pp. 1-36, San Diego, 1975. 178","paragraphs":[]}]}
