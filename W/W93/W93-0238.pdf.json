{"sections":[{"title":"","paragraphs":["J !"]},{"title":"Information and Deliberation in Discourse","paragraphs":["Marilyn A. Walker* lyn@linc.cis.upenn.edu"]},{"title":"1 Introduction","paragraphs":["Tile most common assumption about intention in discourse is that the primary intention of discourse is to eomlnunicate and receive information. This is a founding assumption of every formal model of discourse meaning that I am aware of. The standard account of meaning is that utterances are functions from contexts to contexts whose primary purpose is to describe the world, and whose meaning derives from the fact that they delimit the set of worlds that the conversants believe possible. One of the ramifications of this assumption is that utterances with no new information are infelicitous or have no meaning[i, 2, 14, 5]. However, consider example 1, asserted by a passenger in a vehicle in response to tile driver's comment that the heavy traffic was unexpected: (I) There's somet, hing on fire up there. I can't see what's on fire, but SOMETHING IS. (LW 6/12/92) In the first clause of 1, tile speaker asserts a proposition P, namely that something is on fire. In the second clause, the speaker presupposes P, and finally in the third clause the speaker affirms P. I will argue that examples like this show that a theory of discourse meaning must account for DELIBERATION-based intentions. The DELIBERATION-based view emphasizes that agents produce utterances to support other agents' deliberations about what they want to believe or what they want to do. Agents don't take it for granl.ed that their assertions will be accepted by other agents. I will call clauses like the third one above INFORMATIONALLY REDUNDANT UTTERANCES, henceforth (IRUs). In the examples given here, IRUs are shown in CAPS. The IRU's ANTECEDENT, the utterance which originally added the IRU's propositional content to the discourse, is shown in italics. Section 2 discusses deliberation in discourse. I will show how a set of assumptions about deliberation account for many examples of IRUs in discourse. Then in section 3, I will briefly discuss how some RST relations can I)e viewed as heuristic strategies for achieving DELIBERATIoN-based intentions[9]."]},{"title":"2 Deliberation","paragraphs":["DELIBERATION as a component of a theory of intention in discourse is functionally related to the theory of economic rationality, which in recent years has augmented the INFORMATION-based (logical) view of action [3]. DELIBERATION is the process by which an agent explicitly or implicitly evaluates a set of alternates ill order to decide what s/he wants to believe and what course of action s/he wants to pursue. 1 Thus agents deliberate about whether as well as how to revise their beliefs and intentions as they receive new information[4]. This is partially reflected in the following ATTITUDE assumption[16]:","Â• ATTITUDE: Agents deliberate whether to ACCEPT or REJECT an assertion or proposal made by another agent in discourse. *This research was partially funded by ARO grant DAAL03-89-C0031PRI and DARPA grant N00014-90-J-1863 at the","University of Pennsylvania, and by Hewlett Packard, U.K. 1 Evaluation flmctions (utilities) for beliefs may have a different basis than those for intentions."]},{"title":"144","paragraphs":["Empirical analyses of dialogue can inform an account of deliberation because dialogue provides an explicit protocol of which facts agents believe will affect the ACCEPTANCE or REJECTION of an a~ssertion or proposal. An analysis of IRUs in problem-solving dialogues shows that the process of deliberating about beliefs depends on the type of evidence supporting a belief, and that one of the primary functions of IRUs is to upgrade the strength of the evidence supporting beliefs[18, 17, 20]. Beliefs that are strongly supported cohere with other beliefs and are more difficult to defeat[4]. The process of deliberating about intentions also depends on evidence supporting beliefs that the intention is based on, which can contribute to a perception of 'risk'. However, there is an additional independent factor that contributes to deliberating about intentions: the utility of the resulting 'plan'[ill. 2 IRUs fimction communicatively to support both deliberative processes. Because of the ATTITUDE assumption, there are two fundamental relations in discourse between beliefs and intentions and their supporting beliefs. The SUPPORT relation links beliefs at various endorsement levels, e.g. a premise supports a conclusion and endorses it as an ENTAILMENT[6, 17]. The WARRANTS relation links beliefs with intentions that they are a warrant for, e.g. the belief that you will make a 15% profit may provide a WARRANT for an intention to pttrchase Hewlett Packard stock. Of course, measurable benefits of intentions are the simplest ease. In addition to the factors noted above, other processing factors such as the frequency and salience of beliefs contribute to dei'iberation. Furthermore, preferences may be relevant, so that other things being equal, human agents believe what they prefer to believe[8, 4]. These factors are reflected in the following assumptions:","Â• PREFERENCE: Agents' beliefs are partially determined by their preferences about what to believe, which may have a nonlogica] basis. AFFIRMATION: Repeating a proposition is a weak type of SUPPORT that provides evidence of the speaker's commitment to the truth of the proposition. In addition, affirnlation makes a proposition salient, and may increase the frequency of that prol)osition in memory. Tile AFFIRMATION assumption means that the occurrence of an affirmation is a cuc that the speaker beliew~s that s/he must provide additional SUPPOrtT for his/her assertions. 3 This speaker belief is most often motivated by the perception that some propositions in the discourse are in opposition with one another[19, 7]. In other words, if a proposition P is atlirmed in a context C, something in C must either support or warrant an opposite conclusion Q, or fail to support or warrant P. For example, consider 2, which demonstrates an opposition in supl)ort , apparently hased on the conlnlon-sense inference that torment leads to nnprodnctivity (Ward's 96)[19, 7]:","(2) Tchaikovsky was one of the most tormented men in musical history. In fact, one wonders how hc managed to produce any music at all, BUT PRODUCE MUSIC HE DID.,[WFLN Radio] Examl)le 1 is also motivated by the speaker's goal to provide support, and shows that the speaker 1)eliew;s that visual evidence would support her claim that somclhiug is on fire. It also shows that it. is necessary to represent the relation NOT-SUPPORT, since the fact that the speaker cau'l see whal's on fire fails to SUl)l)Ol't the belief that something is on fire, without supporting its negation. Example 3 is also inotivated hy a combinatiol~ of the AFFIRMATION and ATTITUDE assurnptions, where, as in example 1, the speaker states that she cannot provide support for her claim: (3) I like you Lizzy. I don't know why I like you. But I LIKE YOU. (CS, 3/4/92) Silnilarly, in example 4, the relevant relation seems to be NOT-WARRANT:","2The independence of these factors is easy to see in a simplified domain such as DesignWorld [16, 15], ill which two agents must attempt to maximize utility while negotiating a COLLABORATIVE PLAN for the design of a two room house, and where the utility of tile design plata is a function of the values of the individual pieces of furniture that make up the plan. Imagine that there is a default rule that if an agent can't remember the value associated with a piece of furniture, then s/he can assume that it is worth 1O0 points. Then a proposal to include that. piece of furniture in the final plan would have high utility for that agent, but the belief is not well supported.","3Not all 1RUs in discourse function as alfir,nat.ions [16]."]},{"title":"145","paragraphs":["d (4) lie didn't make a profit from doing it, but lie DID IT. These examples all demonstrate that often the best support for deliberation that a speaker can provide is his/her own AFFIRMATION of the relevant fact. In general, IRUs motivated by SUPPORT are characterized by verbs referring to typical sources of evidence for propositions being deliberated, e.g. see, hear, say, as well as mental state verbs reflecting deliberation, know, remember. IRUs motivated by WirtltAN'r refer to inl.eutionality, costs, or benefits of a course of action as in 4.. The ATTITUDE and PR.EFER.ENCE assumptions motivate example 5, where what is relevant is that tile speaker believes l.hat the hearer may not want to accept the assertion of P, preferring to believe -~ P (llorn's 323)[7]. (5) It's unfortunate that you failed, but FAIL YOU DID. It is possible that P in 5 conflicts with the hearer's view of herself as extremely intelligent, or that tile accel)tance of P would lead the hearer to infer a number of conclusions which she would prefer not to derive. Factivc predicates for other relations that express the difficulty of accepting a proposition are odd, strange, surprising, amazing, I'm sorry that, Ii's a wonder that, and all of these also license affirmation. Finally, when two opposing facts are supported by the same quality of evidence, e.g. linguistic, other factors may be important. In example 6, Jennifer, (j), has received verbal advice from two different sources. Both of the statements shown in CAPS are IRUs, and reflect her deliberation process, showing that what seems to be relevant is the source of these two opposed belieEs: 4"]},{"title":"(Â¢~)","paragraphs":["11. Jennit~.r I understand what you're saying attd I'm sorry 1 have to tell you that, 1 really am. .i. Well, I'm, 1 have more faith in you than what he told me, liE SAID I DIDN'T HAVE TO FILE, BUT THEN YOU JUST TOLD ME I DO II. Yes. and 1 wouldn't want to see you get, in trouble."]},{"title":"3 Information, Deliberation or Contrast","paragraphs":["I'w- argued that supl)orl.iug deliberation is a fundamental iuteul, ion iu discourse. In section 2, l showed how examples of IRUs that would I)e analyzed with RST relations of CONTItAST, MOTIVATION and EXPLANATION are motivated by the intention to support deliberation. One potential integration of rhetorical relation and intention-based theories of discourse is to view schema~s for contrast, ntotivation and explanation as heuristic strategies for achieving discourse intentions of deliberation[13]. However, there are a residue of contrast examples for which it is difficult to give a deliberation account. Example 7 demonstrates that a set-based defiuil.ion of contrast easily SUl)l)orts affirmation[12], llere the sl)eaker is talking about a recent vacation to M~xico."]},{"title":"(7)","paragraphs":["We always had water (in that room). I think we were the only ones, WE NEVER RAN OUT OF WATER. llot water, we ran out of. but WE ALWAYS tlAD WATER. (Viv 3/20/92) It is unclear whether tile affirmations in this example are motivated by tile fact that Viv believed that her audience were unwilling to accel)t her assertions without further support. Ilere, Viv seems to be caught in a rlmtorical schema as she enumerates two sets in set-based contrast. First, We, the others is enumerated with the affirmation and negation of having water. Then a second set, hot water, cold water is enumerated with the attirmation/negation of running out of it. A challellge for the account presented here is to explain what kind of intention motivates Viv's affirmations.","4This excerpt is fl'om a radio talk show for financial advice. ] am gl'atefld to Julia Hirschberg ml(I Martha Pollack for ~wigilmlly transcribing this corpus and providing me with tapes of the original broadcast[10]."]},{"title":"146 References [1] James F. Allen. Recognizing intentions from natural language utterances. In M. Brady and R.C. Berwick, editors, Computational Models of Discourse. MIT Press, 1983. [2] Phillip R. Cohen. On knowing what to say: Planning speech acts. Technical Report 118, University of Toronto; Department of Computer Science, 1978. [3] Jon Doyle. Rationality and its roles ill reasoning. Computational Intelligence, November 1992. [4] Julia R. Galliers. Autonomous belief revision and communication. In P. Gardenfoors, editor, Belief Revision, page 1. Cambridge University Press, 1991. [5] Gerald Gazdar. Pragmatics : implicature, presupposition and logical form. Academic Press, 1979. [6] Barbara J. Grosz and Candace L. Sidner. Attentions, intentions and the structure of discourse. Computational Linguistics, 12:175-204, 1986. [7] Laurence R. Horn. Given as new: When redundant affirmation isn't. Journal of Pragmatics, 15:305-328, 1991. [8] Daniel Kahneman, Paul Slovic, and Amos Tversky. Judgment under uncertainty : heuristics and biases. Cambridge University Press, 1982. [9] W.C. Mann and S.A. Thompson. Rhetorical structure theory: A framework for the analysis of texts. Technical Report RS-87-190, USC/Information Sciences Institute, 1987. [10] Martha Pollack, Julia Hirschherg, and Bonnie Webber. User participation in the reasoning process of expert systems. In AAAI82, 1982. [11] Martha E. Pollack. Plans as complex mental attitudes. In Cohen, Morgan and Pollack, eds. Intentions in Communication, MIT Press, 1990. [12] Ellen F. Prince. On the syntactic marking of the presupposed open proposition. CLS86, 1986. [13] R. Sproull. ,Strategy construction using a synthesis of heuristic and decision-theoretic methods. PhD thesis, Stanford University, 1977. [14] Robert C. Stalnaker. Assertion. In Peter Cole, editor, Syntax and Semantics, Volume 9: Pragmatics, pages 315-332. Academic Press, 1978. [15] Marilyn Walker. Informational redundancy and resource bounds in dialogue. In AAAI Spring Symposium on Reasoning about Mental States, 1993. [16] Marilyn A. Walker. A model of redundant information in dialogue: the role of resource hounds, q~chnical Report IRCS-92-95, University of Pennsylvania Institute for Research in Cognitive Science, 1992. Dissertation Proposal. [17] Marilyn A. Walker. Redundancy in collaborative dialogue. In bburteenth International Conference on Computational Linguistics, 1992. [18] Marilyn A. Walker and Steve Whittaker. Mixed initiative in dialogue: An investigation into discourse segmentation. In Proc. 28th Annual Meeting of the ACL, pages 70-79, 1990. [19] Gregory L. Ward. The discourse flmctions of vp preposing. Language, 66(4):742-763, 1990. [20] Steve Whittaker, Erik.Geelhoed, and Elizabeth Robinson. Shared workspaces: How do they work and when are they useful? Technical report, HP Labs, Bristol, England, 1993. 147","paragraphs":[]}]}
