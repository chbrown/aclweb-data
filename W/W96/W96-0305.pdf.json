{"sections":[{"title":"Acquisition of Computational-Semantic Lexicons from Machine Readable Lexicai Resources","paragraphs":["Jason J. S. Chang and J. N. Chen Department of Computer Science National Tsing Hua University Hsinchu 30043, Talwan, ROC Tel: +886 35 731-069 Fax: 723-694 (jschang,dr818314 }@cs.nthu.edu.tw Abstract","This paper describes a heuristic algorithm capable of automatically assigning a label to each of the senses in a machine readable dictionary (MRD) for the purpose of acquiring a computational-semantic lexicon for treatment of lexical ambiguity. Including these labels in the MRD-based lexical database offers several positive effects. The labels can be used as a coarser sense division so unnecessarily fine sense distinction can be avoided in word sense disambiguation (WSD).The algorithm is based primarily on simple word matching between an MRD definition sentence and word lists of an LLOCE topic. We also describe an implementation of the algorithm for labeling definition sentences in Longman Dictionary of Contemporary English (LDOCE). For this purpose the topics and sets of related words in Longman Lexicon of Contemporary English (LLOCE) are used in this work. Quantitative results for a 12-word test set are reported. Our discussion entails how the availability of these labels provides the means for treating such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives. 1. Introduction","Treatment of lexical ambiguity such as WSD has been found useful in many NLP applications, including information retrieval (McRoy 1992; Krovetz and Croft 1992) and machine translation (Brown et al. 1991; Dagan et al. 1991; Dagan and Itai 1994). Recently, various approaches (Dolan 1994; Luk 1995; Yarowsky 1992; Dagan et al. 1991 ;Dagan and Itai 1994) to word sense division have been used in WSD research. Directly using dictionary senses as the sense division has several advantages. First, sense distinction according to a dictionary is readily available from MRDs such as the LDOCE (Longman 1992). Second, indicative words and concepts for each sense are directly available in numbered definitions and examples. Lesk (1986) demonstated that dictionary entries can be used to generate signatures of senses for WSD. However, using MRD as the knowledge source for sense division and disambiguation encounters certain problems. Dolan (1994) observed that sense division in MRD is frequently too free for the purpose of WSD. A WSD system based on dictionary senses faces an unnecessary and difficult \"forced-choices.\" Most researchers resorted to human intervention to identify and group closely related senses.","This paper describes a heuristic algorithm capable of automatically assigning a label to each of the senses in a machine readable dictionary (MRD) for the purpose of acquiring a computational-semantic lexicon for treatment of lexical ambiguity. Including these labels in the MRD-based lexical database offers several positive effects. The labels can be used as a coarser sense division so unnecessarily fine sense distinction can be avoided in word sense disambiguation (WSD). The algorithm is based primarily on simple word matching between an MRD definition sentence and word lists of an LLOCE (McArthur 1992) topic. We begin by giving the details of material used, including the characteristics of definition sentences in LDOCE and the organization of words in LLOCE. Next, the algorithm for labeling LDOCE senses is described. An illustrative example demonsu~ates the effectiveness of the algorithm. After describing the al-30 gorithm, the experimental results for a 12-word test set are presented. Our discussion also entails the possible implication of the labels to such problems as: acquisition of a lexicon capable of providing broad coverage, systematic word sense shifts, lexical underspecification, and acquisition of zero-derivatives at the sense level. Moreover, the proposed algorithm is compared with other approaches in available literature. Finally, concluding remarks are made. 2. Identifying the topic of senses The labeling of dictionary definition sentences with a coarse sense distinction such as the set labels in LLOCE is a special form of the WSD problem. No simple method can solve the general problem of WSD for unrestricted text. We will show that this labeling task is made simplex for several reasons. For example, consider the definition sentences for the first 5 senses of \"bank\" in LDOCE:","1. land along the side of a river, lake, etc.","2. earth which is heaped up in a l~eld or garden, often making a border or division. 3.a mass of snow, clouds, mud. etc. 4.a slope made at Oends in a road or race-track, so that they are safer for cars to go round. 5.= SANDBANK (a high underwater bank of sand in a river, harbour, etc.).","First of aLl, only simple words are used in the definitions. Furthermore, the text generation schemes are rather regular. The scheme that lexicographers used in generating the definitions above is similar to the DEFINITION scheme described in McKeown (1985). A DEFINITION scheme begins with a genus term (that is, conceptual parent or ancestor of the sense), followed by the so-called differentia that consists of words: semanficaUy related to the sense to provide specifics about the sense. Those relations between the sense and its defining words are reflected in semantic dusters that are termed categorical, functional, and situational clusters in McRoy (1992). Moreover, those relations have been shown to be very effective knowledge sources for WSD (McRoy 1992) and interpretation of noun sequences (Vanderwende 1994). For instance, land, earth, mass, slope, and sand are the genus terms that are categorically related to bank. On the other hand, words in the differentia such as river, lake.field, garden, l~end, road. race-track, and harbour are Situationally related to bank through the Location relation. Other keywords such as rOOd, and race-traÂ¢[~ are related functionally to bank through the PartOfrelation. For the most part, those relations exist conveniently among words under the same topic or across cross-referendng topics in LLOCE. For instance, most of the above mentioned words are listed under the same topic Ld (Geography) of the in-tended label/Ld099, or its cross reference Me (Places). Therefore, these definitions can be disambiguated very effectively on the base of similarity between the defining keywords and the words lists in LLOCE. 2.1. Organizing information in LLOCE In this work, the labels used for tagging dictionary definitions are taken from the LLOCE (McArthur 1992). Words in LLOCE are organized mainly according to subject matter. Nearly 2,500 sets of related words in LLOCE are organized according to 14 subjects and 129 topics (TOP). Cross references (REF) between sets, topics, and subjects are also given to show various inter-sense relations not captured within the same topic. The cross references in LLOCE are primarily between topics.","The sets under which the word is listed in LLOCE are considered as the initial candidates for labeling. For instance, the Candidates for labeling senses of \"bank\" are the foUowing 4 set labels:","Jel04 (banks, exchange, etc.),","Jel06 (banking and saving),","Ld099 (fiver banks), and","Nj295 (bending and leaning) The set label Jel04 (as weU as Jel06) is listed under the topic Je (Banking, Wealth, and Investment), while 31 Ld099 and Nj295 are listed under Ld (Geography) and Nj (Action and Position) respectively. For instance, there is a REF link (in Figure 1) from topic Je to topic De (Belonging and Owning, Getting and Giving). To facilitate estimation of similarity between a definition sentence and a topic, we use TOPS to denote the list of words under a LLOCE topic S, while REFS denotes the list of words under cross references of S. For instance, the label Jel04 (as well as Jel06) is associated with a list of words from its topic (TOPJel04) and cross reference (REFJe l 04 = TOPDe):","TOPJe l04 = TOPJe = {affluent, budget, cut down, deficit, economize, fortune, giro,","income, keep, luxury, maintenance, needy, pay, windfall, amenity .... }","REFJeI04 = TOPDe = {bring back, contribution, doff, equip, facility, keep, yield, ... }. O Subject People Material"]},{"title":"\\ Q Topic CS> Sets O/rganization","paragraphs":["k \\ \\ k \\ Â°oo~ Owning ~a~atedal","-,---_ .... 27z =~ / i r/ / e- / _--Â¢-","i~ / / _A / ~ Â¢- p~ ..... I I \\ ~X'h~ -, cross-reference ... b aak... Figure 1. Subjects, topics, sets, and cross reference between topics in LLOCE. 32"]},{"title":"3. The algorithm","paragraphs":["The algorithm is divided into two stages. The preprocessing steps such as part-of-speech tagging, and removal of stop words are necessary for the algorithm to obtain good results. Various methods for POS tagging have been proposed in recent years. For simplicity, we adapted the method proposed by Churchl(1988) to tag the definition sentence. In the second stage, we select the label which is associated with word lists most similar to the definition as the result. We sum up the above descriptions and outline the procedure for labeling a dictionary sense.","Algorithm: I Sense division for a head word h","Step 1: GiVen a head word h, read its definition, DEFh, from LDOCE.","Step 2: For each definition D ofDEFh, tag each word in D with POS information..","Step 3: Remove all stop words in D to obtain a list of keyword-POS pair, KEYD. i","Step 4: Lookup LLOCE for headword h to obtain a list of sets SETh that contains h. For each S in SETh, compile a set of words TOPS that listed under the topic of S and REFS the set of words listed under it cross references.","Step 5: Compute similarity Sim(D, S) based on Dice Coefficient for all clef'tuitions D ~ DEFh and labels S ,SETh. Sim (D, S) = whereKEYD= the set of POS-keyword pairs in definition D, ~= the overall relevancy of cross references to a topic, wk= 1/the degree of ambiguity of the keyword k, In(a, B)= 1 when a Â• B, In(a, B)= 0 when a ~ B.","Step 6: Assign to D the label S with the maximum value of Sire(D, S) over a threshold.","Initially, the candidates are limited to the set labels indicated in LLOCE for the head word. If the algorithm finds all initial candidates dissimilar, a second run of the algorithm is executed with candidates expanded to all topics in LLOCE."]},{"title":"3.1 An illustrative example","paragraphs":["We illustrate how the algorithm functions using the 5th definition of the word \"interest.\" The preprocess-","ing stage for definition of word \"interest\" includes part-of-speech (POS) tagging and stop word removal,","thereby yielding the following result: h = \"interest\" SETinterest = {Fj228, Fb028, Jell2, KaO06 } D = \"a share in a company business etc. \" POSD = { a/det, share/n, in/prep, a/det, company/n, business/n, etc./adv } KEYD = {share/n, company/n, business/n} /KEYDI = 3"]},{"title":"wshare/n wcompany/n wbusiness/n","paragraphs":["= 1/l{Del05, Hb037, Je114}1 = 1/3 = 1/1{Cc042, Co292, Jh225}1 = 1/3 = 1/1{Gh243, Jd138, Jh225}1 = 1/3 1. In our case. tagging errors have very little negative impact, because words in I.J.,OCE are organized primarily accordln~ to topic not part-of-speech. 33 TOPFj228 = WFj = TOPFb028 = WFb = TOPJell2 = WJe = TOPKaO06 = WKa = {quite/adj, calm/adj .... interest/n, excitement/n, shrill/n .... } {likeN, fancy/v .... attraction/n, appeal/n, interest/n .... } {lend/v, loan/v .... interest/n, investment/n, share/n .... } {entertain/v, amuse/v .... game/n, hobby/n, interest/n .... } REFFj228 = WK = WKa ~,Wkb .... WKh","= { entertain/v, amuse/v, ... game/n, hobby/n, interest/n, .. } REFFb028 = WCc = {friend/n, aquaintance/n .... companion/n, company/n .... } REFJell2 = WDe = {belong to/v, have/v .... share/n } REFKaO06 = WFj = {quite/adj, calm/adj .... interest/n, excitement/n, shrill/n .... } I TOPFj228 u REFFj2281= 1693 I TOPFb028 ~ REFFb0281 = 253 J TOPJell2 ~ REFJe1121 = 446 I TOPKaO06 v REFKaO061 =224 Sim(D, Fj228) 2 Sire(D, Fb028) Sire(D, Jell2) Sire(D, KaO06) =0 = 2x0.33x(lxl)/(253+3) = 0.66/256 = 0.00258 = 2x0.33,,(l+lxl)/(446+3) = 0.66~2/449 = 0.00294 =0","The word lists associated with the label Jell 2 is most similar to the key-words of the definition. Therefore, the algorithm produces Je112 as the label for \"a share in a company business etc.\" 3.2 Experiments and Evaluation An experiment was carried out using a test set 3 containing 12 polysemous words used in recent WSD experiments (Yarowsky 1992; Luk 1995). The 12-word test set used in the evaluation represents much more difficult cases than average. There are on the average 2.6 definitions in LDOCE for each words as opposed to the average 6.4 definitions per words in the test set. Table 1 displays a word by word performance of the algorithm. The results show that on the average the algorithm can assign labels to 87% of the senses with 94% precision. 4. Discussion","In this section, we thoroughly analyze the labeling performed by the algorithm and, in particular, look into several uses that are made possible by the labels' availability. In addition, those cases when the algorithm failed can also be analyzed. Analyses result not only illustrate the merits of these labels, but also imply possible improvement of the algorithm. 4.1. Broad coverage About 50% of the labels are assigned during the second run of the algorithm from the extended candidate set. These labels represent gaps in the LLOCE. So, the algorithm can produce much broader coverage than the original LLOCE. 2. For simplicity, the parameter , is set to i. 3. Only entries relevant to ~e test set m LLOCE are manually emered to ~e computer. We are currently trying to get a licence s.t. the full LLOCE entries in order to ccmduct a more complete test. 34 Table 1. Performance of the extended algorithm","headword Alternate sets in No. of deft- Labeling with expanded candidate set LLOCE nifions inLDOCE La-Incorrect Unknown [ADolicabili- Precision mole sentence slug bass bow cone duty galley n Ac061 n Mf159"]},{"title":"nl~.~ nLa!","paragraphs":["n Cm256 n Gf235 v Gk210","nAgll3 n Hh242"]},{"title":"nGd","paragraphs":["nHb v blk335","adj Kb041 n Kb041"]},{"title":"hE& n.Fgt","paragraphs":["n 1-111234 , n Kb046 n Mf157 n Nj295 v Nj295 vMb vK.h nlag n Na008","n Ai134 n Aj156 n Jb044 nRa","n Fc063 n Jf160 nJh","n Db038 n Mf157 n Mf153 nGd 11 2 Correct belling 1 1 1 1 1 1 1 0 1 1 1 1 2 1 1 0 0 Labelling 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 Labelling 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 Apl: ty 100% 100% 80% 86% 91% 100% 100% 100% 100% 100% 100% 100% 80% 100% 100% 100% 35 headword interest issue star taste","Alternate sets in No. of deft- Labeling with expanded candidate set LLOCE nitions in LDOCE La- Precision","a Fb028 n Fj228 n Ka006 n Je112 v Fb025 v Fj224 v Ka010 n.~.Â£","n Aa020 nGdl80 n Gf243 n Nf153 v Gd174 n.Ga vDÂ¢ nlSa n_N.~ nl',~","a Kd082 n La002 v Kd079 nI:lR nL~ n .N..~ n Ia006 n Nb035 n .QA.L$1.","nFI281 v F1280 v,n v,n n.Qb. n Fb020 8 10 11 11 Correct belling 1 1 2 1 2 1 1 1 1 1 1 0 0 1 2 2 1 1 1 0 0 0 Incorrect Labelling 4 2 1 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 Unknown Labelling 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1"]},{"title":"IlI;']","paragraphs":["ApplicabiUty 88% 80% 73% 91% 100% 75% 100% 100%"]},{"title":"II/ -Ills","paragraphs":["Note: Extended labels are underscored. 4.2. Zero derivation","Dolan (1994) pointed out that it is helpful to identify zero-derived noun/verb pairs for such tasks as normalization of the semantics of expressions that are only superficially different. We have noticed that 36 zero derivatives are an important knowledge source for resolving PP-attachment ambiguity. A PP with an object involved in a noun/adjective zero-derivation has a strong tendency to attach itself to the preceding noun as a modifier. For instance, consider the following example that has an ambiguous PP-attaclmaent problem: We had a lot of interests in common. (= We had a lot of common interests.)"]},{"title":"4.3. Systematic inter-sense relations","paragraphs":["Sanfilippo et al. (1995) contended that strong evidence would suggest that a large part of word sense ambiguity is not arbitrary but follows regular patterns. Moreover, gaps frequently arise in dictionaries and the-sauri in specifying this kind of virtual polysemy. Virtual polysemy and recurring inter-sense relations are closely related to polymorphic senses that can support coercion in semantic typing under the theory of Generative Lexicon of Putstejovsky (1991).","Our experimental results indicate that the labels in LLOCE make it possible to acquire important inter-sense relations, i Many of those relations are reflected in the cross reference information in LLOCE. For instance, LLOCE lists the following cross references for the topic of Eb (Food):","Ac: Animals]Mammals","Ad: Birds","Af: Fish and other (water) creatures","Ah: Parts of animal","Ai: Kinds of parts of plants","Aj: Plant in general","Jg: Shopkeepers and shops selling food most of which are systematic inter-sense relations similar to those described in above-mentioned work. We also observed that words involved in such inter-sense relations are frequently underspecified. For instance, \"chicken\" is listed under both topics Eb and topic Ad, while \"duck\" is listed under Ad but not Eb. By characterizing of some 200 cross references in LLOCE, most systematic inter-sense relations can be easily identiffed among the labeled senses. The labels attached to senses in the MRD, coupled with these inter-sense relations, can then support and realize automatic sense shifts advocated in Putstejovsky and Bouillon (1994). For instance, the sense of \"duck\" label with topic Ad can be coerced into an Eb sense when necessary, with the availability of the lexical rule stipulating a sense shift from Ad and Eb.","Krovetz (1992) observed that LDOCE indicates sense shifts via direct reference (links indicated by a capitalized word with a sense number) and deictic reference (implicit links to the previous sense created by this, these, that, those, its, itself, such a, such an). Sense shifts indicated through a deictic reference are also present in our 12-word test set. For instance, the first 2 senses of \"issue\" are","1. the act of coming out.","2. an example of this. The definition of the 2nd senses indicates an A ctionNoun-CountNoun sense shifts from issue.n.1 to issue.n.2 through a deictic reference of \"this.\" Since those types of definitions pattern are not considered, the labeling algorithm fails in such cases. Further work must be unde~xaken to cope with direct and deictic references, so that such def'mitions can be appropriately labeled and information on sense shifts can be acquired."]},{"title":"4.4. Metonymy or Metaphor","paragraphs":["Many definitions indicate metonymical or metaphorical associations between word senses. For instance,","the 4th and 5th sense of \"star\" are","4. apiece of metal in this shape for wearing as a mark of office, rank, honour, etc.","5. a heavenly body regarded as determining one's fate. 37 The 4th and 5th sense are metonymically associated with two \"star\" senses, star.1 .n.3 (a 5- or more pointed figure) and start.l.n.2 (a heavenly body such as a PLANET), respectively. The algorithm often fails in such cases for two reasons. First, metonymies are not clearly separated and indicated in LLOCE. Second, the genus terms in metonymical senses are often indistinguishable from each other. Further action must be taken to identify the nature of such relations before this kind of ambiguity can be successfully resolved. The presence of phrases \"as a ... 03 Â°' or \"regarded as\" and drastic change in topic toward the second half of the definition may be cues for identifying metonymy and metaphor. 5. Other approaches Sanfilippo and Poznanski (1992) proposed a so-caUed Dictionary Correlation Kit (DCK) in a dialog-based environment for correlating word senses across pairs of MRDs, LDOCE and LLOCE. Dolan (1994) described a heuristic approach to forming unlabeled clusters of closely related senses in a MRD. The clustering program relies on LDOCE domain code, grammar code, and 25 types of semantic relations exu'acted from definitions. Yarowsky (1992) described a WSD method and an implementation based on Roget' s Thesaurus and the training material of the 10-rnillion-word Grolier' s Encyclopedia. The author suggested that the method can also apply to dictionary definitions. Krovetz (1993) described a simple algorithm based on overlap of defining words to identify related senses between morphological variants. The author reported that the success rate was over 80%. No results were reported for closely related senses within a part-of-speech.","In most of the above-mentioned works, experimental results are reported only for some senses of a couple of words. In this study, we have evaluated our method using all senses for 12 words that have been studied in WSD literature. This evaluation provides an overall picture for the expected success rate of the method, when applied to all word senses in the MRD. Directly comparing methods is often difficult. Nevertheless, it is evident that in comparison our algorithm is simpler, requires less preprocessing, and does not rely on information idiosyncratic to LDOCE. Thus, the algorithm described in this paper can readily apply to other MRDs besides LDOCE. Although our algorithm makes use of defining words with various semantic relations with the sense, explicit computation of those relations is not required. 6. Conclusions and Future Work The meth~ proposed in this work takes advantages of a number of linguistic phenomena: (1) Division of senses is primarily along the line of subject and topic. (2) Rather rigid schemes of text generation and predictable semantic relations are used to define senses in MRDs such as LDOCE. (3) The implicit links between instances of many of these relations are available in a thesaurus such as LLOCE.","This work also underscores the effectiveness oflexical rules for coarse WSD. Hand-constructed topic-based classes of words, coupled with lexical rules as common topic and cross references of topics, prove to be highly affecfive both in coverage and precision for WSD, admittedly for sense definitions, a somehow restricted type of text.","Merging senses via labeling has another implication as weU. As discussed in Section 4, the senses sharing the same label (or cross-referencing labels) are frequently associated through various linguistic relations. Making those relations explicit will open the door to flexible treatment of lexicon, semantic typing, and semantic under-specification, all of which have received ever-increasing interest.","In a broader context, this paper promotes the progressive approach to knowledge acquisition for NLP as opposed to the \"from-scratch\" approach. We believe this to be a preferable means to approaching a sound and complete knowledge base. 38 I"]},{"title":"Acknowledgment","paragraphs":["The authors would like to thank the National Science Council of the ROC for financial support of this research under Conu'act No. NSC 85-2213-E-007-042."]},{"title":"References","paragraphs":["1. Brown, P., S.A. Pietra, V.J.D. Pietra, and R. Mercer (1991). \"Word Sense Disambiguation using Statistical Methods,\" In"]},{"title":"Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,","paragraphs":["pp 264-270. 2. Church, Ken W. (1988). \"A stochastic Parts Program and Noun Phrase Parser for Unrestricted Text.\""]},{"title":"In Proceedings of the 2nd Conference on Applied Natural Language Processing","paragraphs":["(ANLP-88), pp 136-","143, Austin, Texas, USA. 3. Dagan, Ido, Alon Itai, and Uldke Schwall (1991). tTwo Languages are More Informative than One,$ Pro-","ceedings of the 29th Annual Meeting of the Association for Computational Linguistics, pp 130-137. 4.Dagan, Ido, Alon Itai (1994), \"Word Sense Disambiguation Using a Second Language Monolingual Corpus,\" Computational Linguistics 20(4), pp 563-596. 5. Dolan, W.B. (1994). \"Word Sense Disambiguation: Clustering Related Senses.\""]},{"title":"In Proceedings of the International Conference on Computational Linguistics,","paragraphs":["pp 712-716. 6.Kilgarriff, Adam (1993). \"Dictionary Word Sense Distinctions: An Enquiry into Their Nature.\""]},{"title":"Computers and the Humanities,","paragraphs":["26, pp 365-387. 7.Krovetz, R. and Croft (1992). \"Lexical Ambiguity and Information Retrieval.\""]},{"title":"ACM Transaction on Information Systems,","paragraphs":["pp 115-141. 8.Krovetz, Robert (1992). \"Sense-Linking in a Machine Readable Dictionary.\" In"]},{"title":"Proceedings of the 30th Annual meeting of the Association for Computational Linguistics,","paragraphs":["pp 330-332. 9.Krovetz, Robert (1993). \"Viewing Morphology as an Inference Process.\" In"]},{"title":"Proceedings of the 16th In-ternational ACM SIGIR Conference on Research and Development in Information Retrieval,","paragraphs":["pp 191-220. J. 0. Lesk, Michael E. (1986). \"Automatic sense disambiguation using machine readable dictionaries: how","to tell a pine cone from a ice-cream cone.\" In"]},{"title":"Proceedings of the ACM SIGDOC Conference,","paragraphs":["pp 24-26, Toronto, Ontario.","11. Longman (1992). \"Longman English-Chinese Dictionary of Contemporary English.\""]},{"title":"Longman Group (Far East) Ltd.,","paragraphs":["Hong Kong.","12.Luk, Alpha K (1995). \"Statistical Sense Disambiguation with Relatively Small Corpora Using Dictio-","nary Definitions;\" In"]},{"title":"Proceedings of the Annual Meeting of the Association for Computational Linguistics,","paragraphs":["pp 181-188. 13.McArthur, Tom (1992). \"Longman Lexicon of Contemporary English.\""]},{"title":"Longman Group (Far East) Ltd.,","paragraphs":["Hong Kong.","14. McKeown, Katherine R. (1985). \"Using Discourse and Focus Constraints to Generate Natural Language Text.\""]},{"title":"Combridge University Press,","paragraphs":["Cambridge, England. 15. McRoy, S. (1992). \"Using Multiple Knowledge Sources for Word Sense Discrimination.\""]},{"title":"Computational Linguistics","paragraphs":["18(1), pp 1-30. 1 6. Putstejovsky, James (1991). \"The Generative Lexicon.\""]},{"title":"Computational Linguistics","paragraphs":["(17)4, pp 409-","441.","17.Putstejovsky, James and Pierrette Bouillon (1994). \"On the Proper Role of Coercion in Semantic Typ-","ing.\" In"]},{"title":"Proceedings of the International Conference on Computational Linguistics,","paragraphs":["pp 706-711. 18. Saniilippo, A., and V. Poznanski. (1992). \"The Acquisition of Lexical Knowledge from Combined 39 Machine-Readable Dictionary Sources.\" In"]},{"title":"Proceedings of the 3rd Conference on Applied Natural Language Processing","paragraphs":["(ANLP-92), pp 80-87, Trento, Italy. 1 9. Vanderwende (1994). \"Interpretation of Noun Sequence.\" In"]},{"title":"Proceedings of the International Conference on Computational Linguistics,","paragraphs":["pp 454-460. 20.Yarowsky, David (1992). \"Word-Sense Disambiguation Using Statistical Models of Roget' s Categories Trained on Large Corpora.\" In"]},{"title":"Proceedings of the International Conference on Computational Linguistics,","paragraphs":["pp 454.-460. Appendix Semantic Table for set labels of 12 Polysemous Words","Word Alternate sets in Semantic Labelling LLOCE","mole I sentence Ising bow cone"]},{"title":"duty","paragraphs":["galley a Ac061 n Mf159 n Be in Ld n Cm256 a Gf235 v Ck210","nAgll3","n Hh242","n Gd","n Hb","n Nk335 n Hh234 n Kb046 n Mf157 n Nj295 v Nj295 vMb v Kb"]},{"title":"nDg","paragraphs":["n Na008 n Ai134 n Aj156 n Jb044 n Ha n Fc063 n Jfl60 nJh n Db038 n Mf157 n Mf153 n Gd small animals harbours and yards skin, complexion and hair geography punishments and deterrents phrases and sentences punishing and fining worms and similar creatures shot and bullets"]},{"title":"communicating","paragraphs":["object generally","striking bows and arrows string instruments"]},{"title":"parts of ships","paragraphs":["bending and leaning bending and leaning putting and taking music and related activitities clothes and personal belongings","typifying and embodying ifmit and seed kinds of coniferous trees ; geometrical shapes substances, materials, objects and equipment rules of behaviour taxes business, work, and employment the kitchen and similar rooms"]},{"title":"parts of ships","paragraphs":["larger kinds of sailing boats communication 40"]},{"title":"Word Alternate sets in Semantic Labelling LLOCE interest issue star taste nFb028 n Fj228 n Ka006 n Je112","paragraphs":["v Fb025"]},{"title":"Iv Fj224 v Ka0110 nNf n Aa020 n Gd180 In Gf243 n Nf153 v Gd174 n Ca !v De n Na : nNb n Ne n Kd082 n La002 v Kd079 n He :n Le !n Na attracting communicating, mainly by reading and writing, pnnting and publishing games and hobbies interest on money attracting and interesting nteresting and exciting interesting and thrilling causing young creatures publications and editions subject and topic results and effects publishing people belonging and owning, getting and giving being, becoming and happening chance doing things actors planets, suns, and stars playing and rehearsing ]specific substances and materials time generally !being, becoming and happening n IaO06 n Nb035 n Gdl51 n F1281 v F1280 v,n Ea' v,n Fa n Gb n Fb020 shapes and models fortune punctuation tasting things Itasting things food generally feeling and behavior generally knowing and learning liking and loving 41","paragraphs":[]}]}
