{"sections":[{"title":"An Algorithm for Generating Quantifiers Norman Creaney","paragraphs":["Faculty of lnformatics","University of Ulster at Coleraine","N Ireland","BT52 1SA","E-mail.\" n. creaney@ulst, ac. uk Tel: +44 (0)1265 324502 Fax: +44 (0)1265 324916 Abstract: Quantifiers, and their associated scoping phenomena are ubiquitous in English and other natural languages, and a great deal of attention has been paid to their treatment in the context of natural language analysis. Rather less attention, however, has been paid to their treatment in the context of language generation. This paper describes an algorithm for generating quantifiers in English sentences which describe small models containing collections of individuals which are inter-related in various ways. The input to the algorithm is, i) a model represented as a collection of facts and ii) an abstract description of the target sentence with gaps where the quantifiers should be. Keywords: lexical choice, realisation, quantifiers 121"]},{"title":"An Algorithm for Generating Quantifiers","paragraphs":["Quantifiers, and their associated scoping phenomena are ubiquitous in English and other natural languages, and a great deal of attention has been paid to their treatment in the context of natural language analysis (Alshawi 1990, Creaney 1995, Grosz et al. 1987, Hobbs and Shieber 1987, Park 1995, Saint-Dizier 1984). Rather less attention, however, has been paid to their treatment in the context of language generation. This paper describes an algorithm for generating quantifiers in English sentences which describe small models containing collections of individuals which are inter-related in various ways. A model is represented as a collection of facts like the following: rep( rl ). sample( sl ). rep( r2 ). sample( s2 ). rep( r3 ). sample( s3 ). rep( r4 ). saw( rl, sl ). saw( r2, sl ). saw( r2, s2 ). saw( r3, s2 ). saw( r3, s3 ). saw( r4, sl )."]},{"title":"saw(","paragraphs":["r4, s2 ). saw( r4, s3 ). In model (1) there are four representatives and three samples and some of the representatives saw some of the samples. The algorithm generates suitable quantifiers to complete sentences of the form:"]},{"title":"QR","paragraphs":["representative(s) saw Qs sample(s) where QR and Qs can be arbitrary quantifiers like; some, two, all, both, one of the, most, etc. The algorithm also handles models containing more relationships than model (I) to generate sentences of the form:"]},{"title":"QR","paragraphs":["representative(s) of Q c company(s) saw Qs sample(s)"]},{"title":"QR","paragraphs":["representative(s) saw Qs sample(s) of Qp product(s) QR representative(s) of Qc company(s) saw Qs sample(s) of Qp product(s) One of the most striking things about the problem is that there are generally a great many sentences which provide reasonable descriptions of any given model. For example, the following are all acceptable for model (1). 2 Every representative saw a sample 3 Every representative saw at least one","sample 4 Most representatives saw at least two","samples 5 A representative saw every sample 6 At least one representative saw every","sample 7 At least two representatives saw most","samples It turns out that there are three distinct sources of this variation and they correspond to three different kinds of choices which are made in the generation algorithm. They are: o quantifier scoping choices o choice of focus sets o choice of individual quantifiers constrained","by the above two choices A great deal has been written about the quantifier scoping problem for natural language analysis (Hobbs & Shieber 1987) and much of this is applicable to the generation problem in the sense that any particular description must assume some particular quantifier scoping arrangement. For example, sentence (2) assumes that \"Every representative\" has wide scope while sentence (5) assumes that \"every sample\" has wide scope, and the sentences are only satisfied in the model under these assumptions. In fact sentences (2), (3) and (4) all assume wide scope for \"representative\" while sentences (5), (6) and (7) all assume wide scope for \"sample\". The gencration algorithm, of necessity, incorporates quantifier scoping. 122 The concept of a focus set has no correlate in the language analysis literature although it is similar to what Barwise and Cooper (Barwise and Cooper 1981) call a witness set. It has to do with choosing some particular subset of the model on which to base the description. Sentence (2) talks about all three representatives while sentence (4) talks only about the subset {r2,r3,r4}. This subset stands in the realtion most to the entire set of representatives {rl,r2,r3,r4} and is the focus set for R in sentence (4). The concept of a focus set will be made more precise below where dependency functions are discussed."]},{"title":"saw( QI(R, rep(R)), Q2(S, sample(S)) ) saw( Q3(R, rep(R) ̂of(R, Q4(C,com(C))), Qs(S, sample(S)) )","paragraphs":["and the purpose of the algorithm is to assign values to the Oi's given some suitable model. It works by processing the PAS recursively and non-deterministically selecting quantifier scopings and focus sets at each level. Quantifiers are then generated based on the cosen focus set."]},{"title":"Inputs to the algorithm","paragraphs":["The inputs to the algorithm are: a model like (1) a predicate argument structure for the target sentence A predicate argument structure (PAS) is essentially an unscoped logical form of the form taken as input to Hobs and Shieber's algorithm (Hobbs & Shieber 1987). It makes explicit the relationships between predicates and there arguments but does not express any quantifier scope relationships. Sentence (2) has the following PAS:"]},{"title":"saw(every(R,rep(R)), a(S,sample(S)) ) Quantifier scoping","paragraphs":["Since the particular scoping framework underlying the generation algorithm is novel a brief explanation is appropriate. The orthodox approach to quantifier scoping is embodied in Hobbs and Sheiber's algorithm and it permits all permutations of quantifiers such that there are no unbound variables in the resulting logical form. For example, Hobbs and Shieber's algorithm produces the scopings (8b-f) for sentence (8a)t:","8 a Every representative of a company saw","some samples b R>C>S"]},{"title":"c C>R>S d S>R>C e C>S>R","paragraphs":["f"]},{"title":"S>C>R","paragraphs":["and sentence (8a) has the following one."]},{"title":"saw( every(R, rep(R)Aof(R,a(C,com(C))), some(S, sample(S)) )","paragraphs":["Each variable in a PAS has a quantifier and a restriction which restricts the values which it may take. O O S's restriction is sample(S) in both cases R's restriction is rep(R) in the first PAS and"]},{"title":"rep(R)Aof(R,a(C,company(C))","paragraphs":["in the"]},{"title":"second","paragraphs":["Since the algorithm generates quantifiers its input PASs are not exactly like these. Instead they have gaps where quantifiers should be: where R > C > S indicates that \"Every representative\" outscopes \"a company\" which in turn outscopes \"some samples\". The missing permutation, R > S > C, is not permitted because it violates what has become known as the unbound variable constraint. The scoping framework which underlies the generation algorithm recognises fewer scopings than (8). The relative scope of two quantifiers is only considered for variables","We adopt the convention of naming variables with the first letter of the head noun with which they are associated (R=representative, C=company, S=sample) and using the symbol '>' to denote relative scope. 123 which are arguments to the same predicate. For example, R must be scoped relative to C because they are both arguments to the predicate of The possibilities are R > C and t3 > R. Similarly, R and S are arguments to the predicate saw and may be scoped either R > S or S > R. The relative scoping of C and S is never considered directly because they do not participate directly in any single predication in the sentence. They may however end up with a relative scoping as a result of taking the transitive closure of other scoping relationships. For example, if it is decided that C > R and R > S, then clearly, since scope is transitive, C > R. In this framework the following scopings are allowed for (8a).","9 a R>S,R>C b S>R>C c C>R>S d S>R,C>R It is clear from (8) and (9) that this framework undergenerates in comparison with Hobbs and Shieber's. However, in the context of language generation, undergeneration is not necessarily a serious problem, provided that there is the ability to adequately describe any model. In fact there is an argument to be made in favour ofa scoping framework which undergenerates with respect to Hobbs and Shieber's as a general approach to quantifier scoping (Park 1995). This is the subject of a future paper."]},{"title":"Dependency functions, partitions and focus sets","paragraphs":["Each variable in a PAS has a candidate set which is defined by its restriction and the model under consideration.","Definition 1: candidate set A variables candidate set is the set of individuals from the model which satisfy the variables restriction. For the PAS: saw(every(R,rep(R)), a(S,sample(S)) ) and model (1), R's candidate set is {rl,r2,r3,r4} and S's is {sl,s2,s3}. When we say that \"Every representative\" has wide scope we are saying that there is a function which maps R's candidate set onto the power set of S's candidate set. This dependencyffunction is computed from model (1) and is exhaustively listed in (lO) below.","10 saw: {rl,r2,r3,r4} ~ power({sl,s2,s3}) rl ~ { sl } r2 ~ {sl, s2} r3 --~ { s2, s3 } r4 ~ {sl,s2, s3} Alternatively, ifS is given wide scope the following dependency function is computed.","11 saw: {sl,s2,s3} -, power({rl,r2,r3,r4}) sl --~ {rl, r2, r4} s2 --~ { r2, r3, r4 } s3 ~ {r3, r4} Focus sets were discussed briefly above and are made more precise now in the context of dependency function partitions. Any dependency function can be partitioned by choosing a arbitrary subset of the mappings it contains as its focus, the remainder being its complement. Of course, the domains and ranges of these sub-functions are appropriately adjusted. The partitions (12a-c) are among the possible partitions of dependency function ( I 0).","12 a focus: saw: {rl} ~ power({sl}) rl -+ { sl }","compt: saw: {r2,r3,r4}","power({sl ,s2,s3}) r2 ~ {sl, s2} r3 ~ {s2, s3} r4 -~ { sl, s2, s3 }","focus: saw: {r2,r3} --~ power({sl,s2,s3}) r2 --~ {sl, s2} r3 --~ { s2, s3 }","compt: saw: {rl,r4} ~ power({sl,s2,s3}) rl ~ { sl } r4 --~ {sl, s2, s3} 124","focus:saw:{r2,r3,r4} --~ power({sl ,s2,s3}) r2 --~ {sl,s2} r3 ~ {s2, s3} r4 ~ {sl, s2, s3} The mapping from partitioned dependency f,mction to quantifiers is non-deterministic as (13) shows. For instance, partition (12b) gives, at least, the three sentences (13bi,ii,iii).","compt: saw: {rl} ~ power({sl}) rl -~ {sl}","Definition 2: focus set The focus set for a variable, given a particular partition is either: o the domain of the partition's focus o the union of the range of the partition's","focus depending on the variable of interest. Not all sentences provide equally good descriptions of the model but they are all true in it. For example, (13ai) is true in (1), assuming \"a\" means at least one, but is not very informative. Bigger focus sets tend to give more information and sound more natural however the generation algorithm is concerned only with presenting alternatives and not with selecting between them. For example, (12a-c) define the following candidate sets for R and S. {rl} {sl} {r2, r3} {sl, s2, s3} { r2, r3, r4 } { sl, s2, s3 } It is useful to note that a variable's candidate set is related to an unpartititioned dependency function in exactly the same way that its focus set is related to the focus of the partitioned function. These relationships are illustrated in appendix 1. Individual quantifiers are selected for generation on the basis of dependency function partitions. For example, the descriptions (13a-c) are licensed by the partitions (12a-c) respectively.","13a i A representative saw a sample ii Exactly one representative saw","exactly one sample III At least hal[the representatives saw exactly two samples Exactly two representatives saw exactly two samples Two. representatives saw most samples Exactly three representatives saw at least twq samples Three representatives saw some samples"]},{"title":"Generating quantifiers","paragraphs":["The process of generating quantifiers takes place after a scoping has been chosen and a dependency function has been constructed and partitioned, so that all decisions are made in the context of a particular partitioning of a particular dependency function. Generation consists of going through the list of all possible quantifiers and checking whether or not each one is consistent with the appropriate variable in the current dependency function partition. Those which are consistent are then generated and those which are inconsistent are rejected. To check the consistency of a particular quantifier with a particular variable it is first necessary to compute the variable's candidate set, focus set, and focus maximum and focus minimum.","Definition 3: Focus maximum and minimum For a variable with wide scope the focus maximum (Fmax) and focus minimum (Fmin) are the same. They are simply the size of the focus set or, equivalently, the number of mappings in the focus of the dependency function.","e.g. R in (12a): Fmax=Fmin= I{rl}l = 1 R in (12c): Fmax=Fmin= I {r2,r3,r4} I = 3 For a variable with narrow scope the focus maximum (Fmax) is equal to the size of the 125 biggest member of the range of the focus of the dependency function.","e.g. S in (12a): Fmax = max(l{sl}i) = 1 S in (12c): Fmax= max( I {sl ,s2} I, I {s2,s3} ], I{sl ,s2,s3} I )","=3 The focus minimum is defined along the same lines as he focus maximum except that the minimum set size is taken.","e.g. S in (12a): Fmin= min([{sl}l)= 1 S in (12c): Fmin= min(I {s1,s2}l, I {s2,s3}l, I {sl,s2,s3}l )","=2 q_inc( 1,_, [a] ). q_inc( 1,_, [somesing] ). q_inc( 1,_, [at, least,one] ). q_inc( 2, _, [at, least,two] ). q_inc( N, _, [some_plur] ):- N > 1. q_inc( N, M, [most] ) :- M < 2*N. q_inc( 1, 1, [the] ). q_inc( 2, 2, [both] ). q_inc( 3, 3, [all,three] ). q_inc( N, N, [all] ). q_inc( N, N, [each] ). q_inc( N, N, [every] ). For R in (12a) the appropriate call is therefore: The checking procedure varies according to the type of quantifier under consideration where quantifiers are classified as one of three types monotone increasing, monotone decreasing or cardinal (Barwise and Cooper 1981).","o Monotone increasing quantifiers are those with an at least N interpretation. They include; a, some_sing, some_plur, the, both, many, at least four","o Monotone decreasing quantifiers are ones with an at most N interpretation. They include; no, few, at most three, less than three quarters","o Cardinal quantifiers are of the form exactly N ?- q_inc( 1, 4, QR ). which returns the following quantifiers: a, some_sing, at least one. Similarly, for 9 in (12a) the appropriate call is: ?- q_inc( 1, 3, QS ). which returns the same set ofquantifiers. Hence sentence (13ai) is generated, as is: Some representatives saw _a sample At least one representative saw a sample A representative saw some samples and other similar sentences formed by selecting from the above quantifiers. The check for monotone increasing quantifiers is simplest. The acceptability of each quantifier is as defined by a call to the following Prolog goal: ?- q_inc( Fmin, Nc, QUANT ). For a monotone decreasing quantifier the check depends on whether it is in wide scope position or narrow scope position. In narrow scope position the check is similar to the one for monotone increasing quantifiers except that: where; Fmin = the focus minimum, Nc = I candidate set], and the q_inc/3 relation is defined along the following lines.","14 % q_inc( +N1, +N2, ?Q ) defines Q as % - \"at least N1 out of a possible N2\" % e.g. \"a man\" means % - at least 1 man out of any number % \"some men\" means % - at least 2 men out of any number % \"both men\" means % - at least 2 men out of a possible 2","o a different collection of quantifiers is","checked - the monotone decreasing ones","o the focus maximum is input rather than the","focus minimum. ?- q_dec( Fmax, Nc, QUANT ). where; Fmax = the focus maximum, Nc = I candidate set[, and the q_dec/3 relation is defined along the following lines. 126","15 % q_dec( +N1, +N2, ?Q ) defines Q as % - \"at most N1 out of a possible N2\" % e.g. \"no man\" means % - at most 0 men out of any number % \"few men\" means % - at most half of all the men % \"neither man\" means % - at most 0 men out of 2 q_dec( 0, _, [no] ). q_dec( 2, _, [at, most, two] ). q_dec( N, M, [few] ) :- M < 2*N. q_dec( 0, 2, [neither] ). The check for monotone decreasing quantifiers in wide scope position is a little bit trickier. For example, to check the consistency of the quantifier at most two in \"At most two representatives saw a sample\", assuming R > S, the following checks need to be made.","O There must be a set of at most two of R's who may or may not have seen a sample. This entails checking that R's focus set contains exactly two members. All other R's outside this set must certainly not have seen a sample. This entails checking the complement of the dependency function to make sure that the quantifier a fails to be consistent with the variable S. These checks are carried by calls to q_dec/3 an q_inc/3 with appropriate input values. The check for cardinal quantifiers is defined in terms of two sub checks: one for a monotone increasing quantifier and one for a monotone decreasing. This follows from the observation that exactly N meant the same as (at least N)A(at most N)."]},{"title":"Embedded quantifiers","paragraphs":["The preceding discussion concentrated on simp!e linguistic structures like (2-7) which contain one main verb and noun phrases with no recursive structure. The processing of a more complex structure like:","16 saw( QR(R, rep(R) ̂of(R, Qc(C,com(C))), Qs(S, sample(S)) ) is done by breaking it down into sub-structures (17) which are processed almost independently.","17 a saw( QR(R .... ), Qs(S, sample(S))) b of( QR,(R, rep(R)), Qc(C, com(C)) ) The variable R is assigned the quantifier OR in (1 7a) and the quantifier OR, in ( 1 7b) but clearly only one of these will ultimately be generated and some special treatment is required. Thes are called R's outer and inner quantifiers respectively. PAS (17b) is processed first. A scoping is chosen for R and C and a dependency function is constructed in the normal way but when it comes to partitioning the function and generating a quantifier for C some care must be taken. Some choices of partition and quantifier must be excluded. What is required is that the resulting focus set for R is the set of all representatives who satisfy restriction (17b) under the chosen partition and quantifier. Consider the following dependency function and associated partition.","18a of: {rl,r2,r3} ~ power( {cl,c2,c3} ) rl --~ { cl } r2 --~ {c2} r3 --~ {c3}","b focus: of: {rl,r2} ~ power({cl,c2}) rl ~ { cl } r2 ~ {c2}","compt: of: {r3} ~ power({c3}) r3 ~ {b3} Based on the focus in (18b) the quantifier exactly one might be generated for C. The corresponding candidate set for R is {rl,r2} but this is not the set of all representatives who satisfy the restriction since r3 also satisfies it. It is to avoid this anomaly that the following constraint on the acceptability of dependency function partitions in this context. 127","19 If variable R is in wide scope position in (17b) then QR' must be of the form"]},{"title":"exactly","paragraphs":["N but is not generated in the final output. Constraint (19) restricts the range of acceptable partitions by restricting the range of acceptable inner quantifiers for R. It also specifies R's outer quantifier as the one which is to be finally generated. It guarantees that R's focus set is maximal in the sense that it contains all possible R's which satisfy the restriction and avoids the above anomoly by failing to allow partition (18b). A parallel but different constraint is applied whenever R is in narrow scope position.","20 If variable R is in narrow scope position in (17b) then QR must be the quantifier V but is not generated in the final output."]},{"title":"The","paragraphs":["algorithm The overall strategy is to process a PAS recursively, assigning quantifiers to the most deeply nested structures first. As a variable's restriction is processed the resulting focus set is passed back up to act as the candidate set for the same variable in the embedding structure. An inner quantifier is also returned together with a flag which indicates scoping choices within the restriction. The algorithm is as follows, where the choose construct indicates non-determinism.","21 to process_PAS p(Qx(X,RX),Qy(Y,RY) ) process_RES RX; process_RES RY; % returned by calls to process_RES: % Xs, Ys: the candidate sets forX&Y % Qx', Qy': the innerquants forX&Y % ScpX, Scp Y: = '>' if head variable % is given wide scope within restriction, % '<' if it has narrow scope or 'nil' if there % are no other variables within the rest'n choose a scoping for X and Y; construct the dependency function; choose a partition; choose outer quantifiers Qx\" and Qy\"; % must be consistent with consts. 19&20 if ScpX = > or ScpX = nil then Qx := Qx\"","else Qx := Qx'; if ScpY = > or ScpX = nil then Qy := Qy\"","else Qy := Qy';","end"]},{"title":"process_PAS;","paragraphs":["to"]},{"title":"process_RES","paragraphs":["RX % X is head of phrase","% this procedure returns: Xs, Qx & ScpX","case 1: RX = p(Qx(X,RX),Qy(Y,RY))","% i.e. RX contains an embedded NP process_RES RY; % returns Ys Qy' ScpY Xs := { X: RX }; choose a scoping for X and Y; % and so assign a value to ScpX construct a dependency function; choose a partition; choose quantifiers Qx and Qy\"; % must be consistent with constraints % 19&20 and ScpX & ScpY","case 2: RX = p(X)","% i.e. RX contains no embedded structure Xs := { X: p(X) }; Qx := nil; ScpX := nil;","end"]},{"title":"process_RES; An example","paragraphs":["Consider the following model: rep( rl ). of( rl, cl ). saw( rl, sl ). rep( r2 ). of( r2, c2 ). saw( rl, s2 ). rep( r3 ). saw( r2, sl ). rep( r4 ). samp( sl ). saw( r2, s2 ).","samp( s2 ). saw( r3, sl ). corn( cl ). saw( r4, s2 ). corn( c2 ). and the target PAS (16). According to process_PAS the following restrictions must be processed first.","22 a of(QR(R,rep(R)), Qc(C,com(C)) ) b samp(S) Starting with (22a): candidate set R = { rl, r2, r3, r4 } candidate set C = { cl, c2 } choose scoping R > C the following dependency function is constructed.","23 of: {rl,r2,r3,r4} --~ power'( {cl,c2} ) rl ~ { cl } r2 ~ {c2} r3 ~{} r4 --~ {} The following partition is chosen. 128","24 focus: of: {rl,r2} ~ power({cl,c2}) rl ~ { cl } r2 ~ {.c2}","compt: of: {r3,r4} ~ power({}) r3 ~ {} r4 --, {} The quantifier a is chosen for C and the candidate set {rl ,r22} is returned. Processing (22b) is straightforward and consists of returning the value {sl,s2}, the set of all samples. Now both restrictions have been processed and PAS (16) is processed with the candidate sets {rl ,r2} and {sa ,s2}. candidate set R = { rl, r2 } candidate set S = { sl, s2 } choose scoping R > S The following dependency function is constructed.","25 saw: {rl,r2} ~ power( {sl,s2} ) rl ~ {sl,s2} r2 ~ {sl,s2} and the following partition is chosen.","26 focus: saw: {rl,r2} ~ power( {sl,s2} ) rl ~ {sl, s2} r2 ~ {sl, s2} compt: saw: { } ~ power( { } ) The quantifiers every and both are now chosen for R and S respectively giving the following sentence. 27 Ever~ representative"]},{"title":"of _a","paragraphs":["company saw both samples Of course different scoping and partitioning choices may have generated different quantifiers. Those in (27) are based on the scoping choices R > C and R > S with the partition choice shown in (26)."]},{"title":"Conclusion","paragraphs":["An algorithm has been described for generating quantifiers in English sentences which describe small models containing collections of individuals which are inter-related in various ways. The algorithm performs a great deal of search with three levels of non-determinism corresponding to. o quantifier scoping choices o choice of focus sets / dependency function","partitions o choice of individual quantifiers constrained","by the above two choices This is not necessarily a problem in the context of language generation where only one solution is sought. An obvious improvement to the algorithm would be to generate a preferred sentence or to rank the outputs as to how well they describe the model. We are currently looking at how this might be done by incorporating something like the preference heuristics that have been used successfully to select quantifier scopings in natural language analysis (Grosz et al 1987). After the choose scoping step in the algorithm quantifiers can be proposed which are preferred in the given scoping position. These proposed quantifiers are then checked first by q_inc/3 and q_dec/3. The details of this have not yet been worked out. The description given of the algorithm is based on binary predicates for the sake of brevity and clarity but the generalisation to predicates with three or more arguments is not difficult. For example, sentences of the following form can be generated: 28 Every boy gave most girls a kiss where there is a different kiss for each <boy,girl> pair. The resulting dependency functions are, however, much bigger, and consequently the search space is also. It is well documented (Webber 1978, Park 1995) that some plural noun phrases are capable of collective interpretations which are not sensitive to quantifer scoping. For 129"]},{"title":"example, the sentence \"'Three men lifted two boxes\" has an interpretation in which three men combined their efforts in a single act of lifting two boxes. The algorithm does not deal with collective interpretations like this. References Alshawi, H, (1990), \"Resolving Quasi Logical Forms.\", Computational Linguistics, 16, 3. Barwise, J, R Cooper, (1981), Generalized Quantifiers andNatural Language, Linguistics and Philosophy, 4, 159-219. Creaney, N, (1995), Implementing Scope and Dependency Constrains in a Typed Attribute Logic, Proceedings of 5th International Workshop on Natural Language Understanding and Logic Programming, Lisbon. Grosz, B J, DE Appelt, PA Martin, and FCN Pereira, (1987), TEAM. An Experiment in the Design of Transportable Natural-Language Interfaces, Artificilal Intelligence, 32, 173-243. Hobbs, JR, SM Shieber, (1987), An Algorithm for Generating Quantifier Scopings, Computational Linguistics, Voi.3, No.l, 47-63. Park, J, (1995), Quantifier Scope and Constituency, Proceedings ACL-95. Saint-Dizier, P, (1984). Handling Quantifier Scoping Ambiguities in a Semantic Representation of Natural Language Sentences. In Dahl, V. and Saint-Dizier, P. (eds.). Proc. I st Int. Workshop on Natural Language Understanding and Logic Programming, (1984). North-Holland. Webber, BL, (1978), A Formal Approach to Discourse Anaphora, BBN report no. 3761, Cambridge, MA: Bolt Beranek and Newman Inc. Appendix 1: terminology diagram","paragraphs":["Candidate sets for R and C","Whole dependency function One possible ]","partition -focus and complement","~ power(,","{ cl, c2 }","r2 ~ {c2}","r3 ~ {c3} cl, c2, c3 }))",".~-~ power((","cl, c2 } {c2}","of: { r3 } ~ power( { c3 } ~\", x r3 ~ {b3}","ocus sets for R and C","Â• Focus maximum (R) = 2 Focus minimum (R) = 2 Focus maximum (C) = 2 Focus minimum (C) = 1"]},{"title":"130","paragraphs":[]}]}
