{"sections":[{"title":"Statistical Machine Translation Using Coercive Two-Level Syntactic Transduction Charles Schafer and David Yarowsky Center for Language and Speech Processing / Department of Computer Science Johns Hopkins University Baltimore, MD 21218 USA fcschafer,yarowskyg@cs.jhu.edu Abstract","paragraphs":["We define, implement and evaluate a novel model for statistical machine translation, which is based on shallow syntactic analysis (part-of-speech tagging and phrase chunking) in both the source and target languages. It is able to model long-distance constituent motion and other syntactic phenomena without requiring a full parse in either language. We also examine aspects of lexical transfer, suggesting and exploring a concept of translation coercion across parts of speech, as well as a transfer model based on lemma-to-lemma translation probabilities, which holds promise for improving machine translation of low-density languages. Experiments are performed in both Arabic-to-English and French-to-English translation demonstrating the efficacy of the proposed techniques. Performance is automatically evaluated via the Bleu score metric."]},{"title":"1 Introduction","paragraphs":["In this work we define,implement and evaluate a novel model for statistical machine translation (SMT).","Our goal was to produce a SMT system for translating foreign languages into English which utilizes some syntactic information in both the foreign language and English without, however, requiring a full parse in either language. Some advantages of not relying on full parses include that (1) there is a lack of availability of parsers for many languages of interest; (2) parsing time complexity represents a potential bottleneck for both model training and testing.","Intuitively, the explicit modeling of syntactic phenomena should be of benefitin the machine translation task; the ability to handle long-distance motion in an intelligently constrained way is a salient example of such a benefit. Allowing unconstrained translation reorderings at the word level generates a very large set of permutations that pose a difficult search problem at decoding time. We propose a model that makes use of shallow parses (text chunking) to support long-distance motion of phrases without requiring deeper analysis of syntax. The resources required to train this system on a new language are minimal, and we gain the ability to model long-distance movement and some interesting properties of lexical translation across parts of speech. One of the source languages we examine in this paper, Arabic, has a canonical sentence-level order of Verb-Subject-Object, which means that translation into English (with a standard ordering of Subject-Verb-Object) commonly requires motion of entire phrasal constituents, which is not true of French-to-English translation, to cite one language pair whose characteristics have wielded great in-fluence in the history of work on statistical machine translation. A key motivation for and objective of this work was to build a translation model and feature space to handle the above-described phenomenon effectively."]},{"title":"2 Prior Work","paragraphs":["Statistical machine translation, as pioneered by IBM (e.g. Brown et al., 1993), is grounded in the noisy channel model. And similar to the related channel problems of speech and handwriting recognition, the original SMT language pair French-English exhibits a relatively close linear correlation in source and target sequence. Much common local motion that is observed for French, such as adjective-noun swapping, is adequately modeled by the relative-position-based distortion models of the classic IBM approach. Unfortunately, these distortion models are less effective for languages such as Japanese or Arabic, which have substantially different top-level sentential word orders from English, and hence longer distance constituent motion.","Wu (1997) and Jones and Havrilla (1998) have sought to more closely tie the allowed motion of constituents between languages to those syntactic transductions supported by the independent rotation of parse tree constituents. Yamada and Knight (2000, 2001) and Alshawi et al. (2000) have effectively extended such syntactic transduction models to fully functional SMT systems, based on channel model tree transducers and finitestate head transducers respectively. While these models are well suited for the effective handling of highly divergent sentential word orders, the above frameworks have a limitation shared with probabilistic context free grammars that the preferred ordering of subtrees is insufficiently constrained by their embedding context, which is especially problematic for very deep syntactic parses.","In contrast, Och et al. (1999) have avoided the constraints of tree-based syntactic models and allow the relatively flat motion of empirically derived phrasal chunks, which need not adhere to traditional constituent boundaries.","Our current paper takes a middle path, by grounding motion in syntactic transduction, but in a much flatter 2-level model of syntactic analysis, based on flat embedded noun-phrases in a flat sentential constituent-based chunk sequence that can be driven by syntactic bracketers and POS tag models rather than a full parser, facilitating its transfer to lower density languages. The flatter 2-level structures also better support transductions conditioned to full sentential context than do deeply embedded tree models, while retaining the empirically observed advantages of translation ordering independence of noun-phrases.","Another improvement over Och et al. and Yamada and Knight is the use of the finitestate machine (FSM) modelling framework (e.g. Bangalore and Riccardi, 2000), which offers the considerable advantage of a fle xible framework for decoding, as well as a representation which is suitable for the fixed two-level phrasal modelling employed here.","Finally, the original cross-part-of-speech lexical coercion models presented in Section 4.3.3 have related work in the primarily-syntactic coercion models utilized by Dorr and Habash (2002) and Habash and Door (2003), although their induction and modelling are quite different from the approach here."]},{"title":"3 Resources","paragraphs":["As in other SMT approaches, the primary training re-source is a sentence-aligned parallel bilingual corpus. We further require that each side of the corpus be part-of-speech (POS) tagged and phrase chunked; our lab has previously developed techniques for rapid training of such tools (Cucerzan and Yarowsky, 2002). Our translation experiments were carried out on two languages: Arabic and French. The Arabic training corpus was a subset of the United Nations (UN) parallel corpus which is being made available by the Linguistic Data Consortium. For French-English training, we used a portion of the Canadian Hansards. Both corpora utilized sentence-level alignments publicly distributed by the Linguistic Data Consortium.","POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al., 1993). French POS tagging was done using the trained French lexical tagger also provided with the fnTBL software. For Arabic, we used a colleague’s POS tagger and tokenizer (clitic separation was also performed prior to POS tagging), which was rapidly developed in our laboratory. Simple regular-expression-based phrase chunkers were developed by the authors for both Arabic and French, requiring less than a person-day each using existing multilingual learning tools.","A further input to our system is a set of word alignment links on the parallel corpus. These are used to compute word translation probabilities and phrasal alignments. The word alignments can in principle come from any source: a dictionary, a specialized alignment program, or another SMT system. We used alignments generated by Giza++ (Och and Ney, 2000) by running it in both directions (e.g., Arabic ! English and English ! Arabic) on our parallel corpora. The union of these bidirectional alignments was used to compute cross-language phrase correspondences by simple majority voting, and for purposes of estimating word translation probabilities, each link in this union was treated as an independent instance of word translation."]},{"title":"4 Translation Model","paragraphs":["Now we turn to a detailed description of the proposed translation model. The exposition will give a formal specification and also will follow a running example throughout, using one of the actual Arabic test set sentences. This example, its gloss, system translation and reference human translation are shown in Table 1.","The translation model (TM) we describe is trained directly from counts in the data, and is a direct model, not a noisy channel model. It consists of three nested components: (1) a sentence-level model of phrase correspondence and reordering, (2) a model of intra-phrase translation, and (3) models of lexical transfer, or word translation. We make a key assumption in our construction that translation at each of these three levels is independent of the others. 4.1 Sentence Translation As mentioned, both the foreign language and English corpora are input with “hard” phrase bracketings and labeled with “hard” phrase types (e.g., NP, VP1",", PPNP2",", etc.) as given by the output of the phrase chunker. These are denoted in the top-level model presentation in Table 2(1). Given word alignment links, as described in Section 2, we compute phrasal alignments on training data. We contrain these to have cardinality (foreign)N ! 1(English). Next, we collect counts over aligned phrase sequences and use the relative frequencies to estimate the probability distribution in Table 2(2). Particularly for smaller training corpora, unseen foreign-language phrase sequences are a problem, so we implemented a simple backoff method which assigns probability to translations of unseen foreign-language phrase sequences. Table 2(3) encapsulates the remainder of the translation model, which is described below.","As an example, Table 3 shows the most probable aligned English phrase sequence generations given an Arabic simple sentence having the canonical VSO ordering. Also, note that all probabilities in the following 1 VP in our parlance is perhaps more properly called a verb chunk:","it consists of a verb, its auxiliaries, and contiguous adverbs. 2 PPNP consists of a NP with its prepositional head attached. Arabic Example Sentence From Test Set","(ARABIC) twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp b- AEtmAd m$rwE Al- mqrr Al- tAly :","(PHR.-BRACKETED AR.) [twSy] [Al- ljnp Al- sAdsp] [Al- jmEyp Al- EAmp] [b- AEtmAd m$rwE Al- mqrr Al- tAly] [:] (AN ENG. GLOSS) [recommends] [the committee the sixth] [the assembly the general] [to adoption draft the decision the following] [:] (ENG. MT OUTPUT) [the sixth committee] [recommends] [the general assembly] [in the adoption of the following draft resolution] [:] (REFERENCE TRANS.) the sixth committee recommends to the general assembly the adoption of the following draft decision : Table 1: An Arabic translation from the test set. We revisit portions of this example throughout the text. All Arabic strings in this paper are rendered in the reversible Buckwalter transliteration. In addition, all words or symbols referring to Arabic and French in this paper are italicized. figuresand tables are from the actual Arabic and French trained systems. Arabic Phrase Aligned English Prob. Sequence Phrase Sequence VP1 NP2 NP3 NP2 VP1 NP3 0.23 VP1 NP2 NP3 VP1 NP2 PP3 0.10 VP1 NP2 NP3 NP3 VP1;2 0.06 Table 3: Top learned sentence-level reorderings for Arabic, for canonical Arabic simple sentence structure VP (verb) NP (subject) NP (object). Subscripts in English phrase sequence are alignments to positions in the corresponding Arabic phrase sequence. 4.2 Phrase Translation Given an Arabic test sentence, a distribution of aligned English phrase sequences is proposed by the sentence-level model described in the previous section and in Table 2. Each proposed English phrase in each of the phrase sequence possibilities, therefore, comes to the middle level of the translation model with access to the identity of the French phrases aligned to it. Phrase translation is implemented as shown in Table 4. The phrase translation model is structured with several levels of backoff: if no observations exist from training data for a particular level, the model backs off to the next-more-general level. In all cases, generation of an English phrase is conditioned on the foreign phrase as well as the type (NP, VP, etc.) of the English phrase.","Table 4 (1) describes the initial phrase translation model. It comes into play if the precise sequence of foreign words has been observed aligning to an English phrase of the appropriate type. In the example, we are trying to generate an NP given the Arabic word string “ Al- ljnp Al- sAdsp” (literally: “the committee the sixth”). If this has been observed in data, then that relative frequency distribution serves as the translation probability distribution. Table 11 contains examples of some of these literal phrase translations from the French data.","The next stage of backoff from the above, literal level is a model that generates aligned English POS tag sequences given foreign POS tag sequences: details and an example can be found in Table 4(2). The sequence alignments determine the position in English phrase and the part-of-speech into which we translate the foreign word. Again, translation is also conditioned on the English phrase type. Table 5 and Table 6 show the most probable aligned English sequence generations for two of the phrases in the example sentence.","If there were no counts for (foreign-POS-sequence, english-phrase-type) then we back off to counts collected over (foreign-coarse-POS-sequence, english-phrase-type), where a coarse POS is, for example, N in-stead of NOUN-SG. This is shown in Table 4(3).","In case further backoff is needed, as shown in Table 4(4), we begin stripping POS-tags off the “less significant” (non-head) end of the foreign POS-sequence until we are left with a phrase sequence that has been seen in training, and from this a corresponding English phrase distribution is observable. We define the “less significant” end of a phrase to be the end if it is head-initial, or the beginning if it is head-final, and at this point ignore issues such as nested structure in French and Arabic NP’s.","Aligned English POS-tag Sequence Translation Probabilities","(conditioned on Arabic POS-tag sequence from NP in example) P ( DT; JJ4 NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.22 P ( JJ4 NN1 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.20 P ( DT; NN1 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13 P ( DT; VBN4 NNS2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.13 P ( DT1 NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.04 P ( DT3 JJ4 NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03 P ( DT1 VBN4 NNS2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.03 P ( DT; NN4 NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02 P ( JJ4 NNS2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02 P ( DT1 JJ4 NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02 P ( NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02 P ( NN4 NN2 j DET1 NOUN-SG2 DET3 ADJ4 , NP) = 0.02 Table 5: From the running Arabic example, top English NP generations given an Arabic phrase DET NOUN-SG DET ADJ. Note: ; denotes a null alignment (generation from null). Generation from a null alignment is allowed for specified parts of speech, such as determiners and prepositions. 4.3 Lexical Transfer 4.3.1 The Basic Model In the basic model of word generation, phrases may be translated directly as single atomic entities (as in Table 4(1)), or via phrasal decomposition to individual words translated independently, conditioned only on the source word and target POS. Word translation in the latter case","Top-level Definitionof Translation Model Example Instantiation of Model Variables Model Description","P ( the sixth committee recommends the general assembly .. j P ( english words j foreign words ) = twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. ) = P ( [twSy]V P","1 [Al- ljnp Al- sAdsp]NP","1 [Al- jmEyp Al- EAmp]NP","2 .. j (1) P ( foreign bracketing , foreign phrase sequence j foreign words ) twSy Al- ljnp Al- sAdsp Al- jmEyp Al- EAmp .. ) P ( NP2 VP1 NP3 PPNP4 PUNC5 j (2) P ( english phrase sequence , phrase alignment matrix j VP1 NP2 NP3 PPNP4 PUNC5 ) foreign phrase sequence ) P ( [the sixth committee]NP","2 [recommends]V P","1 (3) P ( english words , english bracketing , english phrase sequence j [the general assembly]NP","3 .. j foreign words , foreign bracketing , foreign phrase sequence , [twSy]V P","1 [Al- ljnp Al- sAdsp]NP","1 [Al- jmEyp Al- EAmp]NP","2 .. , english phrase sequence , phrase alignment matrix ) NP2 VP1 NP3 PPNP4 PUNC5 ) Table 2: Statement of the translation model at top level.",".","Phrase Translation Model with Backoff Pathways","Example Instantiations Model Statement","P( the sixth committee j Al- ljnp Al- sAdsp , NP ) =","P( the sixth committee j Al- ljnp Al- sAdsp , NP ) (1) P( W","E","1 W","E","2 .. W","E n j W F","1 W","F","2 .. W","F","m , phr type","E )","# # (backoff if C( W","F","1 W","F","2 .. W F m , phr type","E) = 0)","P( DT","1 JJ","4 NN","2 j DET","1 NOUN-SG","2 DET","3 ADJ","4 , NP ) (2) P( T","fine","E","1 T","fine","E","2 .. T fine","E","n ,","i j T","fine","F","1 T","fine","F","2 .. T","fine","F","m , phr","type","E )",". P( the j Al- , DT ) . P( W","E","1 j W","F","","i(1) , T fine E","1 )",". P( committee j ljnp , NN ) . P( W E 2 j W","F"," i(2) , T","fine","E","2 )",". P( sixth j sAdsp , JJ ) . :: P( W","E","n j W F ","i(n) , T fine E","n )","# # (backoff if C( T","fine","F","1 T","fine F 2 .. T","fine","F","m , phr type","E) = 0)","P( DT","1 JJ","4 NN","2 j D","1 N","2 D","3 A","4 , NP ) (3) P( T","fine","E","1 T","fine","E","2 .. T","fine E n ,","i j T","coarse","F","1 T","coarse","F","2 .. T","coarse","F","m , phr","type","E )",". P( the j Al- , DT ) . P( W E","1 j W","F","","i(1) , T fine E","1 )",". P( committee j ljnp , NN ) . P( W E 2 j W","F"," i(2) , T","fine","E","2 )",". P( sixth j sAdsp , JJ ) . :: P( W","E","n j W F ","i(n) , T fine E","n )","# # (backoff if C( T","coarse","F","1 T","coarse F 2 .. T","coarse","F","m , phr","type","E ) = 0)","P( ? j D","1 N","2 D","3 , NP ) (4) P( T","fine","E","1 T","fine","E","2 .. T","fine E n ,","i j T","coarse","F","1 T","coarse","F","2 .. T","coarse","F","m 1 , phr","type","E )",". * ? * .. * ? . * ? * .. * ?","# # (backoff if C( T","coarse","F","1 T","coarse F 2 .. T","coarse","F","m 1 , phr","type","E) = 0)","P( ? j D","1 N","2 , NP ) (4) P( T","fine","E","1 T","fine","E","2 .. T","fine E n ,","i j T","coarse","F","1 T","coarse","F","2 .. T","coarse","F","m 2 , phr","type","E )",". * ? * .. * ? . * ? * .. * ?","# # (backoff if C( T","coarse","F","1 T","coarse","F","2 .. T","coarse","F","m 2 , phr type","E) = 0)",".... .... Table 4: The phrase translation model, with backoff. Examples on the left side are from one of the Arabic test sentences. (1) is the direct, lexical translation level. (2) - (4) constitute the backoff path to handle detailed phenomena unseen in the training set. (2) is a model of finePOS-tag reordering and lexical generation; (3) is similar, but conditions generation on coarse POS-tag sequences in the foreign language. (4) is a model for progressively stripping off POS-tags from the “less significant” end of a foreign sequence. The idea is to do this until we reach a subsequence that has been seen in training data, and which we therefore have a distribution of valid generatons for. The term i in (2) - (4) is a position alignment matrix. At all times, we generate not just an English POS-tag sequence, but rather an aligned sequence. Similarly, in the lexical transfer probabilities shown in this table, there is a function i() which takes an English sequence position index and returns the (unique) foreign word position to which it is aligned4",". Aligned English POS-tag Sequence Translation Probabilities (conditioned on Arabic POS-tag sequence from VP in example) P ( VBZ1 j VERB-IMP1 , VP ) = .28 P ( VBP1 j VERB-IMP1 , VP ) = .17 P ( VBD1 j VERB-IMP1 , VP ) = .09 ... P ( MD; VB1 j VERB-IMP1 , VP ) = .06 Table 6: From the Arabic example, top English VP generations given an Arabic phrase VERB-IMP. is done in the context that the model has already proposed a sequence of POS tags for the phrase. Thus we know the English POS of the word we are trying to generate in addition to the foreign word that is generating it. Consequently, we condition translation on English POS as well as the foreign word. Table 7 describes the backoff path for basic lexical transfer and presents a motivating example in the French word droit. Translation probabilities for one of the words in the example Arabic sentence can be found in Table 8. 4.3.2 Generation via a Lemma Model To counter sparse data problems in estimating word translation probabilities, we also implemented a lemma-","Word Generation","Examples Model with Backoff Pathways","P (WEj droit , NNS) P (WEjWF , Tfine","E ) rights 0.4389 p(rights j droit , NNS) benefits 0.0690 people 0.0533 laws 0.0188","# (backoff if C(WF , Tfine","E ) = 0)","P (WEj droit , N) P (WEjWF ; Tcoarse","E ) right 0.4970 law 0.1318 rights 0.0424 p(rights j droit , N)","property 0.0115","# (backoff if C(WF ; Tcoarse","E ) = 0)","P (WEj droit) P (WEjWF ) right 0.2919","entitled 0.0663 law 0.0652 the 0.0249 to 0.0240","rights 0.0210 p( rights j droit )","# (backoff if C(WF ) = 0)","p( UNKNOWN WORD jWF ) = 1 Table 7: Description of the conditioning for different levels of backoff in the lexical transfer model. The example shows translations for the French word droit (“right”) conditioned on decreasingly specific values. The progressively lower ranking of the correct translation as we move from fine,to coarse, to no POS, illustrates the benefit of conditioning generation on the English part of speech.","Arabic Word English POS English Wd. Prob. ljnp NN committee 0.591 ljnp NN commission 0.233 ljnp NN subcommittee 0.035 ljnp NN acc 0.013 ljnp NN report 0.005 ljnp NN ece 0.004 ljnp NN icrc 0.004 ljnp NN aalcc 0.004 ljnp NN escap 0.004 ljnp NN escwa 0.004 ljnp NN eca 0.003 ljnp NNS members 0.088 ljnp NNS recommendations 0.033 ljnp NNS copuos 0.033 ljnp NNS questions 0.027 ljnp NNS representatives 0.024 ljnp N committee 0.577 ljnp N commission 0.227 ljnp N subcommittee 0.035 Table 8: From running example, translation probabilities for Arabic noun ljnp, “committee”. based model for word translation. Under this model, translation distributions are estimated by counting word alignment links between foreign and English lemmas, as-suming a lemmatization of both sides of the parallel corpus as input. The form of the model is illustrated below:","P ( WE j WF ,Tcoarse","F ,Tfine","E ) =","P ( WE j lemmaE , Tcoarse","F , Tfine","E )","P ( lemmaE j lemmaF , Tcoarse","F , Tfine","E )","P ( lemmaF j WF , Tcoarse","F , Tfine","E )","+ approximated by","P ( WE j lemmaE , Tfine","E )","P ( lemmaE j lemmaF , Tcoarse","E )","P ( lemmaF j WF , Tcoarse","F )","First, note that P ( lemmaF j WF , TcoarseF ) is very","simply a hard lemma assignment by the foreign lan-","guage lemmatizer. Second, English word generation","from English lemma and coarse POS (P ( WE j lemmaE",", TfineE )) is programmatic, and can be handled by","means of rules in conjunction with a lookup table for","irregular forms. The only distribution here that must be","estimated from data is P ( lemmaE j lemmaF , TcoarseE","). This is done as described above. Furthermore, given","an electronic translation dictionary, even this distribution","can be pre-loaded: indeed, we expect this to be an","advantage of the lemma model, and an example of","a good opportunity for integrating compiled human","knowledge about language into an SMT system. Some","examples of the lemma model combating sparse data","problems inherent in the basic word-to-word models can","be found in Table 9. 4.3.3 Coercion Lexical coercion is a phenomenon that sometimes occurs when we condition translation of a foreign word on the word and the English part-of-speech. We find that the system we have described frequently learns this behavior: specifically, the model learns in some cases how to generate, for instance, a nominal form with similar meaning from a French adjective, or an adjectival realization of a French verb’s meaning; some examples of this phenomenon are shown in Table 10. We find this coercion effect to be of interest because it identifies interesting associations of meaning. For example, in Table 10 “willing” and “ready” are both sensible ways to realize the meaning of the action “to accept” in a passive, descriptive mode. droit behaves similarly. Though the English verb “to right’ or “to be righted” does not have the philosophical/judicial entitlement sense of the noun “right”, we see that the model has learned to realize the meaning in an active, verbal form: e.g., VBG ‘receiving” and VB “qualify”."]},{"title":"5 Decoding","paragraphs":["Decoding was implemented by constructing finite-state machines (FSMs) per evaluation sentence to encode relevant portions (for the individual sentence in ques-tion) of the component translation distributions described above. Operations on these FSMs are performed using the AT&T FSM Toolkit (Mohri et al., 1997). The FSM constructed for a test sentence is subsequently composed with a FSM trigram language model created via the SRI Language Modeling Toolkit (Stolcke, 2002). Thus we use the trigram language model to implement rescoring of the (direct) translation probabilities for the English word sequences in the translation model lattice.","We found that using the finite-stateframework and the general-purpose AT&T toolkit greatly facilitates decoder development by freeing the implementation from details of machine composition and best-path searching, etc.","The structure of the translation model finite-statemachines is as illustrated in Figure 1. The sentence-level (aligned phrase sequence generation) and phrase-level (aligned intra-phrase sequence generation) translation probabilities are encoded on epsilon arcs in the machines. Word translation probabilities are placed onto arcs emitting the word as an output symbol (in the figure, note the arcs emitting “committee”, “the”, etc.). The FSM in Figure 1 corresponds to the Arabic example sentence used throughout this paper. In the portion of the machine shown, the (best) path which generated the example sentence is drawn in bold. Finally, Figure 2 is a rendering of the actual FSM (aggressively pruned for display purposes) that generated the example Arabic sentence; although labels and details are not visible, it may provide a visual aid for better understanding the structure of the FSM lattices generated here.","As a practical matter in decoding, during translation model FSM construction we modifiedarc costs for output words in the following way: a fixed bonus was as-signed for generating a “content” word translating to a “content” word. Determining what qualifies as a content word was done on the basis of a list of content POS tags for each language. For example, all types of nouns, verbs and adjectives were listed as content tags; determiners, prepositions, and most other closed-class parts of speech were not. This implements a reasonable penalty on undesirable output sentence lengths. Without such a penalty, translation outputs tend to be very short: long sentence hypotheses are penalized de facto merely by containing many word translation probabilities. An additional trick in decoding is to use only the N-best translation options for sentence-level, phrase-level, and word-level translation. We found empirically (and very consistently) in dev-test experiments that restricting the syntactic transductions to a 30-best list and word translations to a 15-best list had no negative impact on Bleu score. The benefit,of course, is that the translation lattices are dramatically reduced in size, speeding up composition and search operations."]},{"title":"... ...","paragraphs":["etc ...... next phrase,"]},{"title":"......","paragraphs":["S P(the | NULL)","P(an | NULL) P(committee | ljnp) P(commission | ljnp) NULL","P( DT NN | NOUN−SG )","1 1","1P(NP VP NP .. |VP NP NP .. ) 3","2 \"commission\" \"committee\" \"the\" \"an\" 1","2 3 Figure 1: An illustration of the translation model structure for an Arabic test sentence.","319","321","W__:the/-0","0 1","S__:<s>/5.411 2","S__:<s>/5.629 3 S__:<s>/5.835 4 S__:<s>/5.868 5 S__:<s>/5.940 6 S__:<s>/6.226 7 S__:<s>/6.381 8 S__:<s>/6.385 9 S__:<s>/6.396 10 S__:<s>/6.52911 S__:<s>/6.54612 S__:<s>/6.620 13 S__:<s>/6.65714 S__:<s>/6.698 15 S__:<s>/6.711 16 S__:<s>/6.717 17 S__:<s>/6.748 18 S__:<s>/6.825 19 S__:<s>/6.875","20","S__:<s>/6.942 21","S__:<s>/6.946","116","137","W__:committee/-0 224 247 P__ADJP:<epsilon>/-0 412 439 T__-:<epsilon>/0.129","702 714 W__:of/1.969 W__:in/2.215 22 P__NP:<epsilon>/-0 117 138 G__:<epsilon>/-0 225 248 G__:<epsilon>/-0 272 273 W__:general/-0 413 440 T__recommends:<epsilon>/0.227 474 501 W__:the/1.188 W__:a/1.736 W__:this/2.266 703 715 W__:on/2.917 W__:of/1.969 W__:against/4.731 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:after/4.880 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:between/4.602 W__:like/4.665 W__:during/4.572 W__:whether/4.697 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 W__:within/4.766 521 555 W__:of/1.969 558 590 W__:the/0.132 631 630 W__:rapporteur/0.699 W__:decision/1.000 23 P__NP:<epsilon>/-0 118 139 G__:<epsilon>/-0 226 227 W__:committee/-0 322","W__:assembly/-0","414","441 T__recommends:<epsilon>/0.227 522 556 W__:of/1.969 W__:in/2.215 525 559 P__O:<epsilon>/-0","24","P__NP:<epsilon>/-0 119 140 P__O:<epsilon>/-0 249 G__:<epsilon>/-0 415","442 T__2:<epsilon>/0.631 443 T__2#xslax/NULL:<epsilon>/1.194 632 647 P__NP:<epsilon>/-0 367 G__:<epsilon>/-0 523 557 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 592 T__::<epsilon>/0.028 704 716 W__:of/1.969 W__:in/2.215 W__:that/2.614 W__:for/2.660 25 P__O:<epsilon>/-0 228 229 W__:sixth/-0 416 444 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545","445 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 446 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895 475 502 G__:<epsilon>/-0 633 648 P__VP:<epsilon>/-0","120 141","P__NP:<epsilon>/-0 560 561 W__:the/-0 705 717 P__O:<epsilon>/-0 26 P__NP:<epsilon>/-0 417","447 T__-:<epsilon>/0.129","476 503","P__NP:<epsilon>/-0 634 635 W__:draft/0.404 W__:project/1.841 121 142 G__:<epsilon>/-0 230","251 P__VP:<epsilon>/-0 323 325 W__:by/-0 27 P__NP:<epsilon>/-0 524 W__:of/1.969 W__:in/2.215 593 W__:sixth/-0 122 143 G__:<epsilon>/-0 324 W__:to/-0 477 504 W__:adoption/0.711 W__:provision/1.929","532","G__:<epsilon>/-60 706 718 W__:police/-0 28 P__ADJP:<epsilon>/-0 231 252 G__:<epsilon>/-0","418","448","W__:-/-0 526","T__the/NULL#sixth#committee:<epsilon>/0.454","T__the#sixth#committee:<epsilon>/1.871","T__sixth#committee:<epsilon>/1.871562 534 W__:by/-0 123 144 P__O:<epsilon>/-0 29","P__NP:<epsilon>/-0 232 253 W__:adoption/0.711 W__:provision/1.929 527 T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085 563 T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254 W__:to/-0 636 649 P__ADJP:<epsilon>/-0 327 W__:the/-0 419 W__:2/-0","30","P__NP:<epsilon>/-0 124","145","P__O:<epsilon>/-0 528 565 T__-:<epsilon>/0.129","573 W__:-/-0 637 650 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536 W__:in/1.425 W__:that/4.161W__:with/1.853 W__:for/3.134 W__:as/2.616 326 328 W__:the/-0 420 449 W__:2/-0 707 696 W__:in/-0 31 P__NP:<epsilon>/-0 32 P__VP:<epsilon>/-0 33 P__SBAR:<epsilon>/-0 529 566 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:from/3.270 W__:as/3.201W__:about/3.426 594 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:this/2.266 638 651 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536 W__:in/1.425 W__:that/4.161W__:with/1.853 W__:for/3.134 W__:as/2.616 125 146 G__:<epsilon>/-0 421 450 W__:on/2.046W__:of/2.238 W__:by/1.908 W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 34 P__NP:<epsilon>/-0 329 T__the/NULL#general#assembly:<epsilon>/0.938 369 T__had#decided:<epsilon>/2.442 370 T__will#consider:<epsilon>/2.442 639 652 W__:in/1.425 708 719 W__:world/-0 104 126 G__:<epsilon>/-0","422","451","W__:on/2.046","W__:of/2.238W__:by/1.908","W__:at/3.536","W__:in/1.425","W__:with/1.853","W__:for/3.134","W__:as/2.616 530 567 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660W__:from/3.270 W__:as/3.201 35 P__NP:<epsilon>/-0 330 W__:decided/-0 478 505 W__:adoption/0.711 W__:provision/1.929 640 653 W__:on/2.046 W__:by/1.908 W__:in/1.425 W__:with/1.853 709 720 P__VP:<epsilon>/-0 423 452 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 36 P__NP:<epsilon>/-0 233 254 W__:adoption/0.711 W__:provision/1.929 331 W__:consider/-0 531 568 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 641 654 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536 W__:in/1.425W__:that/4.161 W__:with/1.853 W__:for/3.134 W__:as/2.616 710 721 P__O:<epsilon>/-0 147 P__VP:<epsilon>/-0 148 P__PPNP:<epsilon>/-0 424 453 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536 W__:in/1.425 W__:with/1.853W__:for/3.134 W__:as/2.616 37 P__O:<epsilon>/-0 332 307 W__:to/-0 533 570 T__accountable:<epsilon>/0.693 571 T__present/NULL:<epsilon>/0.693 642 655 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 127 P__PPNP:<epsilon>/-0 149 P__NP:<epsilon>/-0 425 454 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536 W__:in/1.425 W__:with/1.853W__:for/3.134 W__:as/2.616 38 P__O:<epsilon>/-0 333 371 W__:with/-0 537 W__:the/-0 711 722W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:every/4.241 W__:another/4.082 128 P__VP:<epsilon>/-0 426 455 W__:in/1.425 39 P__O:<epsilon>/-0","535","538 W__:the/-0 595 W__:following/0.227 129 150 P__O:<epsilon>/-0 334 372 W__:next/1.854 W__:following/0.227 427 456 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 643 656 T__to/NULL#2/NULL:<epsilon>/1.299 T__to/NULL#2:<epsilon>/2.397 657 T__with/NULL#article/NULL#2:<epsilon>/2.397 658 T__under/NULL#review/NULL:<epsilon>/3.091 659 T__by/NULL#2#police/NULL#officers/NULL:<epsilon>/3.091 660 T__in/NULL#only/NULL#2:<epsilon>/3.091 661 T__in/NULL#order/NULL:<epsilon>/3.091 662 T__for/NULL#just/NULL#2:<epsilon>/3.091 663 T__on/NULL#2:<epsilon>/3.091 664 T__at/NULL#2:<epsilon>/3.091 665 T__with/NULL#regard/NULL:<epsilon>/3.091 666 T__for/NULL#2:<epsilon>/3.091 667 T__to/NULL#2.7/NULL#in/NULL:<epsilon>/3.091 668 T__in/NULL#document:<epsilon>/3.091 669 T__into/NULL#the/NULL#world/NULL#economy/NULL:<epsilon>/3.091 40 P__NP:<epsilon>/-0 479 506 W__:adoption/0.711 W__:provision/1.929 428 457 W__:in/1.425 536 572 W__:the/-0","41","P__PPNP:<epsilon>/-0 130 151 P__NP:<epsilon>/-0 234 255 W__:adoption/0.711 W__:provision/1.929 429 458 W__:the/1.188 W__:that/2.597W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 42 P__VP:<epsilon>/-0 131 152 G__:<epsilon>/-0 539 574 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201W__:an/2.837 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 644 670 T__-:<epsilon>/0.129","43 P__NP:<epsilon>/-0 132 153 P__PPNP:<epsilon>/-0 645 646 W__:the/-0","44","P__NP:<epsilon>/-0 133","154","P__VP:<epsilon>/-0","480","508","W__:adoption/0.711","W__:provision/1.929","W__:appropriation/3.108","W__:accreditation/3.18235","257","P__NP:<epsilon>/-0 335 373 W__:rapporteur/0.699 W__:decision/1.000 W__:the/0.132 45 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 46 T__sixth#committee:<epsilon>/1.871 134 155 P__NP:<epsilon>/-0 671 W__:sixth/-0 236 258 P__NP:<epsilon>/-0 47 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 48 T__sixth#committee:<epsilon>/1.871","135 156","G__:<epsilon>/-0 430 459 W__:the/1.188 W__:that/2.597 W__:a/1.736W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 336","374 W__:2/-0 49 T__2:<epsilon>/0.631 50 T__2#xslax/NULL:<epsilon>/1.194 136 157 G__:<epsilon>/-0 237 259 G__:<epsilon>/-0","337 375","W__:2/-0 51 T__-:<epsilon>/0.129 T__-/NULL:<epsilon>/2.988 158 G__:<epsilon>/-0 238 260G__:<epsilon>/-0 569 P__O:<epsilon>/-0 287 338 W__:sixth/-0 672 T__2:<epsilon>/0.631 673 T__2#xslax/NULL:<epsilon>/1.194 52 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 53 T__sixth#committee:<epsilon>/1.871 159 P__VP:<epsilon>/-0 239 261 G__:<epsilon>/-0 596 T__::<epsilon>/0.028 376 W__:committee/-0","674 T__recommends:<epsilon>/0.227 54 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 55 T__sixth#committee:<epsilon>/1.871","160","P__VP:<epsilon>/-0","240","262","P__PPNP:<epsilon>/-0 481 509 W__:adoption/0.711 W__:provision/1.929 W__:appropriation/3.108 W__:accreditation/3.18 W__:accountable/-0 431 460 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:some/3.097 W__:this/2.266 W__:these/3.201 540 575 W__:next/1.854 W__:following/0.227 56 T__asean/NULL:<epsilon>/1.098 57 T__imf-2:<epsilon>/1.098 58 T__concerned/NULL#with/NULL:<epsilon>/1.098","161","T__-:<epsilon>/0.129 241 263 P__NP:<epsilon>/-0 339 377 W__:committee/-0","W__:present/-0 59 T__2:<epsilon>/0.631 60 T__2#xslax/NULL:<epsilon>/1.194 162 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871","163 T__sixth#committee:<epsilon>/1.871 242 264 T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085 T__by/NULL#the#general#assembly:<epsilon>/2.725 265 T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254 T__to/NULL#the#general#assembly:<epsilon>/2.748 266 T__with/NULL#general#assembly#decision/NULL:<epsilon>/3.313 340 342 W__:the/-0 W__:general/-0 675 T__asean/NULL:<epsilon>/1.098 676 T__imf-2:<epsilon>/1.098 677 T__concerned/NULL#with/NULL:<epsilon>/1.098 61 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 62 T__sixth#committee:<epsilon>/1.871","164","P__VP:<epsilon>/-0 243 267 P__VP:<epsilon>/-0 341 343 W__:the/-0 W__:assembly/-0 678 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:every/4.241 W__:another/4.082 63 T__728#xslax/NULL:<epsilon>/1.421 64 T__the/NULL#committee:<epsilon>/1.981 65 T__the/NULL#advisory#committee:<epsilon>/2.268 66 T__729#xslax/NULL:<epsilon>/2.674 165 P__VP:<epsilon>/-0 244 268 P__NP:<epsilon>/-0 564 W__:wish/-0 344 346 W__:the/-0 67 T__recommends:<epsilon>/0.227","166","T__-:<epsilon>/0.129 245 269 P__NP:<epsilon>/-0 432 461 W__:the/1.188 345 347 W__:the/-0","597","G__:<epsilon>/-0 712 723 W__:next/1.854 W__:following/0.227","68","T__that:<epsilon>/-0","167","T__-:<epsilon>/0.129 246 270 T__the/NULL#general#assembly:<epsilon>/0.530 T__the#general#assembly:<epsilon>/2.122 271 T__the/NULL#assembly:<epsilon>/1.941 433 462 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536 W__:in/1.425 W__:that/4.161 W__:with/1.853 W__:for/3.134W__:as/2.616 482 510 W__:adoption/0.711 348 368 W__:accountable/-0 598 W__:next/1.854 W__:following/0.227 69 T__2:<epsilon>/0.631 70 T__2#xslax/NULL:<epsilon>/1.194 168 P__VP:<epsilon>/-0 274 T__accountable:<epsilon>/0.693 275 T__present/NULL:<epsilon>/0.693 434 463 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:under/3.942 W__:at/3.536W__:in/1.425 W__:that/4.161 W__:with/1.853 W__:for/3.134 W__:as/2.616 483 511 W__:adoption/0.711 W__:provision/1.929 349 W__:present/-0 72 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 73 T__sixth#committee:<epsilon>/1.871 169","T__the/NULL#sixth#committee:<epsilon>/0.154 170 T__will#establish:<epsilon>/1.945","276","P__PPNP:<epsilon>/-0 435 464 W__:in/1.425 350 380 W__:2/-0 541 W__:the/0.132 679W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:every/4.241 W__:another/4.082 74 T__the/NULL#general#assembly:<epsilon>/0.530 T__the#general#assembly:<epsilon>/2.122 75 T__the/NULL#assembly:<epsilon>/1.941 171 T__by/NULL#the/NULL#sixth#committee:<epsilon>/0.490 T__by/NULL#the/NULL#sixth/NULL#committee:<epsilon>/1.589 436 465 W__:in/1.425 277 P__NP:<epsilon>/-0 351 W__:article/-0 78 T__-:<epsilon>/0.129 172 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 173 T__sixth#committee:<epsilon>/1.871 437 466 W__:on/2.046 W__:of/2.238 W__:by/1.908W__:under/3.942 W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 250 W__:committee/-0 352 W__:review/-0 71 T__-:<epsilon>/0.129 438 467 W__:in/1.425 W__:with/1.853 278 G__:<epsilon>/-0 353 381 W__:2/-0 79 T__-:<epsilon>/0.129 174 T__-:<epsilon>/0.129 468 W__:-/-0 599 W__:rapporteur/0.699 W__:decision/1.000 T__the/NULL#general#assembly:<epsilon>/0.938 279 T__had#decided:<epsilon>/2.442 280 T__will#consider:<epsilon>/2.442 354 W__:only/-0 80 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 81 T__sixth#committee:<epsilon>/1.871 175 T__2:<epsilon>/0.631 176 T__2#xslax/NULL:<epsilon>/1.194 W__:recommends/-0 484 512 W__:adoption/0.711 281 P__PPNP:<epsilon>/-0 355 W__:order/-0 82 T__to/NULL#2/NULL:<epsilon>/1.299 177 P__VP:<epsilon>/-0 469 W__:recommends/-0 485 514W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 576 600 W__::/-0 680 W__:the/1.188 282 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:than/4.147 W__:per/3.988 356 W__:just/-0 507 542 P__O:<epsilon>/-0 83 T__add:<epsilon>/1.704 84 T__take/NULL:<epsilon>/2.397 178 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545 179 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 180 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895","470 W__:2/-0 577 601 W__:next/1.854 W__:following/0.227 681 W__:the/1.188 W__:a/1.736 T__::<epsilon>/0.028 85 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 86 T__sixth#committee:<epsilon>/1.871","181","T__add:<epsilon>/1.704","182","T__take/NULL:<epsilon>/2.397 283W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:from/3.270 W__:as/3.201 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:per/3.988 471 W__:2/-0 357 W__:regard/-0 486 515W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:into/3.971 W__:about/3.426W__:if/3.704 W__:than/4.147 W__:per/3.988 543 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 87 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871","88 T__sixth#committee:<epsilon>/1.871 183 T__2:<epsilon>/0.631 184 T__2#xslax/NULL:<epsilon>/1.194 472 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 W__:as/2.616 284 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614W__:with/3.075 W__:for/2.660 W__:from/3.270 W__:as/3.201 W__:about/3.426 W__:if/3.704 682 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097W__:this/2.266 W__:these/3.201 W__:another/4.082 W__:the/-0 185 P__VP:<epsilon>/-0 358 382 W__:2.7/-0 473 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 W__:as/2.616 487 516 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:into/3.971W__:about/3.426 W__:if/3.704 W__:than/4.147 W__:per/3.988 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 186 P__VP:<epsilon>/-0 286 T__the/NULL#sixth#committee:<epsilon>/0.454 359","W__:document/-0 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 89 W__:sixth/-0 488 517 W__:of/1.969 187 P__VP:<epsilon>/-0 288","T__the/NULL#sixth#committee:<epsilon>/0.454","T__the#sixth#committee:<epsilon>/1.871 289 T__sixth#committee:<epsilon>/1.871","360","383","W__:the/-0","W__:-/-0 W__:the/-0 490 519 W__:adoption/0.711 W__:provision/1.929 W__:appropriation/3.108 W__:accreditation/3.18 188 T__recommends:<epsilon>/0.227 189 T__recommended:<epsilon>/2.759 290 P__NP:<epsilon>/-0 361 384 G__:<epsilon>/-0","G__:<epsilon>/-0 578 602 W__:rapporteur/0.699 W__:decision/1.000","713","724","W__:the/1.188 90 W__:sixth/-0 190 T__recommends:<epsilon>/0.227 191 T__recommended:<epsilon>/2.759 192 T__recommend:<epsilon>/3.200 291 P__NP:<epsilon>/-0 362 W__:xslax/-0 W__:xslax/-0 580 604 W__:sponsors/1.131","91","W__:2/-0","193","W__:-/-0 292 P__ADJP:<epsilon>/-0 683 W__:the/1.188 W__:a/1.736","725W__:following/0.227 363 385 W__:assembly/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:any/3.434 W__:some/3.097W__:this/2.266 W__:these/3.201 92 W__:2/-0","W__:the/-0 293 T__to/NULL#2/NULL:<epsilon>/1.299 T__to/NULL#2:<epsilon>/2.397 294 T__with/NULL#article/NULL#2:<epsilon>/2.397","295 T__under/NULL#review/NULL:<epsilon>/3.091 296 T__by/NULL#2#police/NULL#officers/NULL:<epsilon>/3.091 297 T__in/NULL#only/NULL#2:<epsilon>/3.091 298 T__in/NULL#order/NULL:<epsilon>/3.091 299 T__for/NULL#just/NULL#2:<epsilon>/3.091","300 T__on/NULL#2:<epsilon>/3.091","301 T__at/NULL#2:<epsilon>/3.091 302 T__with/NULL#regard/NULL:<epsilon>/3.091","303 T__for/NULL#2:<epsilon>/3.091 304 T__to/NULL#2.7/NULL#in/NULL:<epsilon>/3.091","305 T__in/NULL#document:<epsilon>/3.091 306 T__into/NULL#the/NULL#world/NULL#economy/NULL:<epsilon>/3.091 579 603 W__:following/0.227 364 386 G__:<epsilon>/-0 W__:the/0.132 W__:a/3.066 93 W__:-/-0 T__2:<epsilon>/0.631 308 T__2#xslax/NULL:<epsilon>/1.194 309 T__it/NULL:<epsilon>/3.818 581","605 W__:2/-0 194 W__:sixth/-0 W__:by/-0 582 606 W__:2/-0 W__:to/-0","W__:the/-0","195","T__recommends:<epsilon>/0.227","316","317","W__:general/-0 491 520 W__:adoption/0.711 W__:provision/1.929 W__:appropriation/3.108 W__:accreditation/3.18 W__:to/-0 583 607 W__:rapporteur/0.699 W__:decision/1.000 685 W__:with/-0 196 T__recommends:<epsilon>/0.227 197 T__recommended:<epsilon>/2.759 365 W__:assembly/-0 94 W__:sixth/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:some/3.097 W__:this/2.266 W__:these/3.201 198 W__:-/-0 544 W__:next/1.854 W__:following/0.227 584 608 W__:implications/2.139 W__:sponsors/1.131 W__:projects/2.972 686 W__:under/-0 W__:the/-0 310 W__:with/-0 387G__:<epsilon>/-0 199 W__:-/-0 687 W__:by/-0 311 T__recommends:<epsilon>/0.227 312 T__recommended:<epsilon>/2.759 313 T__recommend:<epsilon>/3.200 320 W__:general/-0 585 586 W__:draft/0.404 95 W__:sixth/-0 200 T__recommends:<epsilon>/0.227 688 W__:in/-0 314 T__the/NULL#general#assembly:<epsilon>/0.530 T__the#general#assembly:<epsilon>/2.122 315 T__the/NULL#assembly:<epsilon>/1.941 366 W__:assembly/-0 587 610 G__:<epsilon>/-0 96 W__:asean/-0 201 W__:the/-0 689 W__:in/-0 318 T__the/NULL#general#assembly:<epsilon>/0.530 T__the#general#assembly:<epsilon>/2.122 T__the/NULL#assembly:<epsilon>/1.941 588 611 W__:next/1.854 W__:following/0.227 W__:imf-2/-0 202 W__:will/-0 388 G__:<epsilon>/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:an/2.837 W__:some/3.097 W__:this/2.266 492 W__:adoption/0.711 690 W__:for/-0","W__:the/-0","97","W__:concerned/-0 203 W__:by/-0","389","P__PPNP:<epsilon>/-0 493 W__:adoption/0.711 W__:on/-0","W__:the/-0 98 W__:2/-0 494 W__:adoption/0.711 W__:provision/1.929 W__:appropriation/3.108 W__:accreditation/3.18 W__:at/-0 W__:the/-099","W__:2/-0","W__:accountable/-0 W__:general/-0 691 W__:with/-0","W__:the/-0 204 W__:sixth/-0 W__:present/-0 W__:assembly/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:for/-0 205 W__:-/-0 T__by/NULL#the/NULL#general#assembly:<epsilon>/1.085 T__by/NULL#the#general#assembly:<epsilon>/2.725 T__to/NULL#the/NULL#general#assembly:<epsilon>/1.254 T__to/NULL#the#general#assembly:<epsilon>/2.748 692 W__:to/-0 100 W__:sixth/-0 390 G__:<epsilon>/-0 589 612 W__:rapporteur/0.699 W__:decision/1.000 W__:2/-0 T__the/NULL#general#assembly:<epsilon>/0.530 T__the#general#assembly:<epsilon>/2.122 T__the/NULL#assembly:<epsilon>/1.941 693 W__:in/-0 101 W__:728/-0 W__:the/0.132 206 W__:2/-0","P__VP:<epsilon>/-0 391 W__:had/-0 545 W__:following/0.227 613 W__:following/0.227 694 W__:into/-0 102 W__:the/-0 207 T__recommends:<epsilon>/0.227 392 W__:will/-0 495 W__:adoption/0.711 546 W__:the/0.132 591 614 W__:sponsors/1.131 684 W__:-/-0 103 W__:the/-0 W__:had/-0 208 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201","496","P__NP:<epsilon>/-0","726T__::<epsilon>/0.028","W__:729/-0 W__:will/-0 695 W__:committee/-0 209 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 497 P__PPNP:<epsilon>/-0 615 W__::/-0 W__:officers/-0 105 W__:recommends/-0 T__to/NULL#2/NULL:<epsilon>/1.299 T__to/NULL#2:<epsilon>/2.397 T__with/NULL#article/NULL#2:<epsilon>/2.397","W__:article/-0 W__:2/-0 210 W__:on/2.046 W__:of/2.238 W__:by/1.908 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 498 P__O:<epsilon>/-0 106 W__:that/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:some/3.097W__:this/2.266 W__:these/3.201","393","W__:rapporteur/0.699","W__:decision/1.000 616 W__:committee/-0 697 W__:2/-0 W__:economy/-0 211 W__:add/-0 107 W__:2/-0 499 W__:adoption/0.711 W__:provision/1.929 W__:recommends/-0 728 T__recommends:<epsilon>/0.227 W__:take/-0 394 W__:implications/2.139 W__:sponsors/1.131 W__:projects/2.972 W__:of/-0 108 W__:2/-0 W__:asean/-0 727 T__-:<epsilon>/0.129 T__-/NULL:<epsilon>/2.988","212 W__:2/-0 W__:the/1.188 W__:the/-0 395 G__:<epsilon>/-0 W__:imf-2/-0 729 W__:next/1.854 W__:following/0.227 213 W__:2/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 500 W__:adoption/0.711 W__:provision/1.929","617","W__:following/0.227 W__:xslax/-0 698 W__:concerned/-0 110 W__:sixth/-0 214 T__recommends:<epsilon>/0.227 396 G__:<epsilon>/-0 699 W__:adoption/0.711 W__:provision/1.929 W__:approval/3.758 W__:appropriation/3.108 W__:accreditation/3.18 W__:dependence/3.758 W__:reliance/3.746 76 W__:the/-0 215 T__recommends:<epsilon>/0.227 W__:adoption/0.711 547 W__:the/0.132 397 G__:<epsilon>/-0 513 548 P__NP:<epsilon>/-0 618 W__:rapporteur/0.699 W__:decision/1.000 77 W__:the/-0 216 T__recommends:<epsilon>/0.227","W__:general/-0","T__2:<epsilon>/0.631","T__2#xslax/NULL:<epsilon>/1.194217","W__:recommends/-0 P__ADJP:<epsilon>/-0 619 W__::/-0 112 W__:-/-0 378 W__:assembly/-0 W__:the/1.188 549 W__:next/1.854 W__:following/0.227 W__:recommended/-0 W__:next/1.854 W__:following/0.227","T__the/NULL#general#assembly:<epsilon>/0.530","T__the#general#assembly:<epsilon>/2.122 T__the/NULL#assembly:<epsilon>/1.941 T__the#assembly:<epsilon>/3.641 T__the/NULL#wish/NULL#of/NULL#the/NULL#general#assembly:<epsilon>/3.421 109 W__:-/-0 W__:adoption/0.711 W__:provision/1.929 W__:appropriation/3.108 W__:accreditation/3.18","218","W__:recommends/-0","398","G__:<epsilon>/-0 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:than/4.147 W__:per/3.988 113 W__:-/-0","620","P__PPNP:<epsilon>/-0 730 W__:rapporteur/0.699 W__:decision/1.000 W__:recommended/-0 W__:general/-0 W__:the/-0 W__:on/2.917 W__:of/1.969W__:by/2.975 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:per/3.988 621 W__:rapporteur/0.699 W__:decision/1.000 W__:recommend/-0 379 W__:assembly/-0 731 W__:following/0.227 700 W__:adoption/0.711 W__:provision/1.929 W__:approval/3.758 W__:appropriation/3.108 W__:accreditation/3.18 W__:dependence/3.758 W__:reliance/3.746 114 W__:sixth/-0 219 G__:<epsilon>/-0 W__:on/2.917 W__:of/1.969 W__:by/2.975W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:from/3.270 W__:as/3.201 W__:about/3.426 W__:if/3.704 622","W__:implications/2.139","W__:sponsors/1.131","W__:projects/2.972 732 W__:sponsors/1.131 399 G__:<epsilon>/-0 W__:to/-0 220 W__:committee/-0 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:between/4.602 W__:during/4.572 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 550 W__:rapporteur/0.699 W__:decision/1.000 623 G__:<epsilon>/-0 W__:add/-0 221 W__:recommends/-0 400 G__:<epsilon>/-0 W__:adoption/0.711 W__:provision/1.929 624 W__:rapporteur/0.699 W__:decision/1.000 733 W__::/-0","W__:take/-0 222 W__:recommends/-0 W__:the/0.132 551 W__:following/0.227 W__:the/-0 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 625 W__:implications/2.139 W__:sponsors/1.131 W__:projects/2.972 W__:recommended/-0 401 W__:police/-0 552 W__::/-0","W__:recommends/-0","115","W__:sixth/-0 223 G__:<epsilon>/-0 553 W__:the/1.188 W__:that/2.597 W__:a/1.736W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:draft/0.404","W__:-/-0 W__:the/-0 G__:<epsilon>/-0 W__:of/1.969 626 W__:of/1.969 701 W__:adoption/0.711 734 W__:rapporteur/0.699 W__:decision/1.000 W__:recommends/-0 W__:in/-0 W__:on/2.917W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:into/3.971 W__:about/3.426 W__:if/3.704 W__:than/4.147 W__:per/3.988 627 G__:<epsilon>/-0 W__:adoption/0.711 W__:sixth/-0 W__:sixth/-0 W__:adoption/0.711 W__:provision/1.929 W__:xslax/-0 735 W__:articles/3.975 W__:implications/2.139 W__:sponsors/1.131 W__:projects/2.972 W__:co-sponsors/3.808","402","W__:world/-0 W__:of/1.969 W__:adoption/0.711 W__:provision/1.929 W__:appropriation/3.108 W__:accreditation/3.18 W__:committee/-0 W__:establish/-0 256 285 P__NP:<epsilon>/-0 W__:draft/0.404 W__:project/1.841 403 P__O:<epsilon>/-0 W__:the/1.188 W__:that/2.597W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:draft/0.404 W__:the/-0 T__2:<epsilon>/0.631 T__2#xslax/NULL:<epsilon>/1.194 W__:committee/-0 489 G__:<epsilon>/-60 736 W__:of/1.969 W__:in/2.215 W__:that/2.614 W__:for/2.660","W__:the/-0","W__:decision/-0 G__:<epsilon>/-0","W__:committee/-0 737 G__:<epsilon>/-0","W__:the/-0 404 P__NP:<epsilon>/-0 W__:xslax/-0 G__:<epsilon>/-0 609 W__:of/1.969 405","P__PPNP:<epsilon>/-0 W__:adoption/0.711 G__:<epsilon>/-0 W__:sixth/-0 W__:rapporteur/0.699 W__:draft/0.404 W__:resolution/3.339 W__:project/1.841 W__:xslax/-0 406 P__PPNP:<epsilon>/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 T__the/NULL#general#assembly:<epsilon>/0.530 T__the#general#assembly:<epsilon>/2.122 T__the/NULL#assembly:<epsilon>/1.941 628 P__NP:<epsilon>/-0","W__:committee/-0 W__:recommends/-0 407 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545","408 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 409T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895 410 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049","W__:adoption/0.711 G__:<epsilon>/-60 T__the/NULL#general#assembly:<epsilon>/0.530 T__the/NULL#assembly:<epsilon>/1.941 629 W__:rapporteur/0.699 W__:decision/1.000 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:some/3.097 W__:this/2.266W__:these/3.201 411 P__PPNP:<epsilon>/-0 W__:committee/-0 T__accountable:<epsilon>/0.693 T__present/NULL:<epsilon>/0.693 W__:decided/-0 W__:implications/2.139 W__:sponsors/1.131 W__:projects/2.972 W__:co-sponsors/3.808 W__:article/-0 G__:<epsilon>/-0 W__:to/-0 W__:consider/-0 W__:review/-0 W__:with/-0 W__:draft/0.404 W__:rapporteur/0.699 W__:decision/1.000 W__:with/-0 554 W__:next/1.854 W__:following/0.227 W__:2/-0 W__:draft/0.404 W__:project/1.841 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:no/3.547W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:of/1.969 W__:in/2.215 G__:<epsilon>/-0 W__:under/-0 W__:only/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201 W__:an/2.837 W__:some/3.097W__:this/2.266 W__:these/3.201 W__:next/1.854 W__:following/0.227 G__:<epsilon>/-0 W__:xslax/-0 W__:by/-0 G__:<epsilon>/-60 W__:order/-0 738/0 <epsilon>:</s>/-0 G__:<epsilon>/-0 W__:in/-0 W__:just/-0 W__:committee/-0 W__:rapporteur/0.699 W__:decision/1.000","W__:in/-0 P__O:<epsilon>/-0 W__:xslax/-0 W__:implications/2.139 W__:sponsors/1.131 W__:for/-0 W__:regard/-0 W__:committee/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:an/2.837 W__:some/3.097 W__:this/2.266 P__VP:<epsilon>/-0 W__:on/-0 W__:the/1.188 G__:<epsilon>/-0 W__:advisory/-0 P__VP:<epsilon>/-0 W__:2.7/-0 W__:at/-0 W__:the/1.188 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545","T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NGEN+IN#NN:<epsilon>/4.443 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049 P__NP:<epsilon>/-0 W__:document/-0 G__:<epsilon>/-0 W__:with/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:those/3.154 W__:all/3.201W__:an/2.837 W__:no/3.547 W__:any/3.434 W__:some/3.097 W__:this/2.266 W__:these/3.201 W__:draft/0.404 W__:project/1.841 P__PPNP:<epsilon>/-0 W__:the/-0 G__:<epsilon>/-0","W__:for/-0 G__:<epsilon>/-0 P__O:<epsilon>/-0 G__:<epsilon>/-60 G__:<epsilon>/-0 G__:<epsilon>/-0","W__:to/-0 W__:officers/-0 W__:the/0.132 G__:<epsilon>/-0 W__:xslax/-0 G__:<epsilon>/-0 W__:in/-0 P__PPNP:<epsilon>/-0 G__:<epsilon>/-0 G__:<epsilon>/-0","W__:xslax/-0 W__:into/-0","W__:economy/-0 W__:draft/0.404 W__:project/1.841 W__:xslax/-0 W__:recommends/-0 W__:2/-0 T__-:<epsilon>/0.129 T__-/NULL:<epsilon>/2.988","W__:the/1.188 W__:the/1.188 W__:committee/-0 W__:recommends/-0 W__:2/-0 W__:following/0.227 G__:<epsilon>/-60 W__:general/-0 T__2:<epsilon>/0.631 T__2#xslax/NULL:<epsilon>/1.194","G__:<epsilon>/-0 W__:recommends/-0 W__:it/-0 W__:with/-0 111 W__:assembly/-0 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895 W__:the/0.132 G__:<epsilon>/-0 G__:<epsilon>/-0 W__:on/2.917 W__:of/1.969 W__:against/4.731 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:after/4.880 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:up/5.208 W__:without/5.054 W__:since/5.054 W__:so/5.103 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:between/4.602 W__:like/4.665 W__:during/4.572 W__:whether/4.697 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 W__:within/4.766 W__:upon/5.054 W__:across/5.208 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049 W__:rapporteur/0.699 G__:<epsilon>/-0 W__:general/-0","G__:<epsilon>/-0 G__:<epsilon>/-0 W__:on/2.046 W__:of/2.238 W__:by/1.908W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 P__O:<epsilon>/-0 G__:<epsilon>/-0 W__:recommends/-0 W__:xslax/-0 W__:on/2.046W__:of/2.238 W__:by/1.908 W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 G__:<epsilon>/-0 W__:recommended/-0 W__:the/1.188 W__:that/2.597 W__:a/1.736 W__:this/2.266 W__:the/0.132 P__PPNP:<epsilon>/-0 W__:on/2.046 W__:of/2.238 W__:by/1.908W__:at/3.536 W__:in/1.425 W__:with/1.853 W__:for/3.134 W__:as/2.616 518","P__O:<epsilon>/-0","W__:recommend/-0 W__:on/2.917 W__:of/1.969 W__:against/4.731 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:after/4.880 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:without/5.054 W__:since/5.054 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:between/4.602 W__:like/4.665 W__:during/4.572 W__:whether/4.697 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 W__:within/4.766 W__:upon/5.054 W__:committee/-0 G__:<epsilon>/-0 W__:in/1.425 T__::<epsilon>/0.028 W__:the/-0 T__the/NULL#sixth#committee:<epsilon>/0.454 T__the#sixth#committee:<epsilon>/1.871 T__sixth#committee:<epsilon>/1.871 G__:<epsilon>/-0 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NN:<epsilon>/3.545 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NN#NNS:<epsilon>/4.133 T__IN#NGEN+DT#NN#NGEN+IN#NGEN+DT#JJ#NN#NGEN+IN#NN:<epsilon>/4.443 T__IN#NGEN+DT#NN#NGEN+IN#JJ#NNS#NGEN+IN#NN:<epsilon>/4.644 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NN:<epsilon>/4.895 T__IN#NGEN+DT#NN#NGEN+IN#DT#JJ#NN#NGEN+IN#NN:<epsilon>/5.049 W__:on/2.917 W__:of/1.969 W__:against/4.731 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:between/4.602 W__:like/4.665 W__:during/4.572 W__:whether/4.697 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 W__:within/4.766 W__:the/-0 W__:draft/0.404 W__:project/1.841 G__:<epsilon>/-0 W__:the/1.188 W__:a/1.736 W__:this/2.266 W__:committee/-0 W__:the/-0 G__:<epsilon>/-60 P__NP:<epsilon>/-0 W__:on/2.917 W__:of/1.969 W__:by/2.975 W__:under/4.248 W__:at/3.201 W__:in/2.215 W__:that/2.614 W__:before/4.435 W__:with/3.075 W__:for/2.660 W__:because/4.073 W__:from/3.270 W__:as/3.201 W__:through/4.435 W__:into/3.971 W__:about/3.426 W__:between/4.602 W__:like/4.665 W__:during/4.572 W__:whether/4.697 W__:if/3.704 W__:than/4.147 W__:over/4.385 W__:per/3.988 W__:out/4.410 W__:of/1.969 W__:in/2.215 Figure 2: A portion of the translation model for an Arabic test sentence, compacted and aggressively pruned by path probability for display purposes."]},{"title":"6 Evaluation","paragraphs":["Results Tables A and B below list evaluation results for translation on the Arabic and French test sets respectively. In each case, results for a comparison system – the Giza++ IBM Model 4 implementation (Och and Ney, 2000) with the ReWrite decoder (Marcu and Germann, 2002) – are included as a benchmark. Results were generated for training corpora of varying sizes. For Arabic, we ran our system on two large subsets of the UN corpus and evaluated on a 200-sentence held-out set (refer to Results Table A below). For the 150K sentence Arabic training set, Giza++ and the shallow syntax model achieved very similar performance. We were unable to obtain evaluation numbers for Giza++/ReWrite on the large Arabic training set, however, since its language model component has a vocabulary size limit which was exceeded in the larger corpus. In French we observed the systems to perform similarly on the small training sets we used (Results Table B). We performed some experiments in classifier combination using the two compatible (150K-training-sentence) Arabic systems, wherein a small devtest set was used to identify simple system combination parameters based on model confidenceand sentence length. In situations where our system was confidentwe used its output, and used Giza++ output other-wise. We achieved a 3% boost in Bleu score over Giza++ performance on the evaluation set with these very simple classifiercombination techniques, and anticipate that research in this direction – classifier combination of diversely trained SMT systems – could yield significant performance improvements.","Bleu Score System 150K 500K","Trn. Sent. Trn. Sent. Giza++/ReWrite Decoder 0.17 * 2-level Syntax Model 0.17 0.18 Results Table A: Results comparison for Arabic to English translation on the UN corpus, with a 200-sentence evaluation set. Note that Giza++/ReWrite cannot be run for the 500K sentence training set; the CMU Language Modeling Toolkit, which ReWrite uses, has a vocabulary size limit which is exceeded in the 500K corpus.","Bleu Score System 5K 20K","Trn. Sent. Trn. Sent. Giza++/ReWrite Decoder 0.08 0.11 2-level Syntax Model 0.08 0.09 Results Table B: Results comparison for French to English translation on the Canadian Hansards corpus (200-sentence evaluation set)."]},{"title":"7 Conclusions","paragraphs":["We have described and implemented an original syntax-based statistical translation model that yields baseline results which compete successfully with other state-of-the-art SMT models. This is particularly encouraging in that the authors are not well-versed in Arabic or French and it appears that the quality of the rule-based phrase chunkers we developed in a single person-day offers substantial room for improvement. We expect to be able to at-tain improved bracketings from native speakers and, in addition, via translingual projection of existing bracketers. Secondly, the lemma model we have proposed for lexical transfer provides an efficient framework for integrating electronic dictionaries into SMT models. Although we have at this time no large electronic dictionaries for either Arabic or French, efforts are underway to acquire electronic or scanned paper dictionaries for this purpose. We did evaluate the lemma models in isola-tion for French and Arabic without dictionary inclusion, but in each experiment the results did not differ significantly from the word-specificlexical transfer models, despite their substantially reduced dimensionality. We anticipate that the relatively seamless direct incorporation of dictionaries into the lemma-based models will be particularly effective for translating low-density languages, which suffer from data sparseness in the face of limited parallel text. Finally, we incorporated lexical translation coercion models into this full SMT framework, the induction of which is a phenomenon of interest in its own right."]},{"title":"8 Acknowledgements","paragraphs":["This work was supported in part by NSF grant number IIS-9985033. In addition, we owe many thanks to colleagues who generously lent their time and insights. David Smith shared his tools for Arabic part-of-speech tagging and morphological analysis and answered many questions about the Arabic language. Thanks to Skankar Kumar and Sanjeev Khudanpur for numerous helpful discussions."]},{"title":"9 References","paragraphs":["H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning dependency translation models as collections of finite state head transducers Computational Linguistics, 26(1), 45–60. S. Bangalore and G. Riccardi. 2000. Stochastic finite-state models for spoken language machine translation. In Proceedings of the Workshop on Embedded Machine Translation Systems., pp. 52–59. P. Brown, S. Della Pietra, V. Della Pietra and R. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 12(2), 263–312. S. Cucerzan and D. Yarowsky. 2002. Bootstrapping a Multilingual Part-of-speech Tagger in One Person-day. Proceedings of the Sixth Conference on Natural Language Learning (CoNLL), Taipei, 2002. B. Dorr and N. Habash. 2002. Interlingua approximation: A generation-heavy approach. In Proceedings of AMTA-2002. W. A. Gale and K. W. Church. 1991. A Program for Aligning Sentences in Bilingual Corpora. In 29th Annual Meeting of the ACL, Berkeley, CA. N. Habash and B. Dorr. 2003. A categorial variation database for English. In Proceedings of NAACL-HLT 2003 D. Jones and R. Havrilla. 1998. Twisted pair grammar: Support for rapid development of machine translation for low density languages. In Proceedings of AMTA98, pp. 318–332. D. Marcu and U. Germann. 2002. The ISI ReWrite Decoder Release 0.7.0b. http://www.isi.edu/licensed-sw/rewrite-decoder/. M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, Vol. 19. M. Mohri, F. Pereira, and M. Riley. 1997. ATT General-purpose finite-state machine software tools. http://www.research.att.com/sw/tools/fsm/. G. Ngai and R. Florian. Transformation-based learning in the fast lane. In Proceedings of North Americal ACL 2001, pages 40-47, June 2001. F. J. Och and H. Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447. F.J. Och, C. Tillmann, H. Ney. Improved Alignment Models for Statistical Machine Translation. In Proceedings of EMNLP 1999, pp. 20-28. K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Technical Report RC22176 (W0109-022), IBM Research Division. A. Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing, pages 901-904. Denver, CO, USA. http://www.speech.sri.com/projects/srilm/. D. Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3), 377–404. K. Yamada and K. Knight. 2001. A syntax-based statistical translation model. In Proceedings of ACL-2001, pp. 523–529. K. Yamada and K. Night. 2002. A decoder for syntax-based statistical MT In Proceedings of ACL-2002, pp. 303–310.","Word Translation Probabilities Word translation for mangeait conditioned on","French Word, EnglishPOS mangeait VBG eating 1.00 mangeait VB go 0.50 mangeait VB anticipate 0.50 mangeait VBD were 1.00 mangeait VBP knelt 1.00 mangeait NN bill 1.00 Word translation for mangeait conditioned on","French Word, English Coarse POS mangeait V eating 0.44 mangeait V were 0.22 mangeait V knelt 0.11 mangeait V go 0.11 mangeait V anticipate 0.11 mangeait N bill 1.00 Word translation for mangeait conditioned on","French Word only mangeait eating 0.29 mangeait were 0.14 mangeait go 0.07 mangeait bill 0.07","Word translation for mangeant conditioned on French Word, EnglishPOS mangeant RB mostly 1.00 mangeant JJ final 1.00 mangeant VBN obtained 1.00 mangeant VBG eating 1.00 mangeant WP who 1.00 mangeant IN through 1.00 mangeant NN lard 1.00 mangeant VBZ eats 0.50 mangeant VBZ comes 0.50","Lemma Translation Probabilities Generation of a verb lemma given manger manger V eat 0.60 manger V feed 0.05 manger V have 0.04 Generation of a noun lemma given manger manger N meal 0.06 manger N trough 0.04 manger N loaf 0.04 manger N food 0.04 Generation of an adj. lemma given manger manger J hungry 0.33","Raw lemma translation probabilities","(ignoring English Coarse POS) manger eat 0.28 manger to 0.03 manger feed 0.03 manger out 0.02 manger have 0.02 manger are 0.02 manger , 0.02 manger you 0.01 manger meal 0.01 Table 9: Direct generation (word-to-word translation probabilities at the various levels of backoff) is contrasted with lemma generation. Manger (“to eat”) is a relatively rare word in the Hansards. Note that due to low counts, the desired verb POS (target of generation) for “eat” may not have been observed as a translation in training data. In addition, in this situation, noisy word alignments may cause an incorrect translation to have similar estimated translation probability. This problem is addressed by the lemma model; note the much sharper probability distribution for verb lemmas given manger. Generation of English inflections given lemma and target POS is algorithmic (and irregular exceptions are handled via a lookup table). French Wd. Eng. POS Eng. Wd. Prob. accepter JJ unacceptable 0.12 accepter JJ acceptable 0.12 accepter JJ willing 0.11 accepter JJ ready 0.03 accepter NN acceptance 0.09 accepter NN amendment 0.03 droit VBN entitled 0.66 droit VBN allowed 0.09 droit VBN denied 0.03 droit VBN given 0.02 droit VBN permitted 0.02 droit VBN justified 0.01 droit VBN qualified 0.01 droit VBN allotted 0.01 droit VB qualify 0.14 droit VB be 0.11 droit VB have 0.09 droit VB receive 0.08 droit VB get 0.07 droit VB expect 0.03 droit VBG receiving 0.11 droit VBG getting 0.08 droit NNS rights 0.44 droit NNS benefits 0.69 Table 10: Examples of word translation coercions. Coercions of the French verb accepter “to accept” and the French noun droit “right” (there is parallel polysemy between the two languages for this word, but the predominant sense in our corpus is the philosophical/judicial sense, as opposed to the direction). Eng. Phrase French Eng. Prob. Type Phrase Phrase NP dans le cas présent a situation 0.25 NP dans le cas présent the subject of debate 0.25 NP dans le cas présent the position 0.25 NP dans le cas présent it 0.25 VP dans le cas présent should apply 1.00 ADVP dans le cas présent really 1.00 PPNP dans le cas présent in this case 0.63 PPNP dans le cas présent in this instance 0.04 PPNP dans le cas présent in this actual case 0.04 PPNP dans le cas présent in this particular case 0.04 PPNP dans le cas présent in that case 0.04 PPNP dans le cas présent in the present circumstances 0.04 VP acceptons accept 0.48 VP acceptons agree 0.14 NP acceptons this consent 1.00 PPNP par an per year 0.67 PPNP par an in each year 0.03 PPNP par an for a year 0.03 ADVP par an annually 1.00 NP par an a year 0.79 NP par an each year 0.02 NP un discours a speech 0.83 NP un discours an address 0.05 VP un discours to speak 1.00 Table 11: Examples of direct phrase translations (see Table 4(1)), including some coercions."]}]}