{"sections":[{"title":"","paragraphs":["the goal of ~..~,11. The interface between the conceptual and semantic levels is made through Lexical data Bases (noted as LBs). A concept CO is associated with a LB as illustrated below with LB (qloA~C!2Z2,9.","LB ('~t,l~cr~zrl)={ ~ (agent ~ Brt.rYla~,, theme ~---~ CIB.I~LT, source *--~ Sa/~) 1Â¢/1 (agent ~ ~ theme ~ O8.1IK.T, goal ~ BUYIg) } A predicate is realized in syntax in a lexicalized syntactic template which consists of a head with its subcategorization frame, i.e. its arguments considered as ~s. The interface between the semantic and syntactic levels is made through projection rules as illustrated below for bUY. Syntactic template (agent, theme, source) ~ (agent)~ ....--.\"~~"]},{"title":"]","paragraphs":["(~heme)","Prep NP","buy I ( source )","from As a projection rule associates a predicate with a unique syntactic template, a direct interface between the conceptual and syntactic levels seems possible, as schematically resumed below, see (Stone & Doran 1997).","'IPAhIK~CI'IZN -> ( NP(IK3YER) buy NP(OB.TECT) from NP(SSELLER) NP(S~s,~R) sell NP(oBIECT) to NP(~JY~) } However, alternations must be taken into account. One can decide to use a verb in the passive (see when in the next section). Such information can be featurized at the semantic level: a predicate can be marked with a set of features like [Passive = +]. Such alternation features are taken into account in projection rules, as illustrated below. .h.V.y.[passive = Ã·3 (agent, theme, source) --> NP (theme) be bought from NP (source) by NI::' (agent) Considering that a predicate can be marked with alternation features means that an r_Bassociated with a concept takes into account only lexicalization and not syntactic alternations. Therefore, an r.adoes not have to record all the predicates lexicalizing the concept, and for each predicate, all its syntactic constructions. In the LB associated with an atomic relation, the predicates are either verbal, adjectival or nominal. For example, the LB of r.Em/E[r.aAVZR] includes leave(a~z) and deparrure(a./rz). Thereby, an atomic event can be expressed either in a sentence or an t,l:~. This is required to produce either Ted wants Mary to leave or Ted wants Mary's departure, from an instance of r.l~.~embedded in an instance of ra~NZ XP disjunctions (noted as \"/\") are licensed in syntactic templates. For example, as the theme of want can be realized as an S or ~, its syntactic template is the following (in a fiat structure): NP (e~ie-xzer) want S/NP ( u~e)."]},{"title":"2.2 Rapid overview of the generation process","paragraphs":["Let us examine briefly how to generate an atomic event (i.e. how to generate a token such as El---. 'II:~TX!q[H1,H2, O1] )into an S or ~ given the linguistic data bases presented in 2.1. The first step consists in lexicalizing the class cO (a concept) of the token, i.e. in selecting a predicate in LB (C0). For this selection, the predicates are equipped with tests which take into account conceptual and pragmatic factors. These factors may add one or several alternation feature(s). For example, a S-I:DITN3in which the target is missed can be expressed by ihg..9_l in the conative alternation (Levin 1993): Ted shot at the rabbit (but he missed it). Or, for E1 in the case the person referred to by Ill must be the focus, either bUY without alternation (Mary bought a book from John) or sell with the dative and passive alternations (Mary was sold a book by John) can be selectedl. When a predicate has been selected2 it is instantiated as illustrated in the following structure supposed to be selected for E1 when HI. is in focus: ~ell [Dative = +] [Passive = +] (agent ~ H2, theme ~ 01, goal ~ HI): Next the generation process is based on a recursivity principle. The global lexicalization of E1 is the previous structure in which the tokens are lexicalized recursively. The recursion stops roughly because things are generated typically into \"constants\", i.e. predicates without argulThis requires the syntactic functions to be known, therefore that the lexicalization process can access syntactic information. Syntactic functions must also be known for optional arguments. For example, if the BUYER in an instance of TRANSACTION is not specified, ~ [without-goal = +] is selected (John sold a book), or possibly buy [passive = +] [without-agent = +1 (A book was bought from John). 2In fact, it is preferable that the lexicalization process leads to a list of predicates in order of preference, so as to reduce backtracking in case of incompatibility with future decisions, but the data flow is not within the scope of this paper."]},{"title":"51","paragraphs":["ments (corresponding to nouns without arguments). At the end of this recursive process, a structure is produced in which all the lexical items with a semantic content have been chosen and possibly marked with alternation features. The projection of this lexicalized structure into syntax is then achieved by means of the semantic-syntax interface, i.e. projection rules. This leads to a lexicalized syntactic tree from which a text is derived thanks to the application of syntactic rules and to low level operations. In summary, the generation of a token relies on recursive lexicalization of its class and arguments. Let us now examine the linguistic knowledge needed for realizing a discourse relation, first to the cases where a discourse relation is lexicalized, second when it is not so. 3 Expressing a discourse relation by a lexical item Subordinating conjunctions are cue phrases frequently used to link two sentences:"]},{"title":"because","paragraphs":["lexicalizes (la),"]},{"title":"before and after","paragraphs":["lexicalizes SECdENZ,., (lb)-(ld).","(1)a The metal is flat because Ted hammered it. b Ted hammered the metal before melting it. c Ted cried after Mary's departure. d After hammering the metal, lohn melted it. I consider subordinating conjunctions as predicates with two arguments (called simply ~ and ~u2.). Therefore, the rU3of SET,..EqZE(L~r,2o-.~] includes the two following elements: before (argl ~ 1ST..EVENT, arg2 e-~2NDEVENI) and after (argl ~ 2ND.E'vEVr, arg2 ~ 1ST..EVICT). At the syntactic level, a subordinating conjunction generally subcategorizes either for an s or an 1',t~, (lc) and (ld) with"]},{"title":"after.","paragraphs":["This means that the syntactic template associated with after includes a category disjunction. The anteposition of a subordinate clause, (Id), is considered as an alternation of the conjunction and is represented with the alternation feature [~:x:~:i.~.cn = Ã·] added to the predicate. Adverbials such as"]},{"title":"therefore","paragraphs":["or"]},{"title":"afterwards are","paragraphs":["other cue phrases frequently used to link two sentences. They lexicalize discourse relations, e.g."]},{"title":"therefore","paragraphs":["lexicalize ~ (2a), and"]},{"title":"afterwards St~2.ExrZE","paragraphs":["(2b) and (2c).","(2)a Ted hammered the metal. Therefore, it is fiat. b Ted hammered the metal. Afterwards. he melted it. c Ted hammered the metal, and afterwards he melted it. I consider also those adverbials as predicates with two arguments. So the LB of ~ includes afterwards (argl IST-.EVI~T, arg2 ~ 2ND-EVE'4D. The predicate afterwards is associated with a syntactic template whose root is the category T(as'IEXD and whose leaves are: S(argl)."]},{"title":"Afterwards","paragraphs":["S(arg2). The use of"]},{"title":"afterwards","paragraphs":["in a sentence, (2c), is considered as an alternation. The claim that those adverbials are predicates is linguistically motivated. It extends the lexical approach advocated for s or t,P to T. It bridges the (artificial) gap between sentences and texts. This gap is artificial for several reasons, among them, the fact that the same discourse relation can be expressed in a T or an S, as shown in (2b) and (2c) and in the examples below. Another way to iexicalize a discourse relation is to use an \"operator verb\" such as"]},{"title":"cause","paragraphs":["for ~ (3a), or"]},{"title":"follow","paragraphs":["or"]},{"title":"succeedfor ~","paragraphs":["(3b). To generate (3a) or (3b), it is enough to include cause (argl ~ Cat~ arg2 ~ ~ in the LB of I~:~.I..a2; and follow ~argl ~ 2ND.E , arg2 ~ 1sr-EvI~qI) in the LB of ~ Moreover, a discourse relation can also be expressed in a nominalization of an operator verb, (3c).","(3)a Ted's hammering the metal caused it to be fiat. b Mary's arrival followed / succeeded Ted's departure. c the succession of Ted's departure and Mary's arrival (totally upset Fred) In summary, a discourse relation can be lexicalized by a subordinating conjunction, an adverbial, an operator verb, or the nominalization of an operator verb. A ~ m')ammornctnimll:ttme is then produced. For all these cases, the generadon process is based on recursive lexicaLization. Let us examine cases where a discourse reladon is not lexicalized. 4 Expressing a discourse relation without lexicalizing it In a"]},{"title":"SI. $2","paragraphs":["discourse, there is no lexical item that indicates which discourse relation is involved. The fact that (4a) expresses a l~:t*rrwhile (4b) expresses an EX~.R,gtPX2,1is based on a) the core meanings of"]},{"title":"S1 and $2,","paragraphs":["b) the tenses and aspectual properties of each sentence, and c) extra-linguistic knowledge such as the \"Push Causal Law\" (Lascarides & Asher 1991) for (4b). 52","(4)a Ted hammered the metal. It is fiat b Ted fell. John pushed him. At the semantic level, I propose for a SL $2 discourse the use of a @ predicate. This predicate has the particularity to have no lexicai head. It can be used in several LBs, e.g. in I.B(I:~SLLT) with ~B (a~. ~ ~ arg2 ~ ~ or in t.B(B~t-~..A~I'KI~ v,~.th @ (a~.j1~-)~\"~'I', arg2 ~ ~ It is associated with a syntactic template whose root is T and whose leaves are: S(argl). S(arg2). The Sl, V-ing .... sentences in (5) express a non atomic event without any [exical item to express the underlying discourse relation: (5a) expresses a ~ while (5b) expresses a ~ So, to generate (5), I propose a Â® predicate which is similar to @ except that Â® builds a sentence by concatenating two clauses, the second one being in the gerundive form. (5)a Ted went out of the restaurant, moaning. Â• b Ted hammered the metal, flattening it. There is no room left to explain how to generate a resultative construction (Ted hammered the metal flat) which expresses a ~ without item lexicalizing it. Let us just say that this can be achieved by a \"function\" inspired from (Jackendoff 1993). In summary, a non atomic event can be expressed in a s or T without any item lexicalizing the underlying non atomic relation. It seems that this situation has no equivalent for an atomic event: the underlying atomic relation is always lexicalized (even if it leads to Vt:~ellipsis or gapping). 5 Conclusion This paper has shown that an atomic event is expressed in a ~ or s (Section 2), a non atomic event in a I'~t:,, S or with an item lexicatizing it (Section 3) or not (Section 4). The consequences for text generation are twofold: Â• The conceptual representation of a text should be a tree structure whose non terminal nodes are non atomic relations, and whose leaves are conceptual representations of atomic events (based on atomic relations). These leaves do not correspond to the conceptual representations of the sentences or clauses of the text. Â• From such a conceptual representation (enriched with pragmatic information), the generation process should not be modularized into \"text planning\" and \"sentence planning\", as generally admitted (Reiter t994). The only possible modularization is a component for non atomic events and another one for atomic events. In a lexicalized system, the generation of atomic and non atomic events can be based on the same process, i.e. recursive lexicalization. Formalism and implementation. A formalism for a lexicalized generation system must obviously be inspired from a formalism designed for lexicalized grammar in analysis. Among other advantages, this make it possible to use an already existing grammar for the syntactic level. Among the existing lexicalized grammars, TAG has long been seen as especially well suited for text generation (Joshi 1987). Hence my choice of designing a generation formalism inspired by TAGand called G-T>~3(Danlos 1995, 1998). GT,,K3has been first implemented in ADA(Meunier 1997) and used in three technical domains (chemical, software, and aeronautic). The T3t3grammar used for French is the one written by (Abeill6 1991), The elementary tree families are automatically generated out of a hierarchical representation (Candito 1996). G-T, zK3is currently re-implemented in Java in a multi-agent structure (Meunier & Reyes 1998)."]},{"title":"References","paragraphs":["Abeill~,. A. (1991) Une grammaire lexicalis~e d'arbres adjoints pour le franqais, PhD Thesis, Universitd Paris 7. Candito, M.H. (1996) \"A principle-based hierarchical representation of LTAGs\", in Proceedings of \"COLING'96\". Danlos, L. (1995) \"PrEsentation de G-TAG, un formalisme pour la g6n6ration de textes\", Acres de TALN-95, Marseille. Danlos, L. (1998) \"G-TAG: a Formalism for Text Generation inspired from Tree Adjoining Grammar: TAG issues\", in A.","Abeill~ and O. Rarnbow (eds.), Tree-adjoining Grammars, CSLI, Stanford. Jackendoff, R. (1993) Semantic Structures, MIT Press, Cambridge MA. Joshi, A. (1987) \"The relevance of tree adjoining grammar to generation\" , in G. Kempen (ed), Natural Language Genera-","tion: New Results in Artificial Intelligence, Psychology and Linguistics, Martinus Nijhoff Publishers. Lascarides A. and Asher N. (1991) \"Discourse Relations and Defeasible Knowledge\", in Proceedings of ACL'91, Berkeley. Levin, B. (1993), English Verb Classes and Alternations, The University of Chicago Press, Chicago. Mann W. and Thomson S. (1988) \"Rhetorical Structure Theory: Toward a functional theory of text organization.\"in Text:","An Interdisciplinary Journal for the Study of Text, vol. 8 n Â° 2. Meunier, F. (1997) lmpldmentation d'un formalisme de g~n~ration inspird de TAG, PhD Thesis, Universit6 Paris 7. Meunier, F., Reyes, R. (1998) \"CLEF: Computed Lexical-Choice Extend Formalism\", Rapport n Â° 4, Thomson CSF, Paris. Reiter, E. (1994) \"Has a consensus NL generation architecture appeared, is it psycholinguistically plausible?\", INLG'94. de Smedt K., Horacek H., Zock M., (1996) \"Architectures for Natural Language Generation: Problems and Perspectives\", in","G. Adomi and M. Zock (eds) Trends in Natural Language Generation, Springer-Verlag. Stone, M., Doran, C. (1997) \"Sentence Planning Using TAG\", in Proceedings ACL/EACL '97."]},{"title":"53","paragraphs":[]}]}
