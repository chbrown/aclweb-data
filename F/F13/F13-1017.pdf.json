{"sections":[{"title":"Chunks et activation : un modèle de facilitation du traitement linguistique Philippe Blache","paragraphs":["Aix-Marseille Université, CNRS, LPL","5 Avenue Pasteur, 13100 Aix-en-Provence","blache@lpl-aix.fr"]},{"title":"R","paragraphs":["ÉSUMÉ Nous proposons dans cet article d’intégrer la notion de chunk au sein d’une architecture globale de traitement de la phrase. Les chunks jouent un rôle important dans les théories cognitives comme ACT-R (Anderson et al., 2004) : il s’agit d’unités de traitement globales auxquelles il est possible d’accéder directement via des buffers en mémoire à court ou long terme. Ces chunks sont construits par une fonction d’activation (processus cognitif pouvant être quantifié) s’appuyant sur l’évaluation de leur relation au contexte. Nous proposons une interprétation de cette théorie appliquée à l’analyse syntaxique. Un mécanisme de construction des chunks est proposé. Nous développons pour cela une fonction d’activation tirant parti de la représentation de l’information linguistique sous forme de contraintes. Cette fonction permet de montrer en quoi les chunks sont faciles à construire et comment leur existence facilite le traitement de la phrase. Plusieurs exemples sont proposés, illustrant cette hypothèse de facilitation."]},{"title":"A","paragraphs":["BSTRACT Chunks and the notion of activation : a facilitation model for sentence processing We propose in this paper to integrate the notion of chunk within a global architecture for sentence processing. Chunks play an important role in cognitive theories such as ACT-R cite Anderson04 : they constitute global processing units which can be accessed directly via short or long term memory buffers. Chunks are built on the basis of an activation function evaluating their relationship to the context. We propose an interpretation of this theory applied to parsing. A construction mechanism is proposed, based on an adapted version of the activation function which takes advantage of the representation of linguistic information in terms of constraints. This feature allows to show how chunks are easy to build and how they can facilitate treatment. Several examples are given, illustrating this hypothesis of facilitation."]},{"title":"M","paragraphs":["OTS"]},{"title":"-","paragraphs":["CLÉS"]},{"title":":","paragraphs":["Chunks, ACT-R, activation, mémoire, parsing, traitement de la phrase, expérimentation."]},{"title":"K","paragraphs":["EYWORDS"]},{"title":":","paragraphs":["Chunks, ACT-R, activation, memory, parsing, sentence processing, experimentation. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 229 c⃝ ATALA"]},{"title":"1 Introduction","paragraphs":["L’interprétation d’un énoncé, à commencer par son traitement syntaxique, peut être plus ou moins facile pour un sujet humain. Plusieurs travaux proposent des éléments d’explication de cette variabilité. Au niveau syntaxique, des travaux proposent par exemple des explications en termes de distance pour une relation à établir entre deux éléments, une grande distance étant plus complexe à traiter qu’une plus faible (Gibson, 1998) ; (Grodner et Gibson, 2005). D’autres travaux portent sur l’identification d’un niveau d’activation des items en s’appuyant notamment sur des relations avec le reste de la structure en cours de construction (Lewis et Vasishth, 2005). Dans tous les cas, ces modèles de difficulté abordent la question d’un point de vue global, en tentant d’identifier les paramètres pouvant complexifier le traitement. Nous proposons dans cet article d’aborder un point de vue complémentaire en tentant d’identifier des facteurs qui au contraire peuvent permettre de faciliter le traitement. En se situant dans l’hypothèse d’un traitement incrémental du langage, dans laquelle les mots sont intégrés au fur et à mesure de leur décodage dans une structure en cours de construction, des travaux antérieurs ont montré la possibilité de mesurer la quantité d’information linguistique 1 disponible au moment de l’intégration d’un mot. Dans les cas où le niveau d’information est élevé, le traitement (la compréhension) s’en trouve facilité. En revanche, un déficit d’information entraîne une complexification du traitement. En termes computationnels, la quantité d’information disponible permet de contrôler l’espace de recherche requis pour l’interprétation d’un énoncé. Une construction associée à une faible quantité d’information est très ambiguë et donc difficile à traiter car le nombre d’interprétations possibles (donc l’espace de recherche) est très grand. En revanche, une construction pour laquelle une grande quantité d’information (éventuellement redondante) est disponible sera peu ou pas ambiguë, son espace de recherche plus restreint et son traitement (son interprétation) devient plus facile. Dans certains cas, il n’y a aucune ambiguïté, le traitement est alors purement déterministe. La quantité d’information est dans ce cas un facteur de simplification du traitement et non pas de complexification. D’une façon générale, la quantité (ou densité) d’information disponible est variable selon les parties de l’énoncé ou de la phrase. L’hypothèse que nous formulons est que les zones comportant une densité d’information importante sont traitées plus facilement que les autres. Dans certains cas, ces zones de haute densité peuvent être traitées d’un bloc. Nous nous intéressons dans cet article à cette idée que le processus d’intégration syntaxique pourrait se faire au niveau de ces zones plutôt qu’au niveau des mots. Une présence plus importante de zones de haute densité d’information dans un énoncé ou une phrase faciliterait ainsi son traitement. Cette idée s’appuie sur le principe Maximize On-Line Processing (noté MoP) proposé dans (Hawkins, 2003) : The human parser prefers to maximize the set of properties that are assignable to each item X as X is parsed. [...] The maximization difference between competing orders and structures will be a function of the number of properties that are misassigned or unassigned to X in a structure S, compared with the number in an alternative. Ce principe comporte plusieurs éléments. Il intègre tout d’abord l’idée selon laquelle, dans un processus incrémental, l’intégration d’un mot repose sur la vérification d’un ensemble de propriétés. Il indique également que deux constructions peuvent se distinguer par le nombre de propriétés qu’elles vérifient. La notion de densité d’information recoupe donc ce principe de","1. On entend ici par information linguistique toute propriété morpho-syntaxique ou syntaxique caractérisant la structure en cours de construction. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 230 c⃝ ATALA maximisation : un mot sera plus ou moins facilement intégré à la structure selon que le nombre de propriétés qui lui sont associées est important ou pas. Notre hypothèse est que ces unités, définies par maximisation, correspondent en termes de traitement à des chunks tels que décrits dans les théories cognitives de type ACT-R (Adaptive Character of Thought–Rational (Anderson et al., 2004)) et peuvent à ce titre être stockés en mémoire à court terme et bénéficier d’un accès direct."]},{"title":"2 Chunks et activation","paragraphs":["La notion de chunk est bien connue en TAL, et généralement définie comme une suite de catégories non récursive, formée d’une tête, à laquelle peuvent être adjoints mots fonctionnels et modifieurs adjacents (Abney, 1991) ; (Bird et al., 2009). Nous nous intéressons dans cet article à la façon dont ces chunks peuvent être construits, dans le cadre d’un processus incrémental, par un parseur humain."]},{"title":"2.1 Les chunks dans les théories cognitives","paragraphs":["Le traitement du langage, comme celui des activités cognitives de haut niveau, repose sur la capacité d’identifier des unités de traitement pouvant être de taille et de nature variable. Cette idée est plus particulièrement développée par la théorie ACT-R et son adaptation au langage (Lewis et Vasishth, 2005), (Reitter et al., 2011) dans laquelle les mécanismes de traitement s’organisent autour de buffers (jouant comme en informatique le rôle de mémoire tampon) pouvant mémoriser des chunks. Un chunk est dans cette approche décrit comme un ensemble de propriétés caractérisant une catégorie (ou une unité de plus haut niveau), pouvant par exemple contenir une structure syntaxique partielle (Lewis et Vasishth, 2005). Les chunks sont représentés en ACT-R par des structures de traits et peuvent représenter des objets atomiques ou complexes, offrant la possibilité pour un chunk de faire référence à un autre chunk et exprimer ainsi des relations. La définition d’un chunk est donc très générale et permet de référencer des structures incomplètes ou sous-spécifiées. La théorie ACT-R s’intéresse d’une part aux processus de base et d’autre part aux structures de mémoire sur lesquelles ils s’appuient. Elle distingue notamment entre mémoire procédurale et déclarative, cette dernière permettant de stocker à la fois des informations lexicales (à long terme) mais également les structures nouvelles (à court terme). La mémoire déclarative repose sur un petit nombre de buffers, chacun contenant un chunk. L’élément important de cette organisation réside dans le fait que ces chunks forment une unité et sont utilisables (ou accessibles) directement en mémoire. Cette accessibilité est soumise à un niveau d’activation dépendant de plusieurs paramètres : degré de latence depuis le dernier accès, poids des éléments associés au chunk et qui peuvent l’activer (les sources), mais également force des relations associant les sources au chunk considéré. Il est ainsi possible de proposer une formule permettant de quantifier l’activation d’un chunk i : Ai = Bi + ∑ j WjSji (1) TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 231 c⃝ ATALA FIGURE 1 – Nombre de fixations par catégorie Dans cette formule, B représente l’activation de base (fréquence et historique de l’accès au chunk), W correspond aux poids des termes en relation avec le chunk et S la force des relations reliant ces termes au chunk. Il est donc possible de caractériser un chunk en fonction de son niveau d’activation. Le point important qui nous intéresse ici réside dans le fait que cette activation est en partie dépendante des relations avec le contexte. En d’autres termes, la force des relations permettra d’activer de façon plus ou moins importante un chunk (et donc la catégorie correspondante). Or, l’activation d’un chunk contrôle à la fois sa probabilité et la vitesse de son accès : un chunk fortement activé sera ainsi accessible très rapidement. On remarquera que cette approche est compatible avec le principe MoP de Hawkins (cf. section précédente) : les relations activant un chunk peuvent être vues comme des propriétés dont on recherche la maximisation. Dans le cadre du traitement du langage et plus particulièrement de l’analyse syntaxique, notre hypothèse est que les chunks facilitent l’analyse d’un énoncé. Plus précisément, les énoncés comportant des chunks hautement activés sont traités plus facilement que les autres."]},{"title":"2.2 Une observation expérimentale des chunks dans le traitement de la phrase","paragraphs":["Dans le cadre d’une expérience récente, consistant à acquérir des données de mouvement oculaire de sujets lisant le French Treebank (Rauzy et Blache, 2012), nous avons observé un phénomène intéressant en relation avec les chunks. Le nombre de fixations du regard par mot diffère en effet fortement en fonction de la taille du mot, mais également de sa catégorie. La figure 1 représente le nombre moyen de fixations par catégorie. On observe ainsi que les catégories à contenu lexical (N, V, Adj, Adv) ont un nombre de fixations du regard nettement plus élevé que les mots grammaticaux (Det, Prep, Clit, etc.). Ce phénomène peut être mis en relation avec l’étude de l’évolution de l’indice de surprise (Hale, 2001) dans une phrase. Cet indice reflète une probabilité d’intégration de chaque mot dans la structures syntaxique en cours de construction (calculé comme une fonction de la différence de probabilité entre les structures précédant et celle intégrant le mot courant). Plusieurs expériences ont montré qu’il était un bon prédicteur du temps de lecture, pouvant donc être utilisé comme TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 232 c⃝ ATALA FIGURE 2 – Evolution de l’indice de surprise dans une phrase mesure de difficulté (voir (Demberg et Keller, 2008) pour l’anglais et (Rauzy et Blache, 2012) pour le français). Un indice de surprise peut donc être associé à chaque mot de la phrase. La figure 2 illustre l’évolution de la valeur de cet indice (calculé selon la méthode décrite dans (Blache et Rauzy, 2011)) sur une phrase. On remarque là aussi un phénomène intéressant, soulignant la succession d’indices élevés et faibles en fonction de la catégorie : les mots grammaticaux correspondent systématiquement à un indice de surprise plus élevé que les mots lexicaux auxquels ils sont associés. Ces deux observations sont convergentes : la fixation du regard en lecture englobe en un seul mouvement le token lexicalisé et les mots grammaticaux qui lui sont associés, ce qui peut être prédit au niveau de l’évolution de l’indice de surprise. Elles confortent donc l’hypothèse d’un traitement non pas au niveau du mot, mais directement par chunk, chaque fois que c’est possible."]},{"title":"2.3 Hypothèse","paragraphs":["La théorie ACT-R appliquée au langage fait l’hypothèse que le traitement linguistique d’intégration repose sur des chunks. Ceux-ci sont des structures partielles, pouvant être à la fois stockées dans la mémoire à long terme, mais également construites en temps réel, en mémoire à court terme. Ces chunks reposent sur une notion d’activation, elle-même correspondant au principe Maximize Online Processing : l’intégration d’un mot à une structure (par exemple l’association de deux catégories pour construire un chunk) repose sur la vérification d’un maximum de propriétés. La force des relations unissant un objet avec des éléments qui le précèdent permet d’activer fortement cet objet. Nous émettons l’hypothèse que les chunks facilitent le traitement linguistique. Nous nous appuyons pour cela sur trois aspects :","1. Les chunks sont construits en mémoire sur la base du processus d’activation, qui ne correspond pas à une véritable analyse syntaxique. Leur construction peut reposer sur des mécanismes de bas niveau (comme la fréquence de cooccurrence) ou sur l’accumulation de propriétés ou relations entre deux catégories. Lorsqu’une catégorie est fortement activée par une ou plusieurs catégories précédentes, elle formera un chunk avec elles. Dans la plupart des cas, ces chunks sont formés d’une suite [mot grammatical + mot lexical]. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 233 c⃝ ATALA","2. Les chunks sont stockés en mémoire déclarative et accessibles directement. Certains chunks peuvent être très fréquents voire correspondre à des suites plus ou moins figées (par exemple dans des collocations). Dans ce cas, ils sont stockés en mémoire à long terme. Les chunks construits dynamiquement sur la base d’une activation sont quant à eux disponibles dans des buffers de traitement à court terme.","3. La présence de chunks dans une phrase facilite son traitement : ils sont accessible d’un bloc et ne nécessitent pas d’analyse. Une phrase contenant des chunks sera plus facile à traiter qu’une autre n’en contenant pas. La question qui se pose est celle de la notion d’activation, son évaluation et sa mise en œuvre dans le processus de construction des chunks. Nous proposons pour cela d’utiliser la description des propriétés syntaxiques sous la forme de contraintes. Maximiser les propriétés (et donc activer une catégorie) correspond ainsi à la maximisation de l’ensemble des contraintes à satisfaire. Nous utilisons pour cela la représentation proposée dans le cadre des Grammaires de Propriétés (Blache, 2001)."]},{"title":"3 Propriétés et activation","paragraphs":["Nous présentons dans cette section les principales caractéristiques de l’approche des Grammaires de Propriétés (Blache, 2001) utilisées pour définir la notion d’activation. Elle repose sur la représentation des informations syntaxiques sous la forme d’un ensemble de propriétés pouvant être décrites, suivant la proposition de (Duchier et al., 2009), comme des relations caractérisant un syntagme (ici noté A) et mettant en relation des constituants (notés B, C ou S): Obligation A : ∆B au moins un B Unicité A : B! au plus un B Linéarité A : B ≺ C B précède C Implication A : B ⇒ C si ∃B, alors ∃C Exclusion A : B ̸⇔ C pas de B et C simultanément Constituance A : S? les descendants ∈ S Dépendance A : B ⇝ C B dépend de C Une Grammaire de Propriétés associe à chaque syntagme un ensemble de contraintes. Le tableau suivant illustre la grammaire du syntagme adjectival (noté SA) (extraite du French Treebank, cf. (Abeillé et al., 2003)). Soulignons au passage la compacité de la représentation : 22 contraintes sont utilisées pour décrire les constructions possibles du SA 2",". Constituance AP : {AdP, A, VPinf, PP, Ssub, AP, NP} ? Lin","AP : A ≺ {VPinf, Ssub, PP, NP, AP}","AP : AdP ≺ {A, Ssub, PP}","AP : AP ≺ {A, AdP}","AP : PP ≺ {Ssub}","Dépendance AP : {AdP, VPinf, PP, Ssub, NP} ⇝ A","Unicité AP : {A, VPinf, Ssub} !","Obligation AP : ∆ A","Exclusion AP : VPinf ̸⇔ {PP, Ssub} 2. Le jeu d’étiquettes utilisé est celui du FTB, notant AP pour syntagme adjectival, AdP pour syntagme adverbial, etc. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 234 c⃝ ATALA FIGURE 3 – Graphe des propriétés satisfaites pour “L’industrie est très capable.” Une analyse dans le cadre de GP consiste, pour une suite de catégories donnée, à évaluer l’ensemble des propriétés correspondantes. Une propriété correspondant à une relation entre une ou plusieurs catégories, le résultat de l’analyse est donc un graphe comme représenté dans la figure suivante illustrant l’analyse de la phrase “L’industrie est très capable.”, extraite du FTB. Ce graphe indique les propriétés satisfaites entre les différentes catégories composant la structure syntaxique. Par exemple, la contrainte de linéarité entre le déterminant et le nom est représentée par un arc reliant les deux nœuds correspondants) : Construire une analyse syntaxique dans ce type d’approche consiste donc à chaque étape à parcourir le systèmes de contraintes en évaluant celles qui correspondent aux catégories concernées. Dans une perspective incrémentale, il est donc possible à chaque étape de connaître les relations qui concernent le mot ou la catégorie à analyser. Cette caractéristique constituera la base de la définition de la notion d’activation utilisée ici. Par ailleurs, il est possible de distinguer deux constructions en fonction du nombre de relations permettant de les caractériser. Dans l’exemple précédent, le SA est formé d’un adjectif accompagné d’un modifieur adverbial. L’exemple suivant illustre une construction légèrement différente d’un SA, correspondant à la phrase “L’industrie est capable d’investir.” dans laquelle une infinitive est complément de l’adjectif. Dans ce cas, conformément à la grammaire du SA décrite plus haut, un plus grand nombre de contraintes sera vérifiée, la densité du graphe est donc plus importante. Le nombre de propriétés vérifiées joue un rôle important en offrant la possibilité de quantifier l’information syntaxique. Dans la perspective du principe MoP, la maximisation reposera précisément sur cette capacité. Un des avantages de cette approche réside dans sa souplesse : il est toujours possible d’évaluer les relations existant entre deux catégories, sans qu’il ne soit nécessaire de construire de structure syntaxique. Cette caractéristique répond au besoin d’évaluation de la notion d’activation d’une catégorie : celle-ci sera dépendante du nombre et de la force des relations existant entre un mot et les catégories qui la précèdent. Nous disposons ainsi d’un cadre théorique d’implantation des notions proposées par ACT-R appliquée au langage. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 235 c⃝ ATALA FIGURE 4 – Graphe des propriétés satisfaites pour “L’industrie est capable d’investir.”"]},{"title":"4 Activation et création de chunks","paragraphs":["Nous proposons de définir la notion d’activation sur la base des caractérisations syntaxiques construites à l’aide des contraintes présentées dans la section précédente. Nous avons vu qu’il était possible en Grammaire de Propriétés d’évaluer, pour tout sous-ensemble de catégories, les contraintes qui leur sont attachées. Il s’agit pour cela d’identifier les contraintes pertinentes,à savoir celles qui permettent de mettre en relation les catégories concernées. Le principe est simple et consiste à parcourir la grammaire (l’ensemble des contraintes) et sélectionner celles qui concernent les catégories. En reprenant l’exemple de la grammaire du syntagme adjectival décrite plus haut, le sous-ensemble de catégories {AdP, A} permettra d’identifier comme pertinentes les contraintes suivantes : AP : {AdP, A} ? AP : AdP ≺ A AP : AdP ⇝ A AP : A ! AP : ∆ A En généralisant ce mécanisme, il également possible d’identifier les contraintes qui sont potentiellement pertinentes : soit une contrainte A B reliant deux catégories A et B, la connaissance de A permet de dire que A B pourra devenir pertinente, à la condition que B soit réalisé. Dans le cas de la grammaire du SA, la réalisation de la catégorie AdP permet d’identifier comme contrainte potentiellement pertinente l’ensemble suivant : AP : {AdP} ? AP : AdP ≺ A AP : AP ≺ AdP AP : AdP ⇝ A TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 236 c⃝ ATALA Nous proposons d’utiliser cette caractéristique pour décrire et évaluer la notion d’activation. Dans la perspective d’un traitement incrémental de la langue, le principe consiste à associer à chaque catégorie les contraintes potentiellement pertinentes qui peuvent lui être associées. Remarquons que du point de vue du traitement automatique, cette information n’a pas besoin d’être calculée online, mais peut être compilée. L’ensemble des contraintes ainsi identifiées permet de définir les catégories activées : il s’agit de toutes les catégories appartenant à cet ensemble et pouvant être réalisées après la catégorie en question. Cette dernière information est obtenue en vérifiant les contraintes de linéarité. Dans l’exemple précédent, seule la catégorie A se retrouve activée par AdP (la catégorie AP ne pouvant suivre AdP comme stipulé par la contrainte AP : AP ≺ AdP)."]},{"title":"4.1 Calcul du degré d’activation","paragraphs":["Le niveau d’activation d’une catégorie dans un contexte donné dépend de sa densité ou, en d’autres termes, du nombre de contraintes dont elle est la cible (et dont la source la précède) et de leur poids. Il s’agit donc exactement de la notion d’activation telle que décrite dans la théorie ACT-R. Nous proposons d’évaluer cette activation en tirant parti de la représentation par contraintes. Pour chaque catégorie c de la grammaire, nous établissons une liste de transition formée par toutes les catégories présentes dans au moins une contrainte contenant c et respectant les contrainte de linéarité (i.e. pouvant suivre c). L’activation est alors évaluée comme suit :","– Soit la catégorie courante ci. Notons Trans(ci) l’ensemble des catégories faisant partie de la liste de transition de ci. Notons PP(ci) l’ensemble des propriétés potentiellement pertinentes déclenchées par la catégorie ci. Notons N le nombre de ces propriétés (N =| PP(ci) |).","– Notons PPcj (ci) le sous ensemble de PP(ci) formé des propriétés contenant une catégorie cj, avec n son cardinal. Chacune des propriétés de PP est associée dans la grammaire à un poids. Notons","∑ W","cj","ci la somme des poids de ces propriétés.","– Pour toute catégorie de transition de ci tq cj ∈ Trans(ci), son degré d’activation est donné par","la formule suivante : A(cj)= n N ∗ ∑ W cj ci (2) Le premier terme de l’activation correspond à une évaluation de la densité du réseau de contraintes en rapportant le nombre de contraintes n qui permet d’activer la catégorie étudiée par rapport au nombre total de contraintes potentiellement pertinentes pour la catégorie source. Le second terme correspond quant à lui à la force des relations qui unissent la catégorie courante (ou catégorie activante) à la catégorie activée. Concrètement, en cours d’analyse, cette mesure permettra d’identifier le type de catégorie activée par la catégorie courante ainsi que le niveau de son activation. Lorsque qu’une catégorie est activée et réalisée, elle formera un chunk avec la catégorie qui l’active. Ce chunk pourra avoir un niveau d’activation plus ou moins élevé, identifié par cette fonction d’activation. Notons que cette définition de l’activation permet également de rendre compte des relations lexicales du type collocationnelles. La sélection lexicale entre les termes sera dans ce cas représentée par une contrainte d’implication avec un poids élevée. Il sera ainsi possible de former un chunk doté d’un niveau d’activation fort. L’exemple qui suit illustre l’utilisation de la fonction d’activation pour la construction d’un chunk à l’intérieur du SN entre les catégories Det et N en nous appuyant sur la grammaire extraite TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 237 c⃝ ATALA du French Treebank. Les contraintes dont la catégorie Det est source sont répertoriées dans le tableau suivant, comportant également l’indication de leurs poids (calculé en suivant la méthode proposée dans (Blache, 2012)).","Dépendance Det ⇝ N 7,080586081","Exclusion Pro ̸⇔ Det 4,358766626 Clit ̸⇔ Det 0,003417994","Unicité Det 3,253068199","Exigence Det ⇒ N 2,461019161","Linéarité Det ≺ N 12,18569885 Det ≺ Np 0,718659942 Det ≺ AdP 0,178675795 Det ≺ AP 0,135447163 Det ≺ VPpart 0,077399536 Det ≺ VPinf 0,03891139 Det ≺ Ssub 0,025216138 Det ≺ Srel 0,021433718 Det ≺ PP 0,016570605 Det ≺ NP 0,016030259 L’ensemble de transition de Det extrait de ces contraintes est le suivant : Trans(Det)={N, Np, AdP, AP, VPpart, VPinf , Ssub, Srel, PP, NP} (3) L’évaluation du degré d’activation des catégories de l’ensemble de transition est récapitulée dans le tableau suivant : Catégorie activée Contraintes Densité Poids Activation N 3 0,2 21,72730409 4,345460818 Np 1 0,066666667 0,718659942 0,047910663 AdP 1 0,066666667 0,178675795 0,01191172 AP 1 0,066666667 0,135447163 0,009029811 VPpart 1 0,066666667 0,077399536 0,005159969 VPinf 1 0,066666667 0,03891139 0,002594093 Ssub 1 0,066666667 0,025216138 0,001681076 Srel 1 0,066666667 0,021433718 0,001428915 PP 1 0,066666667 0,016570605 0,001104707 NP 1 0,066666667 0,016030259 0,001068684 Cet ensemble de résultats indique, comme attendu, une forte activation de la catégorie N provenant d’une part du nombre de propriétés potentielles qui l’activent et d’autre part de leur importance (i.e. un poids élevé). Cette forte activation conduit à la constitution d’un chunk"]},{"title":"[Det, N]","paragraphs":["qui sera stocké dans un buffer de la mémoire déclarative. Ce processus d’identification de chunk repose donc sur des mécanismes de bas niveau, effectués en temps réel ce qui se manifeste concrètement par un traitement global notamment au niveau du mouvement oculaire dans le cas de la lecture. L’exemple de la figure 5 illustre ce mécanisme. La réalisation de la catégorie Det permet d’identifier trois propriétés activant le N conduisant à la création du chunk. L’exemple de la figure 6 décrit le même mécanisme, appliqué ici à la constitution d’un chunk formé, dans le cas d’une relative sujet, par le pronom relatif et le verbe qui suit. Les catégories activées les plus importantes (celles correspondant à des contraintes de plus fort poids) sont V et N , représentées dans le cadre associé au pronom relatif. La catégorie V dispose cependant d’un niveau d’activation très supérieur au N . Le V étant réalisé immédiatement après l’activation, ceci conduit à la construction du chunk"]},{"title":"[ProR, V]","paragraphs":[". TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 238 c⃝ ATALA (a) Activation du N (b) Construction du chunk [Det, N] FIGURE 5 – Activation et construction de chunk FIGURE 6 – Activation et construction de chunk, suite Ce processus appliqué à la suite des catégories de la phrase permet de construire la suite de chunks illustrée par la figure 7."]},{"title":"4.2 Les chunks, mécanisme de facilitation","paragraphs":["L’hypothèse que nous défendons repose tout d’abord sur l’idée que les chunks sont construits directement, sur la base de mécanismes tirant parti à la fois de critères de fréquence et de densité de relation. Les mécanismes conduisant à la construction de chunks ne sont donc pas les mécanismes classiques de l’analyse syntaxique : le problème posé consiste à mesurer les relations unissant deux catégories adjacentes alors que l’analyse syntaxique consiste à intégrer une catégorie à une structure syntaxique globale. Il s’agit donc de mécanismes de bas niveau, effectués très rapidement. Une fois construits, ces chunks sont stockés en mémoire et accessibles directement, comme indiqué dans la théorie ACT-R. Notre hypothèse consiste donc à dire que les chunks facilitent le traitement. Leur accès se faisant en bloc, il revient du point de vue cognitif à un accès lexical. De plus, leur intégration se fait également de façon globale. Par conséquent, la présence de chunks dans un énoncé ou une phrase en facilitera le traitement par rapport à d’autres situation où l’intégration devra se faire mot par mot. Autrement dit, une phrase contenant un grand nombre de chunks sera plus facile à traiter qu’une phrase qui en contiendra moins. Illustrons cette hypothèse en revenant sur le cas des phrases relatives. Les travaux en psycholinguistique (Gibson, 2000), confirmés par plusieurs études expérimentales (Fedorenko et al., 2006), (Demberg et Keller, 2009) ont montré que les relatives objet sont plus difficiles à traiter que les FIGURE 7 – Construction des chunks pour la phrase complète TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 239 c⃝ ATALA FIGURE 8 – Cas de la relative objet relatives sujet. Ce phénomène se retrouve au niveau de la construction des chunks. Nous avons vu en effet dans l’exemple de la figure 7 que la relative sujet conduisait à la construction d’un chunk entre le pronom relatif et le verbe. La phrase correspondante contient ainsi 4 chunks au total. La figure 6 illustre ce phénomène par l’impossibilité de construire un chunk contenant le relatif. Celui-ci active bien un certain nombre de catégories, mais aucune d’entre elle ne correspond directement à la catégorie adjacente. Au total, la phrase contenant la relative objet ne contient que 3 chunks. Cet exemple ne prétend bien entendu pas ériger le rôle des chunks en théorie de la difficulté syntaxique comme proposé par (Gibson, 2000). Elle illustre cependant des différences de fonctionnement pouvant accompagner ou compléter ces modèles."]},{"title":"5 Conclusion","paragraphs":["Nous avons présenté dans cet article une approche proposant de donner une place centrale à la notion de chunk dans le processus de traitement de la phrase par des sujets humains. Nous utilisons pour cela l’architecture de traitement des processus cognitifs élaborée dans le cadre de la théorie ACT-R. Cette approche précise le rôle joué par les chunks en mémoire. Elle introduit de plus une notion d’activation permettant d’expliquer la rapidité de traitement de ces objets. Appliquée à la question de l’analyse syntaxique (ou du traitement de la phrase si l’on se situe dans une perspective psycholinguistique), cette théorie offre un cadre permettant de décrire la construction et le rôle joué par ces chunks. En tirant parti d’une description des informations syntaxiques basée sur les contraintes (dans le cadre des Grammaires de Propriétés), nous avons proposé une évaluation de la notion d’activation servant de base à la construction des chunks. Il s’agit d’un mécanisme de bas niveau, n’ayant pas recours à l’analyse syntaxique à proprement parler et qui permet la construction d’unités de niveau supra-lexical facilitant le processus car accessibles directement en mémoire. L’utilisation de telles unités correspond à des observations expérimentales, notamment de mouvement oculaire, montrant que les chunks correspondent à des unités de traitement pertinentes. Il reste à évaluer la validité de l’hypothèse de facilitation des chunks de façon expérimentale. Il s’agira notamment de vérifier que la construction des chunks est un processus de bas niveau et que leur accès correspond à un accès lexical en complétant les observations de mouvement oculaire par des expériences à l’aide de potentiels évoqués et de localisation de source. L’étape suivante consistera à vérifier la facilitation induite par les chunks en termes de temps de traitement. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 240 c⃝ ATALA Remerciements Ce travail réalisé dans le cadre du Labex BLRI (http ://www.blri.fr) portant la référence ANR-11-LABX-0036 a bénéficié d’une aide de l’Etat gérée par l’ANR au titre du projet Investissements d’Avenir A*MIDEX portant la référence ANR-11-IDEX-0001-02."]},{"title":"Références","paragraphs":["ABEILLÉ, A., CLÉMENT, L. et TOUSSENEL, F. (2003). Building a treebank for french. In ABEILLÉ, A., éditeur : Treebanks, Kluwer, Dordrecht. ABNEY, S. (1991). Parsing by chunks. In Principle-Based Parsing. Kluwer Academic Publishers, pages 257–278. ANDERSON, J. R., BOTHELL, D., BYRNE, M. D., DOUGLASS, S., LEBIERE, C. et QIN, Y. (2004). An integrated theory of the mind. Psychological Review, 111(4):1036–1060. BIRD, S., KLEIN, E. et LOPER, E. (2009). Natural Language Processing with Python. O’Reilly Media. BLACHE, P. (2001). Les Grammaires de Propriétés : Des contraintes pour le traitement automatique des langues naturelles. Hermès. BLACHE, P. (2012). Estimating constraint weights from treebanks. In Proceedings of CSLP. BLACHE, P. et RAUZY, S. (2011). Predicting linguistic difficulty by means of a morpho-syntactic probabilistic model. In Proceedings of PACLIC 2011, december 2011, Singapour. DEMBERG, V. et KELLER, F. (2008). Data from eye-tracking corpora as evidence for theories of syntactic processing complexity. In Cognition, volume 109, Issue 2, pages 193–210. DEMBERG, V. et KELLER, F. (2009). A computational model of prediction in human parsing : Unifying locality and surprisal effects. In Proceedings of the 31st Annual Conference of the Cognitive Science Society, pages 1888– 1893. DUCHIER, D., PROST, J.-P. et DAO, T.-B.-H. (2009). A model-theoretic framework for grammaticality judgements. In Conference on Formal Grammar (FG’09). FEDORENKO, E., GIBSON, E. et ROHDE, D. (2006). The nature of working memory capacity in sentence comprehension : Evidence against domain-specific working memory resources. Journal of Memory and Language, 54(4):541–553. GIBSON, E. (1998). Linguistic complexity : locality of syntactic dependencies. Cognition, 68:1–76. GIBSON, E. (2000). The dependency locality theory : A distance-based theory of linguistic complexity. In Image. A. Marantz, Y. Miyashita, W. O’Neil (Edts). GRODNER, D. J. et GIBSON, E. A. F. (2005). Consequences of the serial nature of linguistic input for sentenial complexity. Cognitive Science, 29:261–291. HALE, J. (2001). A probabilistic earley parser as a psycholinguistic model. In Proceeding of 2nd Conference of the North American Chapter of the Association for Computational Linguistics, Pittsburgh, PA. HAWKINS, J. (2003). Efficiency and complexity in grammars : Three general principles. In MOORE, J. et POLINSKY, M., éditeurs : The Nature of Explanation in Linguistic Theory, pages 95–126. CSLI Publications. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 241 c⃝ ATALA LEWIS, R. L. et VASISHTH, S. (2005). An activation-based model of sentence processing as skilled memory retrieval. Cognitive Science, 29:375–419. RAUZY, S. et BLACHE, P. (2012). Robustness and processing difficulty models. a pilot study for eye-tracking data on the french treebank. In Proceedings of the 1st Eye-Tracking and NLP workshop. REITTER, D., KELLER, F. et MOORE, J. D. (2011). A computational cognitive model of syntactic priming. Cognitive Science, 35(4):587–637. TALN-RÉCITAL 2013, 17-21 Juin, Les Sables d’Olonne 242 c⃝ ATALA"]}]}