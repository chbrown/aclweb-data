{"sections":[{"title":"Question Answering Using Web News as Knowledge Base Zhiping Zheng Computational Linguistics Department Saarland University D-66041 Saarbriicken, Germany","paragraphs":["zheng@coli .uni—sb. de"]},{"title":"Abstract","paragraphs":["AnswerBus News Engine' is a question answering system using the contents of CNN Web site2 as its knowledge base. Comparing to other question answering systems including its previous versions, it has a totally independent crawling and indexing system and a fully functioning search engine. Because of its dynamic and continuous indexing, it is possible to answer questions on just-happened facts. Again, it reaches high correct answer rate. In this demonstration we will present the living system as well as its new technical features."]},{"title":"Keywords:","paragraphs":["question answering, QA specific indexing, search engine"]},{"title":"1 Introduction","paragraphs":["AnswerBus3 ([2,3]) is originally designed as a Web-based open-domain question answering (QA) system. It successfully uses natural language processing and information retrieval techniques and reaches very high correct answer rate. Although it is not designed for TREC, it still correctly answers over 70% of TREC-8 questions with Web resources. Because we use commercial search engines as the search tools for the system, we don't know if special indexing system and other possible techniques will work better for the QA tasks.","In the new experiment, we used the contents of CNN Web site and developed a QA system http://www.coli.uni-sb.de/ —zheng/answerbus/news/ 2 http://www.cnn.com/ http://www.answerbus.com/ called AnswerBus News Engine to automatically answer news related questions. We chose CNN Web site as the knowledge base because it has a good archive of news stories since 1996 and the CNN Web site seems having good reputation on timely updating. The goal of this experiment is to use most techniques used in AnswerBus QA system together with some new techniques, such as QA specific indexing described in [2,3] but not fully implemented in original AnswerBus system, and build a QA system to answer time sensitive questions in the real world.","Before building the AnswerBus News Engine, we did another experiment4 ([7]) using part of DUC conference corpus as local archive. The result was exciting. The experimental QA system correctly answered 80% questions designed specially for the local archive."]},{"title":"2 New Features","paragraphs":["AnswerBus News Engine has many new features not used in other QA systems including its previous versions."]},{"title":"2.1 Sentence Level Indexing","paragraphs":["QA systems usually use some search tools to retrieve documents. These search tools include some commercial search engines like Google, Alta Vista. Some other systems tried local search engines for local data, for example, local Web contents or TREC corpus. We partially deployed the techniques used in Seven Tones Search Engine5 ([6,5]) for the search task, since it has a high indexing speed and it is possible to timely update the indexed database part by part.","Comparing to other QA systems, AnswerBus News Engine not only uses a specialized search 4 http://www.coli.uni-sb.de/—zheng/answerbus/local/ 5 http://www.seventones.com/"]},{"title":"251","paragraphs":["engine for QA task, but also crawls and indexes CNN Web site automatically. Also, the special index system is different from other search engine index system in some aspects, for example, sentence level indexing ([4]), temporal indexing and partially updating.","As the results of the new techniques, AnswerBus News Engine is now able to answer some time sensitive questions about the some factual issues just happened half an hour ago."]},{"title":"2.2 Embedded Search Engine","paragraphs":["It is normal that some times a QA system cannot find any answer from the working knowledge base for a question. This doesn't mean there is no answer for the question. In this case, AnswerBus redirects the question to the embedded search engine so users will get a bunch of documents instead of answers. Very likely, if there is an answer to the question, the user can dig it out from the documents given by the search engine."]},{"title":"2.3 Scalability","paragraphs":["The current size of indexed data has been over 700K Web pages from CNN Web site and some of its sub sites. We believe that it has been the largest size of knowledge base for QA tasks at current time. And the designed size can be much bigger than the size we have already reached. This makes it possible for the future system to index the whole Web and answer questions."]},{"title":"2.4 Speed and System Load","paragraphs":["Because of the local indexing, AnswerBus is now able to find the possible answers for a user question in 2-4 seconds. This makes the system fast enough to process more documents to mine the answers.","This also decreases the system load than its previous systems and the system can answer more questions at the same time than its previous versions with same resource."]},{"title":"3 Web Interface","paragraphs":["The system has a Web interface as its previous versions. As in Figure 1, the system lists up to ten possible answers to a specific user question. Each of these answers has a dynamic link back to a specific CNN Web page containing the answer sentence. The navigation bar at the end provides an easy way to try user question with other online systems.","Figure 2 is a screen shot when the system could not find the proper answer and the redirected the user question to embedded search engine. This page only shows 20 items returned by the search engine."]},{"title":"4 Evaluation","paragraphs":["Evaluation of question answering techniques has been a very difficult task. It gets more difficult to evaluate this system because we don't have any baseline or comparable systems. And also because of the dynamic content, it is difficult to design a question set to do the evaluation like TREC.","However, the techniques used in this system and in its previous local archive version [7] are almost same. The evaluation data should be able to technically level the performance of the system.","We refer to the milestones described in [1] and designed a set of 50 questions, which covered all 16 Arthur Graesser s questions categories and three other question categories that ranged from easy to very difficult. The test result is very encouraging and the accuracy is 72% in top 1 and 80% in top 5 (Table 1).","We also compared our search engine results with the search result from the LookSmart search","• 6 engine used by CNN Web site, and the result from the Google site search'. We conclude that our system outperforms these systems.","Question-sentence matching formula used in original AnswerBus system was proved effective in Web-based QA system. However, in the new QA system, it is not working as good as in original AnswerBus QA system. The possible reasons include: 1) The text in CNN Web site is much more formal and the style is much more unique; 2) Fewer redundant information can be found in CNN Web site.","Restricted to the contents of CNN Web site, the system seems working better for news or politics related questions. 6 http://cnn.looksmart.com/r_search 7 http://www.google.com/search?q=site:cnn.com 252"]},{"title":"5 Conclusion\\t","paragraphs":["[4] Based on our experiment on our new QA system, we found that QA specific indexing and searching are quite feasible. Most techniques used in original AnswerBus System can be"]},{"title":"[5]","paragraphs":["scalable to large size knowledge base and still gets high accuracy."]},{"title":"References","paragraphs":["[1] John Burger et al. Issues, Tasks and Program \\t[6] Structures to Roadmap Research in Question & Answering (Q&A). N IS T: hap:11mmn lpir.n ist. go v/p roject s/duc/papers/qa. Roadmappaper_v2.doc 2001","[2] Zhiping Zheng. AnswerBus Question Answering [7] System. Human Language Technology Conference (HLT 2002). San Diego, CA. March 24-27, 2002."]},{"title":"131","paragraphs":["Zhiping Zheng. Developing a Web-based Question Answering System. The Eleventh World Wide Conference (VVWW 2002). Zhiping Zheng. Rule-based Sentence Segmentation for HTML/TEXT Documents. The Thirteenth meeting of Computational Linguistics in the Netherlands (CLIN 2002). Groningen, Netherlands. November 29 2002. Zhiping Zheng. Seven Tones: Search for Linguistics and Languages. The 2nd Meeting of the North American Chapter of Association for Computational Linguistics (NAACL 2001). Pittsburgh, PA. June 2-7, 2001. Zhiping Zheng and Gregor Erbach. Specialized search in linguistics and languages. XI International Conference on Computing (CIC 2002). Mexico City, Mexico. November 25-29, 2002. Zhiping Zheng, Huiyan Huang and Sven Schmeier. Deploying Web-based Question Answering System to Local Archive. Fifth International Conference on TEXT, SPEECH and DIALOGUE (TSD 2002). Brno, Czech Republic. September 9-12, 2002. Honolulu, HI. May 7-11,2002. Table 1. Evaluation on AnswerBus Local Archive","Question Type Number Topl Top5 Wrong 1. Verification 3 1 1 1 2. Comparison 2 0 1 1 3. Disjunctive 2 2 0 0 4. Concept Completion 6 5 0 1 5. Definition 6 5 0 1 6. Example 3 3 0 0 7. Interpretation 3 2 1 0 8. Feature Specification 5 5 0 0 9. Quantification 6 4 0 2 10. Causal antecedent 3 2 0 1 11. Cause Consequence 0 0 0 0 12. Goal orientation 1 1 0 0 13. Enablement 0 0 0 0 14. Instrumental/Procedural 1 1 0 0 15. Expectational 1 1 0 0 16. Judgmental 3 1 0 0 17. Assertion 3 1 1 1 18. Request/Directive 0 0 0 0 19. Nils question 2 0 0 2 253 /142- What's RelatedBookmarks .44 Lent"]},{"title":"-","paragraphs":["rani\\ttp iflormir cotrn ursi-sh de/rizhengormossrerlsus/nesrs/ormorer cgo File Edit View Go Communicato"]},{"title":"A","paragraphs":["Back\\tForward\\t Reload.\\tHorr. Help"]},{"title":"—ittopmw& 1","paragraphs":["11ic, man, hearts dogs \\t","ood,pas have,","Question: How many hearts does an octopus have? Possible answers: I found no answer for your question. You may find the answers in following web pages:","1. News for you -- Giant octopus, Raggedy Ann, mighty thumbs News for you -- Giant octopus, Raggedy Ann, mighty thumbs","2. Octopus seen reaching into China Octopus seen reaching into China","/IndeK.htnl","3. Giant octopus caught off NZ Giant octopus caught off NZ","4. Transcripts Called octopus cards, these smart cards emit a signal that talks to an electronic reader. It-bp \\t","CPT","GontrkanarRIrrs/0103/11/1_ea 00 1,11 7"]},{"title":"R","paragraphs":["File\\tEdit\\t'View\\t5p \\tCommunicator\\t 't4eii 4.\\t;a4\\tA\\t....:\\tA\\tKi\\tNe.\\t"]},{"title":"a","paragraphs":["Back\\tFOJAYMI. \\t Beloacf\\tHome\\tSearch.\\t•Vdetscapa\\tBrint.\\tSecurity\\tShop\\tStop ' BoOkmakka A\\tW"]},{"title":"-","paragraphs":["Fo . http /Minn, coli.uni-ab deirzhenglanswerlsoa/news/answer cgo.\\t","/kV' Wkrat's Related"]},{"title":"-14","paragraphs":["."]},{"title":"1","paragraphs":["10"]},{"title":"4","paragraphs":["Mak9 ;Ask'","Question: What is the origin of the Democratic Party's mascot? Possible answers: 1. While there is no ■recise data for the b\\t'nnin • of the Democratic ■ar\\tits ori 'n can be traced to the late 1700s when","Thomas Jefferson's Democratic-Republican party or • . nized opposition to the Federalist Party. 2. The 1828 'residential cam sal.\\tis also the On' \\tof the Democratic s ar\\t's mascot-- the donk 3. The 1828 campaign was also the origin of the Democratic Party's mascot -- the donkey.","Try, your question on other engines: Alta Vista I AnswerBus I Ask Jeeves I Excite I Goo& I HotBot I Lycos I Northern Light I Start I Yahoo iiki.-\\t. \\t' , i.p Q\\t%.0_,' I Figure 1. Screen Shot of AnswerBus News Engine (1) Figure 2. Screen Shot of AnswerBus News Engine (2)"]},{"title":"254","paragraphs":[]}]}