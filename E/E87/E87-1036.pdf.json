{"sections":[{"title":"","paragraphs":["DECLARATIVE NOOEL FOR DEPENDENCY PARSING - k VIEV INTO BLACKBOARD METHOOOLOGY","Vatkonen, K., Jippinen, H., Lehtota, A. and Ytltammi, N.","KIELIKOHE-pr~ject, SITRA Foundation P.O.Box 329, SF-00121Hetsinki","FinLand","teL. inti + 358 0 641"]},{"title":"877 ABSTRACT","paragraphs":["This paper presents a declarative, dependency constraint model for parsing an infLectionaL free word order Language, t|ke Finnish. The structure of Finnish sentences is described as partial dependency trees of depth one. Parsing becomes a nondeterministtc search problem in the forest of partial parse trees. The search process is able to solve also ambiguities and tong-distance dependencies. Parsing is controLLed by a blackboard system. A ~orking parser for Finnish has been implemented based on the modeL. 1 |RTROOUCT|OB The development of our computational model for dependency parsing has progressed in three parallel and interrelated phases: (1) The development of a perspicuous high Level grammar specification Language which grasps well regularities and"]},{"title":"idiosyncracies","paragraphs":["of inflectional free word order Languages. (2) The acquisition of a grammar using that Language as the description media. (3) The development of a parsing strategy and a compiler for the specification Language."]},{"title":"In","paragraphs":["our first approach the parsing process is described as a sequence of tocat decisions (Netimarkka et at. 1984). A pair of adjacent structures of an input sentence is connected if there exists a valid binary dependency relation between them. Binary relations are boolean expressions of the morphological and syntactic restrictions on argument structures. In that first version dependency sructures were modelled procedurally with finite two-way automata (Lehtota et at. 1985). Grammar descriptions turned out to be complicated to handle, and due to purely Local decisions some gtobat phenomena, such as tong-distance dependencies, were not analyzed. A new grammar description formalism and computational method was developed: a declarative high Level Language FUMDPL (J~ppinen et at. 1986) for a grammar, and an underlying blackboard-based parsing method (Vatkonen and Lehtota, 1986). Recently, we have augmented the"]},{"title":"dependency parsing","paragraphs":["model to cover also tong-distance dependencies. According to the augmented model we have implemented a"]},{"title":"blackboard-based","paragraphs":["dependency parser ADP (Augmented Dependency Parser). In this paper we shortly describe our model and focus on the parsing strategy. For the grammar development environment and the compilation of the high [ever description Language• see Lehtota et at. (1985 e 1986). Our parsing method belongs to the class of constraint systems: a user specifies the constraints holding in the problem domain, and a goat for the computation. The interpreter must search for the goal. The result follows indirectly from the search process, in our model binary relations specify constraints on argument"]},{"title":"structures.","paragraphs":["The goal is to find a matching Local environment description for each word of an input sentence. As a side effect of the recognition"]},{"title":"corresponding","paragraphs":["partial dependency trees are built. The partial dependency trees ere Linked into a parse tree covering the whole sentence (Figure 1).","PROOLEM SPAC(: p|rtt•l dependency trluu of depth one","GOAL: • complete por•l tree W4"]},{"title":"~L 6/~o","paragraphs":["w5 Sentence W I W z W 3 W 4 .. W n","Figure 1. Parsing as a search process in a forest of partial dependency trees."]},{"title":"218 2 GRANNAR OESCR|PTION","paragraphs":["For the development of a grammar notation idiosyncracies of the object Language had to be observed. Finnish is a relatively free word order language. The"]},{"title":"syntactic-semantic","paragraphs":["knowledge ts often expressed in the inflections of the words. Furthermore, the parser was needed to work as a practical toot for real production applications, so the process of parsing was taken as a starting point instead of sentence generation. A grammar description consists of four parts: (1) Type definitions: Linguistic properties, features and categories. (2) A lexicon for associating features with words. (3) Binary dependency relations that may hold between regents and their dependents. (4) Functional 8¢hemmta for defining the Local environments of regents. 2.1 Type definitions in the type definition part a grammar writer defines the types and their values used in a grammar description. This corresponds to the classification of Linguistic properties. There are three kinds of types: CATEGORIES, FEATURES end PROPERTIES. In addition to this the structure of the texical entries is described in this part. CATEGORY statement assigns names in hierarchies. For example, a category SyntCat for word classes could be defined as","(CATEGORY: SyntCat","< (Word) (Noun I Word) (Proper I Noun) (Common I Noun)","(Pronoun I Word) (PersPron I Pron) (OemPron I Pron) (;ntPron I Pron) In a FEATURE statement • feature name and tts values are defined. Values can be mutuaLLy exclusive: adding of the complement value automaticaLLy destroys the old value.","(FEATURE: SyntFeet","< (Locative) ;a name of a place (InfAttr) ;a noun, that may have an","tnfinittvial attribute (CountMessure) ;a countable measure noun °e. PROPERTY values are Like FEATURES except that they may have default values. For example: (PROPERTY: Polar < ( Pos ) Neg >) In this type definition polarity is positive by default. 2.2"]},{"title":"Lexicon","paragraphs":["The parser is preceded by a morphoLogicaL analyzer (J~ppinen and Ytitammi 1986). The morphological anatyzer produces for each word its morphological interpretation including texicat information. The parser associates default features for words. Those words which have"]},{"title":"idiosyncratic","paragraphs":["features, ms all verbs do, are in the parser~s Lexicon. Some example entries of the parser's lexicon: NETRi (Common (SubstNeasure)) HELSINKI (Proper (Locative)) AJATELLA (TrProcV (InfObj PsntisObj)) \"Netri\" (meter) is s measure unit for common nouns. \"Netsink{\" ts s proper noun and a name of a place. \"Ajatetla\" (to think) Js a transitive verb that may have infinittvtat or participle objects. 2.3 Binary dependency retations The dependency parsing model aims at providing analyzed sentences with their dependency trees. According to this approach two elements of • sentence are directly related in a dependency relation tf one depends on another. The two elements ere catted the regent R (or head or governer) and the dependent 0 (or modifier). Binary relations define all permitted dependency relations that may exist between two words in Finnish sentences. For example, the binary relation Subject is the following boolean expression of the morphological end syntactic features of a finite verb and its nominal subject:","(RELATION: Subject (D := Subject)","((R = Verb Act (< lad Cond Imper Pot Ilpartis > (PersonP O)(PersonN D) - Negative - Auxiliary) (Auxiliary llpertis Nom - Negative) (Negative • limper Pr • (S 2P) Neg >)","(Cond Pr S 3P) (Pot Pr Neg)","(IIpartis Nom)> - Auxiliary)>)","(D • PersPron Nom))... R must be an active verb. Further restrictions for it"]},{"title":"219","paragraphs":["appear within angle brackets that indicates a disjunction. Negation is expressed by \"-\". (PersonP D) (PersonH D) indicates an agreement test. O must be e personal pronoun in nominative case in this fragment. In our computational model words of an input sentence appear as complexes of their morphological, syntactical end semantic properties. We call this complex a constituent. If • binary relation holds between R and D, they ere adjoined into a single constituent. This ts what we mean by a functional description. It can be stated formally as mopping f(R,D) -> R I where R' stands for the regent R after that it has bound D. Function f is defined by the corresponding binary relation. This function abstraction should be distinguished from grammatical functions, even though in our grammar specification dependency relations also estimate grammatical functions. 2.4 Functional schemata In functional schemata the Local environment of a regent is described by dependency functions. Functional schemata can be seen as partial dependency tree descriptions. A simplified schema for verb phrases, when a regent is • transitive verb and it is preceeded by s negative auxiliary verb, could be defined aS","(SCHEHA: NegTronsVerb","WHEN (AND (R • ProcVerb Act Transitive)","(LEFT • Auxiliary Negative))","FUNCTIONS (NULTIPLE Adverbial)","(OBLIGATORY Negation Subject Object)","(LEFT Negation Subject Object Adverbial)","(RIGHT Object Subject Adverbial)","HARK (R := VerbP)) This scheme is able to recognize end build, for instance, pertlet dependency trees shown in Figure 2. ¥mr~ WMrt~ Ver~ svb~ eeg eb} subl nag e~v e~| eaj s~j mql Figure 2. Example trees built by a schema NegTransVerb. There ere three parts in the simplified schema NegTransVerb: WHEN. FUMCTIOIIS end HARK. WHEN pert describes features for the regent and its context. FUNCTIONS part describes the dependents for the regent. NULT|PLE clause indicates which dependents may exist multiple times. OBLIGATORY names obligatory dependents. LEFT end RIGHT give the structure of the left and right context of the regent. The free word order is allowed by default because of the particular interpretation of the clauses LEFT and RIGHT. The definition only indicates which dependents exist in the named context, not their mutual order. ALl the permutations ere attoued. There is also means of fixing yard ordering. ORDER clause indicates mutual ordering of dependents. For example, a grammar writer may define for the simple NP#s (ORDER AdjAttr GenAttr R RelAttr) For this particular regent the most immediate Left netghbour must be a genetive attribute. The next to that is an adjective attribute. The right netghbour is a relative clause. For tong-distmnce dependencies the Local decision strategy must be augmented. The binding of |ong-dJstance dependents has two phases: the recognition end the actual binding. In transformational grammar, tong-distance dependencies ere dealt with by assuming that in the deep structure the missing word is in the place it would be in the corresponding simple sentence. It is then moved or deleted by a transformation. The essential point is that tong-distance dependency is caused by an element which has moved from the Local environment of • regent to the Local environment of another regent. Hence a moved element must be recognized by the functional schema associated with that Latter regent. The binding, then, is done Later on by the schema of the former regent. In the recognition phase the tong-distance dependents are recognized and bound \"sway\" (captured), so that the current regent can govern its environment. After this capture the possible Long-distance dependent remains waiting for binding by another scheme. Capturing dependency functions are marked tn the CAPTURE clause: (CAPTURE DistantNember) The dependency function DistentNember is general enough to capture all possible tong-distant dependents. For the actual binding of tong-distance dependents, one must mark in the clause DISTANT the dependents which may be distant: (DISTANT Object)"]},{"title":"220 3 BLACKBOARD-BASED CONTROL FOB DEPENDENCY PARSING","paragraphs":["BLackboard ts a problem-solving model for expert systems (Hayes-Both et at. 1983, Nii 1986). We have adopted that concept end utilized it for parsing purposes. Our blackboard model application is rather simple (Figure 3). There are three main components: • blackboard, m control part end knowledge sources. The blackboard contains the active environment description for a regent. According to the structural knowledge in that environment description corresponding partial parse tree is built in the blackboard. Also all other changes in the state of computation are marked in the blackboard. Functional schemata and binary dependency relations are independent and separate knowledge sources; no communication happens between them. Art data flow takes place through the blackboard. Which module of knowledge to appty is determined dynemicalty, one step at • time, resulting in the incremental generation of partial solutions. In functional schemata s grammar writer has described Local environments for regents by dependency functions. The schemata are compiled into an internal LXSP-form. At s time, only one of the schemata is chosen as an active environment description for the current regent. The activated schema is matched with the environment of the regent by binary relation tests. The binary relations respond to the changes in the blackboard according to the structural description in the active schema and the properties of the regent and dependent candidates. At the same the partial dependency tree is built by corresponding dependency function applications. When s schema has been fully matched end the active regent bound to its dependents through function Links, the Local partial dependency parse is complete. A scheduler for knowledge sources controls the whole system. It monitors the changes on the blackboard and decides Mhat actions to take next. The scheduler employs • finite two-way automaton for recognition of the dependents. I"]},{"title":"BLACKBOARD KNOWLEDGE SOURCES ,...,,v. i i,._.x.i environment description Functional schemata Partial solutions (local dependenc U trees) .... I~ -\"*l dependencu Other computational state uoLa --I relations -- oon, o, ,,0 0o,o ] CONTROL","paragraphs":["figure 3. A blackboard model for dependency parsing."]},{"title":"221","paragraphs":["3.1 The blackboard-based control strategy for dependency parsing For the format definition of the parsing process we describe the input sentence as a sequence (c(1),c(2),...,c(i-1), c(i), c(i+l),...,c(n)) of word constituents. With each constituent c(i) there is associated a set (s(i,1),...,s(i,m)) of functional schemata. The general parsing strategy for each word constituent c(t) can be modelled using • transition network. During parsing there ere five possible computational states for each constituent c(i):","Sl The initial state. One of the schemata associated with ctt) is activated. S2 Left dependent• ere searched for c(i).","$3 c(i) is waiting for the building of the right context. 1) A schema candidate s(iek) associated with c(t) is activated, i.e. the constituent c(t) take• the rote of a regent. Following the environment description in s(i,k), dependents for c(i) are searched from its immediate neighbourhood. Go to the step 2 with j • i-1. 2) The search of left dependents. There are two subcases: 2a) There are no left neighbours (j = 0), none is expected for c(i), or c(j) (j < i) exists and is in the •tats $3. Go to the step 3 with j = j+l. 2b) c(j) (j x i) exists and is in the state SS. Binary relation tests are done. In the case o? a • ucces the lipping f(c(i), c(j)) -> c(i)' takes place. Repeat the •tap 2 with j - j-1 end c(i) = cti),. S4 S5 Right dependent• are searched for c(i). The final state. The schema associated with c(i) has been fully matched and becomes inactive, c(i) is the head of the completed (partial) dependency tree. At any time, only one schema is active, i.e. only one constituent c(i) may be in the state B2 or S4. Only s completed constituent (one in the •tale S5) is allowed to be bound as s dependent for • regent. There may be s number of constituents simultaneously in the state S3. We call these pending constituent• (implemented as a •tack PENDING). 3) Building the right context of the regent. There are two subcases: 3a) There ere no right neighbours (j • n) or none is expected for c(i). Go to the •tap 5. 3b) c(j) (j • i) exists. Go to the step 1 with c(i) : c(i+l) and PENDING = push (c(i), PEND%MG). 4) The search of right dependents. Binary relation tests are done. in the case of succes the mapping f(c(i), c(j)) -> c(i) ~ takes place. Repeat the step 3 with j = j+l and c(i) = c(i)'. 5) The final state. There are two subcases: The parsing process •tarts with c(1) •nd proceeds to the right. Initially all constituents c(1),..,c(n) are in the •tats el. A sentence is welt formed if in the end of the parsing process the result i• • •ingle constituent that has reached the state S$ and contain• all other constituents bound In it• dependency tree. For each constituent c(i) the parsing process can be described by the following five steps. Parsing begins from the •tap 1 with i,k = 1. 5a) The environment description has been matched. if there remains no unbound c(j)'s (j < i or j > i) the sentence is parsed. If c(i+l) exists go to the step 1 with i = i+1. if c(i+l) doesn't exist or the steps followed previous case returned a failure, go to the step 4 with c(i) • pop (PENDING). 5b) The environment description h•• not been matched. Return a failure. 2b 4 ...........","Figure 4. The transition network model of the control strategy."]},{"title":"222","paragraphs":["3.2 The implementation of the control atrategy The control system has two levels: the basic level employs a generat two-way automaton and the upper level uses a blackboard system. There is a ctear correspondence between the grammar description and the control system: the two-way automaton makes local decisions according to the binary relations. These local decisions are controlled by the blackboard system which utilizes the environment descriptions written in the schemata. This two-level control model has certain advantages. The two-way automaton is computationalty efficient in local decisions. On the other hand, the blackboard system is able to utilize global knowledge of the input sentence. ChronoLogicat backtracking To account for ambiguities there are three kinds of backtracking points in the control system. Backtracking may be done in regard to choice of dependency functions, homographic word forms, or associated schemata. Backtracking is chronological. In our system a constituent c(|) may contain several different morphotactic interpretations of a word form. Function backtracking takes place if there are several possible binary relations between a given constituent pair. The preconditions of the schemata may allow multiple schema candidates for a given constituent. All alternatives are gone through one by one, if necessary, in chronological backtracking. As a result, the system may perform an exhaustive search and produce all possible solutions. Register for tong-distance dependencies The recognition of possible fond-distant dependencies is done by the capture function. An element is bound as a possible \"distant member\" in the context where the capture function fires. An element is also moved to the special register for s set of distant elements. The actual binding is done by the distant function from another schema. In chronological backtracking also distant bindings are undone. The strategy of local decisions controlled by global knowledge of the input sentence yields a strongly data-driven, taft-to-right and bottom-up parse whereby partial dependency trees are built proceeding from middle to out. 3.3 EZANPLES To v|suatize our discussion, a functional schema IntrllapNegVP is described in Figure 5. A grammar writer has declared in WHEN-part that R must be a transitive process verb in active tense snd Imperative mood. In its taft context there must be a negative verb in imperative mood and of the textcat form \"El\" (\"NOT\"). There is one obligatory dependency retstion HegVerb. Adverbials may exist multiple times. A grammar writer has written in clauses LEFT and RIGHT the left and right context binary relations of the regent. After the schema has fully matched, the regent is marked VerbP and features PersonH and PersonP of the dependent recognized as HegVerb are marked for the regent.","($CHEHA: lntrlmperNegVP","WHEN (AND","(R : ProcVerb Act Imper (NOT VerbTr))","(Left = 'E% Imper))","FUNCTIONS (OBLIGATORY NegVerb) (NULTIPLE AdverbiaL) (LEFT NegVerb Adverbial Connect) (RIGHT AdverbiaL)",")lARK (R :- VerbP (RecNegVerb (PersonP PersonH))) ) Figure S. A functional schema lntrlmperMegVP A futt trace of parsing the sentence \"~ti eksy mets~ss~l\" (Don't get lost in s forest) appears in Figure 6. Parsing starts from the taft Can arrow). Next tins indicates the selected schema and dependents that are tested. The first word \"itS\" is identified ms a negative imperative verb with no dependents (schema DummyVP ok). The imperative verb \"eksy\" (to get lost) is then tried by the schema IntrlmperNegVP. The binary relation NegVerb holds between the two verbs, and the corresponding dependency function adjoins them. The othen functions fail. Dependents are searched next from the right context. The control proceeds to the word \"mets~ss~\" (forest). For that word no dependents are found and the system returns to the unfinished regent \"eksy\". The schema IntrlmperNegVP has onty two relations remaining: Connect and Adverb|at. The word \"nets~ss~\" is bound as an adverbial. The schema has been fully matched and the Input sentence is completely parsed."]},{"title":"223","paragraphs":["> it~ eksy metsissil NORFO: ((((\"iti\" EI Verb Act Imper Pr S /2P/))) (((\"eksy\" EKSY~ Verb Act Imper Pr S /2P/))) (((\"metsissi\" METSX Noun SG In))) (((\"!\" EXCLAMATION)))) :> (iti) (eksy) (metsissi) Schema: OummyVP nit OummyVP ok (iti) :> (eksy) (metsissi) Schema: lntrlmperNegVP (Negverb Adverbial Connect) NegVerb ok Adverbial failed Connect failed ((iti) eksy) => (metsissi) Schema: TriviatSP (DefPart R) DefPart failed TrivialSP ok","returning to unfinished constituent... ((ili) eksy) <= (metsissi) Schema: IntrlmperNegVP (Connect Adverbial) Adverbial ok IntrlmperNegVP ok => ((iti) eksy (metstssi)) PARSED The parse took 0.87 seconds CPU-time on VAX-11/751. Figure 6. An example of parsing. The second example shows how our parser solves the following sentence (adopted from Karttunen, 1986b) which has a tong-distance dependency: En mini tennisti a|o ruveta petaamaan. not I tennis intend start play I do not intend to start to play tennis. The object of the subordinated infinitiviat clause (\"tennisti\") has been raised in the main clause thus creating a gap. The parse tree of the sentence is in Figure 7. aid Predicate","I","......... • ......... • ......... ÷ ......... • I I I I en mini tenni$tl ruvetl","Negation Subject Distant(I) Object","i","i","peteamaen","Adverbial","I",". ......... +","I","tennilti","Object(I) Figure 7. An example of a tong-distance dependency. In the parsing process the schema NO-VP has matched the environment of the verb \"a|o\" (intend) and the schema O-LocativeVP of the verb \"peLaamaan\" (play). (SCHEMA: NO-VP ASSUME (R :, Negative) FUNCTIONS (OBLIGATORY Object Negation)","(KULTIPLE Adverb|at OistentMember)","(LEFT Auxiliary Negation Object Adverbial Connector)","(RIGHT Object Adverbial Cor~'na)","(CAPTURE OistantNember) CLAUSE READY CHEC~ (VerbObjCongr Negation Object) MARK (R := ProcVP Predicate (Negation (PersonP PersonN))) ) (SCHEHA: FUNCTIONS MARK ) O-LocativeVP (OBLIGATORY Object) (HULTIPLE Adverbial OistentNember) (RIGHT Object Adverbial) (LEFT Object Adverbiat) (CAPTURE P|stantRember) (DISTANT Object Adverb|it) (R :s LocetlveVP Pred|cete) The schema NO-VP has captured the word \"tennisti\" as a DistantNember. The schema O-LocattveVP has Later on bound it as a removed Object. 4 COliPARISON The notion of unification has recently emerged as a common descriptive device in many Linguistic theories Like FUG, PATR-[[ and HPSG (Shieber 1986). Another popular approach has been to apply attribute grammars originally developed as a theory for formal Languages (gnuth 1968). LFG and OCG can be viewed as attribute grammar systems. The trend has been towards strictly declarative descriptions of syntactic structure. Syntactic rules are often expressed in the form of complex feature sets. Our ADP system also uses features, but differs both from the unification-based approach and attribute grammar approach. The basic difference is, of course, that there is neither unification nor correspondence to attribute grammars in our system. We use a pattern matching via binary relation tests. Through blackboard approach we have gained a flexible control. Blackboard system can conveniently take into account global knowledge of the sentence. In our model dependents become \"hidden\" from further processing once they have been found. A regent solely represents the constituents hanging below. This makes the parsing process simpler as the number of constituents decreases during parsing. There ere, however, some cases where some information must be raised from the dependent to the regent (e.g. from conjuncts to the conjunction), so that the regent could represent the whole constituent."]},{"title":"224","paragraphs":["5 CONCLUSION In our system linguistic knowledge and processing mechanisms are separated. Structural information of the functional schemata is interpreted by the blackboard scheduler as control knowledge, according to which dependencies are searched. The difference between local and global decisions is clearly separated. Locat decisions controlled by global knowledge of the input sentence has made it possible to find solutions for problems that are difficult to solve in traditional parsing systems. ADP finds all solutions for an ambiguous sentence. Augmented search process covers tong-distance dependencies as well. Different criteria have been expressed for grammar formalisms (Winogrsd 1983, Karttunen 1986a): perspicuity, nondirectionstity, correspondence with meanings, multiple dimensions of patterning, order-independency, declarativeness and monotontc~ty. Our model rates welt in most of these criteria. Perspicuity, correspondence with meanings and dectarsttveness are satisfied in the way the functional schemata describe local environments for regents. The functional description is monotonic and allows multiple dimensions of patterning. There is s process of parsing as s starting point in the grammar specification, so it lacks nondirectionatity. The weakest point is the order-dependent control mechanism, albeit the grammar description is order-lndependent. Plans for the general, order-independent control strategy have been done. ADP has been implemented in FranzLisp. Experiments w~tn a non-trivial set of Finnish sentence structures has been performed on VAX 11/751 system. An average time for parsing a six word sentence is between 0.5 and 2.0 seconds for the first parse. At the moment the grammar description contains common sentence structures quite well. There are 66 binary relations, 188 functional schemata and 1800 lexicon entries. The lexicon of the morphological analyzer contains 35 000 words. ACKNOWLEDGENENT$ This research has been supported by SlTRA Foundation. REFERENCES Hayes-Roth, F., Waterman, D. and Lenat, D. 1983 Buitding Expert Systems. Addison-Wesley Publishing Company, Reading. Jappinen, H. and Ytitammi, N. 1986 Associative Nodel of Norphotogicat Analysis: an Empirical Inquiry. Computational Linguistics, Volume 12, Number 4, October-December 1986, pp. 257-272. Jappinen, H., Lehtola, A. and Vatkonen, K. 1986 Functional Structures for Parsing Dependency Constraints. Proceedings of COLING861ACL, Bonn, pp. 461-463. Karttunen, L. and Kay, H. 1985 Parsing in a free word order Language. In Dowry, Karttunen and Zwicky (Eds.), Natural Language Parsing, Cambridge University Press. garttunen, L. 1986a The Relevance of Computational Linguistics. A paper presented at the Conference on Finnish Linguistics. Karttunen, L. 1986b Radical Lexicatism. A paper presented at a Conference on Alternative Conceptions of Phrase Structure, New York. Knuth, D. 1968 Semantics of Context-Free Languages. Nathematicat Systems Theory 2(1968a), pp. 127-145. Lehtots, A., Jippinen, H. and Netimarkka, E. 1985 Language-based Environment for Natural Language Parsing. Proceedings of the 2nd European Conference of ACL, Geneva, pp. 98-106. Lehtots, A. and Vatkonen, K. 1986 Knowledge Representation Formalisms and Netsdescriptions for the Interpretation of Finnish. Proceedings of the Third Finnish Symposium on Theoretical Computer Science, pp. 64-87. Netimarkka, E., Jipptnen, H., and Lehtots, A. 1984 Parsing an inflectional free word order language with two-way finite automata. Proceedings of the 6th European Conference on Artificial Intelligence, Piss, pp. 167-176. Also in O'Shea, T. tEd.), Advances in Artificial Intelligence, North-Holland. Nii, N. 1986 Blackboard Systems: The Blackboard Nodet of Problem Solving and the Evolution of gtackboard Architectures. The AI Nagazine, Summer 1986, pp. 38-53, August 1986, pp. 82-106. Shieber, S. 1986 An Introduction to Unification-Based Approaches to Grammar. CSLI Lecture Notes Series, No. 4. Vatkonen, K. and Lehtola, A. 1986 Blackboard Control for Dependency Parsing. A paper presented in Nordisk seminar am maskinoversattetse, 9.-11.10 1986, University of Copenhagen, 12 p. (in print). Winograd, T. 1983 Language as a Cognitive Process. Volume I: Syntax. Addison-Wesley."]},{"title":"225","paragraphs":[]}]}