{"sections":[{"title":"Tree-Adjoining Grammar Parsing and Boolean Matrix Multiplication","paragraphs":["Giorgio Satta *t Universita di Venezia"]},{"title":"The computational problem of parsing a sentence in a tree-adjoining language is investigated. An interesting relation is studied between this problem and the well-known computational problem of Boolean matrix multiplication: it is shown that any algorithm for the solution of the former problem can easily be converted into an algorithm for the solution of the latter problem. This result bears on at least two important computational issues. First, we realize that a straightforward method that improves the known upper bound for tree-adjoining grammar parsing is hard to find. Second, we understand which features of the tree-adjoining grammar parsing problem are responsible for the claimed difficulty. 1. Introduction","paragraphs":["Among formalisms for the computation of syntactic description of natural language sentences, Tree-Adjoining Grammars (TAG) play a major role. The class of TAG's was first introduced in Joshi, Levy, and Takahashi (1975) and Joshi (1985); since then, formal and computational properties of this class have been extensively investigated, and the linguistic relevance of TAGs has been discussed in the literature as well. The reader who is interested in these topics is referred to some of the most recent works, for example Schabes (1990) and Frank (1992), and to the references therein.","Both in a theoretical vein and in view of possible natural language processing applications, the recognition and parsing problems for TAGs have been extensively studied and many algorithms have been proposed for their solution. On the basis of tabular techniques, the least time upper bound that has been attested is O(I G II w I 6) for the random-access model of computation, I GI being the size of the input grammar and I wl the length of the input string. In recent years, improvement of such a worst-case running time has been a common goal for many researchers, but up to the present time the TAG parsing problem has strongly resisted all such attempts. Because of the record of all these efforts, the task of improving the above upper bound is actually regarded as a difficult one by many researchers.","In support of such a common feeling, in this paper we restate the TAG parsing problem as a search problem and relate it to the well-known computational problem of Boolean matrix multiplication. This is done in such a way that time upper bounds for TAG parsing can be transferred to time upper bounds for the latter problem. More precisely, we show that any algorithm for TAG parsing that improves the"]},{"title":"O(IGIJwl 6)","paragraphs":["time upper bound can be converted into an algorithm for Boolean matrix multiplication running in less than O(m 3) time, m being the order of the input • Universita di Venezia, Scienze dell'Informazione, via Torino, 155, 30172 Mestre-Venezia, Italy. E-mail: satta@moo.dsi.unive.it. t This research was done while the author was a post-doctoral fellow at the Institute for Research in Cognitive Science, University of Pennsylvania, 3401 Walnut Street, Philadelphia, PA 19104~228, USA. (~) 1994 Association for Computational Linguistics Computational Linguistics Volume 20, Number 2 matrices. Crucially, Boolean matrix multiplication has been the object of ~nvestigation for many Years: methods that are asymptotically faster than O(m 3) are known, but the more considerable the improvement turned out to be, the more complex the involved computation was found to be. At the present time, the asymptotically fastest algorithms for Boolean matrix multiplication are considered to be only of theoretical interest, because the huge constants involved in the running time of these methods render prohibitive any practical application, given current computer hardware.","As a matter of fact, the design of practical algorithms for Boolean matrix multiplication that considerably improve the cubic time upper bound is regarded as a very difficult enterprise. A consequence of the results presented in this paper is that TAG parsing should also be considered as having the status of a problem that is \"hard to improve,\" and there is enough evidence to think that methods for TAG parsing that are asymptotically faster than O(] G I[w ]6) are unlikely to be of any practical interest, i.e., will involve very complex computations.","The remaining part of this paper is organized as follows. The next section presents the definition of tree-adjoining grammar and introduces the two computational problems that are to be related. Section 3 establishes the main result. Section 4 draws on the computational consequences of such a result and reports some discussion. Finally, Section 5 concludes by indicating how similar results can be found for variants of the TAG parsing problem that have been recently discussed in the literature."]},{"title":"2. Preliminaries","paragraphs":["This section introduces the Boolean matrix multiplication problem and the tree-adjoining grammar parsing problem, along with the definition of tree-adjoining grammar. The notation presented here will be used throughout the paper."]},{"title":"2.1 Boolean Matrix Multiplication","paragraphs":["Let/3 -- {0, 1} be the set of truth values. The logical symbols V,/x are defined as usual. The set of Boolean square matrices Bin, m _> 1, is defined as the set of all m x m square matrices whose elements belong to/3. Given a matrix A c Bm, we say that A has"]},{"title":"order","paragraphs":["m; the element in the ith row and jth column of A is denoted by aij. In Bin, the"]},{"title":"product","paragraphs":["of A and B, written A x B, is a Boolean matrix C such that:","m CiJ ~- V aik /~"]},{"title":"bkj,","paragraphs":["1 <_"]},{"title":"i,j","paragraphs":["<_ m. (1) k~l An instance of the"]},{"title":"Boolean matrix multiplication problem is therefore a pair (A, B)","paragraphs":["and the solution to such an instance consists of the matrix C such that C = A x B. In what follows BMM will denote the set of all possible instances of the Boolean matrix multiplication problem."]},{"title":"2.2 Tree-Adjoining Grammars","paragraphs":["The definition of TAG and the associated notion of derivation are briefly introduced in the following; the reader is also referred to the standard literature (see, for instance, Vijay-Shanker and Joshi [1985] or Joshi, Vijay-Shanker, and Weir [1991]).","A"]},{"title":"tree-adjoining grammar","paragraphs":["is a tree rewriting system denoted by a tuple G = (VN, VT, S, I, A), where VN and VT are finite, disjoint sets of"]},{"title":"nonterminal and terminal","paragraphs":["symbols respectively, S E VN is a distinguished symbol, and I and A are finite sets of"]},{"title":"elementary","paragraphs":["trees. Trees in ! and A are called"]},{"title":"initial and auxiliary","paragraphs":["trees respectively and meet the following specifications. Internal (nonleaf) nodes in an elementary tree 174 Giorgio Satta Tree-Adjoining Grammar Parsing initial tree S"]},{"title":"<.","paragraphs":["auxiliary tro~ A ,4"]},{"title":"d d","paragraphs":["terminal nodes (a) adjunction ,4"]},{"title":"> (b) Figure 1","paragraphs":["Definitions of (a) initial and auxiliary trees and (b) adjunction operation. are labeled by symbols in VN. An initial tree has a root labeled by S and leaf nodes labeled by symbols in VT U {¢}. An auxiliary tree has leaf nodes labeled by symbols in VT U {C} with the addition of one node, called the foot node, having the same nonterminal label as the root node (see Figure la). We define the size of G, written I G ], to be the total number of nodes in all the trees in the set I U A. In what follows we will also denote by TAG the class of all tree-adjoining grammars.","In TAG, the notion of derivation is based on a composition operation called adjunction, defined in the following way. Let 3' be an auxiliary tree having its root (and foot node) labeled by A E VN. Let also 3'' be any tree containing a node ~? labeled by A, and let ~- be the subtree of 3'' rooted in 7. The adjunction of 3' into 3'' at node ~? results in a tree specified as follows (see Figure lb): (i) the subtree ~- is excised from 3'̀;","(ii) the auxiliary tree 3' replaces T in 3'', with the root of 3\" replacing the excised node ~?;","(iii) the subtree ~- is attached to the resulting tree, with the foot node of 3\" replacing ~/in T. In TAG a derivation is the process of recursive composition of elementary trees using the adjunction operation; the resulting trees are called derived trees. Since adjunctions at different nodes can be performed in any order, we can adjoin derived trees into derived trees without affecting our arguments. 175 Computational Linguistics Volume 20, Number 2"]},{"title":"S","paragraphs":["z2 Figure 2 Parse tree 3'' is included in a parse tree of string w = ZlXZ2yz3 in L(G). We say that the derivation of string pair Ix, Y/is a subderivation of a sentential derivation of w. 2.3 Tree-Adjoining Grammar Parsing In order to introduce the definition of the TAG parsing problem on which our results are based, we define in the following the string language derived from a TAG and discuss the notion of parse forest along with the important issue of its representation. Given an alphabet V, we denote by V* the set of all finite strings over V (null string c included).","Although TAG is a class of tree rewriting systems, a derivation relation can be defined on strings in the following way. Let 3' be an elementary tree and let \"7' be a tree obtained from \"7 by means of zero or more adjunction operations. If the yield of \"7' is a string x E V~, that is -y E /, we say that \"7 derives x in G. If the yield of 3, / is a string xAy E V,~VNV,~, that is \"y E A, we say that 3, derives the pair (x,y) in G. In particular, the set of all strings in V~ that can be derived in G is denoted by L(G). In this perspective then, an elementary or a derived tree is seen as a structural description of a string (a pair of strings) derived by the grammar; such a description is called a parse tree. The space of all parse trees associated with a given string by the grammar is called a parse forest.","We introduce now the notion of subderivation. Let w be a sentence in L(G) and let ~, E A derive the pair (xt Y/in G, x, y E V~, with an associated parse tree -y'. If 7' is included in a parse tree of w, we have that w = ZlXZ2yz3 for some zl, z2~ z3 E V~ (see Figure 2). Parse tree \"7' represents the contribution of auxiliary tree 3' to a derivation of w; we say therefore that the derivation of /x~ Y/ from \"7 is a subderivation of a sentential derivation of w. As a consequence of the definition of parse forest, we have that all subderivations of the sentential derivations of w can be read off from the parse forest of w. Part of this information will be used to establish our result, as precisely stated in the next definition. We need some additional notation. Let w =- dld2\"\"dn, n > 0, be a string over some alphabet; symbol pWq denotes the substring dpdp+l ... dq for 1 _< p < q < n and is undefined otherwise. Definition 1 Let G = (VN, VTt St It A) be a tree-adjoining grammar and w E V~ be an input string, I wI = n, n > 0. A parse relation Rp C A x {1..n} 4 associated with the pair /G, w / is specified as follows. For every auxiliary tree \"y in G and for natural numbers p, q~ r and 176 Giorgio Satta Tree-Adjoining Grammar Parsing s, 1 < p < q < r < s < n, Rp(7,p,q,r,s) holds if and only if:"]},{"title":"(i)","paragraphs":["(ii) the pair"]},{"title":"(pWq~","paragraphs":["rWs) can be derived by 7 in G, and the derivation in (i) is a subderivation of a sentential derivation of w in G.","The goal of a parsing algorithm for TAG is one of constructing a \"suitable\" representation for the parse forest of a given string, with respect to a given grammar. However, there is no common agreement in the literature on the requirements that such a representation should meet; therefore the issue of the representation of a parse forest deserves some discussion here.","There seems to be a trade-off between computational timeand space in choosing among different representations of a parse forest. Note that, from an extreme perspective, the input itself can be considered as a highly compressed representation of the parse forest--one that needs a time-expensive process for parse tree retrieval. 1 More explicit representations offer the advantage of time-efficient retrieval of parse trees, at the cost of an increase in storage resources. In practice, most commonly used algorithms solve the parsing problem for TAGs by computing a superset of a parse relation (defined as above) and by representing it in such a way that its instances can be tested in constant time; such a condition is satisfied by the methods reported in Vijay-Shanker and Joshi (1985), Schabes and Joshi (1988), Palis, Schende, and Wei (1990), Schabes (1991), Lavelli and Satta (1991), Lang (1992), and Vijay-Shanker and Weir (1993). From such a representation, time-efficient computations can be used later to retrieve parse structures of the input string.","On the basis of the previous observation, we assume in the following that the solution of the parsing problem involves (at least) the computation of a representation for Rp such that its instances can be tested in constant time: we base our results on such an assumption. More precisely, an input instance of the tree-adjoining"]},{"title":"grammar parsing problem","paragraphs":["is defined to be any pair (G, w), and the unique solution of such an instance is provided by an explicit representation of relation (set) Rp associated with (G, w) as in Definition 1. In what follows, TGP will represent the set of all instances of the tree-adjoining grammar parsing problem."]},{"title":"3. Technical Part","paragraphs":["In this section the Boolean matrix multiplication problem is related to the tree-adjoining grammar parsing problem, establishing the major result of this paper. A precise specification of the studied reduction is preceded by an informal discussion of the general idea underlying the construction."]},{"title":"3.1 The Basic Approach","paragraphs":["Two maps ~ and ~ will be studied in this section. Map ~c establishes a correspondence between the set BMM and a proper subset of TGP containing, in some sense, its most difficult instances. Conversely, map ~ is defined on the set of solutions of all TGP problems in the image of Y', and gives values in the set of Boolean square matrices. Maps ~ and G are defined in such a way that, given any algorithm for the solution of the TGP problem, we can effectively construct an algorithm for the solution of the BMM problem using the commutative diagram shown in Figure 3. 1 I owe this observation to Bernard Lang (personal communication). 177 Computational Linguistics Volume 20, Number 2","multiplication <,4, B> in BMM \" C = A × B","parsing <G, w> in TGP , Rp Figure 3 Maps ~- and ~ define a commutative diagram with respect to any algorithm for Boolean matrix multiplication and any parsing algorithm for tree-adjoining grammars.","Both the BMM and the TGP problems are viewed here as search problems whose solutions are obtained by exploring a search space of elementary combinations. In the case of the BMM problem, the elementary combinations are the combinations of elements of the input matrices. If m is the order of these matrices, the solution of the problem requires the specification of O(m 2) elements of the product matrix, where each element depends upon O(m) elementary combinations (see relation (1)). Therefore the problem involves a search in a space of O(m 3) different combinations. On the other hand, in the TGP problem the elementary combinations are taken to be single applications of the adjunction operation. In parsing a string w of length n according to a tree-adjoining grammar G, we have to construct a parse relation of size O(I G In 4) (see Definition 1), and there are O(n 2) distinguishable combinations in which each element of the relation can be obtained. In the general case then, a number O(I G"]},{"title":"In 6)","paragraphs":["of distinguishable combinations are involved in the parsing problem, and we have to perform a search within an abstract space of this size.","In order to achieve our result, we then establish a size preserving correspondence between the two search spaces above. There is no way of representing matrices A and B within string w without blowing up the search space associated with the target parsing problem. Our choice will then be to represent the input matrices by means of grammar G, which fixes I GI to a quantity O(m2). This forces the choice of n to a quantity O(m~), obtaining therefore the desired relation I G In 6"]},{"title":"= O(1/'/3).","paragraphs":["The general idea underlying the construction is the following one. Observe that non-null elements aik and bk,j in the input matrices force element cij to value 1 in the product matrix if and only if k = k t. The check of such a condition can be transferred to the computation of an adjunction operation in the target parsing problem using the following encoding method. We fix a positive integer b to a (rounded) quantity m~. Then we encode each index i of the input matrices by means of positive integers il, /2, and i3, such that il is O(b 4) and i2, is are O(b). Condition k = k t above is therefore reduced to the three tests kh = k~, 1 < h < 3, which can be performed independently. The test kl = k~ is precompiled into some auxiliary tree of G; the tests k2 = k~ and k3 = k~ are performed by the parser using the input string, as explained below.","Map ~- constructs a string w of distinguishable symbols by concatenating six \"slices\" w (h), 1 < h < 6, each slice of length O(b). Map ~- also encodes the input matrices A and B within the target grammar G; it does so by transforming each non-null element in the input matrices into an auxiliary tree of G in the following way. Non-null element aik is mapped into an auxiliary tree \"~1 having its root (and foot node) 178 Giorgio Satta Tree-Adjoining Grammar Parsing","!","i",", , X 2 !","I"]},{"title":"k; / k3+l J3 1 Y2 , \\ J2 Figure 4","paragraphs":["String w is composed of six slices, and auxiliary trees corresponding to non-null elements"]},{"title":"aik","paragraphs":["and"]},{"title":"bk'j","paragraphs":["derive string pairs (xl, yl} and (x2, y2} matching the slices of w as shown above; integers are used to indicate the position within a single slice of the boundary symbols in strings xl, yl, x2, and y2. The figure depicts the case k = k', resulting in the exact nesting of the two derived trees. labeled by a symbol including integers i1 and kl. Moreover, 3'1 will eventually derive a string pair (xl, yl) with the following property. String xl is the smallest substring of w including the symbol in the /3th position within slice w (1) and the symbol in the k3th position within slice w (2). Furthermore, string yl is the smallest substring of w including the symbol in the (k2 + 1)-th position within slice w (5) and the symbol in the /2th position within slice w (6). This is schematically shown in Figure 4.","At the same time 5 r maps non-null element"]},{"title":"bk,j","paragraphs":["into an auxiliary tree 3'2 having its root labeled by a symbol including integers k~ and"]},{"title":"jl.","paragraphs":["Crucial to our construction, 32̀ will derive a pair of strings"]},{"title":"(x2~y2>","paragraphs":["with the following property. String x2 is the smallest substring of w including the symbol in the (k~ + 1)-th position within slice w (2) and the symbol in the j3th position within slice w (3). Furthermore, string y2 is the smallest substring of w including the symbol in the j2th position within slice w (4) and the symbol in the k~th position within slice w (s). Let us call 3'~ and 3,~ the derived trees obtained from 3,1 and 3\"2 as above. Observe that k2 = k~ and k3 = k~ if and only if the yields of 3\"~ and 3~̀ are exactly nested within w; see again Figure 4.","To complete the construction of G, map 5 v provides an auxiliary tree 3,3 with the following property. Tree 3,3 can contribute to a sentential derivation of w in G if and only if 3\"~ and 3\"~ can be adjoined to it. This is in turn possible just in case integer kl in the root of 3\"1 and integer k~ in the root of 32̀ coincide, as specified by the adjunction sites in 3'3, and the yields of 3~̀ and 3\"~ are exactly nested within w. It follows that, by deciding whether 3'3 contributes to a sentential derivation of w, the parser is able to perform the required test k = k'. Finally, index k in its coded form is discarded in the derivation process above, while indices i and j are preserved in such a way that map","can eventually recover non-null element"]},{"title":"Cq","paragraphs":["by reading off the parse relation. 179 Computational Linguistics Volume 20, Number 2 Table 1 Values off (b) (i) for b = 3 and 1 < i < 15. i 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 f(b)(i) 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 f(2b)(i) 1 1 1 2 2 2 3 3 3 1 1 1 2 2 2 f(b)(i) 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3","The next section presents a detailed specification of maps ~\" and G and proves the above claimed properties. As we will see, the search space defined by the resulting instance of the TAG parsing problem includes the solution of the source matrix multiplication problem. 3.2 The Two Maps The goal of this subsection is to establish a mapping between comparisons of matrix indices in Boolean matrix multiplication and instances of the adjunction operation in tree-adjoining grammar parsing. As already mentioned in the previous subsection, this result is achieved by encoding natural numbers using three positive integers. The encoding is then used to chop off matrix indices into smaller numbers that will be processed independently. This is explained in detail in the following.","For pairs of integers i and b, let qn(i, b) and rm(i, b) be the quotient and the remainder respectively of the integer division of i by b. We define qn+(i, b) = qn(i, b)+l whenever rm(i, b) 0 and qn+(i, b) = qn(i, b) otherwise; we also define rm+(i, b) = rm(i,b) whenever rm(i,b) ~ 0, and rm+(i,b) = b otherwise. Note that, for i > 1, qn+ (i, b) > 1 and 1 < rm+ (i, b) G b. Definition 2 Let b > I be an integer. We associate with b a functionf (b) defined on the set of positive natural numbers, specified as follows: where f(b)(i) = (f~b)(i),f(2b)(i),f(3b)(i)} , f(lb)(i) = qn+(i, b2), f(2 b)(i) = qn+(rm+(i, b2),b), f(3 b) (i) = rm+ (i, b). Table 1 shows some values off (b) for the case b = 3.","Observe that, for i > 1, f(3 b) and f(2 b) give values in the range {1..b}, while f(1 b) can give any positive integer. It is not difficult to see that function fib) establishes a one-to-one correspondence between the set N of positive natural numbers and the set N x {1..b} x {1..b}. In an informal way, we will often refer to value f(1 b) (i) as the most significant digit corresponding to i, and to values f(2 b) (i) and f(3 b) (i) as the least significant digits corresponding to i. In the following, the superscript in fib) will be omitted whenever b can be understood from the context.","We are now in a position to define in detail the maps F and G involved in the diagram of Figure 3 discussed in Section 3.1. As a first step, we study map ~- that takes as input an instance of BMM and returns an instance of TGP. 180 Giorgio Satta Tree-Adjoining Grammar Parsing"]},{"title":"FI(n)","paragraphs":["<A,u, v>"]},{"title":"dq dr","paragraphs":["<A,u, v>"]},{"title":"F2(n)","paragraphs":["<B, U, V>"]},{"title":"d~ ~D ds dq dr <B, u, v> F3(n). _(n) • ~¢n) IS : D <C, u, v> t4 : I c <A, u, t> [ dla D <B, t, v> I D <C, u, v> D dp Figure 5","paragraphs":["Definition of families of auxiliary trees F~ n), n > 1 and 1 < h < 6. Each tree in some class is specified by the values of the integer parameters corresponding to that class. Let n > 1 be an integer. In the following we will refer to sets of terminal symbols VT (\")={dp I' 1Gp_<6(n+1)}, and to sets of nonterminal symbols"]},{"title":"V(N n)= {(A,u,v),(B,u,v),(C,u,v) ] l <u<v<n4}U{C,D,S}.","paragraphs":["Based on these sets, Figure 5 defines families of auxiliary trees F~ n), 1 ( h _ 6. For example, an auxiliary tree 7(P, q, r, s, u, v) C 1~ \") will be specified by providing actual values for the integer parameters p, q, r, s, u, and v, consistently with the definitions of sets"]},{"title":"V(T n)","paragraphs":["and"]},{"title":"V(N n).","paragraphs":["In the following we will also use the initial tree % depicted in Figure 6.","The next definition introduces map ~, which is the core component of the proposed reduction. The definition is rather technical: it will be followed by a more intuitive example. Definition 3 Let (A, B) be an instance of BMM, m the order of matrices A and B. Let also n = Lm~/+1 and ~r -- n + 1. A map ~c is specified in such a way that YZ((A, B)) = (G, w), where"]},{"title":"G =- (w(n)~ V(Tn)~ S~ I1 a (n))","paragraphs":["and w ="]},{"title":"dld2 ... d6~.","paragraphs":["Set I contains the only initial tree %; set 181 Computational Linguistics Volume 20, Number 2 Ys: S"]},{"title":"I D I C I D I E Figure 6","paragraphs":["Definition of initial tree %."]},{"title":"A (n)","paragraphs":["contains all and only the following elementary trees"]},{"title":"(f(h n) =fh,","paragraphs":["1 < h < 3): (i) for every"]},{"title":"aq","paragraphs":["= 1 in A, the auxiliary tree"]},{"title":"7(p,q,r,s,u,v) E P~ n)","paragraphs":["belongs to"]},{"title":"A (n),","paragraphs":["where ; ---- f3(/), q ---- cr +f3(J), r = 4or +f2(j) + 1, s = 5cr +f2(i), U= A(i), V= A(J); (ii) for every"]},{"title":"bq","paragraphs":["-- 1 in B, the auxiliary tree"]},{"title":"7(p,q,y,s,u,v) E F~ n)","paragraphs":["belongs to"]},{"title":"A (n),","paragraphs":["where p= a+f3(i)+l, q= 2cr+f3(j), r = 3a+f2(j), s = 4or +f2(i), u= A(i), v= A(J); (iii) for every pair (A, u, t), (B, t, v) E"]},{"title":"V(N n),","paragraphs":["the auxiliary trees"]},{"title":"7(u,t,v)","paragraphs":["E C~ \"),"]},{"title":"7(u, v) E r~ \")","paragraphs":["belong to"]},{"title":"A(nJ;","paragraphs":["(iv) for every 1 < p < 6a, the auxiliary trees"]},{"title":"n), 7(p) E r (n)","paragraphs":["6 belong to A(\"). In order to have a better understanding of map 9 r and of the idea underlying grammar G and string w, we discuss in the following a simple example, adding more details to the informal discussion presented in Section 3.1.","Let us define a Boolean matrix by specifying only its non-null elements. Assume then that an input instance (A, B / of the BMM problem consists of two matrices of 182 Giorgio Satta Tree-Adjoining Grammar Parsing"]},{"title":"a2,15 1 B:","paragraphs":["C:"]},{"title":"i b 153 I multiplication","paragraphs":["c23"]},{"title":"mapping YI: Y3: <C,l,l>","paragraphs":["<A,1,2> ["]},{"title":"d 2 ~d20+1 <,4,1,2>1 d d 4+3 <A,1,2> 16+2+1 <B,2,1> I","paragraphs":["<C,1,1>"]},{"title":"Y2:","paragraphs":["<8,2,1>"]},{"title":"d4+3+1\"~/~ d16+ 2","paragraphs":["ds+t <B2,I>"]},{"title":"d12+3","paragraphs":["Y4\""]},{"title":"C I","paragraphs":["<C,I,I>"]},{"title":"I","paragraphs":["c C"]},{"title":"I","paragraphs":["<C,I,I>"]},{"title":"d 2 d8+ 1 C d12+3 d20+ 1 (a) (b) Figure 7","paragraphs":["Part (a) shows how non-null elements a2,15 and"]},{"title":"b15,7","paragraphs":["in matrices A and B combine together, forcing element c2,7 in matrix C to value 1; each array element is represented as an arc in a directed graph. Correspondingly, trees 31̀, 32̀, 3'3 and 3'4 in (b) are introduced in G by map ~-. These trees can be composed, using adjunction, with trees"]},{"title":"in","paragraphs":["p~3)"]},{"title":"and","paragraphs":["r~ 3), in such a way that a derived tree is obtained that matches string w and encodes the indices of c2,7. order m = 64, specified as A = {a2,15}~ B :- {b15,7}. The multiplication of matrices A and B results in matrix C consisting of the only non-null element Ca, 7. As already mentioned in Section 3.1, the multiplication process can be seen as a test for equality performed on the second index of a2~ls and the first index of b15,7; in the following these indices will be called \"intermediate\" indices. Element c2,7 in the product matrix is forced to value I if this test succeeds, and the intermediate indices are discarded in the process. See Figure 7a for a schematic representation of such an operation.","In performing an adjunction operation, two requirements must be satisfied. First, the nonterminal label at the adjunction site must match the nonterminal label at the root (and foot node) of the adjoined tree; and second, adjunction must compose trees in such a way that the derived string is compatible with w. In the proposed reduction, each test for equality performed on some pair of intermediate indices by matrix multiplication is transferred to an adjunction operation by map ~, using as targets the two requirements just described. This is exemplified in the following. 183 Computational Linguistics Volume 20, Number 2","According to Definition 3, we find n = 3 and cr = 4. Map J: then constructs a string w ="]},{"title":"dld2...d24,","paragraphs":["which can be thought of as composed of six slices w (h) = 4(h-1)+lW4h, 1 _< h _< 6. Each element in a single slice will be used as a placeholder to record information about matrix indices. Furthermore, map jv exploits functionf (3) (see Table 1) in order to map each non-null element of the input matrices to an auxiliary tree in I~ 3) or F~ 3) (steps (i) and (ii) in Definition 3). More specifically, each index of a non-null element is converted into three digits: the most significative one is encoded as part of the nonterminal symbols, and the two least significative digits are encoded by the terminal symbols in the target tree. Trees \")'1 and \"/2 obtained in this way from non-null elements a2,15 and b15,7 respectively have been depicted in Figure 7b. Two additional trees \"Y3 E F~ 3) and \"Y4 E 1~ 3) have been reported in the figure, that are also added to G by J: (step (iii) in Definition 3).","Crucial to our construction, the test on the intermediate indices of elements a2,15 and b15,7 has been reduced to three independent tests involving smaller integers. More precisely, the equality test on the most significative digits obtained from the intermediate indices has been transferred to the requirement on the matching of the nonterminal labels of the nodes involved in the adjunction. In fact, \"Yl and \"Y2 can be adjoined into \")/3 just in case such a test is satisfied. At the same time, the equality test on the least significative digits obtained from the intermediate indices has been transferred to the requirement on the matching of the derived string with w. In fact, after the adjunction of \"/1 and \"/2 into \")'3 takes place, no terminal symbol can intervene between the internal boundaries of the yield of \"Y1 and the external boundaries of the yield of \"Y2 in slices w (2) and w (s) (see again Figure 7b). Then \"Y3 can participate in a sentential derivation of w just in case all three equality tests above are simultaneously satisfied.","The choice of the order of I wl has been dictated by general considerations on the size of the search spaces associated with the two problems at hand, as already discussed in Section 3.1. As a note, we observe that slices w (2) and w (s) are used in the above construction to pair together least significative digits obtained from intermediate indices. The fact that these indices have range in {1..n} forces the choice of the length of these slices to ~r = n + 1; the example in Figure 7 actually uses the (n + 1)-th symbol of w (2). For uniformity, this value has then been extended to all other slices, fixing I wl to 6or.","In Lemma 1 below we will state in a more precise way the above arguments, and we will also show how derivations of the kind outlined above are the only derivations in G than can match string w, proving therefore the correctness of the reduction. To complete the diagram of Figure 3, we now turn to the specification of map ~. Definition 4 Let/G, w) be an instance of TGP in the image of map ~-, and let m, n, and cr be as in Definition 3. Let also Rp be the parse relation that solves instance /G, w). A map G is specified in such a way that G(Rp) = C, C a Boolean matrix of order m, and element cij is non-null if and only if Rp('y, p, q, r, s) holds for an auxiliary tree ~/(u, v) E E~ n), where (f(h n) =fh, 1 < h < 3) p = f3(i), q = 2¢+f3(j), r = 3 r+f2(j), s = 5cr+f2(i), u = fl(i), v = A(J). In the above definition, functionf (n) is used to retrieve the indices of non-null elements 184 Giorgio Satta Tree-Adjoining Grammar Parsing il ,kl kl ,Yl"]},{"title":")2 i i i i .wl2) . w 5).","paragraphs":["k3/ / \\ ~ k2+l"]},{"title":"J3 h Figure 8","paragraphs":["Non-null elements aik and bkj are mapped into auxiliary trees 3'1 and 3\"2 in G, and trees 3\"~ and 3'~ can successively be obtained compatibly with string w. As a convention, symbols 6h, 6 E {i, k,j} and 1 < h < 3, denote integersfh(6), which indicate either positions within each single slice or components of nonterminal symbols labeling tree nodes. of matrix C. In this case also, the most significative digits associated with the retrieved indices are encoded within the nonterminal symbols of the auxiliary tree -y(u, v), while the two least significative digits are encoded by the position of the yield boundaries of the string derived from ~/(u, v) consistently with the input string w. To conclude our previous example, we see that if we apply the relations in Definition 4 to the derived tree at the bottom of Figure 7b, we get indices 2 and 7 of the only non-null element inC.","The following result shows that any algorithm for the solution of a generic instance of TGP can be converted into an algorithm for the solution of the BMM problem, via the computation of maps 3 v and G. This concludes the present section. Lemma 1 Let/A, B / be an instance of BMM and let/G, w / = ~-(/A, B/). Let also Rp be the parse relation that solves/G~ w/. Then we have A x B = G(Rp). Proof Assume that m is the order of the matrices A and B, n is the natural number associated with m as in Definition 3, and ¢ = n + 1. Let C = A x B and C / = G(Rp).","To prove cij = 1 implies clj = 1, we go through a sentential derivation of w in G and then apply the definition of G. If Cq = 1, then there exists k, 1 < k < m, such that aik = bkj = 1. Let \"Yl and \"y2 be the unique auxiliary trees in G associated by map 3 v 185 Computational Linguistics Volume 20, Number 2 il ,kl kl ,jl il ,Jl"]},{"title":"h h Figure 9","paragraphs":["Tree 7~ is derived from trees \"/~, 7~ and auxiliary trees in G. We use the same conventions as in Figure 8. with"]},{"title":"aik","paragraphs":["and"]},{"title":"bkj","paragraphs":["respectively (steps (i) and (ii) in Definition 3). Tree \"71 has root (and foot node) labeled by nonterminal"]},{"title":"(A,fl(i),fl(k));","paragraphs":["furthermore, the terminal symbols in the yield of \"Yl are (from left to right) d/B(i ), d¢+/B(k ), d4,+/a(k)+l and d5c,+f2(i)."]},{"title":"The","paragraphs":["only pair of substrings of w that ~'1 can derive, by means of zero or more adjunctions of trees in F~ n) and P(')6 , is (f3(i)Wo-+f3(k)~ 4a+f2(k)+1W5o-+f2(i)) • Call ~ a parse tree associated with such a derivation (see Figure 8). In a similar way, auxiliary tree \"Y2 has root labeled by nonterminal"]},{"title":"(B,fl(k);fl(j))","paragraphs":["and derives pair {o- +f3(k )+ l W2o\" +f3(j) ~ 3cr +f2(j) W4cr +f2(k ) } of substrings of w. Call 3~ a parse tree associated with the derivation (see again Figure 8).","According to step (iii) in Definition 3, grammar G also includes auxiliary trees \"y3 = 7(f1(i)~fl (k),fl(j)) E p~n) and \"/4 = 70Cl(/);Aq)) C r~n). Note that the yields of trees 7~ and 7 / 2 are exactly nested within w; moreover, the root (and the foot) nodes of 71 and 72 have been preserved in the derivation. Therefore 3'I and V~ can be adjoined into 73 and the resulting tree 7~ can in turn be adjoined into 74. In this way, 74 derives the pair of substrings of w (f3 (i)W2cr +f3 (j), 3¢ q-f2 (j) W5~r q-f2 (i) } \" Call 7~ the resulting derived tree (see Figure 9). Since derived tree 71 can be adjoined into % in G and a tree can be eventually derived for the input string w, we have"]},{"title":"Re(v4,f3(i),","paragraphs":["2e +f3(j), 3or +f2(j), 5~ +f2(i)), and from the definition of ~ we get"]},{"title":"c;j = 1.","paragraphs":["186 Giorgio Satta Tree-Adjoining Grammar Parsing","Assuming clj = 1, we now prove cij = 1; this is done by arguing that the only sentential derivations for w that are allowed by G are those of the kind outlined above. From the definition of G we have that Rp(%,f3(i), 20 +f3 (j), 30 +f2(j), 50 +f2(i)) holds for the auxiliary tree 3'4 = 3'0cl (i),fl(j)) E F~ n). Equivalently, there exists at least one derivation from '/4 of strings (x,y) = <f3(i)w2o-+f3(j)~3o.+f2~)w5o.+f2(i)) (2) that participates in a sentential derivation of w. Fix such a derivation.","We first observe that, in order to derive any terminal symbol from '/4, auxiliary trees in F~ n), F~ n) and F~ n) must be used. Any tree in F~ n) can only derive symbols in slices w (h), h E {1,2, 5, 6}, and any tree in F~ n) can only derive symbols in slices w (h), h E {2, 3, 4, 5}. Therefore at least one tree in F~ n) and at least one tree in F~ n) must be used in the derivation of (x, y), since (x, y) includes terminal symbols from every slice of w. Furthermore, if more than one tree in F~ \") is used in a derivation in G, the resulting string cannot match w. The same argument applies to trees in F~ n). We must then conclude that exactly one tree in F~ \"), one tree in F~ \"), and one tree in F~ n) have been used in the derivation of (x, y) from 74. Call the above trees 71 = q'(p, k3, k2+1, s, u, kl) E F~ n), \"/2 ~--\" 7(k~+1, q, r, k~, k~, v) E F~ n), and \"/3 = \"/( u/, t, V') E F~ n).","As a second step, we observe that 73 can be adjoined into 74 only if u' =fl(i) and v' = A q) and 3'3 can host 71 and \"/2 just in case u' = u, v' = v, and k I = k~ = t. We also observe that, after these adjunctions take place, the leftmost terminal symbol in the yield of 3'4 will be the leftmost terminal symbol in the yield of 71, that is dp. From relation (2) we then conclude that p =f3(i). Similarly, we can argue that q = 20 +f3(j), r = 3o +f2(j) and s = 50 +f2(i). Finally, adjunction of '/1 and \"/2 into \"/3 can match w just in case k 3 = k~ and k2 = k~.","From the relations inferred above, we conclude that we can rewrite 71 as 70c3(i), k3, k2 + 1,5o +f2 (i),fl (i), kl) C F~ n) and '/2 as '/(k3 + 1, 20 +f3 (/'), 3o +f2(j), k2, kl,fl (j)) E F~ n) . Sincef is one-to-one and k2, k3 c {1..n}, there exists k such thatf(k) = (kl, k2, k3). From steps (i) and (ii) in Definition 3, we then have that aik and bkj are non-null and then cq = l. []"]},{"title":"4. Computational Consequences","paragraphs":["The results presented in the previous section are developed here under a computational perspective. Some interesting computational consequences will then be drawn for the tree-adjoining grammar parsing problem. The following analysis assumes the random-access machine as the model of computation."]},{"title":"4.1 Transferring of Time Upper Bounds","paragraphs":["We show in the following how time upper bounds for the TGP problem can be transferred to time upper bounds for the BMM problem using the commutative diagram studied in the previous section.","Let (A, B) be an instance of BMM and let (G, w} = .T((A, B)); m and n are specified as in Definition 3. Observe that, since n 6 > m, functionf (n) maps set {1..m} into product set {1..n 4} x {1..n} x {1..n}, in other words we have i <_fl(i) <_ n 4 and i <f2(i),f3(i) < n 187 Computational Linguistics Volume 20, Number 2 for 1 < i < m. From the definition of ~', we see that G contains O(m 2) auxiliary trees","p(n) F~n) and p~n). This determines the size of G and we have from each of the classes -1 , I(G,w)] = O(/t/2), since ]w] ="]},{"title":"O(n).","paragraphs":["Each auxiliary tree introduced in G at steps (i) and (ii) of Definition 3 requires the computation of a constant number of instances of functionf (n) on some integer i, 1 ( i ( m. Such a computation can be carried out in an amount of time O(log2(m)) using standard algorithms for integer division. Summing up, the entire computation of ~\" on an instance (A, B) takes time"]},{"title":"O(m 2","paragraphs":["log2(m)). Let"]},{"title":"Rp","paragraphs":["be the parse relation that solves (G, w) = ~'((A, B)). From Definition 1 and the above observations we have that"]},{"title":"]Rp]","paragraphs":["= O(m2n4), that is"]},{"title":"]Re]","paragraphs":["= O(m2+~). We can compute C ="]},{"title":"G(Rp) in","paragraphs":["the following way. For every element"]},{"title":"cij","paragraphs":["we compute"]},{"title":"f(n)(i)","paragraphs":["and"]},{"title":"f(n)(j)","paragraphs":["and then check"]},{"title":"Rp","paragraphs":["according to Definition 4. (Recall also our assumption that an instance of"]},{"title":"Rp","paragraphs":["can be tested in constant time.) Again we find that the entire computation takes an amount of time O (m 2 log 2 (m)). We observe that the computation of ~r and G takes an amount of time (asymptotically) very close to the one needed to store (A,B) or C.","As a consequence of the above discussion and of Lemma 1, we have that any time upper bound for the TGP problem can be transferred to an upper bound for the BMM problem, down to the time needed for the computation of transformations ~- and ~. The following statement gives an example. Theorem 1 Let"]},{"title":"Ap","paragraphs":["be an algorithm for the solution of the TGP problem having running time"]},{"title":"O([GlPlwlq).","paragraphs":["Then any instance of BMM can be solved in time"]},{"title":"O(max{m 2p+q,","paragraphs":["m 2 log2(m)}), where m is the order of the input matrices. Proof From Lemma 1 and from the previous discussion we have that two Boolean matrices of order m can be multiplied in time O(I G IPl w I q + m 2 log2(m)), where ]G I = O(m 2) and Iwl ="]},{"title":"O(m~). []","paragraphs":["Observe that, according to our definition, the TGP problem has a trivial time lower bound"]},{"title":"O(IR p","paragraphs":["I), since this is the amount of time needed in the worst case to store a representation for"]},{"title":"Rp","paragraphs":["that can be accessed in constant time. In practice this means that the upper bound transfer stated by the above result is effective down to O(m 2+2 ). 4.2 Time Upper Bounds for TGP In previous sections we have related the complexity of tree-adjoining grammar parsing to the complexity of Boolean matrix multiplication. Here we speculate on the consequences of the presented result.","As a computational problem, Boolean matrix multiplication has been an object of investigation for many years. Researchers have tried to improve the well-known O(m 3) time upper bound, m the order of the input matrices, and methods were found that work asymptotically faster than the standard cubic time algorithm. Strassen's divide and conquer algorithm that runs in time O(m 2sl) (see for instance Cormen, Leiserson, and Rivest [1990]) has been the first one in the series, and the best time upper bound known to date is approximately"]},{"title":"0(m2\"376),","paragraphs":["as reported in Coppersmith and Winograd (1990). It is worth noting here that the closer researchers have come to the O(m 2) trivial time lower bound, the more complex the computation involved in these methods has become. In fact, if Strassen's algorithm outperforms the O(m 3) standard algorithm only 188 Giorgio Satta Tree-Adjoining Grammar Parsing for input matrices of order greater than 45 or so (see again Cormen, Leiserson, and Rivest [1990]), recently discovered methods that are asymptotically faster are definitely prohibitive, given current computer hardware. At present, no straightforward method is known for Boolean matrix multiplication that considerably improves the cubic upper bound and that can be used in practical cases. Also, there is enough evidence that, if such a method exists, its discovery should be a very difficult enterprise.","Let us now turn to the TAG parsing problem. Many algorithms have been proposed for its solution and an O(I G III U A I] w 16) time upper bound has been given in the literature; see for instance Schabes (1990). We remark here that the dependency on the grammar size can be further improved using techniques similar to the one proposed in Graham, Harrison, and Ruzzo (1980) for the context-free grammar recognition/parsing problem: this results in an O(I G II w 16) time upper bound for the general case. Theorem 1 can be used to transfer this upper bound to an upper bound for Boolean matrix multiplication, finding the already mentioned O(m 3) result.","More interestingly, Theorem 1 implies that any method for the solution of the tree-adjoining grammar parsing problem having running time O(I G II w I s) will give us a method for Boolean matrix multiplication having running time O(m2\"83). Likewise, any O(I G I]wl 4) time method for the former problem will result in an O(m 2'~) time method for Boolean matrix multiplication. Even if the involved constants hidden in the studied construction are large, the resulting methods will still be competitive with known methods for Boolean matrix multiplication that improve the cubic time upper bound. We conclude then that the TAG parsing problem should also be considered as having the status of a problem that is \"difficult\" to improve, and we have enough evidence to think that methods for TAG parsing that are asymptotically faster than O(I G II w I 6) are unlikely to be practical, i.e., will involve rather complex computations. 5. Remarks and Conclusion Polynomial time reductions between decision/search problems are commonly used in providing hardness results for complexity classes not known to be included in P (P is the class of all languages decidable in deterministic polynomial time). We have studied here a polynomial time reduction between Boolean matrix multiplication and TAG parsing, two problems already known to be in P. However, the choice of the mapping allows one to transfer upper bounds from the first problem to the other. In this way TAG parsing inherits from Boolean matrix multiplication the reputation of being a problem tough to improve. We comment in the following on the significance of this result.","As already discussed, the notion of the parse forest is an informal one, and there is no common agreement on which specifications such a structure should meet. The obtained results are based on the assumption that a parsing algorithm for TAG should be able to provide a representation for a parse forest such that instances of the parse relation"]},{"title":"Rp in","paragraphs":["Definition I can be retrieved in constant time. Whatever the specifications of the output parse forest structure will be, it seems quite reasonable to require that an explicit representation of relation"]},{"title":"Rp","paragraphs":["can be extracted from the output in linear time with respect to the size of the output itself, therefore without affecting the overall running time of the method. This requirement is satisfied by all TAG parsers that have been presented to date in the literature.","As a second point, the studied construction provides an interesting insight into the structure of the TAG parsing problem. We see for instance that the major source of 189 Computational Linguistics Volume 20, Number 2 complexity derives from cases of properly nested adjunction operations. Such cases are responsible for a bounded amount of nondeterminism in the computation: to detect how a string divides into subparts according to the adjunction of a derived tree into another, we have to consider many possibilities in general, as much as we do to detect a non-null element within a product Boolean matrix. A closer look at the studied construction reveals also that the parsing problem for linear TAG does not seem easier than the general case, since ~ maps instances of BMM to instances of TGP restricted to such a class (a linear TAG is a TAG whose elementary trees allow adjunction only into nodes along a single spine). This contrasts with the related case of context-free grammar parsing, where the restriction of the problem to linear grammars can be solved in time O(I G II w 12) but no method is known for the general case working with this bound. As expected from our result, the techniques that are used for linear context-free grammar parsing cannot be easily generalized to improve the parsing problem for linear TAGs with respect to the general case.","Finally, we want to discuss here an interesting extension of the studied result. The TAG parsing problem can be generalized to cases in which the input is a lattice representation of a string of terminal symbols along with a partially specified parse relation associated with it. This has many applications for ill-formed input and errorcorrecting parsing. The TAG lattice parsing problem can still be solved in O(I G[I w I 6) time: the general parsing method provided in Lang (1992) can be used to this purpose, and already known tabular methods for TAG parsing can be easily adapted as well.","Without giving the technical details of the argument, we sketch here how Boolean matrix multiplication can be related to TAG lattice parsing. For order m matrices, one can use an encoding function f/(n), where n = [ml/2j + 1, mapping set {1..m} into product set {1..n} x {1..n}. This allows a direct encoding of any instance"]},{"title":"(A, B)","paragraphs":["of the BMM problem into a word lattice wl consisting of 6(n + 1) nodes and O(m 2) arcs, where some arcs involve four nodes and represent a derived tree corresponding to a non-null element in either A or B. Then we can use a grammar G in the target instance of the TAG lattice problem that is defined independently of (A, B) and therefore has constant size. (Such a grammar can be obtained from families F~ n) and F~ n) defined in Section 3 by deleting the integer components in each nonterminal symbol.) The construction obtained in this way relates therefore the BMM problem to the fixed grammar parsing problem, and provides a result even stronger than the one presented in Theorem 1. We have in fact that any algorithm for TAG lattice parsing having running time"]},{"title":"O(IG IP[w","paragraphs":["I q) can be converted into an algorithm for Boolean matrix multiplication running in time O(max{m~, malog2(m)}), independently of p. As an example, O(I G IPl w 14) for TAG lattice parsing becomes"]},{"title":"O(m 2","paragraphs":["log2(m)) for matrix multiplication, for any p. Since many tabular methods for TAG parsing can be easily extended to TAG lattice parsing, this means that the chances of getting an"]},{"title":"0(I G IPlw","paragraphs":["14) time upper bound for the TAG parsing problem itself by means of these techniques are really small."]},{"title":"Acknowledgments","paragraphs":["I am indebted to Yves Schabes who suggested to me the original idea of relating a standard computational problem to the tree-adjoining grammar parsing problem. I want to thank Bernard Lang, Owen Rambow, and Yves Schabes, who have provided, directly or indirectly, important suggestions for the development of the ideas in this paper. Comments from two anonymous referees have also been very helpful in improving the exposition of the results reported in this paper. Finally, I am grateful to Aravind Joshi for his support in this research. None of these people is responsible for any error in this work. This research was partially funded by the following grants: ARO grant DAAL 190 Giorgio Satta Tree-Adjoining Grammar Parsing 03-89-C-0031, DARPA grant N00014-90-J-1863, NSF grant IRI 90-16592, and Ben Franklin grant 91S.3078C-1. References Coppersmith, D., and Winograd, S. (1990). \"Matrix multiplication via arithmetic progression.\""]},{"title":"Journal of Symbolic Computation,","paragraphs":["9(3), 251-280. Special Issue on Computational Algebraic Complexity.","Cormen, T. H.; Leiserson, C. E.; and Rivest, R. L. (1990)."]},{"title":"Introduction to Algorithms. The","paragraphs":["MIT Press. Frank, R. (1992)."]},{"title":"Syntactic locality and tree adjoining grammar: grammatical, acquisition and processing perspectives.","paragraphs":["Doctoral dissertation, University of Pennsylvania.","Graham, S. L.; Harrison, M. A.; and Ruzzo, W. L. (1980). \"An improved context-free recognizer.\""]},{"title":"ACM Transactions on Programming Languages and Systems,","paragraphs":["2(3), 415-462.","Joshi, A. K. (1985). \"How much context-sensitivity is necessary for characterizing structural descriptions--tree adjoining grammars. In"]},{"title":"Natural Language Processing--Theoretical, Computational and Psychological Perspectives,","paragraphs":["edited by D. Dowty, L. Karttunen, and A. Zwicky, 206-250. Cambridge University Press. Originally presented in a Workshop on Natural Language Parsing at Ohio State University, Columbus, Ohio, May 1983.","Joshi, A. K.; Levy, L. S.; and Takahashi, M. (1975). \"Tree adjunct grammars.\""]},{"title":"Journal of Computer System and Science,","paragraphs":["10(1), 136-163.","Joshi, A.; Vijay-Shanker, K.; and Weir, D. (1991). \"The convergence of mildly context-sensitive grammatical formalisms.\" In"]},{"title":"Foundational Issues in Natural Language Processing,","paragraphs":["edited by S. Shieber and T. Wasow, 31-82. MIT Press.","Lang, B. (1992). \"Recognition can be harder than parsing.\" Abstract submitted to the Second TAG Workshop, June 1992.","Lavelli, A., and Satta, G. (1991). \"Bidirectional parsing of lexicalized tree adjoining grammars.\" In"]},{"title":"Proceedings, Fifth Conference of the European Chapter of the Association for Computational Linguistics,","paragraphs":["Berlin, 1991, 27-32.","Palis, M. A.; Shende, S.; and Wei, D. S. L. (1990). \"An optimal linear-time parallel parser for tree-adjoining languages.\""]},{"title":"SIAM Journal on Computing,","paragraphs":["19(1), 1-31. Schabes, Y. (1990)."]},{"title":"Mathematical and computational aspects of lexicalized grammars.","paragraphs":["Doctoral dissertation, University of Pennsylvania. Available as technical report (MS-CIS-9048, LINC LAB179) from the Department of Computer Science.","Schabes, Y. (1991). \"The valid prefix property and left to right parsing of tree-adjoining grammar.\" In"]},{"title":"Proceedings, Second International Workshop on Parsing Technologies,","paragraphs":["Cancun, Mexico, February 1991, 21-30.","Schabes, Y., and Joshi, A. K. (1988). \"An Earley-type parsing algorithm for tree adjoining grammars.\" In"]},{"title":"Proceedings, 26th Meeting of the Association for Computational Linguistics,","paragraphs":["Buffalo, June 1988, 258-269.","Vijay-Shanker, K., and Joshi, A. K. (1985). \"Some computational properties of tree adjoining grammars.\" In"]},{"title":"Proceedings, 23rd Meeting of the Association for Computational Linguistics,","paragraphs":["Chicago, July 1985, 82-93.","Vijay-Shanker, K., and Weir, D. J. (1993). \"The use of shared forests in TAG parsing.\" In"]},{"title":"Proceedings, Sixth Conference of the European Chapter of the Association for Computational Linguistics,","paragraphs":["Utrecht, 1993, 384-393. 191"]}]}