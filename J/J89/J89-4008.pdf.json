{"sections":[{"title":"ABSTRACTS OF CURRENT LITERATURE Selected Dissertation Abstracts","paragraphs":["Compiled by: Susanne M. Humphrey, National Library of Medicine, Bethesda, MD 20209 Bob Krovetz, University of Massachusetts, Amherst, MA 01002 The following are citations selected by title and abstract as being related to computational linguistics or knowledge representation, resulting from a computer search, using the BRS Information Technologies retrieval service, of the Dissertation Abstracts International (DAI) database produced by University Microfilms International.","Included are the UM order number and year-month of entry into the database; author; university, degree, and, if available, number of pages; title; DAI subject category chosen by the author of the dissertation; and abstract. References are sorted first by DAI subject category and second by author. Citations denoted by an MAI reference do not yet have abstracts in the database and refer to abstracts in the published Masters Abstracts International.","Unless otherwise specified, paper or microform copies of dissertations may be ordered from:","University Microfilms International","Dissertation Copies","Post Office Box 1764","Ann Arbor, MI 48106","telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042","for Canada: 1-800-268-6090. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate source for copies is sometimes provided at the end of the abstract.","The dissertation titles and abstracts contained here are published with permission of University Microfilms International, publishers of Dissertation Abstracts International (copyright by University Microfilms International), and may not be reproduced without their prior permission. NEW REPORTS AND MEMOS Net-Based Plan Synthesis Bahler, Dennis Rex University Microfilms International ADG89-01237 This work is concerned with the synthesis, characterization, and verification of plans. Planning is the problem of synthesizing a set of actions to accomplish a goal. In this thesis, components of a planning system--situations, operator schemata, and operators--are defined and discussed. Schemata may be used to form a plan grammar, and operators may be considered as labels on its productions. A taxonomic classification of plan grammars is established depending on their structure, and the functionality of such grammars is discussed for attacking important problems in plan synthesis, particularly resource acquisition and/or release and simple forms of spatial reasoning. When situational rules are appended to a plan grammar, a generic planning problem can be defined.","Representations of situations, schemata, and operators are defined employing a new class of net called the generalized condition/event net (GC/Enet), and the relationship of plans to nets is discussed with reference to two important new net properties--mutual persistence of event sequences and liveness with respect to a set of places.","Next, the taxonomy of plan grammars is extended into a taxonomy of planning problems. Along with well-known algorithms for solving problems in the simpler classes, two new algorithms are presented for problems in the most general class. All the algorithms operate by growing a net from two initially Computational Linguistics, Volume 15, Number 4, December 1989 269 Protos: A Unified Approach to Concept Representation, Classification, and Learning Bareiss, Ellis Raymond, Jr. University Microfilms International ADG89-01270 A Massively Parallel Natural Language Processing Architecture with Distributed Control Berg, Howard George Jr. University Microfilms International ADG89-02614 Abstracts of Current Literature unconnected components. Embedded in this net is a partially ordered set of events representing the occurrence of operators. The most basic search problem to be solved by a planning system is identified for the most general class of problem and a complexity result about it is proved.","Finally, this thesis describes a means of abstractly characterizing multi-agent plans as a strict partial ordering defined over a multiset of operators. This ordering, called an operator occurrence ordering, makes it possible to define rigorously the notion of plan and plan execution and to prove formally certain important properties of nonlinear plans and executions, including plan correctness and validity of a plan with respect to a problem. A theorem is proved about necessary and sufficient conditions under which an operator ordering terminates execution having achieved a desired goal. The primary contribution of this research is a unified approach to concept rel:,resentation, classification, and concept learning. This approach has been implemented as a computer program, Protos, which learns concepts as it performs classification under the guidance of a teacher. The soundness of the approach has been demonstrated by successfully applying Protos to the task of acquiring knowledge for performing heuristic classification at an expert level of proficiency.","The Protos approach addresses the complexities of representing, using, and learning natural concepts. These concepts are polymorphic and ill-defined. Most machine learning research is based on inductive learning and deductive classification, which are more suitable for artificial domains (e.g., mathematics) than natural domains (e.g., medicine). In contrast, Protos takes an exemplar-based approach. It represents concepts extensionaily as sets of retained exemplars, classifies a new instance by recalling a similar exemplar and explaining its similarity to the instance, and learns when a classification failure indicates that knowledge is missing. Because Protos learns as a byproduct of classification, its performance continually improves.","Protos has been experimentally evaluated by training it to diagnose hearing disorders. An expert audiologist trained Protos with 200 cases of hearing disorder. Through this small amount of training, Protos evolved into an expert system whose classification performance was comparable to that of experienced human clinicians. This research describes a new massively parallel model for natural language processing and knowledge representation. This model, Autonomous Semantic Networks (ASNs), addresses shortcomings in previous approaches. The serial-processor models of natural language processing become bogged down in the searching and manipulation of the large amounts of world knowledge they need to understand the texts they read. The existing massively parallel models have the potential to avoid that bottleneck. However, the current state of the art makes necessary operations such as variable binding and the use of ordered relations extremely difficult. The ASN model represents a middle road--a massively parallel model that can easily build and manipulate representations of new and changed concepts 270 Computational Linguistics, Volume 15, Number 4, December 1989 Abstracts of Current Literature resulting from the reading of the input. This is an essential ability for a natural language processing system to have to handle inference and anaphoric reference.","The ASN model has as its basis a spreading activation-based network of units and the connections between them. These form the knowledge representation portion of the model. In addition, ASNs have two other classes of nodes. The first class, WTA nodes, allows the search and selection among units based upon their activation. The second class of nodes is composed of the construction nodes. Construction nodes manipulate the units in the knowledge representation. Depending on the exact type of node, it can either add a connection between units, delete a connection, or allocate a new unit. The notion of indirection in the operations of construction nodes allows them to implement variable-like constructs.","The usefulness of ASNs is shown by a network that processes a simple multiple-sentence text. The implementation of schemata, disambiguation, and discourse processing in ASN-based systems is also discussed. Large Vocabulary Speaker-Independent Continuous Speech the SPHINX System Lee, Kai-Fu University Microfilms International ADG88-26533 Speaker independence, continuous speech, and large vocabulary are three of the greatest problems in automatic speech recognition. Previous accurate speech recognizers avoided dealing with all three problems simultaneously. This dissertation describes SPHINX, the first system to demonstrate the feasibility of accurate large-vocabulary speaker-independent continuous speech recognition.","SPHINX is based on four important principles: use of a sophisticated yet tractable model of speech, incorporation of human speech knowledge, utilization of speech units that are trainable, well understood, and context-insensitive, and ability to learn and to adapt to individual speakers.","Hidden Markov models (HMMs) are used to represent speech in SPHINX. Hidden Markov modeling is a powerful technique capable of robust and succinct modeling of speech. With their efficient maximum likelihood training and recognition algorithms, HMMs have already been successfully applied to more constrained tasks.","Within the framework of hidden Markov modeling, SPHINX uses human knowledge in several ways. Perceptually motivated parameters were incorporated using frame and segment level integration techniques. Also, an optimized set of phones and word pronunciations were derived from human phonetic/lexical knowledge and tuning experiments. The incorporation of knowledge resulted in substantial improvements in recognition accuracy.","It is well known that the same phone in different contexts has different realizations. A good unit of speech must be trainable, yet models context-dependent and word-dependent effects. Two novel units, function word-dependent phone model and the generalized triphone model, are introduced. These units led to very substantial improvements in performance.","Finally, to improve the system given some knowledge of the speaker, two learning algorithms are introduced to modify the system to adapt to an input speaker. The first algorithm is based on speaker cluster selection, and the other involves deleted interpolation of various speaker-independent and speaker-dependent HMM parameters. Computational Linguistics, Volume 15, Number 4, December 1989 271 Knowledge Intensive Planning Luria, Marc A. University Microfilms International ADG89-02194 Building and Maintaining Hierarchical Semantic Nets Mili, Hafedh University Microfilms International ADG88-25145 Abstracts of Current Literature","SPHINX attained a word accuracy of 96% on the 997-word resource management task. It is much more accurate than any previously reported results on similar tasks. In fact, it is comparable to the best speaker-dependent systems. By using sophisticated modeling techniques to exploit abundant training data, SPHINX has bridged the gap between speaker-independent and speaker-dependent recognition. This thesis describes a program called KIP (Knowledge Intensive Planner). KIP is a general, commonsense planner that can reason about planning situations in the real world for which it is provided information. KIP is the planning component of the UC (UNIX consultant) system. KIP is used to solve the problems the user poses to the UC. KIP has knowledge about UNIX commands, including the effects of those commands and under what conditions those commands can and should be issued. The best plan is reported to the user after determining the goals of the user, selecting and specifying a plan that fulfills the goals of the user (plan determination), testing if the plan will work in this particular problem situation without causing unacceptable consequences, and modifying this plan if necessary.","A major problem in commonsense planning is the focus of attention on relevant knowledge. In particular, the problem of identifying potential plan failures in a plan is difficult, since there are often many sources of plan failure, both for failures due to an unsatisfied condition of a plan and failures due to goal conflict. This problem is further complicated because many values of conditions in a particular planning problem may be unknown. To address the problem of identifying potential plan failures, a new idea, called a concern, has been introduced. Concerns identify which aspects of a plan are most likely to fail. Knowledge-intensive AI applications require the development and maintenance of increasingly large, consistent, and up-to-date knowledge bases. Knowledge engineering remains largely manual, presenting a major bottleneck to the development of intelligent systems. This research explores methods to build automatically and maintain hierarchical semantic nets. Such semantic nets that are manually built and laboriously updated exist according to some rules that are imprecise at best. The approach followed is one of taking advantage of the structure existing in readily available knowledge sources to build and/or maintain hierarchical semantic nets.","Three methods were investigated, dealing with knowledge sources of varying structural complexity. The first two methods, briefly summarized in this thesis, proved useful in the context of an intelligent information retrieval system that used a hierarchical semantic net to match documents to queries. However, both methods suffered, to varying degrees, from the vagueness and lack of clear semantics of hierarchical relations in human-made hierarchies. The third method, DK method, is based on a precise characterization of hierarchical relationships.","The DK me, thod is based on the observation that human-made hierarchies are often built in a way such that concepts' properties follow clear patterns, similar to the patterns implied by inheritance in taxonomies. These patterns are described by 272 Computational Linguistics, Volume 15, Number 4, December 1989 Learning Effective Search Control Knowledge: An Explanation-Based Approach Minton, Steven University Microfilms International ADG88-26537 Abstracts of Current Literature regularity, a generalized form of inheritance. It is argued that regularity is a fundamental property of hierarchies, and a model of hierarchies (DK model of hierarchies) that embodies regularity is proposed. In this model, hierarchical relations are described by predicates that represent the particular relationships that hold between the properties of a concept and the properties of its descendants. Adding a concept to a DK hierarchy is then reduced to a problem of classifying that concept using the hierarchy as a hierarchical classifier. The cognitive and mathematical foundations of this approach are discussed. In particular, a fuzzy model of DK hierarchies and its associated classification algorithm are proposed to handle the uncertainties and exceptions to regularity that often plague human-made hierarchies. The fuzzy models are then tested on two human-made hierarchies, and the results show the validity of our approach. To solve problems more effectively with accumulating experience, a problem solver must be able to learn and exploit search control knowledge. Although previous research has demonstrated that Explanation-Based Learning (EBL) is a viable approach for acquiring control knowledge, in practice the learned control knowledge may not be useful. For control knowledge to be effective, the cumulative benefits of applying the knowledge must outweigh the cumulative costs~ o~---testing whether the knowledge is applicable. Previous ~esearch in EBL has ignored this issue, which I refer to as the utility problem. Most researchers have simply demonstrated that EBL can improve performance on particular examples without analyzing exactly when performance improvement will occur. In practice, it is much more difficult to improve performance over a population of examples than it is to improve performance on isolated examples.","One answer to the utility problem is to search for \"good\" explanations--explanations that can be profitably employed to control problem solving. Instead of simply adding control knowledge haphazardly, a learning system must be sensitive to the problem solver's computational architecture and the potential costs and benefits of adding knowledge. This thesis analyzes the utility of EBL, and describes a method for searching for good explanations. The method, implemented in the PRODIGY/EBL system, consists of a three-stage heuristic search. Given a problem solving trace, PRODIGY first selects what to learn. The system chooses from a variety of target concepts, each representing a different strategy for optimizing performance. Second, after creating an initial explanation from the trace, PRODIGY searches for a representation of the explanation that is efficient to match. Finally the system empirically tests the effectiveness of the learned control knowledge to determine whether it is actually worth keeping.","The thesis includes a set of comprehensive experiments testing the performance of the PRODIGY/EBL system and its components in several domains. In addition, a formal description of EBL is presented, together with a correctness proof for PRODIGY's generalization method. 273 Computational Linguistics, Volume 15, Number 4, December 1989 Syntactic and Thematic Contributions To On-Line Sentence Comprehension Speer, Shari Rae University Microfilms International ADG89-01396 A Knowledge-Based Message Generation System for Motor and Speech Disabled Persons: Design Methodology and Prototype Testing Sy, Bon Kiem University Microfilms International ADG88-17749 Abstracts of Current Literature Current linguistic theories assume a rich lexicon, in which individual lexical entries are associated with syntactic subcategorization information and semantic argument structures. Verbs in particular are associated with sets of thematic roles that indicate the types of sentential context in which they may appear. Five experiments explore the ways that thematic relations and syntactic phrase structure contribute to the parsing process in human language comprehension. Two on-line tasks, phoneme monitoring and self-paced reading, are used to measure sentence processing during the comprehension of NP-V-NP-PP sentences.","The first experiment provides empirical evidence from a sentence completion task to confirm linguistic intuitions about the thematic roles likely to be associated with the arguments of agentive transitive verbs. S-V-O contexts tested in the first experiment are extended to create materials for the subsequent experiments. Experiments two and three show processing effects due to syntactic complexity (verb-attached vs. verbal objectattached prepositional phrases) and due to the thematic role preferences of the verbs. These effects replicate across the auditory and visual modalities. Experiments four and five examine the contributions of preposition (IN and WITH), verb type, verb-preposition pairing, and preposition-thematic-relation pairing on the parsing process for sentences of the same syntactic structure (verb-attached prepositional phrases). Results indicate that verb type and preposition-thematic relation pairing influence on-line decisions of the human language parser. A computer-based nonvocal communication device is an aid to assist nonvocal, motor disabled persons in generating written and spoken messages through an \"interrogation\" process. This process is executed by suggesting a list of probable messages for the user to affirm, deny, or select from. The message search strategy' used in existing devices is usually based on fixed statistical information (such as the occurrence frequency of a message). This existing approach is ineffective when a user attempts to use the device to generate infrequently used messages (i.e., messages with low likelihood or low occurrence frequency).","This ineffectiveness is overcome, at least in part, through the development of a Knowledge-based Message Generation System (KMGS), which can \"reason out\" a desired message. The reasoning process; is based on the embedded knowledge concerning the likelihood and the grammatical structure of the message, as well as any sources of information (such as partially understandable speech) provided to the system. The new approach can effectively seek out the desired message even if it is infrequently used, and thus improves the communication rate of the device.","The current design of KMGS makes use of an entropy measurement in the selection of message elements for the knowledge base, which optimizes both the articulateness and the fluency of the system. The knowledge base of the system is a language graph encoded with English grammatical rules and message elements. The search for the message elements is conceptualized as a path search in the language graph, and a special frame architecture is used to construct and partition the graph. Bayesian belief reasoning from the Dempster-Shafer 274 Computational Linguistics, Volume 15, Number 4, December 1989 A Study of the Article System in English Chen, Pi-Fen Liu University Microfilms International ADG89-00019 A Semantics for Groups and Events Lasersohn, Peter Nathan University Microfilms International ADG88-24557 Abstracts of Current Literature Theory of Evidence is augmented to cope with the time varying evidence so that both the information from external sources (such as a speech recognition system) and the embedded knowledge can be used to optimize the process of message search. An \"information fusion\" strategy is introduced to integrate various forms of external information. Experimental testing results of the prototype system are reported. This dissertation aims to answer the following questions frequently asked by adult second language learners of English: (a) when do we use the? (b) when do we use a(n)? and (c) when do we use neither the nor a(n)? This study discusses mass and count nouns in English, and what makes an NP definite and what makes it indefinite. It also discusses the generic use of English articles. It is argued that not every mass noun can be converted into a count noun and vice versa. Four principles are given for mass/count conversion. For (in)definiteness, three requirements--existence, uniqueness, and familiarity--are posited for the use of the. Subtle differences among the generic use of the, a(n) and O, the zero article, are discussed, and their respective distributions and restrictions are presented. An overall system of article usage is presented for second language learning. This dissertation provides a model-theoretic semantics for English sentences attributing a property or action to a group of objects, either collectively or distributively. It is shown that certain adverbial expressions select for collective predicates; therefore collective and distributive predicates must be distinguishable. This finding is problematic for recent accounts of distributive predicates that analyze such predicates as taking group-level arguments, and hence as not distinguishable from collective predicates.","A group-level treatment of distributives is possible, however, if predicate denotations are relativized to a set of events for which a part/whole relation is defined. An event in which a group performs an action distributively will have subevents in which each of the group's members perform the same action; an event in which the group performs the action collectively will not.","This analysis also makes possible an account of the fact that adverbials expressing collective action commonly have an additional use expressing spatial proximity, both in English and cross-linguistically. (Compare John and Mary lifted a piano together with John and Mary sat together.) A spatial \"trace\" function on the set of events allows formal definitions for the spatial uses of such adverbials to exactly parallel the definitions for the collectivizing uses.","The dissertation also provides arguments for a set-theoretic (as opposed to lattice-theoretic or merological) model for plurality, in which the group membership relation is distinct from the subgroup relation.","Certain quantifiers are shown sensitive to distinction between different sorts of group-level event. To accommodate this fact, it is suggested that verbal denotations provide, for each event, both an \"inclusion set\" and an \"exclusion set\"--corresponding roughly to positive and negative denotations. If the inclusion Computational Linguistics, Volume 15, Number 4, December 1989 275 Information Structure in Planned, Written and Unplanned, Spoken Discourse Lee, Chingkwei Adrienne University Microfilms International ADG88-17573 Abstracts of Current Literature and exclusion sets are allowed under certain circumstances not to complement each other, correct results obtain.","The splitting of verbal denotations into inclusion and exclusion sets also allows the solution of certain problems in previous accounts of the semantics of subject-verb agreement for number. The dissertation closes with a defense of the hypothesis that agreement (in English) is conditioned primarily by the semantics. A taxonomy of discourse entities based on the reconsideration of Prince's 19811 trichotomy of given-new information and Minsky's 1975 'frame' conception is created to analyze four thousand discourse entities from lectures and writings of four linguistics professors on the same or closely related subject matter to determine the differences of information structure in planned, written and unplanned, spoken discourse.","Two discourse models based on entities are proposed to account for planned, written and unplanned, spoken discourse respectively. Based on these two models, research hypotheses concerning the differences between the two types of discourse are formulated. The procedures of data analyses are to code each token according to six factor groups, input the coded tokens into a computer to run the sorting routines of the VARBRUL 2 program to obtain the frequencies of seven aspects of entities in the two types of discourse, use four statistical tests, the ~ test, matched t-test, coefficient correlation test, and Ryan-Einot-Gabriel-Welsch multiple range test, to determine if the differences are significant.","It is found that there are significantly more local entities, partial-referent entities, modified noun entities, and longer entities in planned, written discourse than in unplanned, spoken discourse, and that there are significantly more pronoun entities, animate entities, and shorter entities in unplanned, spoken discourse than in planned, written discourse. These findings suggest that those entities occurring in writing need more time to process, while those occurring in speaking need less time to process. When the major categories of entity types are examined, the hierarchies of their occurrence in the two types of discourse are the same. Based on this finding, an entity-based model of communication (the E. B. Model of Communication) that depicts the way people write and speak is proposed: messages are originally conceived in the form of framed/slotted entities, which are used most in discourse; situationally evoked entities, which are called forth from the situation involved to facilitate or to ease communication, are used least; in the process of delivering the text, textually dependent entities, which are used more than situationally evoked entitie,; and less than framed entities, are derived from framed entities. The present study makes it possible to explain and predict communication breakdown quantitatively in terms of entities. Implications and applications of the present study are given. 276 Computational Linguistics, Volume 15, Number 4, December 1989 Abstracts of Current Literature Scripts as Knowledge Representation: Evidence from Two Case Studies of Aphasia Speicher, Barbara Lynn University Microfilms Order Number ADG89-02700 From French to English: A Look at the Translation Process in Students, Bilinguais, and Professional Translators Gerloff, Pamela Ann University Microfilms International ADG88-23316 Scripts, a theoretical model of knowledge representation, is rich in linguistic and extralinguistic context. Scripts are situational routines, such as going to a bank or a restaurant. They contain information about settings, roles, props, sequences of actions, and typical vocabulary. Scripts, which provide predictions and expectations about an exchange, allow people to function automatically in such routines. Examining language-disordered populations makes possible our disentangling of linguistic knowledge from real world knowledge. Aphasic subjects offer insights impossible to capture from normal subjects.","In this dissertation, two nonfluent aphasics participated in two sets of tasks based on the restaurant script and scripts they had developed for therapy. Each task set included scriptal tasks manipulating setting, roles, and props; metascriptal task(s) manipulating sequence and requiring verbal descriptions; and non-scriptal task(s) utilizing contexts unrelated to the scripts while eliciting the same vocabulary (target lexemes) that the aphasics had used in the scriptal tasks. The tasks usually elicited verbal production and occasionally non-verbal manipulation of scriptal elements.","The restaurant script findings support the paradigm of scripts as underlying representations of knowledge because scriptal tasks elicit the highest percentage of appropriate responses. These aphasics demonstrate knowledge of the sequence of activities within the script and sensitivity to the various scriptal features. Specifically, setting and roles prove highly facilitative of scriptal vocabulary. A strong interdependency between scripts and vocabulary emerges. Scripts help these aphasics access more language. Also, typical vocabulary seems to trigger a script. The subjects occasionally invoke scripts to aid in their retrieval of words.","Scripts may have both beneficial and detrimental effects on application from therapy to other contexts. Communication strategies compensate for linguistic limitations. These aphasics demonstrate two types of circumlocution, scriptal and semantic. Serial naming, classified as a reemergence of egocentric speech, allows these aphasics to answer questions they would have been unable to answer otherwise. The scriptal paradigm enables us to explore and reanalyze several aphasic behaviors. A study was conducted using think-aloud protocols to investigate the translation processes of students, bilingual speakers, and professional translators. The study consisted of twelve subjects: four intermediate level college students learning French as a second language; four bilingual speakers of French and English, none of whom had significant prior experience with translation; and four professional translators, none of whom had grown up bilingually. Subjects were given a French magazine article and asked to \"think out loud\" as they translated it into English. Participants had access to dictionaries and a thesaurus. The think-aloud protocols were audio- and video-tape recorded and transcribed verbatim. They were then coded for problem-solving strategies and behaviors and the size of language units worked with (e.g., word, phrase, clause, sentence). The data were analyzed to determine differences in processing among the groups, the range of individual variation within groups, and different \"types\" of processors that emerged. Computational Linguistics, Volume 15, Number 4, December 1989 277 Abstracts of Current Literature","Central findings were that translation gets neither \"easier\" nor faster as one becomes more experienced with the language and more practiced with translation. Problems simply become more complex, and experienced language users hold themselves to higher standards than do novices, leading them to find more problems with ~Lhe text and to spend more time and effort on those they find. Bilinguals and translators engaged in more total problem-solving activity and made more solution attempts per problem than the students did. They also generated more possible translation choices, did more editing and continuous monitoring, and worked through the text a greater number of times.","All participants worked mostly in small syntactic units, but bilinguals and translators also worked in larger discourse chunks, demonstrating greater range and flexibility in their processing styles.","Experience with translation was found to be a more reliable predictor of processing style than degree of language proficiency.","The study discusses the structure of the translation process, the importance of context building in translation, and differences in processing styles within and among the groups, identifying various \"types\" of processors that emerged. Some hypotheses are offered concerning processes that are most likely to produce good translations. Implications for both education and research are presented. 278 Computalional Linguistics, Volume 15, Number 4, December 1989"]}]}