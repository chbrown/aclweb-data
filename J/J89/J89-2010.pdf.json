{"sections":[{"title":"Book Reviews Natural","paragraphs":["Language Parsing Systems be used in educational applications. Bal~ker, van der Korst, and van Schaaik put a new twist on using a generator to implement and test a linguistic theory: they propose using such a program to teach a particular theory (in this case lexical functional l;rammar) in a computational linguistics course.","An odd fact about the book is that it is published in two volumes, each relatively short (under 200 pages). The topics are split between the volumes, with half the papers from each category in each book. I could find no particular motivation for finding a paper in one volume or the other. The foreword, introduction, and contents are repeated in both books, and each has an index, which unfortunately is split between the volumes, so you need to look up topics twice to find, all the papers that address them. Overall, the division into volumes is more annoying than useful (I inevitably found myself on the right page of the wrong volume when looking for a particular paper), and since there is no organization to the division, it is unlikely that someone would be interested in one volume and not the other.","Despite these complaints with the presentation and some of the papers, the book is useful for researchers in NLG and related fields to see the range of work going on in Europe. While the papers themselves are short, their bibliographies can lead the interested reader to a wealth of related material. Furthermore, workshops such as the one motivating this book are important and their results need to be published. In a young field such as NLG the focus of the workshops needs to be broad so that it can define what the major issues are. Collections such as this one and Kempen (1987) help other researchers see how their work interacts with the field as a whole. As the field matures, however, these workshops need to become more focused. As in the AAAI-88 workshop (Hovy, McDonald, and Young 1988), the organizers and the editors need to formulate questions and encourage researchers to address them directly. This will provide more unity in the resulting collections, allowing a reader to get a complete picture of issues rather than isolated snapshots of individuals' work. REFERENCES","Hovy, Eduard; McDonald, David D.; Young, Sheryl 1988 Proceedings of the AAAI Workshop on Text Planning and Realization (AAAI-88), St. Paul, MN.","Kempen, Gerard 1987 Natural Language Generation: New Results in Artificial Intelligence, Psychology, and Linguistics, Martinus Nijoff, Dordrecht, The Netherlands.","McDonald, David D.; Meteer, Marie W.; and Pustejovsky, James D. 1987 Factors Contributing to Efficiency in Natural Language Generation. In: Kempen (1987); 152-182. Marie Meteer is an associate scientist working on natural language generation in the AI Department of BBN Systems and Technologies Corporation. She is the primary developer of the SPOKESMAN generation system, which combines a newly designed text planner and the linguistic realization component Mumble-86. She is also finishing her Ph.D. at the University of Massachusetts at Amherst on decision making and revising in natural language generation. Meteer's address is: BBN Systems and Technologies Corporation, 10 Moulton Street, Cambridge, MA 02138. E-mail: mmeteer@bbn.com NATURAL LANGUAGE PARSING SYSTEMS Leonard Bolc (ed.) (Polish Academy of Sciences) Berlin: Springer-Verlag, 1987, xviii + 367 pp. (Symbolic Computation and Artificial Intelligence","Series) ISBN 3-540-1\"7537-7 and 0-387-17537-7 (hb) Reviewed by Petr Sgall Charles University This volume, containing nine systematic studies on several of the most advanced parsers, fulfills very well the editor's aim characterized in his short preface, namely to present detailed accounts of research by outstanding specialists. The need for a complex overview of the present state of research in the field is mentioned here as a point for subsequent work.","J.G. CarboneU and P.J. Hayes point out in their contribution (pp. 1-32) how a multi-strategy approach (dynamically changing the procedures according to kinds of constructions being parsed) together with failsoft heuristics and with user interaction can be used for an efficient treatment of semantic and structural ambiguity. Two implemented experimental parsers integrating several parsing strategies are characterized: CAS-PAR, combining a case-oriented strategy (based on domain semantics) with linear pattern matching, and thus obtaining the flexibility and robustness needed to handle several kinds of deviations from grammaticality; and DYPAR, including a context-free grammar (with domain information grouped into hierarchical semantic categories), a pattern matching component, and a mapping into a canonical form (accounting for semantic equivalence). Furthermore, an integration of the strategies involved is discussed, yielding a multi-strategy algorithm that uses top-down case-frame expectations to constrain bottom-up pattern matching. ATNs with logical variables and unification are compared with definite clause grammars and used as the basic ingredients of the system described by T.W. Finin and M. Stone Palmer (pp. 33-48). A similarity between the applied framework and certain aspects of lexical functional grammar are pointed out.","The third contribution, by J.G. Neal and S.C. Shapiro (pp. 49-92), stresses the role of natural language understanding, pointing out that natural language serves as its own metalanguage. A system understanding sentences about the use of language is described, which includes a kernel language (expressing the knowledge necessary for a poor language user to be able to be 122 Computational Linguistics, Volume 15, Number 2, June 1989 Book Reviews Natural Language Parsing Systems further instructed) and a set of inferences making it possible to construct a knowledge base. No clear boundary between syntax, semantics, and world knowledge is preferred, and the semantic network consists of nodes representing intensional concepts and arcs corresponding to non-conceptual binary relations between them. Many examples illustrate how a parser (with applicable rules activated in parallel and with bi-direc-tional inference) can be used to enrich the knowledge system.","In the next study (pp. 93-135), J. Pitrat brings arguments in favor of declarative knowledge. The interpreter presented here (parsing chess comments in French) is general enough for the knowledge formalism to take an arbitrary form, although (as the author states) it does not yet use its knowledge as a metaknowledge and is not more powerful than ATNs, especially in dealing with word order.","M. Thiel's contribution (pp. 137-159) is devoted to issues of probabilistic parsing with weights introduced into the lexicon as well as into the set of grammar rules and the control structures. Weights of words and rules are modified in accordance to text type and subject domain.","The word is the central notion of the approach described by S.L. Small (pp. 161-201), who takes all complex expressions of natural language as basically idiomatic and attempts to substitute all syntactic and semantic rules with word experts, which interact together and with higher-order (pragmatically based) processes. One may ask whether the procedural definition language is suitable for a specification of a word expert of such a general character. In any case, the lexically based treatment of syntax and semantics certainly is of great significance.","A. S~gvall Hein presents the Uppsala Chart Processor, using R. Kaplan's approach and points out how efficient the parsing by such a system may be (pp. 203-266). The main advantages of the processor are summarized as consisting, first of all, in a clean cut between the processor and the language, a clean control structure provided by the active chart, the uniformity in processing, the generality and flexibility of the formalism, and the implementation with good tracing facilities.","A breadth-first parser is described by W.A. Martin, K.W. Church, and R.S. Patil (pp. 267-328), who use an adapted version of J. Earley's context-free algorithm, with a procedural grammar, several procedures supporting modularity, and G. Gazdar's treatment of unbounded dependencies. Some difficult grammatical phenomena are treated as \"exceptions\", without an adequate degree of generality.","The volume is concluded by W. Dilger's discussion of the syntax-directed translation in the system PLIDIS (Karlsruhe), which uses a tree-directed grammar (pp. 329-361). On the basis of formal definitions and proofs it is shown here that the grammars of this kind have less computational capacity than transformational grammars; the latter are understood as unsuitable for translating the input sentences into semantic representations, since the complex transformational manipulation of trees makes the grammar not only too strong, but also too difficult to control.","This book consists of well-chosen contributions, representing some of the main developments in parsing, a field whose importance keeps growing thanks to the growing relative weight of natural language comprehension within AI and to the broadening interest in machine translation. Among the developments not represented in Bolc's volume, perhaps the most interesting is that working with dependency grammar (as for English, recent results of a long-term project can be found in Kirschner 1987; for a framework attempting at an integration of unification and dependency, see Hellwig 1988); this approach seems to be more advantageous than the constituency-based trends especially in what concerns the treatment of free word order (which has already been recognized as being far from marginal and playing an important role in the topic-focus articulation, relevant for the issues of quantifier scopes; see Sgall et al. 1986).","It is to the merit of the book that English is by far not the only language handled. Such aspects as the attention paid to the ease of control and enrichment of parsers, to their flexibility with respect to various subject areas, and to the integration of accounting for syntactic and semantico-pragmatic phenomena make the volume a valuable contribution to the development of computational linguistics. Even though progress in the domain has brought new achievements during its production, the volume remains worth reading, since many basic ideas and significant insights are contained, and several original approaches illustrated there are by far not obsolete. REFERENCES","Hellwig, Peter. 1988 Chart Parsing According to the Slot and Filler Principle. In Proceedings of the International Conference on Computational Linguistics (COLING-88), Budapest, Hungary; 242-244.","Kirschner, Zden~k 1987 APAC3-2: An English-to-Czech Machine Translation System. Explizite Beschreibung der Sprache und automatische Textbearbeitung XIII, Charles University, Faculty of Mathematics and Physics, Prague, Czechoslovakia.","Sgall, Petr; Haji~ov~l Eva and Panevov~t, Jarmila 1986 The Meaning of the Sentence in its Semantic and Pragmatic Aspects. Reidel, Dordrecht, The Netherlands and Academia, Prague, Czechoslovakia. Petr Sgall, born 1926, graduated in general and Indo-European linguistics at Charles University, Prague, in 1949, and has been working at the university since then, predominantly in theoretical and computational linguistics. Since 1959 he has been the head of a research group in machine translation and language comprehension. Together with Eva Haji~ov~i and Jarmila Panevov~, he published The Meaning of the Sentence in its Semantic and Pragmatic Aspects, presenting the synthesis of the group's approach to a stratificational and functional linguistic description. SgaU's address is: MFF UK-- Computational Linguistics, Volume 15, Number 2, June 1989 123 . Book Reviews Philosophy, Language, and Artificial Intelligence: Resources for Processing Natural Language Linguistics, Malostranskd n.25, 118 00 Praha 1, Czechoslovakia. PHILOSOPHY~ LANGUAGE~ AND ARTIFICIAL INTELLIGENCE\" RESOURCES FOR PROCESSING NATURAL LANGUAGE Jack Kulas, James H. Fetzer, and Terry L. Rankin (eds.) (University of Idaho, Moscow; University of","Minnesota, Duluth; and IBM AI Support Center,","Palo Alto, CA) Dordrecht: Kluwer Academic Publishers, 1988, xii +","421 pp. (Studies in Cognitive Systems) ISBN 1-55608-073-5, $99.00, Â£58.00, Dfl 195.00 (hb) Reviewed by Peter Ludlow State University of New York at Stony Brook Sometimes philosophers and linguists say things that are of interest to computer scientists or would be of interest if properly explained. Unfortunately, philosophical work and theoretical linguistics are seldom explained in ways that make them seem relevant to computer scientists. That is, they are seldom explained in ways that suggest directions for future research. Given this communication problem, there is a definite need for a volume that can bring together some of the best work in the philosophy of language, linguistics, and natural language processing, and show how work in the philosophy of language and linguistics has been and can be applied to problems in natural language processing. Unfortunately, despite the title ~ and the promotional literature, this volume does not fulfil the need. Part of the problem is that none of the papers in the volume describe work in which the theoretical insights of philosophers and linguists are implemented. There are simply no papers on natural language processing. There is an introduction by Kulas that is supposed to show why these essays are important to AI researchers. But while the introduction occasionally provides reasonable summaries of the essays, it doesn't come close to suggesting applications of the theoretical work to AI. It may well be that computer scientists ought to be familiar with the essays in the book. Most of the essays are, after all, classics. But it is pedagogically naive to think that one can drop, for example, Davidson's \"Truth and Meaning\" in the lap of a computer scientist and suppose that it suggests anything in the way of a research program.","Another part of the problem is that the volume has been limited to papers that originally appeared in books or journals published by D. Reidel. This is unfortunate, for a number of sections of the book could have been greatly strengthened with the addition of material pub-124 lished elsewhere. Now it may be that the editors intended to provide something like \"D. Reidel's Greatest Hits\", but s~ach a strategy seems to me misguided. There is nothing intrinsically interesting about the fact that a paper was first published in a Reidel journal. It may be that tile move was inspired by the desire to hold down costs, 2 but if the editors were successful in holding down costs, the savings certainly were not passed along to the customer. The price of the 12-essay volume is $99!","Thus far my comments have been strong, but general. I think a section-by-section discussion of the book may be in order, to point out specific concerns and to suggest ways in which the collection might have been improved.","The book begins with a prologue entitled \"Modes of Meaning\", which contains Grice's \"Utterer's Meaning, Sentence Meaning, and Word Meaning\"--a great paper, but what it is supposed to suggest to the AI researcher is unclear. Nor is Kulas's introduction much help here, as he offers only a one-sentence summary of the paper.","Part 1 of the book is entitled \"Formal Syntax of Natural Language\", but is really about the question of whether natural languages are context-free. The first essay has no place in this volume. It is a short piece that Pullum wrote as a \"Topic . . . comment\" column for Natural Language and Linguistic Theory, which attempts to sort out who was the first to show that natural language is not context-free. The piece is not, nor do I believe it intended to be, a serious piece of academic research. (Pullum has even expressed amusement that \"Topic... comment\" columns have been indexed and abstracted.) 3 This is not a criticism of Pullum; he has other work on the problem of the context-freeness of natural language (e.g., Pullum 1983) that would have made much better additions to the volume. For that matter, Gazdar and Pullum (1985) would also have been a better choice. The second piece in Part 1 is Shieber's \"Evidence Against the Context Freeness of Natural Language\", which is a solid piece showing how Swiss-German is weakly non-context-free. But Shieber would be the first to admit that the implications of the result for natural language processing are of no great moment.","Part 2 of the collection is entitled \"Semantic Aspects of Natural Language\" and contains Davidson's \"Truth and Meaning\" and Hintikka's \"Semantics for Proposi-tional Attitudes\". I've already noted that the import of Davidson's paper (which makes no concessions to the non-philosopher) is never made clear. As for Hintikka's paper, it isn't really about semantics, but is an application of possible-world semantics to the problem of the attitudes. It more properly belongs with the Perry and Stalnaker papers in Part 5. What is unfortunate about this part of the collection is that there really has been confusion between philosophers and computer scientists about what semantics isma confusion that could have been straightened out here. Most computer scien-Computational Linguistics, Volume 15, Number 2, June 1989"]}]}