{"sections":[{"title":"American Journal of Computational Litrguis tics Mi","paragraphs":["crof i che 4 7"]},{"title":"A SURVEY OF SYNTACTIC ANALYSIS PROCEDURES FOR NATURAL LANGUAGE Computer Science","paragraphs":["Department Courant-Institute of Matheniatical Sciences New"]},{"title":"York University 251 Mercer","paragraphs":["Street, New"]},{"title":"York. 10012 FYris survey was prepared under","paragraphs":["contract No. N00014-67A-0467-0032 with the Office of Naval Research, and was originally issued as Report No. NSO-8 of the Courant Institute of Mathematical Sciences, New York ~niversity. Copyright 0"]},{"title":"1976 Association for Computational Linguistics k SURVEY OF SYNTACTIC ANN-YS IS PROCEDURES FOR NATURAL LANGUAGE","paragraphs":["RALPH GRXSHMAN"]},{"title":"Computer Science Department Courant Institute","paragraphs":["of"]},{"title":"Mathematfical","paragraphs":["Sciences New"]},{"title":"York University This survdy was prepared under contract No. N00014-E7A-0467-0032 wCth","paragraphs":["the OffZce"]},{"title":"of NauaZ Research, and","paragraphs":["was originaZZy issued as Report No."]},{"title":"NSO-8 of the Couraat Institute of MathematicaZ Sciences, New","paragraphs":["York University. SUMMARY This report includes a brief discussion of the role of automatic syntactic analysis, a survey of parsing procedures used in the analysis of natural language, and a discussion of the approaches taken to a number of difficult linguistic problems, such as conjunction and graded acceptability. It also conta'ins precise. specifications in the programming language SETL of a number of parsing algorithms, includinq several context-free parsers, a unrestricted rewriting rul e Parser, and a transformational parser. Table of Contents Page The Role of Syntactic Analysis"]},{"title":"..................... i, Computational and","paragraphs":["Theoretical Lir:guistics.."]},{"title":"........","paragraphs":["I"]},{"title":"...............","paragraphs":["GENEFtAL SURVEY OF PARSING PROCEDITmS 1, 1 Early Systems : Context-Free and Context-Sensitive Parsers-........."]},{"title":"....I..........................L.","paragraphs":["11"]},{"title":"......... Transformational","paragraphs":["Analyzers : First Sys terns. lq","Transformational Analyzers : Subsequent Developmepts 1::",",>I"]},{"title":"...............","paragraphs":["Other Syntactic Analysis Procedures. ..-I","-3 Parsing with Probability and Graded Acceytability"]},{"title":"..","paragraphs":[".--V 7s"]},{"title":".......................","paragraphs":["Conjunction and Adjunction.. L Tl"]},{"title":"..........................","paragraphs":["ALGORITHM SPECIFICATIONS."]},{"title":"...... Parsing","paragraphs":["Algorithms for Context-Free Grammars."]},{"title":"3","paragraphs":["1 A Parser for Unrestricted Rewriting Rule Grammars.."]},{"title":"54 . Parsing Procedures","paragraphs":["for Transformational Grammars.. 60 APPENDIX- A Very Short Introduction to SETL......"]},{"title":".","paragraphs":["34"]},{"title":"....................................... BIBLIOGRAPHY","paragraphs":["92 1. INTRODUCTION The Computer Science Department of dew YorK University, under contract to the Office of Naval Research, has prepared a series of reports examining selected areas of artificial intelligence. We hope in these aritical surveys to place in perspective the main lines of past research and thereby perhaps to suggest fruitful directions for future work. As part of these surveys we have prepared precise specificatibns, in the programing language SETL, of some"]},{"title":"of","paragraphs":["the basic algorithms in each area. These specifications are intended to provide clear points of reference for structuring our review of past work."]},{"title":"*****","paragraphs":["This first report is concerned with natural language processing sys tems, systems which are able to accept instructions 'or data in natural language. In Very general terms, these systems process the text through several stages: (1) syntactic: analyzes the structure of each sentence (or other text unit) and rearranges the elements of the sentence to simplify its structures; this stage should recognize paraphrases due to altexnati~~e arra~lgements of words in a sentence (2) semahtic: restructures the sentences into the form used"]},{"title":"for internal","paragraphs":["processing, such as inference or data retrieval; depending on the application, the output may be a command in an information retrieval language, a structure based on some set of semantic \"primitives\", or a tabular structure suitable as a data base; this stage should recognize some of the paraphrases due to alternative choices of words. (3) pracjmatic: interprets the text based on particular context (problem situation or data base) ; this stage should recognize sentences which are equivalent in effect, (such as \"Thr~w that switch.\" and \"Turn on the light.\")"]},{"title":".","paragraphs":["The reader will note that these stages are very-.vaguely characteri zed. Current language processing sys tems differ very greatly"]},{"title":"in","paragraphs":["their structure and not oven these general divisions can be identified in all systems. Ihe pragmatic stage is the most heterogeneous and the common threads which do appear are based more on general problem-solving methods than on specifically linguistic techniques. Since the semhntic stage maps into the notation required by the pragmatics, it is correspondingly varied. There is"]},{"title":", however,","paragraphs":["a fair amount of current research on the selection of semantic primitives or selnantic classes; some of this research is reviewed"]},{"title":"in","paragraphs":["the proceedi~~gs of a recent Courant Institute symposium on Directions in Artificial Ir~llciligence (Courant ComputPr Science Report No. 7)"]},{"title":".","paragraphs":["The syntactic stage is by far"]},{"title":"the","paragraphs":["best established a'rrd-most clearly defined. There is a general (although far from total) agreement on the most; basic u~lderlying principles, and thare are a number of widely-used procedures. For this stage"]},{"title":",","paragraphs":["therefore, it seems possible to present a survey of current research in some organized fashion. In the report ~dlich follows, we have endeavored to show th.e relation between the various syntactic analyzers in terms of their historical development, linguistic assumptions, and a lalysis procedures. For a broader survey of automated language processing, readers are referred to [Jalker 19731"]},{"title":"- 1.1 The Role of","paragraphs":["Syntactic Analysis The systems we shall be describing are all motivated by particular applications requiring natural language input, rather than by purely linguistic considerations. Consequently, the pjarsing of a text (determining its structure) w-ill be viewed as ari essential step preliminary to processing the information in the text, rather than as an end in itself. There are a wide variety of applications involving natural language input, such as machine translation, information retrieval"]},{"title":",","paragraphs":["question answering, conunand systems, and data collection. It may therefore seem at first that there would be little text processing which wa"]},{"title":"id' be generally","paragraphs":["usefu,i beyond the"]},{"title":"determination","paragraphs":["of a"]},{"title":"structurjal description","paragraphs":["(e. g. a par'se tree) for each sentence. There are, however, a numbet of operations whfch can reqularize sentence structure, and thereby simplify- the subsequen"]},{"title":"vA","paragraphs":["application-specif ic processing. For example, Some material in sentences (enclosed in brackets in the ekamples below) can be omitted or \"zeroed\": John ate cake and Mary [ate] cookies."]},{"title":". . five","paragraphs":["or more [than five] radishes i3e talks faster than John [taLks]."]},{"title":". . . the","paragraphs":["man [whom] I met"]},{"title":".","paragraphs":["Sentence structure can be regularized by restoring such zeroed information. Other transformations can relate sentences with normal word order"]},{"title":"(I crushed those","paragraphs":["grapes. That I like wine is evident.) to passive (Those grapes were crushed by me.) and cleft It is evident that I like wine.) constructions, and c= relate nominal (the barbarians' destruction of Rome) and verbal (the barbarians destroyed Rome) constructions. Such transformations will permit further (e. g., semantic) processing to concern itself with a much smaller nurnper of structures. In addition, if the structures are appropriately chosen, operator-operand relations should be clearly evident in the output of the syntactic stage. Some lexical processes, such as nominalization and lexical decomposition, are considered syntactic by"]},{"title":"some and","paragraphs":["semantic by others. Whether a clear division between the syntactic md semantic stages is ~ossible at all has been a major point of controversy in linguistics"]},{"title":"--","paragraphs":["between interpretive and generative semanticists"]},{"title":"-- over","paragraphs":["the past decade. We may therefore expect that, while some transformations will clearly be the province of the syntactic stage and others the province of the semantic stage, there will be a considerable fuzzy area- in between. This, hmever, should not disqualify automatic syntactic analysis as an area of separate research; there is hardly a"]},{"title":"field","paragraphs":["of science"]},{"title":"or","paragraphs":["enqineering which"]},{"title":"is clearly","paragraphs":["deIineaked"]},{"title":"from its","paragraphs":["neighbors. The"]},{"title":"last few years have seen most","paragraphs":["work"]},{"title":"in","paragraphs":["language"]},{"title":"processing","paragraphs":["devoted"]},{"title":"to","paragraphs":["the"]},{"title":"development of","paragraphs":["integrated sys"]},{"title":"terns,","paragraphs":["combining"]},{"title":"syntactic, semantic, pragmatic,","paragraphs":["and"]},{"title":"generative components.","paragraphs":["This was a healthy and p~dicthle reaction to the earlier research, which had largely approached syntactic processing in isolation"]},{"title":"froin these other areas. Pt","paragraphs":["produced"]},{"title":"some","paragraphs":["systcms whose"]},{"title":"modest","paragraphs":["successes dispelled the skepticism that"]},{"title":"natural","paragraphs":["language proccs-"]},{"title":"sors would","paragraphs":["ever be able to"]},{"title":"-","paragraphs":["do anything. These systcms indicated how"]},{"title":"syntactic, semantic,","paragraphs":["and praglnn tic informL~t ion IIIUS~"]},{"title":"interact to select","paragraphs":["the"]},{"title":"correct sentence","paragraphs":["analysis. It"]},{"title":"is now generally","paragraphs":["understood that syntactic processing by"]},{"title":"itself is","paragraphs":["inadequate"]},{"title":"to select","paragraphs":["the intended analysis of a sentence. e should not conclude from this, however, that it"]},{"title":"is impossible to","paragraphs":["study the processes"]},{"title":"of","paragraphs":["syntax analysis separately"]},{"title":"from the other components. Rather, it","paragraphs":["means that syntax analysis must be studied with"]},{"title":"an","paragraphs":["undarstanding of its"]},{"title":"role in","paragraphs":["a larger"]},{"title":"system","paragraphs":["and the info-rmation it should be able to call upcjn"]},{"title":"from","paragraphs":["other"]},{"title":"components (i e. ,","paragraphs":["the processing which the subsequent con~ponen ts must do to select among the analyses produced by the syntactic component)"]},{"title":". While","paragraphs":["recognizing"]},{"title":"the","paragraphs":["importa~~ce"]},{"title":"of","paragraphs":["total systems in insuring that none of the problems has fallen in the gaps between stages and been forgotten,"]},{"title":"it","paragraphs":["still seers that more specialized research"]},{"title":"projects are essential if","paragraphs":["the"]},{"title":"field-of natural","paragraphs":["lal~yuage"]},{"title":"proces-","paragraphs":["sing is"]},{"title":"to mature.","paragraphs":["The development"]},{"title":"of","paragraphs":["another total system"]},{"title":"will","paragraphs":["not advance the field"]},{"title":"unless","paragraphs":["it endeavors to perform"]},{"title":"some","paragraphs":["particular processing task better than its predecessors; the problems are too vast for each research project to usefully attack the problems involved in all the phases of processing at once. Some researchers have asserted recently that hatural language processing can be done without syntax analysis. It seems"]},{"title":"to","paragraphs":["US that such claims are exaggerated, but they do arise out of some observations that are not without validity: (1) For the rekitively simple, sentences whose slemantics is within the scope of current artificial dnt~lligence systems, sophisticated syntactic processing is unnecessary. This Was certainly true of some early questipn-answering sys teqs"]},{"title":",","paragraphs":["whose syntax was limited to a few fixed imperative structures, into"]},{"title":"which adjective and","paragraphs":["prepositional phrabe modifiers could be inserted. It is questionable whether this is true of the most syntactically sophisticated of today's sys terns (such as Pdtrick's) In any case, it is hard to imagine how sentences of the complexity typical in technical writing c~uld be undetstood without utilizing syntactic (as well as semantic) restrictio$s to select the correct analysis. (2) Syntactic analysis may appear in guisks other than the traditional parsing procedures ; it can be interwoven with other components of the system and cqh be embedded into the analysis programs themselves. This will often increase the parsing speed considexably"]},{"title":". The","paragraphs":["\"grammar in program\" approach which characterized many of the early machine translation efforts is still employed"]},{"title":"in","paragraphs":["some of today's systems. Its primary justification seems to be parsing efficiency, but this should be a secondary, consideration for research purposes at present, sinoe most current systems are able to parse (or, as often, reject as unanalyzable) a sentence in under a minute. More important as research goals should be the ability to manage grammatical complexity and the ability to communicate successful methods to others. In both these regards, a syntactic analyzer using attmified, semiformal. set of rules is bound to be more effective. (3) Syntax analvsis can be driven by semantic analysis (instead of being a separate, earlier stage)"]},{"title":",","paragraphs":["and, in particular, can be done by logking for semantic patterns in the sentence. Syntax analysis is done separately because there are rules of sentence formation and %ransformation which can be stated in terms of the relatively broad syntactic categories (tensed verb, count noun, etc. )"]},{"title":". If","paragraphs":["the semantic classes are subcategorizations of the syntactic ones then clearly the tr2i.p~ for~nntions could be stated in terms of sequepces of semantic classes. For those trnnsfor~nations which are properly syntactic, however, we would find that several transformations at the semantic stage would be required in place of one at the syntactic stage; certain useful generalizations would bc last. The strongest axgument of"]},{"title":"those","paragraphs":["advocating a scm~ntiss-dri.\\.cn syntax is the ability of people"]},{"title":"to","paragraphs":["interpret sentcncos from semantic clues in the face of syntactic errors or missing infor-","11 mation (\"I want to"]},{"title":"-","paragraphs":["xx to the inovies tonight. )"]},{"title":".","paragraphs":["This argument works both ways, however"]},{"title":"--","paragraphs":["people can also use syntactic rules when semantics is lackirlg; Sox esample, to understand the function of a word in a sentence without knowing its meaning (\"Isn't that man wearing a very frimple coat?\")"]},{"title":".","paragraphs":["Ultimately, we want an analyzer which can"]},{"title":"work","paragraphs":["from partial information of either kind, and research in that directi~n is to be welcomed (sone work on parsing in the face of uncertainty has been done by speech-understanding groups). At the same time, since sczcessful processing of \"perfect\" sentences is presumably a prerequisite for processing imperfect sentences, it seems reasonable to continue devoting substantial effort to the rrmsibrable pl-oblems which remain in analyzing perfect sentences. 1.2 ComputationaJ and Theoretical Linguistics Theodtical linguists and the sort of computational linguists we have been considering espouse quite different research objectives"]},{"title":". A","paragraphs":["primary interest of transformational linguists is expl;.ining grammatical competence"]},{"title":"--","paragraphs":["how people come to accept some sentences as grammatical and reject others as ungraunatical. In parti6ular, they are concerned trri th language universals"]},{"title":"--","paragraphs":["principles of grammar which apply to all natural languages."]},{"title":"Computational","paragraphs":["linguists, in"]},{"title":"contrast,","paragraphs":["are"]},{"title":"usually","paragraphs":["delighted if they"]},{"title":"can manage to","paragraphs":["handle one"]},{"title":"language (two,","paragraphs":["if they"]},{"title":"'re","paragraphs":["translating)."]},{"title":"Their primary","paragraphs":["concern"]},{"title":"lies","paragraphs":["ih transforming sentences"]},{"title":"-- often assumed to","paragraphs":["be gramrnatioal"]},{"title":"-- into","paragraphs":["a form acceptable"]},{"title":"to some","paragraphs":["particular application"]},{"title":"s","paragraphs":["ys"]},{"title":"tern. They are concerned","paragraphs":["with the"]},{"title":"efficiency","paragraphs":["of such"]},{"title":"processing, whereas","paragraphs":["theoretical linguists generally"]},{"title":"don ' t worry","paragraphs":["about the recogni"]},{"title":"tion problem at","paragraphs":["all. I.Ionetheless, the"]},{"title":"two","paragraphs":["specialties"]},{"title":"should","paragraphs":["have many"]},{"title":"common areas","paragraphs":["of interest. Questions of grammaticality"]},{"title":"- are","paragraphs":["important, because exuerience"]},{"title":"has","paragraphs":["shown that a grammatical constraint which+"]},{"title":"one","paragraphs":["case determines if h sentence is"]},{"title":"or","paragraphs":["is not acceptable will in other cases be needed to choose between correct and incorrect analyses of a sentence. The relations between sets of sentences, which are a prime focus of transformational grammar, particularly in the Harrisian f famework, are crucial to the success of syntactic analysis procedures, since they enable a large variety of sentences to be reduced to a relatively small number of structu'res"]},{"title":".","paragraphs":["More generally, both specialties seek to understand a particular mode'of communication. Traditional linguists axe"]},{"title":"interested in","paragraphs":["a mode whioh has evolved as an efficient"]},{"title":"means","paragraphs":["of communicating"]},{"title":"ideas between","paragraphs":["people; ultimately, we may hope that they will understand not only the principles of language structure, but also some of tlle reasons why language has developed in this way. Computational linguists,"]},{"title":"in","paragraphs":["studying how language can be wed for man-machine communication, are really asking much the same questions. They want to develop a mode of communication for which people are naturally suited and they want to understand the principles for designing languages which are efficient for comn~micating ideas. PROCEDURES We can impose several rough groupings"]},{"title":"on","paragraphs":["the set of parsers"]},{"title":"in order","paragraphs":["to structure the follawing survey. To begin"]},{"title":"withr we may try to separate those","paragraphs":["sys tcms davclobed with solme reference to transformational theory from the nont-ransforlnational sys terns. This turns out slso to be an approximate historical di+vision, since most systems written since 1965 have made soir~c connection with transformational theory, even though their ihcthods of analysis nmy ke only di%tzantly related to transfol-mational mc ch an i s IIIS"]},{"title":".","paragraphs":["Z'hc tr~~nsformatianal systcms may in turn be divided into those parsers which have bccn systematically clerivca from a specific transformational g~ncrative gracunar and those which have \"sacrificed\" this direct connection rrii th a generative grammar in order to obtain a"]},{"title":"more","paragraphs":["direct and efficient algorithm for recovering base struckures. This division appears to be in part a result of our inadequate theoretical understanding of tran'sformational grammars, and may be reduced by some recent theore tical work on transformational grammar's. 2.1 Early Systems : ContextLFree"]},{"title":".","paragraphs":["and Context-Sensi tive Parsers The prctransformational systems, developed mostly between 1959 and 1965, were, with a few esccptions, parsers for context-free languages, although cloaked in a nur~ber of different guises. These sys terns were based on immediate constituent analysis, dependency tlieory"]},{"title":",","paragraphs":["linguistic string theory, or sometimes no theory at all. The largest and probably the most important of these early projects was the Harvard Predictive Analyzer [Runo 19621. A predictive analyzer is a top-down parser for contest-free grammars written in Greibach normal form; this formulation of the grammar was adopted from earlier work by Ida Rhodes for her Russian-English translation project. The size of the"]},{"title":"grammar was staggering:","paragraphs":["a 1963 report [Kuno 19631 quotes figures of 133 Uord classes 'and about 2100 productions. Even with a grammar of"]},{"title":"this size, the","paragraphs":["system did"]},{"title":"not","paragraphs":["incorporate simple agreement"]},{"title":"restrictions","paragraphs":["of English"]},{"title":"syntax Since","paragraphs":["the program was designed to produce parses for sentences which"]},{"title":"were presumed to","paragraphs":["be grammatical (and not to differentiate between"]},{"title":"grammatical,","paragraphs":["and nongrammatica1 septences)"]},{"title":", it was","paragraphs":["at first hoped that it could operate without these restric-"]},{"title":"tions. It was soon discoveredr however,","paragraphs":["that these restric-"]},{"title":"tions","paragraphs":["were required"]},{"title":"to eliminate","paragraphs":["invalid analyses of grammatical sentencds"]},{"title":". Because the direct","paragraphs":["inclusion of, say,"]},{"title":"sub","paragraphs":["ject-verb number agreement"]},{"title":"would cause a","paragraphs":["large increase in an already very large grammar, the Harvarq group chose instead to include a special mechanism in the parsing program to perform a rudimentary check on number agreement. Thus"]},{"title":"the","paragraphs":["Harvard Predictive Analyzer, though probably the most successful of the context4 ree analyzers, clearly indicated the inadequacy of a context- free formulation of natural languqge grammar. The ~arvard Predictive Analyzer parsing algorithm progressed through"]},{"title":"several","paragraphs":["stages. The first version of the predictive analyzer produced only one analysis of a sentence. The next"]},{"title":"version","paragraphs":["introdtxed an"]},{"title":"automatic","paragraphs":["backup mechanism"]},{"title":"in","paragraphs":["order to produce all analyses of a sentence. This"]},{"title":"is","paragraphs":["an exponential time algorithm, hence very slow"]},{"title":"for","paragraphs":["long sentences; a 1962 report gives typical times as 1 minute for an 18 word sentence and 12 minutes for a 35 word sentence. An improvement of more than an 0- of magnitude was obtained in the final version of the program by using a"]},{"title":"bit matrix for","paragraphs":["a path-elimination technique [Kuno 19651. When an attempt was made to match a nonterminal symbol to the sentence beginning at a particular word and no match was found; the corresponding bit was turned on; if the same symbol came"]},{"title":"up","paragraphs":["again later in the ~arsing at the same point in the sentence, the program would not have to try to match it again. Another important early parser was the immediate constituent anal-yzer used at RAND."]},{"title":"his","paragraphs":["system used a grammar"]},{"title":"in","paragraphs":["Chornsky normal form. and a parsing algorithm designed by John Cocke, which produced"]},{"title":"all","paragraphs":["~nalyses bottom-up in"]},{"title":"a single","paragraphs":["left-to-right scan"]},{"title":"of","paragraphs":["-the"]},{"title":"sentence [Hays","paragraphs":["1967"]},{"title":"f. This was a fqst","paragraphs":["algorithm but - because"]},{"title":"all","paragraphs":["parses were dcve loped si~~~ult-nncous ly"]},{"title":"it","paragraphs":["nccdcd a lot of space for long sentences; the Rand system appears therefore to have bccn limited to sentences of about 30 words. A differe~k"]},{"title":"bottom-up ~IIA~YS~S","paragraphs":["PI-occadure was ust2d ill the first linguistic string t~n~lh*sis pqogram dcval~pcd at the University of Pennsylvania [Harris 19651. This proctxlure, called a cycling cancelling. automaton, makes n stvies left-to-right passes through."]},{"title":"the","paragraphs":["sentence;"]},{"title":"in","paragraphs":["each p~~ss one type"]},{"title":"of","paragraphs":["reduction was"]},{"title":"performed.","paragraphs":["The string parser recognized two classes of strihgs : first o~der, pot containing verb-object, and second order, containing verb-ob ject ; the reduction i,f the sentences was correspondingly done in two stages. In addition & to these reductions, which corresponded to context-f ree rules the parsipg program also included some syntactic restricti~ns which were checked when second order strings were reduced. A system incorpo;t-ating this &lrclinq automaton ~chcme was later used by Bross at Rdsewll Park for the analysis of rrlcdical reports [Bross 196 8, ~hapiro 19711. As far as we k~low, onJy one major parsing system has been developed using a context-sensitive phrase structure graimar, This was DZACON, Direct English Access and Control, which was designed as a natural laqguaqe interface to a co~r~isnd, contml, and information retrieval system for the Army and was developed at General Electric [Craig 1'3661. DZACOiJ was one of the first systems to provide flexible, systematic interaction between the parser and the semantic con~ponent. Associgated with each production"]},{"title":"in","paragraphs":["the grammar was a semantic rule. ~hese rules operated on a ring-structured data base and had the functions"]},{"title":"of locating,","paragraphs":["adding, and changing"]},{"title":"information in","paragraphs":["the data"]},{"title":"base.","paragraphs":["The parsing"]},{"title":"was done","paragraphs":["bottom-up, developing all analyqes of the sentence in parallel. As each reduction was performed, the"]},{"title":"associated semantic rule","paragraphs":["was invoked. In the Case of a query,"]},{"title":"the sequence","paragraphs":["of"]},{"title":"rules","paragraphs":["associated"]},{"title":"with the correct analysis","paragraphs":["was Q supposed"]},{"title":"to Locate the desired answer in the data base. In some cases","paragraphs":["a rule could not be applied to the data base (e.g.,"]},{"title":"a particqlar relation between two items","paragraphs":["did not exist) ; the"]},{"title":"rule","paragraphs":["then returned"]},{"title":"a","paragraphs":["fail-ure signal to the parser, indicating"]},{"title":"that the analysis was semantically","paragraphs":["anomalous, and this analysis was aborted. Woods has noted [Woods 197Ql that the parser used in the Dmm4 pro jecf may produce redundant parses, and has given a parsing algorithm"]},{"title":"for","paragraphs":["context-sensitive languages which"]},{"title":"repedies this","paragraphs":["deficiency"]},{"title":". 2-2 Transformational Analyzers:","paragraphs":["First Systems When"]},{"title":"the theory of transformational grammar was elaborated in the early l.9601s there was","paragraphs":["considerable interest in finding a corresponding recognition procedure. Because the grammar is stated in a generative form, however, this is no simple matter."]},{"title":"A &hornsky) tree transformational grammar","paragraphs":["consists of a set of context-sensitive phrase structure rules, which generate a"]},{"title":"set of base treesa,","paragraphs":["and a set"]},{"title":"of","paragraphs":["transformations, which act"]},{"title":"on base trees to produce the","paragraphs":["surf ace trees. A (Harris) string transfo~tional grammar consists of a finite set of sequences of word categories, called kernel sentences, and a set of transformations which combine and modify these kernel sentences t6 e the other sentences of the language. There are at least three basic problems in reversing"]},{"title":"the","paragraphs":["generative process: (1) for a tree transformational grammar, assigning to a given sentence a set of parse trees which includes all the surface trees which would be assigned by the trans formational grammar (2) giveq a tree not in the base, determining which sequences of transf ormatigns might have applied to generate this tree (3) having decided on a transformation whose result may be the present tree, undoing this transformation If we attack each of these problems in the most straightforward manner, we are likely to try many false paths which will not lead to an analysis. For the first problem, we could use a context-£ ree gramrnar which will give all the surface trees assigned by the transformational granunar, and probably lots more The superabundance of ''false\" surface trees is aggravated by the fact that most E~~glish words have more than one word category (play more than one syntactic role), although normally only one is used"]},{"title":"in","paragraphs":["any given sen'tcnce. F the second and third prpb?ems, rrie can mnswuct a set of reverse tYans formations ; however, since we are probably unable to determine uniquely in, advance the transformations which produced a given tree, we will have to try many sequences of reverse transfolrrnations which will not yield a base tree. Because of these problems, the earliest recognition procedure, ctlggested by Matthews, was based on the idea of synthesizing trees to match a given sentence. Although some checks were to have been made against the sentence during the generation procedure, it was still an inherently aery ir~efficient procedure and was never implemented. Two. major systems were developed in the mid-GO 's, however, which did have limited success: the system of Zwicky et al. at MITRE and that of Petrick. The transf orrnational generative grammar from which the MITRE group worked had a base component with about 275 rules and a set of 54 transformations [Zwicky 19651. For the recognition proce-","It dure they developed manually a context- f ree covering\" grammar with about 550 productions to produce the surface trees and a set of 134 reverse transformational rules. heir recognition procedure had four phases: (1) analysis of the sentence using the context-free covering grammar (with a bottom-up parser) (2) application of the"]},{"title":"revexse trans","paragraphs":["rorrnational"]},{"title":"rules 'i3) for each","paragraphs":["candidate base tree produced by steps (1) and (2)"]},{"title":", a check whether","paragraphs":["it can in fact be generated by the base component (4)"]},{"title":"for each base tree and sequence of transformations which passes the","paragraphs":["test in step (3)"]},{"title":",","paragraphs":["the (forward)"]},{"title":"trans-","paragraphs":["foZmations are applied to verify that the original sentence can in fact be generated (The final check in step (4) is required bccause the covering"]},{"title":"grammar may lead. to","paragraphs":["spurious matches of a"]},{"title":"transformation to","paragraphs":["the"]},{"title":"sentence in the reverse transformational process","paragraphs":["and"]},{"title":"because","paragraphs":["the reverse"]},{"title":"transformations may not","paragraphs":["incorporate' all the constraints included in the forward transformations. ) The"]},{"title":"covering grammar produced","paragraphs":["a large number of spurious surface analyses which the parser must process. The 1965 report for example,"]},{"title":"cites a","paragraphs":["12"]},{"title":"word sentence","paragraphs":["which produced 48 parses"]},{"title":"with","paragraphs":["the covering grammar; each must be followed through steps (2) and (3) before most can be eliminated. The system was therefore very slow; 36 minutes were required to analyze one 11 word sentence. TWO"]},{"title":"measures","paragraphs":["were taken Sy the MITRE group"]},{"title":"to","paragraphs":["speed up the program: \"super-trees\" and rejection rules [Walker 196 61"]},{"title":".","paragraphs":["\"Super-trees\" was the MITRE term for a nodal span representation,"]},{"title":"in which","paragraphs":["several parse trees were represented in a single structure. They intended to apply the reverse transformations"]},{"title":"to these","paragraphs":["super-trees,"]},{"title":"thus processing several","paragraphs":["possible surf ace trees simultaneously; it is"]},{"title":"not clear","paragraphs":["if they succeeded in implementing this idea. Rejection rules were tests which were applied to the tree during the reverse transformational process (step (2) above)"]},{"title":", in order,","paragraphs":["to eliminate some trees as early as possible"]},{"title":"in","paragraphs":["the parsing. The rejection rules incorporated some constraints wi~j-ch previously were only in the forward transformational component, and so eliminated some trees in step 12) which before had survived to step (4)"]},{"title":".","paragraphs":["The rejection"]},{"title":"rules had a","paragraphs":["signific:ant effect on parsing times"]},{"title":"- the 11","paragraphs":["word"]},{"title":"1","paragraphs":["sentence which took 36 minutes hefore"]},{"title":"now","paragraphs":["took only 6 The system developed by Petrick [Petrick 1965, 1966; Keyser 19671 is similar in outline: applying a series oE reverse transformations, checking if the"]},{"title":"resulting tree","paragraphs":["can be generated by the base component, and the: verifying the analysis by applying the forward transfo~mations ta the base tree"]},{"title":". There are,","paragraphs":["however, several diifere~ces from the M'TTRE system, motivated by the desire to have a parser which could be produced automatically from the generative formulation of the grammar. Petrick devised a procedure to generate, from the base component and trans formations, an enlarged context-free granunar sufficient to analyze the surface sentence structures. He also automatict*J.ly converted a set of forward transformations mi?- ting certain conditions into pseudo-inverse (reverse) transformations. HAS parsing procedure also oif fered from the dITRE algorithm in the way in which the reverse transformations are applied. In the MITRE: program reverse transformations operated on a sentence tree, just like foqvard trarlsformations in a Chonlsky grammar. Petrick, on the other hand, did riot construct a surface tree in the analysis phase; when a particular reverse transformation came up for consideration, he built just enough structure above the sentence (using the enlarged context-£ ree grammar) to determine if the transformation was applicable. If it was, the transformation was applied and the structure above the sentence then torn down again; what was passed from one reverse transformation to the next was only the string of word categories. In the verifying phase, of course, Pexrick had to follow the rules of Chon~ky grammar and apply the forward transformations to a sentence tree. The price for generality was paid in efficiency. Petrick's problems were more severe than MITRZ's for two reasons. ~irst, the ~bsence of"]},{"title":"a","paragraphs":["sentence tree during the application of the reverse trans formational rules meant that many sequences of re-rse transformations were tried which"]},{"title":"did","paragraphs":["not correspond to any sequence"]},{"title":"of tree transformations","paragraphs":["and"]},{"title":"hence","paragraphs":["would eventually be rejected. Second, if several"]},{"title":"rever se","paragraphs":["transformations"]},{"title":"Could","paragraphs":["apply at"]},{"title":"some point in the","paragraphs":["analysis,"]},{"title":"the procedure","paragraphs":["could not tell in advance which"]},{"title":"would lead","paragraphs":["to a valid deep structure. Consequently, each"]},{"title":"one","paragraphs":["had to be tried and the resulting structure followed to a deep structure of a \"dead end\""]},{"title":"(where","paragraphs":["no more transformations apply). This produces a growth in the number of analysis paths which is exponential"]},{"title":"in the number of","paragraphs":["reverse"]},{"title":"transformations","paragraphs":["applied. This"]},{"title":"explssion","paragraphs":["ntn be avoided only"]},{"title":"if","paragraphs":["the"]},{"title":"reverse transformations include","paragraphs":["tests of the current analysis tree"]},{"title":"to","paragraphs":["d6terrnine which transformations applied"]},{"title":"to generate .this","paragraphs":["tree. Such tests were included"]},{"title":"in","paragraphs":["the manually prepared reverse transformations of the MITRE group, but it would have been fax too complicated for Pe trick to produce such tests automatlcally when inverting the"]},{"title":"trans formations. Potrick's system has been","paragraphs":["significantly revised over the past decade [Petrick 1973, Plath 1974aI. In the current system the covering grammar and reverse trans formations are both prepared manually. The trans formational decomposition process works on a tree (as did MITRE 's)"]},{"title":", and","paragraphs":["considerably flexibility has been .,provided in stating the trankformations and the conditions of applicability"]},{"title":".","paragraphs":["The transformations and conditions may be stated either in the traditional dorm (used by linguists)"]},{"title":"or in","paragraphs":["terms of elementary operations combined in LISP procedures. The resulting system is fast enough to be used in an information retrieval system"]},{"title":"with","paragraphs":["a grammar of moderate size; most requests are processed"]},{"title":"in less than one minute. 2.3 Transformational","paragraphs":["Analyzers: Subsequent Developmi!ints One result of"]},{"title":"the early","paragraphs":["transforrnati~nal systems was a recognition of the importance sf finding an efficient parsing procedure if traiisformationa.l analysis was ever to be a useful"]},{"title":"19","paragraphs":["techni~ue. As the systems indicated, there are two main obstacles"]},{"title":"to an","paragraphs":["efficient procedure."]},{"title":"First,","paragraphs":["there is the problem of refini'ng the surface analysis, so Chat each sentence produces fewer troes for which transformational decomposition must be atten~pted. This has generally been approached by using a inore 1% powerful mechanism than a context-.free parser for the surface analysis. Second, there"]},{"title":"is the","paragraphs":["problem of dctcrrnining the base structure"]},{"title":"(or","paragraphs":["kernel sentences) from the surface struc.t:ure in a relatively direct fashion. This has generally been"]},{"title":"done","paragraphs":["by associaEing particular rules for building the deep structure with"]},{"title":"rules of","paragraphs":["the"]},{"title":"surface structure analysis.","paragraphs":["The approach here has generally been ad hoc, developing a reverse mapping without mplicit reference to a evrresponding set of fo~ward trans format ions. Several groups which have played a significant role in the development of current parsing systems have been tied together by their comofl use c>f recursive transition networks. Althouqh their use of these transition networks is not central to their basic contribution, it is frequently referred to and so deserves a"]},{"title":"few","paragraphs":["words"]},{"title":"of","paragraphs":["explanation. A transition network is a set of nodes (including one initial and at least one terminal node) and a set of directed arcs between the nodes, labeled with symbols from the language; it is a standard representation for regular languages. A recursive transition network is a set of transition networks in which the arcs of one network may also be labeled with the names of other networks; it is a form of representation of context-f ree languages. In contrast to the usual context-f ree phrase structure grammars, this is equivalent to allowing regular expressions in place of finite sequences of elements in productions. This does not increase the weak generative capactity of the grammars, but allows nonrccursive formulations for otherwise recursive const-ructions. The first system using such a network was developed by Thorne, Bratley, and Dewar at Edinburgh [Thorne 1968, Dewar 19691. They started with a regular base grammar, i-e., a transition network. The importake"]},{"title":"of using a","paragraphs":["regular base lies"]},{"title":"in their claim that some","paragraphs":["transformations are equAvalent"]},{"title":"in","paragraphs":["effect to changing"]},{"title":"the base","paragraphs":["to a"]},{"title":"recursive transition network. Transfor-","paragraphs":["mations which could not"]},{"title":"be handled","paragraphs":["in this"]},{"title":"fasion, such as conjunction, were incorporated in^̂ the","paragraphs":["parsing program. Parsing a sentence"]},{"title":"with","paragraphs":["this surface grammar should then also give some indication of the associated base and transfsLTnational structure."]},{"title":"Their","paragraphs":["published papers"]},{"title":"do","paragraphs":["not describe, however, thee process by which the surface grammar is constructed and so it is not clear just how the"]},{"title":"transformation","paragraphs":["and base structure is extracted, from their parse."]},{"title":"The recutsive transition","paragraphs":["network was developed"]},{"title":"into an augmented recursive","paragraphs":["transition network grammar in the system of Bobrow and Frasex"]},{"title":"mw 9 An","paragraphs":["ausmented network is one"]},{"title":"in","paragraphs":["which an arbitrary predicate, written in some general purpose language (in this case, LISP). may be associated uith each arc in the network. A transition in the netw~rk is not allowed if the predicate associated with the arc fails. These predicates perform two functions in the grammar. First, they are used to incorporate restrictions in the language which would be difficult or impossible to state within the amtext-free mechanisms of the recursive network, e. g."]},{"title":", agreement","paragraphs":["restrictions. Second, they are used to construct the deep structure tree as the sentence is being parsed. The augmented transition network was further developed by Woods at Bolt Beranek and Newman. In order to regularize the predicates, he introduced a standard set of operations for building and testing the deep structure lWoods 1970bl. He considerably enla~ged the scope of the grammar and added a semantic component fbr translating the deep structure into information retrieval commands. With these additions, the system served as a moderately successful natural language input interface to a retrieval system for data about moon rocks [Woods 1972, 19731. The augmented transition network, and in particular the formalism developed bv Woods, has proven ta be an effective instrument for constructing natural language front-ends which"]},{"title":"is relatively simple to implement and use; it is","paragraphs":["probably the most widely used procedure today. Like several of the systems described above, Proto-RELADES, developed 1 IBM Cambridge"]},{"title":"[Culicover","paragraphs":["19691, tried"]},{"title":"to","paragraphs":["obtain a11 efficient tr~nsfor~national decomposition algorithm by linking the rules"]},{"title":"for building the","paragraphs":["deep"]},{"title":"structure to the","paragraphs":["productions"]},{"title":"of","paragraphs":["the surface granmar. Their surface granunar was also augmented by restrictions (in PL/I this"]},{"title":"time).","paragraphs":["Aorvover, their system differed"]},{"title":"from","paragraphs":["those mcntioncd earlier"]},{"title":"in several important respects","paragraphs":[": ~irst, the surf ace grammar allowed context-sensitive as"]},{"title":"well","paragraphs":["as contest-free rules. Second, the rulcs which built"]},{"title":"the deep structure","paragraphs":["during the parse were"]},{"title":"in the","paragraphs":["form af reverse transformations acting or! an (incomplete) sentence tree (in contrast to the rules used by V400dsr for example, which first put- wer& -8nto registers labeled \"subject\""]},{"title":", \"verb\",","paragraphs":["and \"object\" and later build a tree out of them). Proto-RELADES was tested as a restricted English language preprocessor for a library card catalog retrieval system [Loveman 19711. One drawback of these procedures was the relatively ad hoe methodsr from a linguistic point of view, used to construct the surface grammars and to"]},{"title":"tie","paragraphs":["them in to the appropriate reverse"]},{"title":"trans formations. A","paragraphs":["more principled approach to trans formational decomposition was proposed by Joshi and Hiz 1962, Biz 19671. In contrast to the systems described above, their procedure was based on Harris' string transformational granunar. One advantage of the Harrisian theory over that of Chomsky is the theoretical basis it provides for the segmentation of the sentence into \"linguistic strings\" (Chomsky 's theory, in contrast, makes no general assertions about the surface structure of sentences.) The procedure of ~oshi and Hiz was predicated on the claim that, from an analysis of the sentence into linguistic strings, one could directly determine the transformations which acted to produce the sentence, without having to try many sequences"]},{"title":"sf reverse transformations.","paragraphs":["Their proposed sys"]},{"title":"tern","paragraphs":["therefore consisted"]},{"title":"of","paragraphs":["a procedure for linguistic"]},{"title":"string analysis","paragraphs":["(a"]},{"title":"context-free","paragraphs":["parsing"]},{"title":"problem at the level ,of","paragraphs":["simpli fication"]},{"title":"of","paragraphs":["their original"]},{"title":"proposal) and","paragraphs":["a set"]},{"title":"of rules","paragraphs":["which"]},{"title":"constructed from","paragraphs":["each string a corresponding kernel-like sentence. Their original proposal was a simplified scheme"]},{"title":"which","paragraphs":["accounted"]},{"title":"for","paragraphs":["only a limited set of trans.formations. It has been followed by a good deal of theoretical work on adjunct grammars and"]},{"title":"trace","paragraphs":["conditions [Joshi 19731 which has laid a fbrrnal basis for their procedures. These studaies indicate kow it may be possible, starting from a transformational grammar not specifically oriented towards recognition, to dkterrnine the"]},{"title":"features of","paragraphs":["a sentence"]},{"title":"which","paragraphs":["indicate that a particu1a.c transfor-"]},{"title":"mation","paragraphs":["applied"]},{"title":"in generating it, and hence","paragraphs":["to produce"]},{"title":"an","paragraphs":["eff"]},{"title":"i-cient analysis procedure*","paragraphs":["Another group which has used linguistic string analysis is the Linguistic Strinq Project at New York University, led by Sager [Sager 1967, 1973; Grishman 1973a, 1973131. Their system,"]},{"title":"which","paragraphs":["has gone through ssveral"]},{"title":"versions since 1965, is based on a","paragraphs":["context- free grammar augmented with restrictions. Because"]},{"title":"they were","paragraphs":["conce ned"]},{"title":"with processing","paragraphs":["scientific text, rather than commands or queries, they were led to develop a grammar of particularly broad coverage. The present gramrr~ar has about 250"]},{"title":"context-free rules","paragraphs":["and about 200 restrickions; although not as"]},{"title":"swift","paragraphs":["as"]},{"title":"some of the smaller","paragraphs":["systems, the parser is able to analyze most sentences"]},{"title":"in less than","paragraphs":["one minute. Because of the large"]},{"title":"size of","paragraphs":["their grammar, this group *has been particularly concerned with techniques for organizing and specifying the grammar"]},{"title":"which","paragraphs":["will facilitate further development. In particular, the most recent implementation of their system has added a special language designed for the economical and perspicuous staement of the restrictions [Sager 19751. One of the earlier versions of this system, with a much more restricted grammar, was used as"]},{"title":"the","paragraphs":["front end for an information retrieval system developed by Cautin at the University of Pennsylvania [Cautin 1369 ]"]},{"title":". The ~inguistic","paragraphs":["String Project system has recently been extended to include a transformational decomposition phase; this phase follows the linguistic? string analysis [IIobbs 19751. As"]},{"title":"in the","paragraphs":["case of the Joshi-IIiz parser, thc strings ide~~tificd in"]},{"title":"the","paragraphs":["sentence generally indicate which rcvcrsc transfrsrmatisns must be applied. '?he trans'forrnations are written in an extension of the 1-anguage which was used fur writing the restrictions. The systelus of Woods, Petrick, and Sayer exhibit a range of approaches"]},{"title":"to the","paragraphs":["prob J.m of tral.lsf or~naticanal deceinpos i tion. Their parsing p~octzclurcs are si filar in ,nany respects: they have a contcxt-£see granunar as the Ertt~uowsrk for their surface analysis, and they use procedures both to cspress gral1~11rltical co~~straints and to effect the reverse transformations. Petrick's system differs"]},{"title":"from","paragraphs":["the others"]},{"title":"in","paragraphs":["two primary respects : the restrictions on the context-free grammar are imposed by filtering trans forn~a-tions which act early in the transformatipnal phase to reject ill-formed trees, rather than by procerlures operating during the surface analysis. This wol ld seem to be disadvantageous"]},{"title":"from","paragraphs":["the point of view of efficicncy, since erroneous parses which might be aborted at the 'beginning of the suxface analysis must be followed through the entire surface analysis and part of the transformational deconpssi tion. Second, the trans formations are not associated"]},{"title":"wi.m","paragraphs":["particular productions of the surface grarxnar, but rather with particular patterns in the tree (\"structural descriptions\")"]},{"title":", so","paragraphs":["pattern match; ng operations are required to determine 1;rhich transformations to apply. These differences reflect Petrick 's c'iesire to remain as close as is practical to the formalism of transformational linguistics. The primary distinction of the Woods system is that the deep structure tree is built during the surface analysis. Consequently, his \"transformati.ona1\" procedures consist of tree building rather than tree transforming operations. The tradeoffs between this approach and the two-stage analyzers of petrick and Sager"]},{"title":"are","paragraphs":["difficult tg weigh at this time. They are part of the more general problem of parallel vs. serial processing; e.g. should semantic analysis be done concurrently with Syntactic analysis. Parallel processing is preferred if the added time required by the deeper analysis is outweighed by the fraction of incorrect analyses which can be eliminated early in the parsing erocess. In the case of"]},{"title":"s","paragraphs":["?mantic analysis, it clearly depends on the relative complexity of the syntactic and semantic components. In the case of"]},{"title":"transformational","paragraphs":["analysis, it depends on"]},{"title":"the","paragraphs":["fraction"]},{"title":"of grammatical","paragraphs":["and selecti~nal"]},{"title":"constraints which can","paragraphs":["be"]},{"title":"expressed","paragraphs":["at: the"]},{"title":"surface level (if most of these can only be realized through transformational","paragraphs":["allalysis"]},{"title":", concurrent trans formational","paragraphs":["analysis"]},{"title":"is probably","paragraphs":["more"]},{"title":"efficient). This may","paragraphs":["depend"]},{"title":"in","paragraphs":["Lurn"]},{"title":"on","paragraphs":["the type"]},{"title":"of","paragraphs":["surface analysis ;"]},{"title":"for example, the","paragraphs":["relationships"]},{"title":"exhibited","paragraphs":["by linguistic string analysis axe suitable"]},{"title":"for expressing many of these","paragraphs":["constraints, so there is less motivation"]},{"title":"in the Linguistic","paragraphs":["String Project system for concurrent trans formational decomposition. 2.4. Other Syntactic Analysis Pxocedures The system developed by Winograd at M. I. T. [Winograd 19711 for accepting English commands and questions about a \"block world\" also uses a context-free grammar augmented by restrictions. Winograd's context-free grammar was encoded as a set of procedures instead"]},{"title":"of a","paragraphs":["data structure to be interpreted, but this is not a material difference. His grammar is based","I1 on Halliday 's systemic grammar\" to the extent that it extracts from a sentence the set of features described by Halliday; however, Halliday 's grammar (at least in its present stage of' development) is essentially descriptive rather than generative, so"]},{"title":"most of","paragraphs":["the detailed grammatical structure had"]},{"title":"to be supplied by Winograd.","paragraphs":["His parser does not construct a deep"]},{"title":"structure;","paragraphs":["rather,"]},{"title":"it","paragraphs":["builds semantic structures directly during parsing. The primary distinctive feature of his system is the integration"]},{"title":"of","paragraphs":["the syntactic component with senantics and pragmatics (the manipulation of objects in the block world) ; hi$ parser"]},{"title":"is thus","paragraphs":["able to use not only syntactic constraints but also semantic and pragmatic information in selecting a proper sentence analysis. With regard .to the serial vs. parallel distinction drawn"]},{"title":"in the","paragraphs":["previous section, his system would be characterized as highly patallel. A number of natural language systen~s ?lave used granunars composed of finrestricted phrase-structure rewriting rulcs. Since unrestricted rewriting rules, like transformational grammars, can be used to define any recursively enumerable language, they may be suf ficicnt for analyzing both surface and deep structure. As with transformational. grallunars, it will in practice be necessary to inlpose some cons tralnt (such as ordering) on the rules, so that the language defined is recursive; otherwise a parser will never be able to determine whzther some sentences are grammatical or not. One parser for unrestricted rewriting rules was described by Kay [Kay 19671. This parser includqd a number of mechanisms for restricting the application of rules, such as rule ordering, specifying part of the structure dominated by one elernentkof the rule, or requirihg the equality of the structures don~inatcd by two"]},{"title":"elements. These","paragraphs":["mechanisms do not increase the gcnera-tive power of"]},{"title":"the grammars,","paragraphs":["but are designed to make granunars easier to write. Kay described how his parser could be used to effect some gfeverse transformations. Kay's parser was incorporated into a system called REL (Rapidly Extensible Langllage) developed by Thompson, Dostert, et al. at the California Institute of Technoloqy [Thompson 1969, Dostert 19711"]},{"title":".","paragraphs":["Kay's original parsor was auqmented by allowing a set of binary features to be associated with each node, including feature tests as park of the rewrite rules, and permitting more general restrictions where the features were inadequate. The REL system was designez to support a number"]},{"title":"of graimnars, each interfaced to its own data base. One of these is REL English,","paragraphs":["which"]},{"title":"analyzes","paragraphs":["a"]},{"title":"subset of","paragraphs":["English"]},{"title":"into a set of sub","paragraphs":["ject-verb-ob ject-time"]},{"title":"modifier","paragraphs":["deep"]},{"title":"structures","paragraphs":["; this grammarhas"]},{"title":"239 rules. In","paragraphs":["support"]},{"title":"of","paragraphs":["the use of general rewrite"]},{"title":"rules","paragraphs":["with features, they"]},{"title":"note that only","paragraphs":["29"]},{"title":"of","paragraphs":["the 239"]},{"title":"rules required","paragraphs":["constraints"]},{"title":"which","paragraphs":["could not be conveniently stated"]},{"title":"in","paragraphs":["terms of feature tests. This is also a factor in"]},{"title":"efficiency, since","paragraphs":["binary"]},{"title":"feature","paragraphs":["tests can be performed very quickly. Another"]},{"title":"system","paragraphs":["which uses"]},{"title":"unrestricfed rewriting rules","paragraphs":["with"]},{"title":"optional conditions on the elements is the \"Q\" system","paragraphs":["developed by"]},{"title":"Colmerauer [Colmerauer 19701.","paragraphs":["*his system is presently being used"]},{"title":"in a","paragraphs":["machine"]},{"title":"translation prqject","paragraphs":["af"]},{"title":"the","paragraphs":["Universitv"]},{"title":"of Montreal [Kittredge 19731. Colmerauer","paragraphs":["and de Chastellier [de Chastellier 196 9 ] have also investigated"]},{"title":"the possibility of using Wijngaarden grammars (as were","paragraphs":["developed"]},{"title":"for","paragraphs":["specifying ALGOL 6 8) for :tr.ansformational"]},{"title":"decomposition","paragraphs":["and"]},{"title":"machine","paragraphs":["translation. Like"]},{"title":"unrestricted rewriting rules, W-grammars","paragraphs":["can define"]},{"title":"every recursively enumerable laquage,","paragraphs":["and"]},{"title":"so can perform the functions of","paragraphs":["the syrface and"]},{"title":"reverse transformational components.","paragraphs":["They show"]},{"title":"how","paragraphs":["portions"]},{"title":"of transformational","paragraphs":["grammars"]},{"title":"of English","paragraphs":["and French may be"]},{"title":"rewritten as W-grammarsr","paragraphs":["with the"]},{"title":"pseudo-rules in","paragraphs":["the W-grammar taking"]},{"title":"the","paragraphs":["place"]},{"title":"of the","paragraphs":["transfol'mations~ 2.5 Parsinq with Prop-ability and Graded Acceptability In"]},{"title":"all","paragraphs":["the systems dqscribed above, a sharp line was drawn between correct and incomect parses: a teminal node either did or did not match the next"]},{"title":"word in the","paragraphs":["sentence: an analysis"]},{"title":"of","paragraphs":["a phrase was either acceptable or unacceptable. There are circumstances under which"]},{"title":"we would want","paragraphs":["to relax these requirements. For one thing, in analyzing connected speech, We segmentation and identification of words can never be done with"]},{"title":"complete certainty. At best, one can","paragraphs":["say"]},{"title":"that a certain sound","paragraphs":["has"]},{"title":"some","paragraphs":["probability"]},{"title":"of being","paragraphs":["one"]},{"title":"phoneme and son= other","paragraphs":["probabiJi"]},{"title":"ty of being another phoneme; some expected","paragraphs":["phonemes may"]},{"title":"be lost entirely in the sound received. consequently, one will associate","paragraphs":["some"]},{"title":"nufier","paragraphs":["with each terminal node, indicating the probability"]},{"title":"or quality of match; noflcrminal nodes will be assigned some value","paragraphs":["based"]},{"title":"on","paragraphs":["the"]},{"title":"values of","paragraphs":["the"]},{"title":"terminal","paragraphs":["nodes )xneath. Another"]},{"title":"circuinstance arises in natural language","paragraphs":["systems which aro sophisticated mough to realize that"]},{"title":"syntactic","paragraphs":["and"]},{"title":"semantic rcs trictions are rarely all-or-nothing affairs, and","paragraphs":["that"]},{"title":"some","paragraphs":["restrictions arc stronger than others# Fur rsan~pla, the nominative-accusative"]},{"title":"distinction","paragraphs":["has become"]},{"title":"qui tc !tqc,ak for relative","paragraphs":["pronouns (?The man ~17x1"]},{"title":"I met","paragraphs":["1'ester;Flay. ) but remains strong for"]},{"title":"personal pronouns (*The","paragraphs":["man whom,"]},{"title":"me ~nct","paragraphs":["yesterday.)."]},{"title":"As a","paragraphs":["result, a parser which wants"]},{"title":"to","paragraphs":["get the best analysis even"]},{"title":"if","paragraphs":["every analysis violates"]},{"title":"some","paragraphs":["constraint must associate a measure of grammaticality or acceptability with the analyses of"]},{"title":"portions of","paragraphs":["the"]},{"title":"sentence,","paragraphs":["and ultimately with the analyses of the entire sentence. In principle,"]},{"title":"one","paragraphs":["could generate every sentence analysis with a nonzero acceptability"]},{"title":"or","paragraphs":["probability of n~atch, and then select"]},{"title":"the","paragraphs":["best"]},{"title":"analysis","paragraphs":["obtained. IIobbs [1974] has described a"]},{"title":"modi-","paragraphs":["fication to the bottom-up nodal spans parsing algorithm which uses this approach. WPlks [1975] uses an essentially similar"]},{"title":"technique in his","paragraphs":["lLuguage analyzer based on \"preference semantics"]},{"title":"\" A","paragraphs":["more efficient approach, called \"best-first\" parsing, has been"]},{"title":"developed","paragraphs":["by Paxton and Robinson of the Stanford Research"]},{"title":"Institute as","paragraphs":["part of a speech understanding system"]},{"title":"axto ton 19731. Their","paragraphs":["procedure involves a modi fication of the standard top-down serial parsing algorithm"]},{"title":"for","paragraphs":["ccntext-free grammars. The standaqd algorithm generates"]},{"title":"one","paragraphs":["possible parse tree until it gets stuck"]},{"title":"(generates a","paragraphs":["terminal node"]},{"title":"which","paragraphs":["does not match"]},{"title":"the next","paragraphs":["sentence word) ;"]},{"title":"it","paragraphs":["then \"backs up\" to try another alternative. The"]},{"title":"best-first procedure instead tries all alternatives in IleL A measure is associated with each","paragraphs":["alternative path, fadicating the likelihood that this analysis matches the sentence pwssed"]},{"title":"so far and","paragraphs":["that it"]},{"title":"can be","paragraphs":["extended"]},{"title":"to a let@ s@xtence analysis. At each","paragraphs":["moment, the path with the higbsst"]},{"title":"likelihood is","paragraphs":["extended;"]},{"title":"if its measure falls","paragraphs":["below that"]},{"title":"otner path, the parser","paragraphs":["shifts its attention to that 2-6 ur~lon4uhction and Adjunction"]},{"title":"mere am$ certain pervasive","paragraphs":["natural language c~nstructivns rch ds not fit naturally into the standard syntax analysis dues, such as"]},{"title":"augmented context-free parsers. Two","paragraphs":["of se"]},{"title":"are coordinate","paragraphs":["conjunctions and adjuncts. Special"]},{"title":"reastAres have Deen developed to","paragraphs":["handle these constructions; these measur&s deserve brief mention here."]},{"title":"allowed patterns","paragraphs":["of"]},{"title":"occwl-rence","paragraphs":["of con joinings in a sentence are quite regular. Loosely speaking, a sequence of"]},{"title":"e nts in the","paragraphs":["sentence tree may be followed by a con junction aad by same or all of the elements immediately preceding the jrmction. For example, allowed patterns of con joining subject-verb-ob ject-and-sub ject-verb-ob ject (I drank"]},{"title":"dw and nary ate","paragraphs":["cake. )"]},{"title":", sub","paragraphs":["ject-verb-ob ject-and-verb-object"]},{"title":"a milk and ate cake.","paragraphs":[") and sub ject-verb-ob ject-and-ob ject [I ikank dlk and seltzer. )"]},{"title":". There","paragraphs":["are certain exceptions, known"]},{"title":"as ing phenomena, in which","paragraphs":["one of the elements following the","amjlmction may be omitted; for example, sub ject-verb-object-and-ject-object (I drank milk and Mary seltzer.)"]},{"title":". trouble with","paragraphs":["coordinate conjunctions is that they can t anywhere"]},{"title":"in","paragraphs":["the structure of a sentence. Thus,"]},{"title":"it would be possible","paragraphs":["tr, extend a context-free surface to allow for all*possible conjoinings, such an extension increase the size of the grammar by perhaps an order of"]},{"title":". The alternative scheme which has therefore been","paragraphs":["developed"]},{"title":"involves the","paragraphs":["automat'ic generation of productions"]},{"title":"which allow","paragraphs":["for conjunction as required during the parsing process."]},{"title":"When a conjunction","paragraphs":["is encountered in the sentence, the normal parsing procedure is interrupted and a special co~ljunction node is inserted"]},{"title":"in","paragraphs":["the parse tree. The alternative"]},{"title":"values of this","paragraphs":["node provide for the various conjoi~~cd"]},{"title":"element 'sequences allowed at","paragraphs":["this point."]},{"title":"An interrupt","paragraphs":["mechanism"]},{"title":"of","paragraphs":["this sort including"]},{"title":"provision for gapping, is","paragraphs":["part of the Linguistic String Project parser [Sager 19671. A similar mechanism is included in Woods"]},{"title":"'","paragraphs":["augnlen ted transition network parser [Woods 19731 and a number of other sys terns. This solves the problem of correcting the context-frcc granmar for conjunctions, but"]},{"title":"the","paragraphs":["contest-f rcc granw~lar is generally only a small part of"]},{"title":"the","paragraphs":["total system."]},{"title":"The","paragraphs":["task remains of modifying the routines which enforce granxmatical constraints and the transformations to account for con junctions. Since practically every routine which examines a parse tree is someWow affected by conjunction, this can be a large job, but fortunately"]},{"title":"the","paragraphs":["changes are very regular for most routines."]},{"title":"The","paragraphs":["Linguistic String Project grammar; by performing a&l operations on the parse tree through a s~nall nunbcr of low-level"]},{"title":"routines, was","paragraphs":["able to localize the changes to these routines and a"]},{"title":"srngll","paragraphs":["number of restrictions (such as nun&er agrcerneJt) which are specially af fectcd by"]},{"title":"con","paragraphs":["junction [Raze 19741. Certain classes of adjuncts or modifiers give rise to a different kind of problem: a high degree of syntactic ambiguity. For instance, in the sentence) \"I fixed the-pipe under"]},{"title":"the sink","paragraphs":["in the bathroom tzri th a wrench."]},{"title":"\" there is no","paragraphs":["syntactic basis for deciding whether the pipe had a wrench the sink had a wrenoh, the bathroom had a wrench, or the tixing was done with a wrench. If semantic and pragmatic restrictions are invoked during the syntactic analysis, the parser will have to generate several analyses, all but one of which will (hopefully) be rejected by the restrictions ; this is moderately inefficient. If syntactic analysis precedes semantic processing i the ambiguities of the various adjuncts wi 11 be multiplied producing dozens of analyses for a sentence of moderate size ; this is hopelessly inefficient-A more efficient solution has the parser identify the adjuncts and list for each adjunct the words it could be modifying, without generating a complee separate arp-alysis for each possibilfty. The ambiguities associated with the adjuncts are thus factored out. The semantic and pragmatic components may then choose for each adjunct its most likely or acceptable host (modified word). This may be done either during the syntactic analysis [woods 1973, Simmons 19751 or after the syntax phase is complete [~orgida 1975, Hobbs 19751. 3. ALGORITHM SPECIFICATIOtJS We present below precise specifications"]},{"title":"for","paragraphs":["some of the parsing algorithms which"]},{"title":"have","paragraphs":["been discussed. These algorithms are presented"]},{"title":"in","paragraphs":["SETL, a programming language which"]},{"title":"is","paragraphs":["based"]},{"title":"on","paragraphs":["concepts"]},{"title":"Prom","paragraphs":["set theory and has been developed at New York University by a group led by Jack Schwartz. The large variety of data types, operators, and control structures"]},{"title":"in SETL","paragraphs":["makes it possible to specify"]},{"title":"the","paragraphs":["algorithms"]},{"title":"in a","paragraphs":["relatively compact and natural fashion. An implementation is available which includes most of the fcaturcs of the specification language, so that algorithms can be tested"]},{"title":"in essentially","paragraphs":["the form in"]},{"title":"which they","paragraphs":["are published. A description of the subset of SETL whici~ has been used in this report is given in the appendix. 3.1 Parsing Alqorithms for Context-Free Grammars _. Context-free grammars played a major role i the early stages"]},{"title":"of","paragraphs":["automatic"]},{"title":"natural","paragraphs":["language analysis. A1 though they have now generally been superceded by more con~plex and powerful grammars, many of these grammars are based on or have as one of their"]},{"title":"components","paragraphs":["a context-f ree grammar. The selection"]},{"title":"of an","paragraphs":["efficient context-free parser theref ore remains an i~nportant considerat ion in natural Language analysis. Jecause so"]},{"title":"many","paragraphs":["different"]},{"title":"context-free","paragraphs":["parsers"]},{"title":"have","paragraphs":["been proposed, a comprehensive survey would"]},{"title":"be","paragraphs":["impracti cable. We si~all rather present a taxonomy according t.u which most context-free parsers can be classified, and illustrate this classification with five of the possible basic zlgorithms. At the end we shall mention which 6f these are beinq used"]},{"title":"in current","paragraphs":["natural language systems"]},{"title":".","paragraphs":["T?L~ first division we shall make is according to the amount of memory space requLred"]},{"title":"by the","paragraphs":["parser. Type 0 parsers store only the parse tree currently being built. The other parsers grabally accumulate data from which all parses of a sentence can be extracted; types 1, 2 and 3 store this data in decreasingly compact representations. The four types are : (0) Develops a single parse tree at a time; at any instant the store holds a set of nodes corresponding"]},{"title":"to the","paragraphs":["nodes of an incomplete potential parse tree ft) The store holds a set of nodes, each of which represents the fact that some substring of the sentence, from word f to word R, can be analyz~d as some symbol N. (2) The store holds a set of nodes, each of which represents an analysis of some substring of the sentence, from word f to word"]},{"title":"a, as some symbol","paragraphs":["N (if there are several different analyses of words f to 11 as some symbol N, there will be several nodes corresponding to a single node in a type 1 parser). (3) The store holds a set of nodes, each of which corresponds to an analysis of? some substring of the sentence; from word f to word"]},{"title":"a,","paragraphs":["as some symbol N appearing as part of some incomplete potential parse tree (if symbol N, spanning words f to !L, appears in several of the incomplete potential parse trees, there will be several nodes corresponding to each node in a type 2 parser)"]},{"title":". Type (0)","paragraphs":["parsers require only an qmount of storage proportional to the length of the input sentence. The storage requirements of type (1) parsers grow as the cube of the length, while the requirements for types (2) and (3) grow exponentially. A second division can be made between top-down and bottom-up parsers. A third criterion for classification is whether alternative parses of a sentence are all produced together (parallel parser) or are generated sequentially (serial parser) ; this division doe$ not apply to type (0) parsers. Finer divisions can be made of some of these categories. For example, among bottom-up parsers we can distinguish those which perform a reduction only when all required elements have been found from those which make a tentative reduction when the first element of a production is found (so-called"]},{"title":"\" left-corner parsers\"). Parallel parsers can","paragraphs":["be classified according to the orderin(- strategy they use in building nodes: by leftmost or rightmast word subsumed i"]},{"title":". e ,","paragraphs":["spanned) by the node or by levell. In addition, we shall not consider a number of optimization strategies, such as selectivity matrices and shaper and general-ized shaper tests for top-down parsers. We shall naw describe algorithms in five of the cateyorics: A Type 0 Top-down serial B Type 2 Bottom-up parallel C Type 1 Bottom-up parallel D ~y~e' 2 Top-down seri a1 E Type 1 Top-down serial We have not included any type 3 parsers bccausc, despite their profligate use nE storage, they do not operate inuch Easter than type 0 parsers. The only reported use of such a parser of which we are aware is the \"Error-Correcting Parse Algorithm\" of Irons (Cornm. ACM - 6, 669 (1963) )"]},{"title":". A","paragraphs":["top-down left-to-right parallel strategy was employed so that the parser could make a suitable modification to the sentence when it \"got stuck1' because","of an error in the input. STSITL ~rocedures are given for these five parsers. The input data structures are the same in all cases: The sentence, passed through parameter SENTENCE, is a tuple. The elements 0 the tuple, the words of :he sentence, are to be matched by terminal symbols from the grammar. The context-f ree grammar, passed through parameter GRAMMAR, is a set each of whose elements corresponds to a production* The production a -+ al a2"]},{"title":"... 0 a","paragraphs":["r? is transformed into the [ntl) -tuple <ao, alra2,"]},{"title":".. ,a,","paragraphs":["> The root symbol sf the grammar is passed to the parser in parameter ROOT. Algorithm A, Type 0 T-op-down Serial","This procedure builds the parse trees for the input sentence sequentially in a two-dimen~iona$ arrap TREE. The first subscript of TREE specifies the number of the node, the second selects t component of the node as follows: TREE(n,'NAME1) name of node n TREE (n"]},{"title":", ' PARENT '","paragraphs":[") number of Barent node of node n (= 0 far root node) TEE ( n"]},{"title":", '","paragraphs":["DAUGHTERS"]},{"title":"'","paragraphs":[") tuple of numbers of daughter nodes of node n TREE (n"]},{"title":", '","paragraphs":["CURRENT OPTIOY ) tuple of current production used to expand this node TREE (n, 'ALTEEJATIVE OPTIONS~') set of tuples representing productions not yet! tried for this node TRlEE (n, 'FW1) TREE (n, 'LW+~') number of first sentence word subsumed by node n (number of last s~ltence word subsumed by node n)"]},{"title":"+ 1 As","paragraphs":["each analysis of the sentence is completed, it is added to the skt PARSES. When parsing is finished, this ~t of trees is returned as the value of the function PARSE. The variable NODES holds a count of the number of npdes in the parse tree; this is also the number af the node most rqcently added to the tree. WORD holds the number of the next word in fie sentence to be matched. The heart of the parser is the recursive proced~re EXPAND. EXPLtD is passed one argument, the number of a node in the parse tree. IY EXPAND has not been called for this node before, it will try to expand the node, fbe."]},{"title":", build","paragraphs":["a parse tree below the node which matches part"]},{"title":"of","paragraphs":["the remainder of"]},{"title":"the","paragraphs":["sentence. If EXPAND has already been called once for this node"]},{"title":"--","paragraphs":["so that"]},{"title":"a tree","paragraphs":["already exists below"]},{"title":"this node --","paragraphs":["EXPAND tries to find an alternate tree below the node which will match up"]},{"title":"with","paragraphs":["part of"]},{"title":"the","paragraphs":["remainder"]},{"title":"of the","paragraphs":["sentence. If EXPAND is successful"]},{"title":"-- an","paragraphs":["(alternate) tree below the node was found"]},{"title":"-- it returns the value true;","paragraphs":["if it"]},{"title":"is","paragraphs":["unsueeessful, it returns false. In the case where the node corresponds do a terminal sy~nbol, EXPAND will return true on the first call only if the synbol matches the next word"]},{"title":"in","paragraphs":["the sentence; it will always"]},{"title":"return","paragraphs":["false"]},{"title":"on","paragraphs":["the second call. definef PARSE (6'11~filhlAR~ ROOT, SENTENCE) ; local PARSES, TREE, NODES, WORD ; TREE ="]},{"title":"nR; PARSES","paragraphs":["= nz; WORD = 1; 'LIJODES = 1;"]},{"title":"/*","paragraphs":["set up"]},{"title":"root","paragraphs":["node (node 1)"]},{"title":"*/","paragraphs":["TREE(,̂"]},{"title":"'NAME')","paragraphs":["= ROOT; TREE(1, 'FW') = WORD;"]},{"title":"/*","paragraphs":["loop until a11 parse trees have been formed"]},{"title":".*/ (while","paragraphs":["EXPAND (1 ) )"]},{"title":",/* if","paragraphs":["tree spans entire sentence, add to set"]},{"title":"*/ if","paragraphs":["WORD eq ( ( Km?TENCE) +1J then PARSES = PARSES U {'I'REE); end if WORD; end"]},{"title":"while","paragraphs":["EXPAND; re turn PARSES ; end PARSE; definef EXPAND(X) ; local I, OPT; if"]},{"title":"GRAMMARITREE(X~~NAME~H eq nR","paragraphs":["then"]},{"title":"/*","paragraphs":["terminal symbol"]},{"title":"*/ if","paragraphs":["TREE (X, 'ALTERNATE OPTIONS"]},{"title":"'","paragraphs":[") eq 0 then"]},{"title":"/* first call -- test for match with sentence */","paragraphs":["TREE (X, 'ALTERNATE OPTIONS"]},{"title":"'","paragraphs":[") = nR; if WORD le #SENTENCE then if SENTENCE(W0RD) eq TREE(x, 'NAME') then WORD = WORD"]},{"title":"+ 1;","paragraphs":["TREE(X, 'LW+lf) = WORD; return true ; end if SENTENCE; end if WORD; else"]},{"title":"/* second call */ WORD","paragraphs":["= WORD-1; end if TREE; return false; end if GRAMMAR;"]},{"title":"/* nonterrninal symbol */ if","paragraphs":["TREE"]},{"title":"(x,","paragraphs":["'ALTEFWATE OPTIONS"]},{"title":"'","paragraphs":[") eq Sl then"]},{"title":"/*","paragraphs":["first call, retrieve options from grammar"]},{"title":"*/ TREE (XI 'ALTERNATE OPTIONS '","paragraphs":[") = GRAMMAR{TREE"]},{"title":"(x,","paragraphs":["'NAME"]},{"title":"'","paragraphs":[") ; TIREB(X, 'DAUGHTERS') = nult; OPT = 52; else"]},{"title":"/*","paragraphs":["second or subsequent call"]},{"title":"*/","paragraphs":["OPT = TREE(XI 'CURRENT OPTION'); I = #OPT; end if TREE;"]},{"title":"/*","paragraphs":["select next option to try"]},{"title":"*/","paragraphs":["GE3'OPT: if OPT eq 0 th\\en OPT from TEIEE(X, 'ALTERNATE OPTIONS1) ; TREE"]},{"title":"(x,","paragraphs":["'CURRENT OPTION' )"]},{"title":"--","paragraphs":["OPT; I = 1; end if OPT;"]},{"title":"/*","paragraphs":["ekpand node"]},{"title":"*/","paragraphs":["kvhile I ge 1)"]},{"title":"/* work","paragraphs":["on lth element of current option"]},{"title":"*/ /* if","paragraphs":["corresponding node not in parse tree, add it"]},{"title":"*/ i\\f","paragraphs":["TREE (XI 'DAUGIITERS"]},{"title":"'","paragraphs":[") (I) eq"]},{"title":"Q","paragraphs":["then NODES A NODES"]},{"title":"+ 1: TREE","paragraphs":["(NODES, 'NAME ) =, OPT (I) ; TREE= (NODES,"]},{"title":"' FW '","paragraphs":[") = WORD ; TREE (NODES, 'PARENT"]},{"title":"'","paragraphs":[") = X; TREE (XI"]},{"title":"'","paragraphs":["DAUGHTERS"]},{"title":"'","paragraphs":[") (I) = NODES ; end if TFCEE;"]},{"title":"/* kry for","paragraphs":["an(other) expansion of this node"]},{"title":"*/ b if","paragraphs":["EXPAND (TREE (X,"]},{"title":"'","paragraphs":["DAUGIlTERS"]},{"title":"'","paragraphs":[") (I) ) then"]},{"title":"/*","paragraphs":["expansion found.."]},{"title":". if","paragraphs":["this is last element, return successfully, else advance to next element"]},{"title":"*/ if I eq #OPT","paragraphs":["then TREE (X,"]},{"title":"'","paragraphs":["LW-1' ) = \\J@RD; return true; else I=I+l; end if I; else"]},{"title":"/*","paragraphs":["no expansion found"]},{"title":". . . erase","paragraphs":["this node and examine previous erernent"]},{"title":"*/","paragraphs":["TREE (NODES) ="]},{"title":"n; NODES","paragraphs":["= NODES-1; TREE"]},{"title":"(x~","paragraphs":["'DAUGHTERS"]},{"title":"'","paragraphs":[") (I) = R; I = 1-1; end if EXPAND; end while I;"]},{"title":"/*","paragraphs":["all expansions for this option have been generated; if more options, loop, else return falsa,"]},{"title":"*/ OPT","paragraphs":["= Q; if TREE (X, 'ALTERNATE OPTIONS"]},{"title":"'","paragraphs":[") ne nR then go to GETOPT; ; re turn false ; end EXPAND; One way of viewing this procedure is to consider each node as a separate process. Each process creates and invokes the processes corresponding to its daughter nodes. In SETL, the algorithm cannot be represented directly in this way, since there are no meckgmisms for creating and suspending processes. Instead, the data which would correspond to the local vaxiab1.e~ of the process are stored as components of each node in the parse tree. In languages which provide for the suspension of processes, such as SIMULA, the algorithm can be represented even more succinctly (see, for example, a version of this algorithm in \"Hierarchical Program Structures\" by 0.-J, Dahl and C. A. R. Hoare, in Structured Progrminq by 0.-J. Dahl et al., page 201). Algorithm B- Type 2 Bottom-up Parallel This algorithm is sometimes called the \"Immediate Co~stituent Analysis\" (IcA) alqorithm, because it was used quite early in parsing natural langqage with ICA grammars, 1%- constructs all nodes in a single left-to-right pass over the sentence. As each word is scanned, the parser builds all nodes which subsume a portion of the sentence ending at that word. The nodes ( \"spans\" ) are accumualted in a two-dimensional array SPAN, whose first subscript specifies the number of the span and whose second subscript selects a component of the span, as follows: SPAN (n, 'NAME"]},{"title":"'","paragraphs":[") = name of span n SPAN (n, 'FW' ) = number of first sentence word subsumed by span n SPAN (n, 'LW+ll) = (number of last sentence word subsumed by span n)"]},{"title":"+ 1","paragraphs":["SPAN"]},{"title":"(n,","paragraphs":["'D'AUGHTERS') = tuple of numbers of daughter spans of span n. At the end of the routine is some code to convert SPAN, a graph structure with each span potentially a part of many parses, into a set of parse trees. This code has two parts: a loop to find all root odes created in the immediate constituent analysis, and a recursive routine EXPAND which makes copies of all descendants of the root node and puts them in TREE. Each node in the tree has the following comr,onents: TREE(n, 'NAME') = name of node n TREE(n, 'FW') = number of first sentence word suksumed by node n TREE(n, 'LW+ll) = (nunher of last sentence word subsumed by node n)"]},{"title":"+ 1","paragraphs":["TREE (n, 'DAUGHTERS') = tuple of numbers of daughter nodes of node n TREE (11, 'PARENT')= number of parent node of node n. The set of parse trees is accun\\ulated i.n PARSES and finally returned as the value of the function PARSE. definef PARSE(GRAMMAR,ROOT,SENTENCE) ; local TODO, WORR, CURRENT, DEF, DEFNAME, DEFELIST, REM, SPAN,"]},{"title":", SPANS! TREE,","paragraphs":["NODES, PARSES, MS, I;"]},{"title":"/* initialization */ SPAN","paragraphs":["= n1; SPANS = 0; TODO = nl;"]},{"title":"/*","paragraphs":["iterate"]},{"title":"over WORD=last","paragraphs":["word subsumed by spans being constructed"]},{"title":"*/ (1","paragraphs":["<= VWORD <= #SENTENCE)"]},{"title":"/*","paragraphs":["add span"]},{"title":"whose","paragraphs":["name is sentence word"]},{"title":"*/ ADDSPAN","paragraphs":["(SENTENCE (WORD)"]},{"title":", WORD,","paragraphs":["WORD+l,"]},{"title":"nult)","paragraphs":[";"]},{"title":"/* TODO","paragraphs":["contains the numbers of spans which were just created and for which ye have not yet checked whether they can be used as the last daughter span in building some more spans"]},{"title":"*/","paragraphs":["(while TODO ne nl)"]},{"title":"/* select a","paragraphs":["span from TODO"]},{"title":"*/ CURRENT from TODO; /*","paragraphs":["loop over all productions whose last element = name of current span"]},{"title":"*/","paragraphs":["(VDEF E GRAMMAR(DEF(#DEF) eq SPAN(CURRENT, 'NAME'))"]},{"title":"/* separate left","paragraphs":["and right sides of production"]},{"title":"*/","paragraphs":["DEETIAME = hd DEF; DEFELIST = tl DEF;"]},{"title":"/* if","paragraphs":["elements preceding last element of production can be matched by spans, add a new span whose name = left-hand side of prodncision for each match*/ (~REM E MATCH (DEFELIST (1: (#DEFELIST) -1)"]},{"title":", a","paragraphs":["SPAN (CURmNT, 'FW') ) ) ADDSPAN (DEFNAME, hd REM, SPAN (CUIXWNT, 'LW+l')"]},{"title":",","paragraphs":["(tl REM) -t <CURRENT>) ; end VREM; end"]},{"title":"VDEF; end while TODO;","paragraphs":["end 1 \\= VWORD;"]},{"title":"/*","paragraphs":["eXtract trees from set of spans"]},{"title":"*/ PARSES","paragraphs":["= nl; (1 <= \\tI <= SPANS"]},{"title":"I (SP.W(I;'NAMG') aq ROOT)","paragraphs":["and (SPAN (1,"]},{"title":"' FW'","paragraphs":[") eq 1) and (SPAN(I,'LW+lt) eq SE SENTENCE)+)̂)) NODES = 1; TREE ="]},{"title":"nl; TREEC~)","paragraphs":["="]},{"title":"SPANIII;","paragraphs":["TREE: (1, 'DAUGHTERS"]},{"title":"'","paragraphs":[") = EXPAND (TREE (I,"]},{"title":"'","paragraphs":["DAUGEITERS"]},{"title":"'","paragraphs":[")"]},{"title":", 1)","paragraphs":["; end 3, <="]},{"title":"VI;","paragraphs":["return PARSES ; cnd PARSE; define rVLATCII (ELTST, ENDWDPI) ; local I, NTUP;"]},{"title":"*","paragraphs":["MATCH finds all n-tuples of spans whose names match the elen~ents of the n-tuple ELIST md .cqhich span a portion of the sentence whose last word +l = ENDFVDPI; returns a set, each element of which is an (ntl) -tuple, whose tail is one of the n-tuple-of spans and whose head is the rlunher of the first word spanned by the n-tuple of spans"]},{"title":"*/","paragraphs":["if ELIST cq nu9t then return ((ENDwDP~~~); else return [U: 1 <= 1 <= NODESJ (if (SPAN (I, 'NAME"]},{"title":"'","paragraphs":[") eq ELXST (#ELIST) ) and (SPAN (I, 'LFJ+ll ) eq ENDWDP1) then"]},{"title":"CNTUP","paragraphs":["+ <I>, NTUP E bylTCH (ELIST (1: ($ELIST) ,SPAN (1, 'FlY' ) )"]},{"title":"1","paragraphs":["else nl) ; ; end MATCH ; &fix%@ ADDSPAN (NAME, FW r LWP1, DAUGHTERS )"]},{"title":"I* ADDSPAN builds a span whose components are passed in","paragraphs":["the four parameters"]},{"title":"*/ mms","paragraphs":["= SPANS+l; %Pm[SP.SrgNAME') = NAME:; S~hWiiI(SPANL:,'E'W') = FW; SP~(SPANS,'LW+~') = LWP1; S3Pm [SPANS,"]},{"title":"' DAUGHTERS '","paragraphs":[") = DAUGHTERS ; SmS"]},{"title":"h TOM); *~bef EZ~PAND (DAW, PAR)","paragraphs":[";"]},{"title":"/*","paragraphs":["creates a node for each span in DAW and each descendant thereof, and returns a tuple with the numbers of the nodes (in TREE) corresponding to the spans in DAW"]},{"title":"*/ Dr Ni eq","paragraphs":["Q then return 52; ;"]},{"title":"n","paragraphs":["= zBtplt;","1 S = NODES"]},{"title":"+; 1; S","paragraphs":["= BODES;"]},{"title":"ei~3","paragraphs":["="]},{"title":"SPANCS); E(Nr*PARENT1)","paragraphs":["= PAR;","(N,'DAqGHTERS') = EXPAND(TREE(N, 'DAUGHTERS') ,N) ; p = D + <N>; end YS; Algorithm C Type 1 Bottom-up Parallel Algorithm C is the basic \"nodal spansr' parsing algorithm [Cocke 19701. The sequencing logic is identical to that for Algorithm 3. The ~nly difference in the tree representation"]},{"title":"ia that","paragraphs":["all spans in Algorithm B with conunon values in"]},{"title":"the","paragraphs":["NIIME, FW, and LW+1 components are joined into a single span in Algorithm C. The DAUGHTERS component now becomes a set, each of hose elements correspands to the value of the DAUGHTERS compbnent of one of the spans in Algorithm B (this set is called the \"division list\" .in the nodal spans algorithm): sp~~(n, 'DAUGHTERS ') = a set each of whose elements is a tuple of numbers of daughter nodes of span n In order to effect this change in the trce, it is necessary only to modify the procedure ADDSPN~ to check whether a span with the specified value of NAME, FW, and LW+1 aIlr?i?aay exists: define ADDSPAiJ (NFr).IE, FW, LWP1, DAUGHTERS) ; local S;"]},{"title":"if 1","paragraphs":["<= 3s <= SPANS'"]},{"title":"I (SPA;J(S,'NtUIET)","paragraphs":["eq NUE) and (SPNI (S"]},{"title":", ' FW'","paragraphs":[") eq FIJ) and SP"]},{"title":", L)","paragraphs":["ec, LWP1) then DAUGHTERS in SPALJ (S, 'DAUGHTERS') ; else SP=\\JS = SPRNSSl; SPAN(SPm~,'NM~') = NAME; ,SPAN (SPANS, ' FW' ) = FW; SPAN(SBANS,~LW+S.~) = LWP~; SPAN (SPANS, DAUGHTERS 1 = {DAUGHTERS"]},{"title":"1","paragraphs":["; SPANS"]},{"title":"in TODO; end if; re turn","paragraphs":["; end ADDNODE; The procedure for converting the spans into a set of trees is now more complicated than for ~lgorithm B; see, for example, Wens 1:1975], Sec. 7. Algorithm D. Type 2 Top-down Serial We now seek to combine the advantages of algorithm A with those of algorithms B and C. Algorithms B and C would construct any given tree over a portion of the sentence only once, whereas algorithm A might construct some trees many times during the course of a parse. On the ~ther hand, B and C would construct many trees which A would never try to build. More precisl~ly, B and C would build trees while processing word n+l which could not enter into any parse for any sentence whose first n words were those processed so far. To combine these algorithms, we shall return to the basic framewdrk provided by algorithm A. To this we add a mechanism for recording \"well formed substrings.\" The first time the parser tries to analyze a portion of the sentence beginning at word f as an instance of symbol N, this mechanism records any and all trees constructed below node N. The next time the parser tries symbol N at word f, the saving mechanism retrieves this information so"]},{"title":"mat","paragraphs":["the trees below N need not actually be rebuilt. The previously-completed trees are stored in the two-dimensional array WFS, whose structure is identical to that of SFAN in algorithm- Bc WFS (n, 'NAME' ) = name of well-formed substririg n WFS (n, 'FW') = first word of well-formed substring n WFS (n,'LW+lr ) = (last word of well-formed substring n)"]},{"title":"+ 1 WFS (n,","paragraphs":["'DAUGHTERS"]},{"title":"'","paragraphs":[") = tuple of numbers of daughter substrings of substring n WFSS sholds the numbei- of substrings in WFS. When the parsing operation is complete, WFS will contain a subset of the elements which were in TREE at the end of algorithm B. The tree used by the top-down parser must be augmented to allow for the possibility that khe parser is not building a trce below a given node but rather consulting the table of well-formed substrings for that node. In that case the node will have, instcad of a tuple of daughters and a set of alternative options, the nun.lber of the well-formed substring currently being used in the taree and the set of alternative weil-formed substrings. The structure of a node is thus: TRl?Lr;-(n,'NrW1) = name of node n TREE (n, 'PARENT') = number of psrcnt node of node n (= 0 for root node) TREE (n, 'UAUGHTERS ') = tuple of nunhers of daughter nodes of node n (= nult if node is r,latched by well-formed substring) TREE (n, 'WFS1) =*number of well-formed substring matched to node n (= Q if not matched to a substring) TREE (n, 'CURRENT 0PTIC3iJ1 ) = tuple of current production used to expand node n (= SZ if node is matched by a well-formed substring) TREE (n, 'ALTERNATE 0PTI:ONS"]},{"title":"'","paragraphs":[") = set of tdplcs rcprcsenting productions not yet tried for node n TREE (n, 'ALTERNATE WFS"]},{"title":"'","paragraphs":[") = set of numbers of well-form6d substrings not yet tried for node n 'TREE (n,'FW1) = number of first word subsum~d by node n TREE (n, 'LW+lt) = (number of last word subsumed by node n)"]},{"title":"+","paragraphs":["1 Finally, we require a table which indicates, for each symbol N and sentence word f, whether a11 the well-formed substrings for N starting at f have been recorded in WFS. For this the parser uses the two-dimensional array EXPANDED: EXPANDED(N,f) ="]},{"title":"true if","paragraphs":["all substrings have been recorded, Gi if not. The text of procedure D is given below; comments arE included only for those statements added to procedure A. def inef PARSE"]},{"title":"(GRAMMAR,","paragraphs":["ROOT, SENTENCE) ; local PARSES"]},{"title":", TREE, NDDEG ,","paragraphs":["WORD, WFS"]},{"title":",","paragraphs":["WFSS"]},{"title":",.","paragraphs":["EXPANDED $ TREE"]},{"title":"= nR; PARSES","paragraphs":["="]},{"title":"nR","paragraphs":["; WFS"]},{"title":"=","paragraphs":["rlk; WFSS = 0; EXPANDED ="]},{"title":"nR;","paragraphs":["WORD ="]},{"title":"1;","paragraphs":["NODES"]},{"title":"= I;","paragraphs":["TR'TE"]},{"title":"(1, 'NW '","paragraphs":[") = ROOT ; TREE(1,'EW1) = WORD; (while EXPAND (1) )"]},{"title":"if WORD eq","paragraphs":["(#SENT+ENCE"]},{"title":"+ 1) THEN","paragraphs":["PARSES"]},{"title":"= PARSES","paragraphs":["U"]},{"title":"{TREE 1","paragraphs":["; end if WORD; end while;"]},{"title":"return <PARSES","paragraphs":[",WFS> ; end"]},{"title":"PARSE;","paragraphs":["definef EXPAND(X) ; local I, S, LAST, OPT; if EXPANDED (TREE (X, 'NAME"]},{"title":"'","paragraphs":[")"]},{"title":",","paragraphs":["TREE (X,"]},{"title":"'","paragraphs":["FW' ) ) eq true then"]},{"title":"/* the expansions for","paragraphs":["this"]},{"title":"symbol have","paragraphs":["been computed before"]},{"title":"*/ /* if this is a new node, get its","paragraphs":["WFS"]},{"title":"entries */ if","paragraphs":["TREE"]},{"title":"(x,","paragraphs":["'ALTERNATE WFS"]},{"title":"'","paragraphs":[") eq Q then TREE(X,'ALTERNATE WFS') ="]},{"title":"IS, 1 -","paragraphs":["< S"]},{"title":"-","paragraphs":["< WFSS"]},{"title":"I","paragraphs":["(WFS (S"]},{"title":", 'NAME","paragraphs":[") eq TREE"]},{"title":"a,","paragraphs":["'NAME"]},{"title":"'","paragraphs":[") ) and"]},{"title":"(WFS(S,'FWi) eq","paragraphs":["TREE(X, 'FWr))) end"]},{"title":"if","paragraphs":["TREE;"]},{"title":"if TREE (x,","paragraphs":["'ALTERNATE WFS"]},{"title":"'","paragraphs":[") eq na then"]},{"title":"/* all WFSs","paragraphs":["tried for this node"]},{"title":"*/ worn","paragraphs":["= TREE(X,'FW') ;"]},{"title":"rsturn false; else GETOPT: if","paragraphs":["OPT eq R then OPT"]},{"title":"from","paragraphs":["TREE (-XI 'ALTERNATE OPTIONS"]},{"title":"'","paragraphs":[") ; TREE: (XI 'CURRELJT OPTION I)= OPT; I = 1; end"]},{"title":"if OPT;","paragraphs":["(while"]},{"title":"I ge 1) if TREE(x,'DAUGHTERS') (I) eq Q","paragraphs":["then NODES = NODES"]},{"title":"+ 1; TREE","paragraphs":["(NODES, 'NAME') = OPT(1) ; TREE (NODES,"]},{"title":"' FW '","paragraphs":[") ="]},{"title":"WORD","paragraphs":["; TREE (NODES,"]},{"title":"'","paragraphs":["PARENT"]},{"title":"'","paragraphs":[") ="]},{"title":"X; TREE(x,'DAUGI~TERS') (I)","paragraphs":["= NODES; end"]},{"title":"if TREE; if","paragraphs":["EXPAND (TREE (X, DAUGHTERS ) (I) ) then if I eq #OPT then TREE (X, 'LW+ll ) -= WORD;"]},{"title":"/*","paragraphs":["record substring matched by node X"]},{"title":"*/","paragraphs":["ADDWFS (TREE"]},{"title":"{X","paragraphs":["]. ) ; TREE(X,'WFSI) = WFSS; return true ; se I = I+1 end"]},{"title":"if I;","paragraphs":["else TRSE (JODES) ="]},{"title":"a;","paragraphs":["NODES = NODES-1; TREE (X,"]},{"title":"'","paragraphs":["DAUGHTERS"]},{"title":"'","paragraphs":[") (I) = 52; I = 1-1; end if EXPAND; end while I; OPT ="]},{"title":"Q; if TREE","paragraphs":["(X, 'ALTERHATE OPTIONS"]},{"title":"'","paragraphs":[") ne nR then go to GETOPT; ;"]},{"title":"/* all expansions","paragraphs":["tried"]},{"title":"*/","paragraphs":["EXPANDED (TREE (X, 'NAME"]},{"title":"' 1","paragraphs":[",WORD) = true ; return false; end EXPAND; define ADDTUFS (NODEX)"]},{"title":"/*","paragraphs":["add"]},{"title":"an entry to","paragraphs":["WFS"]},{"title":"*/ local I; WFSS","paragraphs":["= WFSS+l; WFS (WFSS, 'NAME') = NODEX('NAME') ;"]},{"title":"WFS(WFSS,~FW~)","paragraphs":["="]},{"title":"NODEX(~FN~);","paragraphs":["WFS (IVPSS"]},{"title":", LW+~","paragraphs":[") = NODEX ( LW+L ) if"]},{"title":"NODEX('DAUGHTERS1) ne Q then WFS(NFSS,'DAUGHTERS')","paragraphs":["= [+:"]},{"title":"I E NODEX('DAUGHTERS1)","paragraphs":["] <TREE (I, T~~~f"]},{"title":"1","paragraphs":[">; end"]},{"title":"if","paragraphs":["NODEX;"]},{"title":"return","paragraphs":[";"]},{"title":"end","paragraphs":["AQDWFS;"]},{"title":"Note that","paragraphs":["this parser"]},{"title":"returns an","paragraphs":["ordered pair consisting"]},{"title":"of the","paragraphs":["set of trees and the set of well-formed sSstrings, since the"]},{"title":"trees","paragraphs":["alone do"]},{"title":"not contain complete information","paragraphs":["about"]},{"title":"the sentence","paragraphs":["analysis. Algorithm E Type 1 Top-Down Serial To complete"]},{"title":"our","paragraphs":["set"]},{"title":"of","paragraphs":["algorithms,"]},{"title":"we","paragraphs":["shall apply to Algorithm D"]},{"title":"the same","paragraphs":["change we made"]},{"title":"to convert","paragraphs":["Algorithm B"]},{"title":"to","paragraphs":["Algorithm C. That is, where in Algorithm"]},{"title":"D we","paragraphs":["may have had Sevc~.~.; ,~e11"]},{"title":"formed","paragraphs":["substrings with the same"]},{"title":"values of","paragraphs":["XAP?, l?W, LIJ4-1,"]},{"title":"we","paragraphs":["shall combine these into a"]},{"title":"single","paragraphs":["substring"]},{"title":"ir,","paragraphs":["Algorithm"]},{"title":"E:","paragraphs":["The component DAUGHTERS"]},{"title":"'becomes a","paragraphs":["set, each"]},{"title":"o: whose elements is","paragraphs":["a tuple corresponding to"]},{"title":"the","paragraphs":["value"]},{"title":"of","paragraphs":["DAUGHTERS"]},{"title":"of one","paragraphs":["of ti,e substrings"]},{"title":"in Aigorithm D. Just","paragraphs":["as we only had to change AD7idODE"]},{"title":"in Algorithm","paragraphs":["B, we only have to change ADD~FS"]},{"title":"in","paragraphs":["Algorithm D. define ADCWF$ (NODEX) ;"]},{"title":"local W, I,","paragraphs":["DAUGHTERS;"]},{"title":"/*","paragraphs":["conpdte DAUGHTERS for substring"]},{"title":"*/ DAUGHTERS","paragraphs":["= Q; if NODEX ("]},{"title":"' DAUGHTERS '","paragraphs":[") ne SZ then DAUGHTERS = : I E NODEX ("]},{"title":"' DAUGHTERS '","paragraphs":[") ] <TREE (I,"]},{"title":"' WFS '","paragraphs":[") > ; end $f NODEX;"]},{"title":"/* &arch","paragraphs":["for well formed substring with identical ;.IMil3,"]},{"title":"m,","paragraphs":["LW+l"]},{"title":"*/ if 1","paragraphs":["<= 3 W <= WFSS"]},{"title":"1","paragraphs":["( (WFS (W ,INAME"]},{"title":"'","paragraphs":[") eq NODEX ( 'NAME"]},{"title":"'","paragraphs":[") ) and (WFS (W,"]},{"title":"'FW') eq NQDEX('FW')","paragraphs":["1 and (WFS(W, 'LiV+1') eq NODEX('LW+l') )"]},{"title":"/*","paragraphs":["found one, add daughter to set"]},{"title":"*/ then if","paragraphs":["DAUGHTERS ne 52 then DAUGHTERS in WFS (W"]},{"title":", '","paragraphs":["DAUG:ITERS"]},{"title":"'","paragraphs":[") ; end if DAUGHTERS ; else WFSS = WFSS+I : WFS(WFSStlNAM, 1 = NOIT'~.~(.('NAME'); WFS(WFSS,'r;bW1) = NOUEY(~FWI); WFS(WFSP~~LW~-~~) .= NODEX('~;W+~');"]},{"title":"- 0 WFS[WFSS,'U~,'JG~L hs","paragraphs":["= Lf DAUGrlTF., eq R +hen nR else DAUGHTERS ; end if 3~; 2e turn ; end ADDWFS; Use of the Varioub Algo~ithms in Natural Language Systems The type 0 top-down algorithm (algorithm A) is one of the simplest and lnost frequently used. For example, a special version of this algorithm (for Greibach normal form grammars) was used in the original Harvard predictive Analyzer [ICuno 19621. The later version of the ~arvard system, incorpornti~~g a \"path elimination\" technique, was a type 1 top-down serial parser, a variant of Algorithm E; instead of saving all daughters in WFS during the parse, they were recomputed later for those nodes appearing in a parse tree [Xqo 19651. Several current sys.t;cms use nug111&11t;ed context-f ree grammars : grammars to which have bccn uddcd restrictions on the parse tree typically in the form of LISP predicates, which must be true if the tree is to be accepted as a sentence L~~~alysis. The lBinocjrcld [197l] svs tern uses an acy~ented contest-f ree grarmar with the context-f ree component encoded as a program rather than, data. The parsing strategy is essentially that of !a type 0 top-down algorf-thm, except that back-up is explicitly controlled rather than automatic. Woods"]},{"title":"'","paragraphs":["system [1970b] also uses a type 0 top-down algorithm, although somewhat different from the one presented here since his grammar is a recursive transition network. The LincJuistic String Project system [Sager 19671 started out with a parser based on a type 0 top-down algorithm; for efficiency it later progressed to a type 2 top-down algorithm. A type 2 rather than a type 1 algorithm was used because the restrictions can o11e analysis of a portion of the sentence as a particular symbol while accepting another analysis of the same portion of the sentence as the same syxbol. For a type 2 algorithm, this means simply el-ininating some nodes i'n WFS; for a type 1 algorithm, whe~e a single node may represent several ttrees, a complicated procedure which could create new nodes would have been required in general. The Linguistic String Project parser is considerably more complex than the type 1 top-down serial parser shown above (algorithm D), in part because of the restrictions which must be evaluated during the parse, in part because (for reasons of skoroge ecorloiny) the system makes it possible to save only selected nodes in WFS."]},{"title":"The","paragraphs":["type"]},{"title":"2 bottom-up parallel algorithm","paragraphs":["also"]},{"title":"saw","paragraphs":["early use in"]},{"title":"5% natural","paragraphs":["language processing. The parser designed by Cocke for"]},{"title":"the","paragraphs":["Rand system was a special"]},{"title":"version","paragraphs":["of this algorithm for Chomsky normal form grammars. A thorough"]},{"title":"survey","paragraphs":["of the different"]},{"title":"ordering strategies possible with","paragraphs":["this algorithm was given by Hays [1967]."]},{"title":"This","paragraphs":["algorithm"]},{"title":"was subsequently","paragraphs":["developed by Cocke (among others)"]},{"title":"into","paragraphs":["a type"]},{"title":"1 bottom-up paralleL","paragraphs":["algorithm"]},{"title":"named \"nodal spans\" and","paragraphs":["subsequently into"]},{"title":"a type .1","paragraphs":["top-down parallel algorithm called \"improved nodal spans\" (see Cocke [1970] for a description of these algorithms). The latter is very similar to a parsing algorithm described by Earley [19 701"]},{"title":". +These","paragraphs":["type 1 algorithms"]},{"title":"have, to &he","paragraphs":["best of"]},{"title":"our","paragraphs":["knowledge, not yet been used"]},{"title":"in","paragraphs":["natural language"]},{"title":"parsing. In","paragraphs":["closing"]},{"title":"a few remarks","paragraphs":["are"]},{"title":"in","paragraphs":["order on the practical importance of the differences between the various algorithms. How significant is the difference between type 2 and type 1, between top-down"]},{"title":"and","paragraphs":["bottom-up"]},{"title":", be tween","paragraphs":["serial and parallel? There has been"]},{"title":"no","paragraphs":["systematic study"]},{"title":"of","paragraphs":["these questions, and the answers to them are in all likelihood qyite grammar specific. For example, the advantage of the tcjp-down parser is that, in working on word n+l, it eliminates from consideration those symbols"]},{"title":"which","paragraphs":["could"]},{"title":"not occur in any","paragraphs":["parse"]},{"title":"tree","paragraphs":["whose first"]},{"title":"n terminal","paragraphs":["symbols are the first n words of the sentence. Is this a"]},{"title":"large effect?","paragraphs":["Although"]},{"title":"I am not aware","paragraphs":["of any"]},{"title":"measurement","paragraphs":["of this quantity, the factor seems to be relatively small for large-coverage English grammars"]},{"title":"--","paragraphs":["perhaps reducing the number of symbols in half. The advantage of type 1 over type 2 algorithms depends"]},{"title":"on","paragraphs":["the degree of ambiguity of the grammar. How frequently can a portion"]},{"title":"of","paragraphs":["i+ sentence be analyzed as a particular symbol in several ways? For unaugmented context-free grammars the answer in general has been very frequently"]},{"title":"--","paragraphs":["this was one of the problems of the context-free systems."]},{"title":"For","paragraphs":["such grammars, type 1 algorithms would be much more efficient. When restrictions are added, however, they discriminate some"]},{"title":"of the analyses from","paragraphs":["others. L"]},{"title":"53 A","paragraphs":["rich set of syntactic, semantic, and pragmatic restrictions (available so far only for small subsets of English in limited areas of di~coursa) would presumabl~~ eliminate almost all ambiguity, so that the advantage of a type 1 algorithm would then be small. Finally, We should mentian the difference butwecn serial and parallel parsers. Since serial and parallel algorithms wi'll have created the same nupber of nodes by the time parsing is con~plete, the difference in time is probably quite small. The parallel algorithm pay have the edge because \"bookkeeping\" is simpl'er. Also; the parallel algorithm can handle left rccursio:~ naturlaily, whereas a special mechanism is requirca for top-down serial parsers. On the other hand, a serial algorithm may be preferable if only the first parse of a sentence is required. In addition, the serial algorithms can more sim~ly handle the situation where memory space is marginal. Normally most of the space in algoritnms D and E is used by the set WFS, not by TREE. Consequently a type 1 or 2 serial parser can \"rescue itself\" when memory is almost exhausted by reverting to a type 0 algorithm; this simply means tnat it stops saving nodes in WFS. In terms of the SETL programs given above this requires, in addition to a change to ADDWFS, only that elements of EXPANDED no longer be set t6 true qnce -savTng has been tern~inated. 3.2. A Parser"]},{"title":"for","paragraphs":["Unrestricted Rewritina Rule Grammars A"]},{"title":"number of natural language systems, such as REL (at","paragraphs":["the California"]},{"title":"Institute of","paragraphs":["Technology) and"]},{"title":"the Q-system (at","paragraphs":["the"]},{"title":"University of Montreal) have","paragraphs":["used unrestricted phrase"]},{"title":"structure grammars. In such grammars,","paragraphs":["each"]},{"title":"rule specifies","paragraphs":["that"]},{"title":"some sequence of symbols be rewri'tten as some other sequence of symbols.","paragraphs":["The"]},{"title":"parsing","paragraphs":["algorithm used"]},{"title":"in these system was","paragraphs":["described by Kay"]},{"title":"in 1967 (\"Experiments","paragraphs":["with a"]},{"title":"Powerful.","paragraphs":["Parser,\""]},{"title":"Martin","paragraphs":["Kay, ih"]},{"title":"26me","paragraphs":["Conference"]},{"title":"Internationale sur le Traitmcnt Automatique","paragraphs":["des Langues"]},{"title":", Grenoble) . Kay","paragraphs":["added qudte a"]},{"title":"few features to the","paragraphs":["basic parsing procedure"]},{"title":"to create","paragraphs":["his \"powerful parser\". These included"]},{"title":"rule ordering and conditions on rule","paragraphs":["application. Other"]},{"title":"unrestricted rewriting rule sys","paragraphs":["terns have"]},{"title":"also","paragraphs":["included some such features. to ~ermit the parsimonious description of c?~mplex natural language grammars. In this newsletter, however, we shall not be concerned with these additional features ; only the basic parsing procedure will be described below. The parser to be presented represents only a small modi-"]},{"title":"fication to the context-free parser","paragraphs":["B (the \"immediate"]},{"title":"constituent","paragraphs":["analyzer\") given earlier"]},{"title":". To","paragraphs":["understand this"]},{"title":"modification,","paragraphs":["consider the following example."]},{"title":"We","paragraphs":["are given"]},{"title":"a context-Free grammar","paragraphs":["which includes the productions a -+ def and x+ya ad the sentence ydef We shall create"]},{"title":"a","paragraphs":["diagram"]},{"title":"for the","paragraphs":["sentence by making eath word"]},{"title":"into an arc connecting twa","paragraphs":["nodes,"]},{"title":"which","paragraphs":["are labeled with the number"]},{"title":"of the","paragraphs":["word"]},{"title":"in the sentence and the number +1: Context-free parser","paragraphs":["B"]},{"title":"would","paragraphs":["fifst"]},{"title":"apply","paragraphs":["the"]},{"title":"product a","paragraphs":["-+ do£"]},{"title":"in reverse, to obtain a","paragraphs":["span"]},{"title":"'a\" ,","paragraphs":["we"]},{"title":"can indicate","paragraphs":["this thus: Note that"]},{"title":"the arc","paragraphs":["for"]},{"title":"thc","paragraphs":["spa"]},{"title":"connects","paragraphs":["nodas"]},{"title":"corresponding to","paragraphs":["the first"]},{"title":"word","paragraphs":["and the"]},{"title":"last","paragraphs":["word"]},{"title":"+ 1","paragraphs":["subsurnod by I"]},{"title":"span.","paragraphs":["The parscr"]},{"title":"would then","paragraphs":["apply x -c"]},{"title":"y a","paragraphs":["in"]},{"title":"rcvcrse:","paragraphs":["getting a span which subsumes"]},{"title":"the","paragraphs":["entire sentence. Now consider analyzing the"]},{"title":"same sentence","paragraphs":["with the"]},{"title":"unrestricted","paragraphs":["phrase structure!"]},{"title":"grammar","paragraphs":["z+ya x+zb"]},{"title":"We","paragraphs":["begin by ilsing the first production"]},{"title":"tc","paragraphs":["reduce the se~~tcnce"]},{"title":"to y a","paragraphs":["b. This"]},{"title":"raises the","paragraphs":["problem"]},{"title":"of","paragraphs":["how to label tthc"]},{"title":"no~ic","paragraphs":["between arcs a and b. ~lthough a"]},{"title":"and b","paragraphs":["together subs~~a"]},{"title":"the","paragraphs":["last three words of"]},{"title":"the","paragraphs":["sentence, no fraction of- this C~II be assigned individually to a"]},{"title":"or to b;","paragraphs":["hence we cannot label this new node with the number of a sentence word, hlstead,"]},{"title":"we assign a nzw,","paragraphs":["unique label (here, v1)"]},{"title":"to","paragraphs":["the"]},{"title":"node: PiCri can thea reverse the second","paragraphs":["production to get a span"]},{"title":"z Fhallly we reverse","paragraphs":["the third production to get q span x subsuming the entire sentence: In the progzam below, new node names are created by"]},{"title":"cans oal the SWL function newat, which returns","paragraphs":["a different Ucpe symbol (a \"blank atom\" in SETL terminology) each time it is called. We have retained the span component names EW and LW+l for the labels of the nodes at the ends of the arc, moxagh their values may now be blank atoms instead of numbers. A production of the form al"]},{"title":"... a","paragraphs":["+ bl"]},{"title":"... b n n is represented by th8","paragraphs":["structure <<al, ...'a >, bl,...,b > n n GRAMPlZSR is a set of such structures. For example, the mnlclestsicted rewriting rule grammar given above would be encOded4ar;r","C < < a, b>, d, e, fz, < < zQ>, y, a>, < < x>, Z, b >"]},{"title":"3 fact that spans numbered s. s, were formed by lying","paragraphs":["an inverse production to spans numbered dl"]},{"title":". . . d n Zs mxxm3ed by assigning the component","paragraphs":["CONSTITUENTS with value define URRP&SSE (GRAMMAR, SENTENCE) local SPAN, SPANS, WORD, TODO, CUFtRENT, DEF, DEFNAME, DEFELIST, MS ;"]},{"title":"/* initialization */ SPAN","paragraphs":["= nl; SPANS = 0; TODO = nult;"]},{"title":"I*","paragraphs":["iterate over WORD=last word subsumed by spans being cons tructed"]},{"title":"*/ (1","paragraphs":["<= VWORD <= #SENTENCE)"]},{"title":"/* add","paragraphs":["span whose name is sentence word"]},{"title":"*/ RDDSPAN","paragraphs":["(SENTENCE (WORD)"]},{"title":",","paragraphs":["WORD"]},{"title":",","paragraphs":["F?ORD+l, nu1 t) ;"]},{"title":"* TODO","paragraphs":["co~ltains the nunhers"]},{"title":"of","paragraphs":["spans which were created and for which we have not yet checked just whether they can be used as the last daughter span in building some more spans"]},{"title":"*/","paragraphs":["(while TODO ne nult)"]},{"title":"/*","paragraphs":["select a span from TODO"]},{"title":"*/","paragraphs":["CURRENT = hd TODO; TODO = tl TODO;"]},{"title":"/*","paragraphs":["loop over all productions whose last element = name of current span"]},{"title":"*/","paragraphs":["(VDEF E GRAMMAR~DEF(#DEF) eq SPAN (CURRENT, ') )"]},{"title":"/*","paragraphs":["separate left and right sides of production"]},{"title":"*/","paragraphs":["DEFNkW = hd DEF; DEFELIST = tl DEF;"]},{"title":"/* if elements","paragraphs":["preceding last element of production can be matched by spans, add new spans whose names = left-hand side of production for each match*/ (VFSM E MATCH (DEFELIST (1: (#DEFELIST) -1)"]},{"title":",","paragraphs":["SFX~ (CURRENT, 'FW' ) ) ) ADDSPANS (DEFNAMEet hd REM, SPAN (CURRENT, 'LW+l )"]},{"title":", (tl REM)","paragraphs":["+ <CURRENT>) ; end VREM; end VDEF; end while TODO; end 1 <= VWORD; return SPAN; end URRPARSE; define MATCH (ELIST, ENDWDP~) ; local I, NTUP;"]},{"title":"/* MATCHfinds all n-tuples sf spans whose names match the elements of","paragraphs":["the n-tuple ELIST and which span a portion of the se~ltence whose last word"]},{"title":"+","paragraphs":["1 = ENDWDP1; returns a set, each element of which is an (n+l) -tuple, whose tail is one of the n-tuples of spans and whose head is the number of the first word spanned by the n-tuple of spans"]},{"title":"*/ if","paragraphs":["ELIST eq nult then return ( <ENDWDPl> ; else return [U: 1 <= I .f= NODES] (if (SPAN (I, 'NAME"]},{"title":"'","paragraphs":[") eq ELIST (#ELIST) ) and (SPAN ( I, 1"]},{"title":"'","paragraphs":[") eq ENDWDP~) then {NTUP + <I>, NTUP E MATCH (ELIST (1: (#ELIST) -1) ,SPAN (I, 'FW' ) )"]},{"title":"I","paragraphs":["else nl) ; ; end MATCH; define ADDSPANS (LHS"]},{"title":", FW,","paragraphs":["LWP1, CONSTIT~JENTS ) ;"]},{"title":"/* builds a sequence of spans whose names are","paragraphs":["given by tuple LHS, with the first span beginning at FW and the last one ending at LWPl"]},{"title":"*/","paragraphs":["local W, I, TUP; W = FW; TUP =\"nuLt; (1 <= VI <= #LHS) SPANS = SPANS"]},{"title":"+ I;","paragraphs":["TUP = TUP -+ <SPANS>; SPAN(SPANS,'NAME1) = LHS(1)-; SPAN (SPANS, TW') = W; W = if I eq #LHS then LXPl else newat; SPAN (SPANS, 'LW+l"]},{"title":"'","paragraphs":[") = W; end 1 <= VI; SPAN (SPANS, 'CONSTITUENTS"]},{"title":"'","paragraphs":[") = <TUP"]},{"title":", CONSTITUENTS>; TODO","paragraphs":["= TUP -t TODO; return; end ADDSPANS; The unrestricted rewriting rule parser has the power of a Turing machine. The user is afforded great flexibility"]},{"title":"in","paragraphs":["the manipulation of sentence strings. One drawback ~f such power, however, is the absence of a decision procedure"]},{"title":"-- no","paragraphs":["parser can determine, for an arbitrary grammar of this type, that a given sentence string is ungrqmrnatical. The user must tllcrefore be careful to design grammars so that the parser will terminate (in a reasonable amount of time) for any input sentence. 3.3. Parsinq Procedures for Transformational Grammars Most linguistic research over the past fifteen years has been conducted within the framework of transformational grammar developed by Chom'sky and ~arris. In the early 19601sr a few years after the blossoming of transforma~ional grammar, several efforts were begun to develop parsers which could operate fairly directly from a transformational grammar. Two of these achieved some measure of success: a project at MITRE led by Donald Walker [Zwicky 1965, Walker 19661 and work at MIT by Stanley Petrick [19651. These twa efforts had quite different objectives. The MITRE group was concerned with a specific practical application: development of a natural language interface for a military information retrieval sys tex. They developed a grammar for a subset of English meeting their requirements and were primarily concerned with designing a parser which could handle this particular grammar. Petrick, in contrast"]},{"title":", developed","paragraphs":["a general parsing procedure which would work with any member of a class of transformational grammars. This difference in objective affeeked a number of design decisions regarding the parsing procedure, as we shall see later on. Petrick and his coworkers, at the Air Force Cambridge Research Laboratory and now at XBM, Yorktown Heights, have modified the parser to reflect changes in transformational grammar and to adapt it for use as the front-end in an information retrieval system. IPetrick 1966,1973,1975; Keyser 1967; Plath 1974a, 1974bl. Interestingly enough, these modifications have brought Petrick's parser much closer to the original MITRE design. Since the structure of trans fom'iational grammar has varied in time and between different schools of linguistic theory, the notion of a transformational parser is not we11 defined. In order to present a parsing algorithm, we have selected a particularly simple granular formulation. This Eorinulation corresponds a~proxirnate~ly to the early work of Chomsky (e.g., Syntactic Structztres) and the theory used in the early versions of the MITRE and Petrick systems, Complicating factors, such as features and content-sensitive rules for lexical insertion, have been on~itted. The grammar consists of a bass curnps~t8nt and a ~~~Lz~~s~oI*~*:LI- $.iunnZ conty~?t~?zd. The base componant is a context-free granunar which produces a set of dcsp s trnc-t;u~.a trees. The t:-ansfor~natiorla1 coi~~ponent is a set of tree-rewriting rulcs which, when applied to a deep structure tree, produces one or more su~fucc s t~ucture trees. The frontiers (tern~inal node sequences) of Lhe surface structure trees are the sentences of the language. The root symbol of the base component is named S. The base component also contains a distinguished symbol COMP which appears on the left side of only one production: COrviP -+ #"]},{"title":"s","paragraphs":["# # is referred to as the sentence boundary marker, With the exclusion of this production, the CralImIar is not recursive. Each transformation consists primarily of a s +~ztctu~a 2 index and a strztctuz~at change. The strllctural irldex is a tuple (vector)"]},{"title":", <si . . . s","paragraphs":["> I each of whose components 1' n is either a symbol (name of a node) or \"Xu- The structural change is a tuple <sclr."]},{"title":". . ,sc","paragraphs":["of the same length as the n structural index. Each of its components is ir turn a tuple","SC =<SC i il,."]},{"title":"- . ,sc","paragraphs":[">, possibly empty (ni = 0). Each of the scij in, is either a terminal symbol or an integer between 1 and n. The application of fransfomational rules is based"]},{"title":"dh","paragraphs":["the notion of a proper anatysis, which is in turn based on the concept of a cut of a tree. Roughly speaking, a cut is defined by drawing a line from left to right through a tree, passing only through nodes (hot through the lines connecting nodes) ; the nodes thus passed through form the cut. For example, for the tree"]},{"title":"-- - -<> I1","paragraphs":["PRO I like turnips the sequence of nodes NP, VERB, M form a cut. More formally (Aho and Ullman, The Theory of Parsing, Trans Zation, and Compiling, Vol. I, pg.140), a cut is a subset C of the nodes D of the tree such that I* no node in C is on a successor path from some other node in C 2. no other node of D can be added to C without violating rule 1 If the na&nes of the nodes in the cut, arranged in sequence from left to right, match the structural index of the transformation, the cut is a proper analysis of the tree with Y respect to this transformatiofl. A structural index matches the sequence of node names if there exists a substitution of sequences of symbols (possibly null and not incldding #) for the occurrences of \"X\" in the structural index which will make the structural index identical to the sequence of names. For example, the cut NP VERB N would be matched by any of the structural indices NP VERB"]},{"title":"N","paragraphs":["The"]},{"title":"proper analysis","paragraphs":["associates with each element"]},{"title":"of","paragraphs":["the"]},{"title":"structural index","paragraphs":["(except possib~y \"XX\"s) a nods"]},{"title":"in thc","paragraphs":["tree and"]},{"title":"hence","paragraphs":["a"]},{"title":"subtree, the trce dominated by","paragraphs":["that"]},{"title":"node.","paragraphs":["The?"]},{"title":"structural","paragraphs":["change indicates how these subtrees are"]},{"title":"to be","paragraphs":["shuffled to effect the trans"]},{"title":"fornation.","paragraphs":["sc specifies what"]},{"title":"i is to","paragraphs":["go into the position occupied by the node matching sc"]},{"title":"i","paragraphs":["If sci is a 1-tuple, we simply"]},{"title":"have a","paragraphs":["case of"]},{"title":"one","paragraphs":["11ode (and the sabtrce it"]},{"title":"dominates)","paragraphs":["replacing another;"]},{"title":"if sc is an i n","paragraphs":["tuple,"]},{"title":"n","paragraphs":[">"]},{"title":"1, we","paragraphs":["first substitute sc for the or~yinal node and then insert sci2 1"]},{"title":". . . , sc . il lni","paragraphs":["as right"]},{"title":"siblings of that","paragraphs":["node: If scij is an integer,between 1 and n, the new node"]},{"title":"is","paragraphs":["the node matched to the scij-th element of the structural index; if SCij"]},{"title":"is a","paragraphs":["terminal symbol, the new node is a terminal node with that name. Because the value of sci may be the null tuple < >, it"]},{"title":"is","paragraphs":["possible for a"]},{"title":"node in","paragraphs":["the tree to be left with no successors. We therefore \"clean up\""]},{"title":"the tree","paragraphs":["after applying the transformation by deleting any nonteminal node not dominating at least one terminal node. The prescription just given is inadequate for components"]},{"title":"~f the structural","paragraphs":["index equal"]},{"title":"to \"X\", since","paragraphs":["these may match zero or moxe than one node. ide shall cons train the transforna-tions"]},{"title":"so","paragraphs":["that"]},{"title":"nodes in the","paragraphs":["cut which are matched by \"~\"'s do not"]},{"title":"take","paragraphs":["part"]},{"title":"in","paragraphs":["the transformation."]},{"title":"In","paragraphs":["terms of the structural change, if sik ="]},{"title":"\"x\"","paragraphs":["then sc = <k> and no other scij k = k. As an example (3 siqplfication of the example in Keyser and Petrick, Syntactic AnaZysis, p. 9), consider the passive transformation. Its structural index is <PIPt AUX, Vt XI NP, XI BY, PASS> and its structural change Applied to the tree ART the crocodi it produces the proper analysis indicated by the dotted line Applying the transformation yields the tree ART PREDP AUX the girl BE EN frighten BY"]},{"title":"the","paragraphs":["crocodile In additian to the structural index and structural change, some trans formations may have an identity condition, requiring that the subtrees matched by two elen~ents of the structural index be identical for the transEorma.t=ion to","~PP 1~ The rule COMP -+ # S #, which maes the base conponcnt recursive, also plays a special role"]},{"title":"in","paragraphs":["the transformations. If the structure appears in the parse trce, we call the tree dominated by that S a c?3)istitltdnt (or embedded) sentence, and the tsce &~ninated by the next S above COMP the rnadl?,ix sentence parse tree. The transformations are of h~o types, s and binarii (or embedding). In a singulary transformation, the structurar index does not contain the symbol #. In a bhary transformation, the structural index is of the form a #. B B y"]},{"title":",","paragraphs":["whete a, 8, and y are strings of symbols not containing #. The binary transformation deEetes these boundary markers (if # are the ith and jth con~yonents of the structural index, then none of the SC~.~ = i or j"]},{"title":",","paragraphs":["thus combining"]},{"title":"a","paragraphs":["constituent sentence with its matrix sentence.. The transformations are also cl ssed as optio~wl or ob lt gatory. Just like the generation of sentences with a context-free grap.uilar, the application of t.ransfornations to a base structure may be viewed. as a ndndeterninistic process. Depending on the choices made, one of several possible surface structures may be obtained from a single deep structu-e. The transformations are considered"]},{"title":"in","paragraphs":["a fixed order to be"]},{"title":"described","paragraphs":["momentarily. If there"]},{"title":"exists no proper","paragraphs":["analysis"]},{"title":"for","paragraphs":["a transformation, the transfqrhation is skipped. If there exist several proper analyses, one is"]},{"title":"chosen.","paragraphs":["If the"]},{"title":"transformation","paragraphs":["is obligatory, it is then applied;"]},{"title":"if it 1s","paragraphs":["optional, a choice is made"]},{"title":"to","paragraphs":["apply it"]},{"title":"or","paragraphs":["not. The singulary"]},{"title":"and","paragraphs":["binary"]},{"title":"trans","paragraphs":["formations are separately ordered. The tr ~sformationol process begins by selecting an embedded sentence tree not including any other embedded sentence. The singulary transformations are applied in sequence"]},{"title":"to","paragraphs":["this"]},{"title":"tree;","paragraphs":["structural indices are matched against the embedded tree, not"]},{"title":"the entire parse","paragraphs":["tree. The binary trans-fokmations are then applied to this tree and its matrix sentence"]},{"title":"tree;","paragraphs":["one of these should actually transform the tree, deleting the embedded sentences"]},{"title":"(if","paragraphs":["none applied, we would eventually be left with a surface structure containing"]},{"title":"# ' s ,","paragraphs":["which would be rejected)"]},{"title":".","paragraphs":["Another deepest ernbedded sentence is selected and the process repeats until no embedded sentences remain. The singulary trans formations are then applied to the entire tree, completing the generating process (if the base structure contained no embedded sentences, this would be the only step)"]},{"title":".","paragraphs":["In order to parse a sentence"]},{"title":"--","paragraphs":["obtain its deep structures"]},{"title":"-- we","paragraphs":["would like to reverse the process just describedv. First"]},{"title":"build one","paragraphs":["or more ;.>otential surface structure parse trees for a sentence and $hen, by applying the transformations in reverse, try to obtain a valid deep structure from each of these. We shall deal with these two steps in turn. The surface structure parse tree will, in general, contain many structures which could not be directly generated by the base component. If we want to produce all the surface structure trees for a sentence using a context-free grammar, it will be necessary to augment the base component. For example, if the base component contains the production A+XY and there is a transformation which interchanges"]},{"title":"x","paragraphs":["and Y, the rule"]},{"title":"must be","paragraphs":["included"]},{"title":"in","paragraphs":["the grammar which"]},{"title":"is","paragraphs":["used to produce the surface"]},{"title":"structure trees.","paragraphs":["Petrick has described (in his P21. D. thesis) a procedure which can determine fro111 the base and transfor~national components, how the base must be augmented"]},{"title":"in order to","paragraphs":["obtain all surface struc.turt3"]},{"title":"trees.","paragraphs":["Because a"]},{"title":"trnnsformntion","paragraphs":["can replace"]},{"title":"one","paragraphs":["node with two, it is possible"]},{"title":"for","paragraphs":["rcgcated"]},{"title":"application of","paragraphs":["such a transforma-"]},{"title":"tion","paragraphs":["to produce a node in"]},{"title":"the","paragraphs":["surface. structure with an arbi-arbitrary n~unbes of inmediate descendants. Tllis cans th~t. an infinite n~ur~el\""]},{"title":"of","paragraphs":["rules"]},{"title":"must be","paragraphs":["added to 1 base component. Petrick noted, however, that; if a limit is placed on the length of sentences to be analyzed (and certain minimal assumptions are made about the grammar)"]},{"title":",","paragraphs":["only a finite number of rules are required. (Alternatively,"]},{"title":"it","paragraphs":["seems, a recursive transition network could be used tu obtain the surface structure, since such a device allows a node to have an arbitrary number of immediate descendants"]},{"title":".","paragraphs":[") This augmented grcnlmar will produce all the valid surface structure parse trees but it will a! so produce,"]},{"title":"in","paragraphs":["general,"]},{"title":"many spurious","paragraphs":["trees (trees"]},{"title":"not","paragraphs":["derivable fl-om deep structures) This is unavoidable, since a context-free yranuuar"]},{"title":"is","paragraphs":["a ri~uch weaker computational device than a tra~:sfosmati on5.1 grannaar. Because the language defined by the augmented base component is larger than that defined by the tranxEormationa1 graminar, the augmented base component is called a coda19ing gramrzar. Since each spurious surface analysis will have to undergo a len'gthy"]},{"title":"reverse","paragraphs":["tra~sformational process before it !S recognized as invalid, it is important to"]},{"title":"minimize the","paragraphs":["number of such parses. The seriousness"]},{"title":"of","paragraphs":["this problem is indicated-by"]},{"title":"some early results","paragraphs":["obtained by"]},{"title":"the","paragraphs":["MITRZ group."]},{"title":"The MITRE system did not have a procedure for automatically augmenting the base","paragraphs":["component; theirs"]},{"title":"was","paragraphs":["assembled manually. Using"]},{"title":"a small","paragraphs":["grmar.,"]},{"title":"one of their 12-word test","paragraphs":["sentences obtained 48"]},{"title":"surface analyses, almost","paragraphs":["all of thorn spurious. Petrick had"]},{"title":"similar experience:","paragraphs":["he found that the"]},{"title":"covering grammars","paragraphs":["produced by"]},{"title":"his procedure-were too broad,","paragraphs":["producing too many surface parses. He has instead, like the"]},{"title":"MITRE","paragraphs":["group, produced his surface grammars manually, by analyzing"]},{"title":"oonstructions which","paragraphs":["appear"]},{"title":"in","paragraphs":["the surf ace structure of input sentences"]},{"title":"to","paragraphs":["determine which productions are required."]},{"title":"In tYlis way,","paragraphs":["he has been able to produce a practically useful covering grammar for a limited area of discourse. These practical difficulties do n~t negate the value of an automatic procedure, such as that described by Petrick, which will produce a covering grammar we can be surc is complete (will produce all valid surface analyses)"]},{"title":". They do","paragraphs":["indicate, however, the value"]},{"title":"of","paragraphs":["developing procedures which produce \"tighter\" surface grammars, perhaps by observing that certain sequences of transEormations are impossible and hence suppressing the corresponding surface grammar productions. They also suggest that a more powerful device than a- context-free"]},{"title":"grammar -- such as an","paragraphs":["\"augmented* context-free"]},{"title":"grammar\" should","paragraphs":["perhaps be used to generate the surface analyses. This"]},{"title":"view","paragraphs":["is held by a number"]},{"title":"of","paragraphs":["workers, such as Sager and Woods, who are also aiming at"]},{"title":"a","paragraphs":["transformational decomposition. Armed with a covering grammar, we turn now to the construction of a reverse transforrnafional component. This"]},{"title":"component should","paragraphs":["produce, from a surface structure, all base structures which can generate the surface structure (and for a spurious surface structure, indicate that there"]},{"title":"are no","paragraphs":["base structures)"]},{"title":". *","paragraphs":["\"augmented\" meaning here that the grammar may contain predicates which are arbitrary computable fiu7ctions. The first problem is that it is not always possible to construct such a component. If a (fonvard) transformation simply deletes a portion of the parse tree, it"]},{"title":"will","paragraphs":["in general be impossible to reconstruct that portion when working backwards from the sur'facc structure: there may be an infinite"]},{"title":"number ~f","paragraphs":["deep"]},{"title":"structures which","paragraphs":["produce"]},{"title":"one surface","paragraphs":["structure. Such a situation"]},{"title":"is","paragraphs":["called i.z*z*e~?sur:~l~zb It1 .JG tt.t%'cv~ ('Phis is in contrast to recoverable delcti~ns, which make use of a compo~~ent af forward transformations briefly iiontionod oarlier: identity conditions. An idcntiCy condition specifics"]},{"title":"two or","paragraphs":["more colnpar~cnts of the struotura3. index; tlle tuL~nsformst.iun may be applied only if the trccs doit~inated by the nodes matched by these eleinents aiue identical. If soc~e"]},{"title":"--","paragraphs":["but"]},{"title":"not","paragraphs":["a11"]},{"title":"-- sf thcse trces are","paragraphs":["deleted by a transformation, the deletion is recoverable: the reverse transfs~-matisnal. component may restore the deletion by. copying another part of the tree. ) So, to be able to construct a reverse component at all, the grammar may contain no irrecoverable de leci ons"]},{"title":".","paragraphs":["Life would be relatively easy if, for each transformation, one could produce an inverse tra~~sfsrmation which undoes the change wrought in the tree. Unfort:unatcly, for the £om of trar~sforrnation we have chosen, this is nut possible. Cor~s ider, for exangle; a transformatior1 with structural index and structural change Suppsse that the only structure to which it ever applies in the generation of a sentence is producing bg"]},{"title":"as transformation seenp straight forward","paragraphs":["enough.","xse transformation need not be a true inverse ; it mt hawe to be able to reconstruct any input given to transformation. It need only be able to repon-Senputs which occur in the derivation of sentences. this case, it must insert a B dominating a C !&!#"]},{"title":"m* This","paragraphs":["operation cannot be performed in the transformationaL sm dasc?r%bed above (unless a B dominating a C is present in the tree)"]},{"title":".","paragraphs":["In terms of elementary changes to"]},{"title":"a parse tree, tHis formalism permits","paragraphs":["only deletion (of 1. replacement (of 6ne node by another), and sister adjunction (insertion of one node \"next\" to another, with both natedqby the same notie); it does not allow insertion oS node' below another. This formalism was used in Petrick's original system. Most more recent systems, including the system and Petrick's later systems, have allowed a"]},{"title":"r set of elementary","paragraphs":["operations, capable of making an ftrary change to a tree. Even if the set of operations is sufficient to form a set oE rehxse transformations, their formation is not trivial. a such as the one just considered, the reverse trans-","on cannot be genexated from an examination of the transformatian alone One must examine the entire to see how the transformation is used in sentence on, This is a complex process which has (to the oras knowledge) nevert been programmed. In the MITRE"]},{"title":", the reverse","paragraphs":["transfofdn'ations were all produced I Petrick, seeking orj yinally a procedure which w~uld work cal2y from the transf~rmational grammar took a actifberent tack. He developed a reverse transformational & which mapped the surface strirrg (the senkence) hto a set of potential deep structure strings; the latter -me"]},{"title":"~~ parsed by the base component. The individual ions","paragraphs":["of the reverse component are str&ng and not kme mewr5,ting sules"]},{"title":".","paragraphs":["The advantage of this approach lies in the simplicity of forming the individual reverse transformations. The reverse transformations will be in one-to-one corresponAence with the forward ones, and each reverse transformation T' can be computed on the basis of the corresponding forward transformation T alone. These reverse transformations will satisfy the following property: for any tree t with frontier s, if T maps t into t1 with frontier sl, then T' maps s1"]},{"title":"into","paragraphs":["s. Suppose we are given a fonvard transformatisr~ with structural index si and structural change sc. since we are interested only in the frontier and not in the internal structure of the tree, we shall use a rcd~xccd structural change rsc = [+: 1 <= i <= #SC] sc(i) obtained by concatenating the elements. of the structural change. The fact that a proper analysis exists for a tree with frontier s implies that s can be givided into substrings s1 t"]},{"title":"- ,Sn","paragraphs":["such that, for all j from 1 to n, a tree can be"]},{"title":"*","paragraphs":["built with root si and frontier s j","(unless si = 'X1,","j j","in which case there is np, restridtion on s .) :","3 The transformation rearranges the string into a set of 1 substrings s given by (for j from 1 to r, r = #rsc) j S' (1) = if rsc( j) is an integer then $(rsc(j)) else rsc(j) ,s (rsc (r) )"]},{"title":"*","paragraphs":["using the, covering grammar."]},{"title":"How","paragraphs":["can"]},{"title":"this shuffle be reversed?","paragraphs":["We begin by creating an .inverse structuraZ index"]},{"title":"isi (1","paragraphs":["<= j <= r) according to. j isi(j)"]},{"title":"= if rsc(j) is an","paragraphs":["integer then si(rsc(j))"]},{"title":"else rsc(j) and an invrrae structura2","paragraphs":["change"]},{"title":"isc (1","paragraphs":["= j C="]},{"title":"n) j","paragraphs":["according to isc(j) = if 3k"]},{"title":"I","paragraphs":["rsc(k) eq j then"]},{"title":"k","paragraphs":["else si(j) TQen giTlen *a"]},{"title":"string s ' , we divide it into r","paragraphs":["substrings, requiring that the? j-th"]},{"title":"substring be the","paragraphs":["frontier of"]},{"title":"some","paragraphs":["tree with root isi (again"]},{"title":"unless isi","paragraphs":["="]},{"title":"' X'","paragraphs":[")"]},{"title":".","paragraphs":["One"]},{"title":"of j j these","paragraphs":["divisions"]},{"title":"will","paragraphs":["be the"]},{"title":"s .","paragraphs":["produced 'by the forward 3"]},{"title":"transformation","paragraphs":["(there may"]},{"title":"be others) . These","paragraphs":["substrings are then rearranged according"]},{"title":"to thB isc,","paragraphs":["producing the","original string s","j s (j) ="]},{"title":"if isc(","paragraphs":["j) is an integer then s' (kc( j) ) else iscl j) If there are several matches to the"]},{"title":"isi, the","paragraphs":["transformation must be applied to all; we can only be sure that one"]},{"title":"of","paragraphs":["the resulting strings will be s. If the forward transformation 1"]},{"title":"is","paragraphs":["a recoverable"]},{"title":"deletion","paragraphs":["involvi3s identity conditions, the"]},{"title":"formulas","paragraphs":["given above are somewhat more complicated. Given a set of reverse transformations, we must finally specify the sequencing among them. The reverse transformations should be considered in precisely the reverse order fro11 that of the corresponding forward transformations. The sequericihg is again cyclic, with each iteration now creating"]},{"title":"an embedded","paragraphs":["sentence. Even if a"]},{"title":"reverse","paragraphs":["transformation matches the sentence being decomposed, one cannot be sure that the corresponding forward transformation was involved in the generation of"]},{"title":"the sentence.","paragraphs":["Uridoing the transformation may lead to a dead end (no other reverse transformations apply), and arkother transformation may also"]},{"title":"have","paragraphs":["produced the current structure. Consequently, both possibilities"]},{"title":"--","paragraphs":["unsdoing and not undoing the transformation"]},{"title":"--","paragraphs":["must Lie followed. In analogy with the fonvard transformations, one can say that all reverse transformations are optional. This implies, unfortunately, that parsing ti~ne can increase exponentially with the nuinber of applicable transformations. Such a procedure has therefore proved impracticabLe for a11 but the smallest grammars and sentcn~cs. To avoid this exponential growth, ths parser must have some way of dctermining directly from a tree the last transformation which applied to produce the trce. An analysis must be made of the possible intermediate structures which can arise in sentence generation, and the resulting information trans1 ated into conditions on the reverse transformations. Such an anaLysis has not been automated, but it: is norrr.al2y a straightforward and integral part of the manual construuti~n of a reverse transformational component. The MITRE group was able to specify the appropriate conditions for ail their reverse trans formations ; their sys tern provided for optional reverse transformations but their grammar did not utilize this facility. Eliminating optional reverse transformations is more di f ficulC in a reverse zornponen t using string ~cwriting rules, not retaining any tree structure between transforn~akions."]},{"title":"*","paragraphs":["Most of the information which is needed to determine which transformation to undo is not available. In any case, the original impetus for using string rewriting rules"]},{"title":"--","paragraphs":["providing a procedure which can operate directly from the transformational grammar"]},{"title":"--","paragraphs":["is lost when we seek to add, for reasons of efficiency, re~erictdons which are not automatically generated from the grammar.."]},{"title":"* Petrick's","paragraphs":["original system, using s~ring rewriting rules, did retain some low-level tree structures between transforrna-tions"]},{"title":", but","paragraphs":["his later sys terns did not"]},{"title":".","paragraphs":["Petrick'"]},{"title":"s current parser,","paragraphs":["part of"]},{"title":"the","paragraphs":["REQUEST sys tern, is"]},{"title":"mu& closer in overaL1","paragraphs":["structure to the MITRE design, A set of potential surface structure trees are operated upon"]},{"title":"by","paragraphs":["a reverse transformational component consis*ing of tree rewriting rules. The"]},{"title":"reverse","paragraphs":["transformations are prepared manually, not obtained automatically from"]},{"title":"corres-","paragraphs":["ponding forward transformations. The conditions on the reveree tra,nsformations are sufficiently tight to obviate the need for optional reverse transformations. As a result, they are able to operate efficiently with a moderately large set of reverse transl?ormations (about \" 130)"]},{"title":". Once a11","paragraphs":["reverse transformations have been applied, the resulting structures nust be checked to determine which are valid deep structures. If the reverse transforn~ations work on trees, each tree must be examined for productions not in the base component. If the reverse transformations work on"]},{"title":"strings, each string musk","paragraphs":["be parsed using the base component. The original Petrick and MITRE procedures envisioned a final synt.hesis phase. This phase would apply to each deep structure produced by the reverse transformational component. It would apply the corresponding forward transf or-mations to determine whether the original sentence can be recovered; if it cannot, the deep structure is rejected. Such a .check is necessary if the reverse transformations can produce deep structures which do not lead-back to the original sentence and perhaps do not lead to any sentence at all. This is certainly the case with the reverse transformations applied to strings; such transformations are unable to capture many constraints present when applying the fomard transformations to trees. It can also be true with reverse transformation's working on trees, if the constraint9 on the reverse transformations are too loose. With revera transforinations on trees, however, it should be possible to formulate constraints sufficiently tight as to obviate the need for a synthesiq phase. A synthesis check is optional in the current Petrick-Plath system. Instead of applying the forward transformations in a sepsrate synLhesis phase after a deep structure is obtained, however, they are applied during analysis after each corrcspond jng inverse transformation"]},{"title":"is","paragraphs":["applied. THE PROCE,D,UKE We present below a SETL verllion of one of Petrick's early trans farnational parsers. As was noted earlier, this algo-"]},{"title":"rithm is of","paragraphs":["i~nportance because"]},{"title":"it is","paragraphs":["the only procedure which can work dircctly"]},{"title":"from a forward transformational","paragraphs":["gramlear. The SETL program has bcen adapted from the LISP prvyr~m developed by Petrick at the Air Force Cambridge Research 1,aboratories (1966)"]},{"title":",","paragraphs":["and is somewhat simpler than the version presented in Petrick's thesis. In particular, the 1966 version preserves no tree structure between reverse transformations. Considerable liberty has bcen taken in rewriting the program for presentation here. Features which were not deemed essential to an understanding of the basic procedure were deleted. Specifically, the procedure for converting Iolwirr-d to reverse trans formations was not included; identity conditions in transformations were not prsvided; optional denrents"]},{"title":"in","paragraphs":["structural indices twrc not allowed. On the other hand, the gross flow of control of the LISP program has bcen preserved. The main procedure of the parser, XFPARSE, takes five arguments : SENTENCE the string to be analyzed XFMiiI the set of reverse transformations iq UEVXFMN S the number of transformations BASEGR the (context- free) base component AUXRULES the additional rules which must be added to the base component to form the covering grammar The"]},{"title":"context-free grammars have","paragraphs":["the"]},{"title":"form described in","paragraphs":["Sec."]},{"title":"3.1.","paragraphs":["Each"]},{"title":"trans formation has","paragraphs":["the"]},{"title":"fbllowing","paragraphs":["components :"]},{"title":"XFMN (i ,'ISIf","paragraphs":[")"]},{"title":"inverse structural index","paragraphs":["XFNY"]},{"title":"(i, 'NAME')","paragraphs":["name of"]},{"title":"transformation","paragraphs":["XFMH"]},{"title":"(i\", ' TYPE '","paragraphs":[")"]},{"title":"type of transformation","paragraphs":[": 'UNARY'"]},{"title":"or ' BINARY' if","paragraphs":["the transformation"]},{"title":"is","paragraphs":["unary,"]},{"title":"it aiso'has the component XFMN (it","paragraphs":["'ISC')"]},{"title":"inverse structural","paragraphs":["change"]},{"title":"if","paragraphs":["the"]},{"title":"transformation is binary, the inverse structural change will contain","paragraphs":["a"]},{"title":"pair of sentence","paragraphs":["boundary"]},{"title":"markers, with the component sentence inside the markers and","paragraphs":["the"]},{"title":"matrix sentence outside (the general form is m m m #","paragraphs":["c c c"]},{"title":"#.m m m ,","paragraphs":["with"]},{"title":"the m's","paragraphs":["part"]},{"title":"of the matrix sentence and","paragraphs":["the c's part"]},{"title":"of the component) . For the parser, it is","paragraphs":["more"]},{"title":"convenient","paragraphs":["to"]},{"title":"represent this","paragraphs":["as two"]},{"title":"separate","paragraphs":["tuples,"]},{"title":"one with the boundary markers","paragraphs":["and the"]},{"title":"elements between","paragraphs":["them replaced by"]},{"title":"the","paragraphs":["symbol 'COMP' ("]},{"title":"m m m","paragraphs":["'COMP'"]},{"title":"m m m","paragraphs":[")"]},{"title":"the other","paragraphs":["with"]},{"title":"the","paragraphs":["elements between the"]},{"title":"markers","paragraphs":["(c c c)"]},{"title":"In the transformation, these are components","paragraphs":["XFm"]},{"title":"(i, 'ISC-MATRIX'","paragraphs":[")"]},{"title":"inverse","paragraphs":["structural change"]},{"title":"for matrix sentence inverse structural","paragraphs":["change"]},{"title":"for","paragraphs":["component: sentence"]},{"title":"The value of","paragraphs":["XFPARSE"]},{"title":"is","paragraphs":["a set,"]},{"title":"with each","paragraphs":["element giving"]},{"title":"one","paragraphs":["possible deep Structure frontier for"]},{"title":"the","paragraphs":["sentence, and the"]},{"title":"reverse transformations","paragraphs":["which"]},{"title":"were","paragraphs":["applied"]},{"title":"to obtain","paragraphs":["that deep structure. To determine whether"]},{"title":"these","paragraphs":["are in fact deep"]},{"title":"structures","paragraphs":["for the sentence, it would be necessary"]},{"title":"to","paragraphs":["go through the generative transformational phase"]},{"title":"for each potential","paragraphs":["deep"]},{"title":"structure","paragraphs":["and"]},{"title":"verify","paragraphs":["that the"]},{"title":"original sentence can be","paragraphs":["obtained. If"]},{"title":"the deep structure contains no","paragraphs":["embedded"]},{"title":"sentences,","paragraphs":["the"]},{"title":"structure","paragraphs":["of"]},{"title":"an element in","paragraphs":["the"]},{"title":"returned set is <deep-structure-frontier, trans","paragraphs":["formations-applied> where deep-s"]},{"title":"tructure-f rontier","paragraphs":["is a"]},{"title":"tuple","paragraphs":["whose"]},{"title":"elcmcnts are","paragraphs":["the"]},{"title":"symbols in the frontier of","paragraphs":["we"]},{"title":"possible","paragraphs":["deep"]},{"title":"structure. Transformations-applied is","paragraphs":["a li,~llplo"]},{"title":"whose clcmcnts are the transformations applicd","paragraphs":["to obtain 'this deep"]},{"title":"structure","paragraphs":["; the"]},{"title":"first elenlent gives","paragraphs":["the lust"]},{"title":"transformation","paragraphs":["applied"]},{"title":"in","paragraphs":["the"]},{"title":"decomposition,","paragraphs":["and"]},{"title":"hence","paragraphs":["the first which"]},{"title":"would","paragraphs":["bc applicd"]},{"title":"in gcrleration.","paragraphs":["If tihe deep"]},{"title":"structure colitains an","paragraphs":["cmbcdded sen tcnce"]},{"title":",","paragraphs":["the"]},{"title":"element","paragraphs":["will"]},{"title":"still","paragraphs":["be a pair as"]},{"title":"just","paragraphs":["described;"]},{"title":"deep-structure-f rontier, however,","paragraphs":["will"]},{"title":"not","paragraphs":["incltida as"]},{"title":"elements two","paragraphs":["boundary"]},{"title":"markers","paragraphs":["and the intervening cl~beddcd"]},{"title":"suntence.","paragraphs":["Instead at that"]},{"title":"point in","paragraphs":["the tuple"]},{"title":"will bc an","paragraphs":["elenlent"]},{"title":"which","paragraphs":["Is"]},{"title":"itself","paragraphs":["a pair, with the"]},{"title":"first element","paragraphs":["the"]},{"title":"frontier cf","paragraphs":["the embedded sentence and"]},{"title":"the","paragraphs":["second the transf~rmations applied to"]},{"title":"decompose","paragraphs":["the enbedded sentence. The"]},{"title":"transformations-applied","paragraphs":["element of the top-level pair will include only the embedding transformation"]},{"title":"and","paragraphs":["the transfor~nations applied to the sentence before it was divided into matrix and constituent. Since each"]},{"title":"reverse","paragraphs":["transformation"]},{"title":"is","paragraphs":["optional and may apply"]},{"title":"in several ways, there will usually","paragraphs":["be n~dny paths to follow during the decon~position process. In XFPARSE, each"]},{"title":"such","paragraphs":["path"]},{"title":"is","paragraphs":["recorded as"]},{"title":"an elenlent in the","paragraphs":["set TODO; the element is a f ronbtier,'history pair, j ust like those produced as output. The main"]},{"title":"loop","paragraphs":["of* the parser runs over the"]},{"title":"trsns-formations.","paragraphs":["For each clement"]},{"title":"TODO, if","paragraphs":["the transformation applies"]},{"title":"all","paragraphs":["possible transforms"]},{"title":"of","paragraphs":["the element are added to TODO;"]},{"title":"since","paragraphs":["the transformation is optional, the ori~inal element remains as"]},{"title":"well.","paragraphs":["When an inverse embedding transforma-"]},{"title":"tion","paragraphs":["applies, XFPARSE is called recursively"]},{"title":"to","paragraphs":["deco~~~pose"]},{"title":"the","paragraphs":["embedded sentence. de fine"]},{"title":"f XFPARSE","paragraphs":["(SENTENCE"]},{"title":",","paragraphs":["XFMN"]},{"title":", NUMXFMNS , BASEGR ,","paragraphs":["AUXRULES ) ; local TODO, DONE,"]},{"title":"PARSES, SGRAMMAR,","paragraphs":["XFMNNO, CONT, SEiOT, XFAPPLD, MATCHSET, MATCH"]},{"title":",","paragraphs":["COMPPARS"]},{"title":",, ROMP","paragraphs":["MATRIX, P ; WNE = { <SENTENCE,"]},{"title":"nult> 1","paragraphs":["; PARSES ="]},{"title":"nk; /*","paragraphs":["compute covering grammar */b SGRAMMAR = BASEGR CJ AUXRULES ;"]},{"title":"/* iterate over transformations */","paragraphs":["( 1 <= YXF~NO <= NUMXFMNS) TODO 1= DONE ; DONE ="]},{"title":"nR; /* iterate over","paragraphs":["active continuations"]},{"title":"*/ (WONT E","paragraphs":["TODO) SENT = CONT (1) ; XFAPPLD = CONT (2) ; MATCHSET=PROCES (SENT, XFMN (XFMNNO"]},{"title":",","paragraphs":["ISI ) ,1, SGRAMMAR) ;"]},{"title":"/*","paragraphs":["iterate over matches to"]},{"title":"structural","paragraphs":["index"]},{"title":"*/ (YMATCH E MATCHSET) if","paragraphs":["XFMN (XFMtJNO"]},{"title":", '","paragraphs":["TYPE"]},{"title":"'","paragraphs":[") eq"]},{"title":"' BINARY' then /*","paragraphs":["for binary transformatibns, first try to analyze embedded sentence"]},{"title":"*/","paragraphs":["COMl?PARS=XFPARSE (IMPOSE (MATCH, XFMI ( XFJ!GJNQ,"]},{"title":"' ISC-COMP '","paragraphs":[") )"]},{"title":",","paragraphs":["XFMN"]},{"title":",","paragraphs":["XFMNJO, BASEGR, AUXRULES) ;"]},{"title":"/*","paragraphs":["iterate over analyses"]},{"title":"of","paragraphs":["embedded sentence, adding matrlx"]},{"title":"with","paragraphs":["analyzed embedded sentence to continuations"]},{"title":"*/ CVKOMP E COMPPARS) MATRIX=IMPOSE (MATCH","paragraphs":[",XFMN (XFMNNO"]},{"title":", ' ISC-MATRIX'","paragraphs":[") ) ; <MATRIX, <XFMiWO> -t XFAPPLD>"]},{"title":"in","paragraphs":["DONE ; end YKOMP; else"]},{"title":"/*","paragraphs":["unary transformation"]},{"title":"*/ /* add","paragraphs":["transformed sentence to continuations*/ NEWSENT"]},{"title":"=","paragraphs":["IMPOSE (MATCH, XFNJ (XFK~L\\I~,"]},{"title":"'","paragraphs":["ISC"]},{"title":"'","paragraphs":[") ) ;"]},{"title":"<NEWSENT,","paragraphs":["<XFMiVNO> + XFAPPLD>"]},{"title":"in DONE","paragraphs":[";"]},{"title":"end VMATCH; /\"include untrans formed sentence in continuations, since reverse transformation is optional */ CONT in","paragraphs":["DONE;"]},{"title":"end","paragraphs":["VCONT;"]},{"title":"end 1 c= V","paragraphs":["XFMNdO ;"]},{"title":"/\"fi lraransfo~.mations haw bcon triod */ /* select and return those strings Which can be analyzcd by tho base component */ t -1 return {PCDONE~","paragraphs":["PARSE (DASRGR, b"]},{"title":",P","paragraphs":["(1) )"]},{"title":"ne n$)","paragraphs":[";"]},{"title":"cnd","paragraphs":["XFPARSE;"]},{"title":"Most of the work of","paragraphs":["the"]},{"title":"parser is done","paragraphs":["by the"]},{"title":"two Eoutines","paragraphs":["PROCES and IMPOSE, PROCES matches"]},{"title":"cv-rant","paragraphs":["string against"]},{"title":"the inverse","paragraphs":["struct~iral index, an1 IMPOSE con~putes the e'flfect"]},{"title":"of the inverse structural change.","paragraphs":["PROCES takes"]},{"title":"four arguments","paragraphs":[": SENTENCE STARTWD"]},{"title":"the","paragraphs":["string to be matched the"]},{"title":"structural indax","paragraphs":["the"]},{"title":"number","paragraphs":["o the"]},{"title":"fixst","paragraphs":["word"]},{"title":"in the string","paragraphs":["to"]},{"title":"be matcl~ed","paragraphs":["by the"]},{"title":"structural index (,this argument is","paragraphs":["required because the procedure operates"]},{"title":"recursively; its value is 1 for","paragraphs":["calls"]},{"title":"from","paragraphs":["XFPARSE) the context-free"]},{"title":"gl-anmar used in matching","paragraphs":["the"]},{"title":"structuxal index to","paragraphs":["the string. The value of PRQCES is a set, with each element giving one match of the structural index to the string. Each element is a forest, .i.e."]},{"title":", a","paragraphs":["tuple of trees, where each tree is represented as described in Sec. 3.1~. The 11th tree of the forest h~s as its root Symbol the nth element of the structural index. Successive trees subsume contiguous segments of the string being matched. The following xoutine differs from Petrick's routine of thg same name in using recursion instead of iteration. def inef PROCES (SENTENCE, SI ,STARTWD, GRAMMAR) ; local R, RMDRSI, MATCHES, EI\\;IDWD, P, PI, RMDRMATCH, PARSES;"]},{"title":"/* split","paragraphs":["off first element of structural index"]},{"title":"*/","paragraphs":["R = hd SI; WRSI = tl SI;"]},{"title":"/*","paragraphs":["parse part of remainaer of sentence with this element*/ PARSES = PARTPARSE (GRAMMAR I R, SENTENCE STARTWD) ; MATCHES = nR; (VP E PARSES)"]},{"title":"* set","paragraphs":["ENDWD = next word in sentence to be matched"]},{"title":"*/","paragraphs":["ENDWD = P (1,"]},{"title":"' LW+ll","paragraphs":[") ; if RMDRSI eg nult then"]},{"title":"/* if at","paragraphs":["end of swim, accept parse tree for last element of s.i. only if it extends to end of sentence"]},{"title":"*/ if","paragraphs":["ENDWD eq ( (#SENTEiJCE)"]},{"title":"+ 1)","paragraphs":["then <P> in MATCHES; end if ENDWD; else"]},{"title":"/* not","paragraphs":["ak end of s. i."]},{"title":",","paragraphs":["call PROCES recursively to process next element"]},{"title":"*/","paragraphs":["RMDRMTCH = PROCESS (SEIITENEE ,RMDRSI:"]},{"title":", ENDWD ,","paragraphs":["GRAMMAR) ;"]},{"title":"/*","paragraphs":["concatenate parse tree for current element to each forest of matches to succeeding elements*/ ( YM E RMDRMTCH) <P> + M in WCHES; end RMDRMTCH ; end if RMDRSI; end"]},{"title":"VP","paragraphs":["PARSES; re turn MATCHES ; end PROCESS, The transformational parser"]},{"title":"uses two varieties of context-free parser.","paragraphs":["The first, called simply PARSE, has the external specifications givcn in Sec. 3J.A. Tho other, PARTPARSE, differs"]},{"title":"in","paragraphs":["three respects : 1. the routine takes a fourth aryumant, STARTWD, specifying the first word"]},{"title":"in","paragraphs":["the sentence"]},{"title":"to be","paragraphs":["matched by the parser (ptccodiny words"]},{"title":"am","paragraphs":["ignored) ; tho"]},{"title":"returned value","paragraphs":["includes parse"]},{"title":"trccs which","paragraphs":["do"]},{"title":"not","paragraphs":["extend to the end of the sentence. 2."]},{"title":"if","paragraphs":["tho specified koot symbol is"]},{"title":"' X' tbc","paragraphs":["routine creates a set of parse trees, each containi~qj"]},{"title":"a single node,","paragraphs":["named X, spa~lning all possible substrings with first w6rd = STARTWD 3. the sfmbol COMP will match an element of the string which is a tuple (since, as noted earlier, an embedded sentence is represented as a tuple)."]},{"title":"The","paragraphs":["first two changes are effected by +ilodifyir~g the main routine of the first parser presented in Sec. 3.1. de fine f PARTPARSE (GIIA~AR, ROOT, SEW'PEACE sTARTII'D) ; local PARSES, TREE, iJODES, IVORD, LW; if ROOT eq 'X' then return 1, 'NAME', XI>, <1,'FW1,STARTWD>, <l,'~~+l',~\\d+l>}, (STARTWD~~) <= LW <= !!SENTENCE} ; end if ROOT; if STARTWD gt #SE~JQENCE then return nP,; end if STARTWD; TREE = nR; PARSES = nR; WORD = SqhRTWD; NOUES = 1;"]},{"title":"TREE(~,~NAME~)","paragraphs":["="]},{"title":"ROOT; TGE(1,'FW')","paragraphs":["= 'rJORV; (while @XPh?D"]},{"title":"(1 ,GRAMMAR,SENTENCE)","paragraphs":[")"]},{"title":"PARSES =","paragraphs":["PARSES"]},{"title":"u","paragraphs":["{TREE"]},{"title":"1 : end while","paragraphs":["EXPAND;"]},{"title":"recurn PARSES","paragraphs":[";"]},{"title":"end PAR'fPARSE","paragraphs":["; The"]},{"title":"third change is accomplished by modifying one line in the","paragraphs":["EXPEL\\ID"]},{"title":"routine of the first parser in","paragraphs":["Sec."]},{"title":"3.1. The line","paragraphs":["which tests"]},{"title":"for a match against","paragraphs":["the"]},{"title":"current sentence word is","paragraphs":["changed from."]},{"title":"i f","paragraphs":["SENTENCE (WOW)"]},{"title":"eq","paragraphs":["TREE (X"]},{"title":",","paragraphs":["'NAME"]},{"title":"'9 to if","paragraphs":["(SE:JTEtJCs"]},{"title":"(WORD) eq","paragraphs":["TREE"]},{"title":"(X , '","paragraphs":["NAME"]},{"title":"'","paragraphs":[") ) or ("]},{"title":"(type","paragraphs":["SENTENCE (YJORD)"]},{"title":"aq tupl) and","paragraphs":["(TREE"]},{"title":"(x,'NAME1.)","paragraphs":["eg 'COMP') ) IMPOSE, which"]},{"title":"computes the","paragraphs":["effect of the structural change,"]},{"title":"is a routine with two arguments.","paragraphs":["FQREST"]},{"title":"is a tuple","paragraphs":["of"]},{"title":"trees representing","paragraphs":["the match"]},{"title":"to the structural index (one element","paragraphs":["of the"]},{"title":"value","paragraphs":["returned byL PROCES) SC is the"]},{"title":"structural change component","paragraphs":["of a"]},{"title":"transformation In","paragraphs":["addition, KOMP"]},{"title":",","paragraphs":["which (for binary trans formations) holds"]},{"title":"the embedded","paragraphs":["sentence and its transformational history,"]},{"title":"is passed from XFPARSE to IMPOSE","paragraphs":["as a global"]},{"title":"variable.","paragraphs":["IMPOSE"]},{"title":"returns","paragraphs":["a"]},{"title":"tuple,","paragraphs":["the"]},{"title":"frontiers of","paragraphs":["the"]},{"title":"trees in","paragraphs":["the"]},{"title":"forest as rearranged in accordance with","paragraphs":["the"]},{"title":"structural","paragraphs":["change. definef IMPOSE (FOREST ,SC) local"]},{"title":"I;","paragraphs":["return [+: I E SC] if (type I) eq int then FRONTIER(FOREST (I) ) else if I eq 'COMP' then CKObJP, G~SC?"]},{"title":"<I>; and","paragraphs":["IMPOSE; The function FRONTIER takes as its argun~ent a tree and returns the frontier of the tree. Since the root= node of tha trcc specifies tho words spn~rncd in the sentence (variable Si7J4T, t?~6~~3a~?d ~;ZI XFPAWE) this is trivial: de fin& FRQNrTLER(TREE) ; local. FNs L'CVPJ,; ~:CJ = TREE (1, 'FI~J') ; ES~P~ = TREE(~,.~LW+~~) ; return SENT (FF.7: LWP1-FW)- ; end FROLITIER;"]},{"title":"84 Rppendix. A Very","paragraphs":["Short"]},{"title":"Intrahction to","paragraphs":["SETL"]},{"title":"(Prepared in collaboration with Norman ~uhin,","paragraphs":["CIMS"]},{"title":".","paragraphs":[") SETL"]},{"title":"is a programming lwguage designed aro set-theoretic structions and developed at NYU by","paragraphs":["a"]},{"title":"group","paragraphs":["led"]},{"title":"by Jack2Schwartz. rich set of operators and control structures provided in SEZL are intended to make the specification of algorithms coneiderably easier in","paragraphs":["SETL"]},{"title":"than in other higher-level languages. To facilitate the reading of our artificial inteliigerlce surveys, ua have used only a subset af","paragraphs":["SETL;"]},{"title":"this subset is described in pages which follow.","paragraphs":["Those"]},{"title":"few %points where we haw","paragraphs":["deviated a"]},{"title":"true SETL subset are marked on the left with asterisks and mated at the end of this section. mer information on SETL is available in J. T. Schwartz, On Programming: An Interim Report on the 6 Project, Parts I and XI. Courant Computer Science Notes, Cowant Institute of Mathematical Sciences, New York Univ. X. Kennedy and& Schwartz, \"An Introduction to","paragraphs":["the Set"]},{"title":"retical Language SET&","paragraphs":["\""]},{"title":"Comp. and","paragraphs":["Math. with Appl"]},{"title":". - 1","paragraphs":["9 7. Wuch"]},{"title":"of the expression semantics of","paragraphs":["SZTL"]},{"title":"is modeled on that wed @in the mathemakical theory of sets, and many of the syntactic ca~~entlans used reflect notions which are standard in","paragraphs":["that theory."]},{"title":"However, for programmin~urposes","paragraphs":["a set"]},{"title":"theory including atoms which tnemselves have no nemrs","paragraphs":["but"]},{"title":"may freely be @ers of sets is more conveniegt ban pure set theory. Thus SETL contains","paragraphs":["both a"]},{"title":"general","paragraphs":["dath"]},{"title":"vb","paragraphs":["ject"]},{"title":"(the set) and other operationally more efficient structures known as atoms","paragraphs":[";"]},{"title":"among these is a vector-like object known as a tuple, Atoms - (1) 12)","paragraphs":["(3) (4) (5) integers (.1276) character strings ('hel.10, pally"]},{"title":"'","paragraphs":[") bit strings"]},{"title":"(10101b)","paragraphs":["boolean constants"]},{"title":"(true","paragraphs":["lbr false E"]},{"title":"Ob)","paragraphs":["blank atoms (created by the function NEWAT, the SETL equivalent of the LISP GENSYM) Q,"]},{"title":"the","paragraphs":["undefined atom labels (labels precede s tatcments"]},{"title":", separated by a colon) subroutines and","paragraphs":["functions tuples"]},{"title":"(one-dimensional","paragraphs":["arrays of variable length;"]},{"title":"i. e.,","paragraphs":["ordsred lists;"]},{"title":"written as","paragraphs":["<1r 2,"]},{"title":"' threeJ>","paragraphs":[";"]},{"title":"the","paragraphs":["null tuple"]},{"title":"is designated nult)","paragraphs":["Sets are unordered collections of elements, written as {1,2,"]},{"title":"'","paragraphs":["three' ) :he null set is designated nR Oper at OPS Integers arithmetic"]},{"title":"+ * , comparison (eq,ne, it, gt, lc,","paragraphs":["gel max,min, abs Booleans and, or, hot (abbreviated n)"]},{"title":", cq, ne","paragraphs":["Character and bit strings concatenatiton"]},{"title":"*(+I,","paragraphs":["Length #"]},{"title":",","paragraphs":["substriqq (S(1:K). is the string"]},{"title":"of","paragraphs":["length X starting with the Ith element, like tb~ PL/I s&string function) Tuples A tuple is a sequence of components Cl,,C2,C3,."]},{"title":". . , all","paragraphs":["but a finite number of which are equal to R, the undefined atom- (1) T (K) is the Kth component of T (2) T(1:K) is the tuple of length K starting with the Ith element (3) #T ds the index of the last defined component of T (4) hd T E T(1) tR T I T(2:(#T-1)) T -+ U is the concatenation of tuples T and U Tuples are often used as push-down stacks, using T(#Ttl) = X to push X on the stack and T(#T) = 8 to pop the stack. Sets X E. S (true if X is an element of X, otherwise false) arb S (an arbitrary element of set S) 4"]},{"title":"u","paragraphs":["B (union of sets A and B) A (7 B (intersection of sets A and B) A'"]},{"title":"/ B","paragraphs":["(symmetric difference of se$s A and B). A"]},{"title":"-","paragraphs":["R (difference, set) #S (numbernof elements in set S) A with B 2 A U (B)"]},{"title":"- A less B","paragraphs":["= Aw- {B} sets may be compared using eq, ne, incs (in'cludes) Precedence There. are ;three levels of precedencz: (1). (highest built-in binary operators proiucing Boolean from non-Boolean values (eq, ne, lt, gt, le, ge, incs, E) (2) unary operators."]},{"title":"- (3)","paragraphs":["other binary operators Within each level, evaluation is le f t-to-right"]},{"title":". Set","paragraphs":["~efinition A set may be defined by enumeration"]},{"title":"IA,B,c} or by a","paragraphs":["set-former: {EXPR(X~,"]},{"title":". . . , X","paragraphs":[")"]},{"title":",","paragraphs":["range-restriction"]},{"title":"I c (X . . ,-X","paragraphs":[") } n l* n which forms the set of values EXPR(,X1,."]},{"title":". . ,Xn)","paragraphs":["for those X1"]},{"title":", . . , within the","paragraphs":["range-restriction for which C (X"]},{"title":". . . ,X","paragraphs":[") n 1"]},{"title":"' n is","paragraphs":["true. The range-restriction is a series of items, one for each of the X"]},{"title":"of","paragraphs":["the form"]},{"title":"i For","paragraphs":["example, Two abbreviated forms are allowed: {X E S"]},{"title":"I C(X)] foe, Ix,,X E S I","paragraphs":["'C(X)I and"]},{"title":"IEXPR(X) ,","paragraphs":["XES} for"]},{"title":"{E?xPR'(x) ,","paragraphs":[",~~~$tipe}"]},{"title":"Conditional Operators","paragraphs":["if BOOL then EXPRl e~.je EXPR2 has the value EXPR1 if BOOt is true, the value EXPR2 if.BOOL i.s false. The else is considered a unary operator, so tha-t;. if X gt 0 then Y else X"]},{"title":"+ Y is","paragraphs":["analyzed as (if X gt 0 then Y else X)"]},{"title":"+ Y","paragraphs":["Functional Application and Sets If"]},{"title":"F is a","paragraphs":["set and A any set or atom then (1) F{A] (if #P gt 2 then tR P else P (2)"]},{"title":", P E F I","paragraphs":["(\"P"]},{"title":"is","paragraphs":["a tuple\") and (#P gt 2) and (P (1) eq A)"]},{"title":"1","paragraphs":["e.g.,"]},{"title":"if F is a set of pairs, F{A) is the set of all X such","paragraphs":["that <A,X> E F. (2) F(A) if #F{A} eq 1 then grb F{A) else $2."]},{"title":"i . e . , the","paragraphs":["unique image of A under F. (3) F [A] z the"]},{"title":"union of","paragraphs":["the"]},{"title":"elements of FIA}. Sets","paragraphs":["are often used to define complex mappings. For instance, F = {<111>, <2,4>, <3,9>Ir or alternatively F(1) = 1; F(2) = 4; F(3) = 9; defines a set mapping the first three integers"]},{"title":"into their squares. In either","paragraphs":["case, F(1)"]},{"title":"is 4","paragraphs":["and F(4)"]},{"title":"is Q.","paragraphs":["Quantified Boolean Expressions The basic forms for quantified boolean expressions are"]},{"title":"The first: is","paragraphs":["true if C"]},{"title":"(x) is true for some x in","paragraphs":["s, and further-"]},{"title":"more sets x to the","paragraphs":["first"]},{"title":"value","paragraphs":["found"]},{"title":"far","paragraphs":["which C (x)"]},{"title":"is true; the","paragraphs":["second"]},{"title":"is true if","paragraphs":["C(x) is true for all"]},{"title":"x in","paragraphs":["s. Several range restrictions may be"]},{"title":"combined: The alternate,","paragraphs":["numerical, forms"]},{"title":"of","paragraphs":["range restrictions,"]},{"title":"such as min -","paragraphs":["< 3 x"]},{"title":"-","paragraphs":["<"]},{"title":"max and min -","paragraphs":["< Vx"]},{"title":"-","paragraphs":["<"]},{"title":"max, .","paragraphs":["may also be used. Compound Operators Co-mound operatogs 'hdve the form lop: range-restrictions"]},{"title":"I C (Xlr . . . , X,)","paragraphs":["] EXPR (x~,"]},{"title":". . ,X","paragraphs":[") n where op is a binary operator and the range-restrictions have the form described earlier. The value of this expression is the value of variable VALUE after executing: PILE = ~EXPR~X~,"]},{"title":". . . , X","paragraphs":[")"]},{"title":", range-res trictions I C (XI,. . . , X","paragraphs":[")"]},{"title":"1","paragraphs":["; n n VALUE"]},{"title":"from P1.W; (while","paragraphs":["PILE"]},{"title":"ne nR) X from","paragraphs":["PILE; 'VALW = VALUE"]},{"title":"op X;","paragraphs":["end"]},{"title":"while","paragraphs":["P~LE; For example,","[max: X E 11r2t311 (X+1) is 4 K","Statements __/ \"\" All statements are terminated by a"]},{"title":"semicolon. Assignment A","paragraphs":["= EXPR; <ArB,C> = EXPR; is the same as A=EXPR(l) ;B=EXPR(2) ;C=EXPR(3) t Assignment may also be done"]},{"title":"with","paragraphs":["the operator \"is\": \"EXPR is V\""]},{"title":"is an expression","paragraphs":["with value &XPR and the side effect of assigning this value to V X in S;"]},{"title":"is S","paragraphs":["= S with X; X from S; is X=avb S; S = S lcss X; X out S; is S = S less X; Transfer go to LABEL; Conditional"]},{"title":"if","paragraphs":["BOOLl then BLOCK, else"]},{"title":"if","paragraphs":["BOLL2 then"]},{"title":"...","paragraphs":["else BLOCK ; n ~teration (while BOOL) BLOCK;"]},{"title":"(vxl Sit X2 E S2(X1),.-.I~(~1t-.-t X n","paragraphs":[")) BLOCK;"]},{"title":"(M -","paragraphs":["< YX"]},{"title":"-","paragraphs":["< N) BLOCK; (N"]},{"title":"-","paragraphs":["> VX >"]},{"title":"M)","paragraphs":["BLOCK;"]},{"title":"- etc.","paragraphs":["Scope of Conditionals and Iterators The BLOCK indicated above as the scope of a SETL conditional statement ,or iterator is any sequence of SETL statements. Note that the semicolon terminatir~g the block is in addition to the semicolon terminating the final statement of that block. This semicolon may be replaced by an end statement such as end V; end VX; end while; end while BOOL; to indicate to the reader which scope is being closed. Ex.: (1"]},{"title":"- VX -","paragraphs":["< 100"]},{"title":"I","paragraphs":["P(X)) Y(#Y+l) = X; end VX; if Y gt O then S = S with X; else N = Ni-1; end if Y; Output print EXPR1,EXPR2,."]},{"title":". .","paragraphs":[",EXPRn; Subroutines and Functions Subroutines defined by define SUB(X,Y,Z); BLOCK end SUB; invoked by SUB (A,B, C) ; exit from subroutine by return;! Functions defined by definef FCN (X,Y, Z) ; BLOCK end FCNr invoked by FCN(A,B,C) exit from function by return EXPR; Infix operator definition defined by X infixop Y; BLOCK end A infixop B; Scoping local X,Y, Z; defines X,Y, and Z as local to the current subroutine or function (these variables are allocated on entry to the routine). Name scoping is dynamic, as in LISP; a variable declared loca 1 by procedure p is availale to all procedures invoked by p which do not themselves declare the variable local. Thus define P; local X; Q(1) ; print X; return; end"]},{"title":"$;","paragraphs":["define Q (Y) ;"]},{"title":"x","paragraphs":["="]},{"title":"7; return;","paragraphs":["end Q; will print a 1. Differences from Standard"]},{"title":"---","paragraphs":["SE'rL Standard SETL uscs a somewhat smaller character set than we have adopted in this survey. Thus -t (addition), -+ (co~~catcnation) and U (union) Are all written as"]},{"title":"+","paragraphs":["in standard SETL;"]},{"title":"* (multiplication)","paragraphs":["and n (intersection) are written as"]},{"title":"*.","paragraphs":["We have adopted the simple and familiar name-scoping rules of the current SETL irnplen~entatiorl in place of the relatively con~plex ones of the SETL standard. iVe have written all variables function ni;mes, and s~broutin names in upper case, operator names and other tokens in lower case. BIBLIOGRAPHY [Aho 19721 A. V. Aho and J. D. Ullrnan. The Theory of Parsing, Translation, and Compiling, Vol- I. Prentice-Hall, Englewood Cliffs"]},{"title":", N. J.","paragraphs":["[Bobrw 19691 D. Bobruw and B. Fraser, \"An Augmented State Transition Network Analysis Procedure, \" Proc. International Joint Conference on Artificial"]},{"title":"Intelligence [Borgida 19 751 Alexander","paragraphs":["Borgida, Topics in the Understanding"]},{"title":"of English","paragraphs":["Sentences by"]},{"title":"Computer.","paragraphs":["Tech. Rep. 78, Dept."]},{"title":"of","paragraphs":["Computer Science, Univ."]},{"title":"of","paragraphs":["Torsnto. [Bross 19681"]},{"title":"Irwin Bross;","paragraphs":["\"A Syntactic Formula"]},{"title":"for English Sentences","paragraphs":[": Application to Scientific Narrative, 1 t Cornpu2ers and"]},{"title":"Biomedical","paragraphs":["Research 1, 565. [Cautin 19691 Harvey Cautin, Real English: A Translator to Enable Natural Language Man-Machine Conversation. Thesis, Moore School of ~lectrical Engineering, Univ, of Pennsylvania"]},{"title":".","paragraphs":["[Cocke 1970"]},{"title":"1 J. Cocke and J. T. Schwartz,","paragraphs":["Programming Languages and their Compilers. Lecture Note series, Courant"]},{"title":"Institute","paragraphs":["of Mathematical Sciences, New York Univ; [Culmerauex 19 70 1 Alain Colrnerauer"]},{"title":",","paragraphs":["\" ~es Sys terns-Q ou un formalisme pour analyser et synthe tiser des phrases sur ordinateur. Publ. interne no. 43, ~aculte' des sciences, ~niversi te' de ~ontre'al. [Craig 19661 J. A- Craig, S. C. Berenzner, H. C. Carney, and C. R- Longyeart \"DEACON: Direct English Access and Control. \" Proc- 1966 Fall Joint Computer Conf., Thompson Books, Washington,"]},{"title":"D. C.","paragraphs":["ICuliQgver 19691 P. Culicover, J. Kimball, C. Lewis, D. Loveman, J. Moyne, An Automated Recognition Grammar for English, IBM Technical Repor? ZSC 69-5007. Cde Chastellier 1969 ] G. ae Chastellie~ and A. Colrnerauer-, \"W-Grarpmar, I I Proc. 24 flafional ~6nf. Assn. for Comp"]},{"title":". Mach. .","paragraphs":["[Dewar 19691 HI Dewar, P. Bratley, and J. P. Thorne, \"A Program for the Syntactic Analysis of English Sentences,"]},{"title":"\"","paragraphs":["Cornm. Assn. Comp. Mach. 12, 476. [Dostert 19711 B. Dostert and F. Thompson, \"How Features Resolve Syntactic Ambiguity,\" Proc* Symposium on Information Storage and Retrieval. [Earley 19 701 J. Earleyr \"An Efficient Context-Free Parsing Algorithm. Camm* Assn- Cornp- Mach. 13, 94. i~rishman 1973a] Ralph Grishman, \"~mplementation of the String Parser of English, \" in Natural Language Processing, ed. R. Rustin, Alqorithmics Press, New York. [Grishman 1973bJ R. Grishman, N. Sager, C. Raze, and B. Bookchin, \"The Linguistic String Parser."]},{"title":"\" Proc.","paragraphs":["1973 Natl; Computer Conf."]},{"title":",","paragraphs":["AFIPS Press, Montvale, N"]},{"title":". J.","paragraphs":["[Xarris AS) 651 Zellig Harris, String ~nalysis of Sentence Structure. Mouton, The Hague. [Hays 19671 David Hays Introduction to Computa+ional Linguistf cs. American Elsetrier, NeiJ York. [Hi2 19671 D. Hiz and A. Joshi, \"Transfomati'onal Decomposition: A Simple Description of an Algorithm for Transformational Analysis of English Sentences- \" 2'eme Conf. Ipternatidnale sur le Traitement Automatique des Langues"]},{"title":",","paragraphs":["Gsenoble"]},{"title":". [liobbs 19 $4","paragraphs":["] Jerry Hobbs"]},{"title":", A","paragraphs":["Metalanguage for ~xpressi~g Grammatical Restrictions -in Nodal Spans Parsing ~f Natural. Language. Courant Computer Science Report"]},{"title":"$2,","paragraphs":["Courant Inst. Rath. Sci._, New York ~niv, [Eiobbs 19751 J. Hobbs and R. Grishman, \"The Automatic. Transfbrrnational Analysis of English Sentences: An 1mplkmentation.\" Submitted to Xnt'l J. Conputer Matn. [~rons 19631 N. Irons, \"Error-Correcting Parse Algorithm.. =om. Assn. Comp. Mach. 6, 669. [~oshi. 19621 Aravind Joshi, A procedure for transformational decoinposition. Transformations and Discc~rse Analysis Pape-rs $42, UnitT. of Pennsylvania, [Joshi 19 331 Atavind Joshi, \"A Class of Tr,-;ulsformational Grammars \" In The Formal Analysis of Natural Languages* ed. MI Gross"]},{"title":", M. Halle, and","paragraphs":["M. -P. Schiitzenberger, Mouton, The Hague.","11 [Kay 19671 Martin Kay, Experiments with a powerful Parser.. PI In 2&me Conf. Internationale sur le ~raitement Automatique des Langues"]},{"title":",","paragraphs":["Grenoble. [Keyser 19671 S. 5. Keyser and S. R. petrick, syntactic Analysis * Air Force Cambirdge Research ~aboratories, -WCRL-6 7-0 305. [Kittredge 19731 Richard Kittredge et al., TAUM 73. A report of the Projet de Traduction Automatique de I'universit6 de ~ontrgal. [Kuno 19621 S. Kuno and A. G. Oettinger, \"~ultiple-Path Syntactic Analyzer.\" Information Processing 1962, North-Holland, Amstetdam. [Kuno 19631 Su$umo Kuno, \"The Multiple-path Syntactic Analyzer for English. \" Report No. NSF-9 in Mathematical Linguistics and Automatic Translation of the Computation Lab., Harvard Univ. [Kmo 19651 Susumo KWO, \"The Predictive Analyzer and a Path Elimination Technique.\" Comm. Assn. Comp. Mach. 8, 453. [Loveman 19711 D. Loveman, J. Moyne, and R. Tobey, \"CUE: A Preprocessor System for Restricted, Natural English. In Proc. Symposium on Information Storage and ~etrieval. [Owens 1'9751 Phillip Owens, A Comprehensive Survey of Parsing Algorithms for Programming Languages, Courant Computer Science Report #4, Courant Inst. Math, Sci"]},{"title":". , New","paragraphs":["York Univ. (Forthcoming)"]},{"title":". [Paxton 19731 W; H.","paragraphs":["Paxton and A. E. Robinson, \"A Parser for a Speech ~ndeistanding System. \" Advance Papers of the Third Intl. Joint Conf. on ~rtif iciai Intelligence, S'tanford Research Instjtute, California. [Petrick 1965 ] S tqley Re Petrick, A Recognition Proceddre for Trans formational Grammars. Doctoral Disseztatf on"]},{"title":".","paragraphs":["[petrick 19661 Stanley R. Fetrick, A irogram for Transformational Syntactic Analysis, Air Force Cambridge Research Laboratories, AFCRL--66-698. [Petrick 19731 Stanley R. Petrick, Transformational Analysis, II In Natural Language Processing, ed. R. Rustin, Algorithmics Press, N. Y.","[Petrick 19 75 I Stanley R. Petrick, \"Design of the Underlying Structure for a Data Base Retrieval. System. \" In Directions in Artificial Intelligence: Natural Language Processing, ed. R. Gsishman Courant Computer Science Report #7, Courant Institute of Mathematical Sciences, New York nit', [Plath 19 74a] Warren J, Plath, \"Transformational Gramcar and Trans formational Parsing in the REQUEST Sys tern."]},{"title":"\"","paragraphs":["In Computational and Mathematical Linguistics, Proc, Intl. Gonf. on Computational Linguistics, ed-A. Zampolli, [Plath 1974b] Warren J*. Plath, String Transformations in the REQmST System. IBM TI J. Watson Research Center, RC 4947 (#21963). [~aze 19741 Carol Raze, A computatidnal treatment of c~osdinate conjunctions. Talk at 12 Ann. Meeting of Assn. of Computational Linguistics, Amherst, Mass., July 26, 1974. [Sager 19 671 Naomi Sager, \"Syntacti~ analysis of natural language. n In Advances in Computers, No. 8, ed. Fa Alt and M. Rubinoff, Academic Press, N. Y. [Sager 19731 Naomi Sager, \"The string parser for scientific literature"]},{"title":".","paragraphs":["\" In N%tural Language Processing, ed. R. Rustin, Algorithmics Press, N. Y. [Sager 19751 N. Sager and R. Grishman, \"The Restriction Language for Co~mputer Gr&mars of Natural Language. \" Comrn. Assn- Comp. Mach. 18,390. [Shapiro 19711 P- Shapiro and Dw Stermole, \"ACOEUl (Automatic Coder Report Narrative) : An Automatied Natural-Language Question-Answering System for Surgicm Reports,"]},{"title":"\"","paragraphs":["Computers and Automation, Feb. 1971, p. 13. [Simmons 19751 R. Simmons and G. Bennett-Wovak, \"Semantically Analyzing an English Subset for the Clowns Microworld, \" Tech. Report NL-24, Dept. of Computer Sciences, Univ. of Texas at Austin. [Thompson 19691 F. 9. Thompson, P. C. Lockenan, B. Dostert, and R. S. Deverill, \"REL: A Rapidly Extensible Language Sys tern. \" Proc. 24 Natl. Conf. Assn. Cornp. Mach. [Thorne 13681 J. P. Thorne, P. Bratley, and H. Dewar, h he Syntactic Analysis of English by ~achine. it ~achine Intelligence 3. [walker 19661 D. Walker, P. Chapin, M. ~eis, and Lo Gross, Recent Developments in the MITRE Syntactic Analysis Procedure. MITRE Report MTP-11.","11","[Walker 19 73 ] Donald Walker, \"Automated Language Processing. In Annual Review of Informaticjn Science and Techn'olog.~, Vo1. 8, ed. C. Cuadra, American Society for Informa-Lion Science, Washington, Do C. [Wilks 19 751 Yorick Wilks"]},{"title":", \"An","paragraphs":["Intelligent Analyzer and Understander of English.\" Comrn. Assn. Cornp. Mach. 18, 264. [Winograd 19 711 Terry Winograd, Procedures as. a Representation for Data in a Computer Program for Understanding Natural Language. MIT Report MAC TR-48. [Woods 19 70a)- William A. Woods, \"Con@ext-Sensitive Parsing. \" Cum. Assn. Cornp. Mach. 13, 437.","[Woods 1970bJ William A. Woods, \"Transition Network Grammars","tI for Natural Language Analysis. Corn. Assn. Cornp. Mach. 13, 591. [Woods 19721 W. A. Woods, .RI M. Kaplan, B. Nash-Webber, The Lunar Sciences Natural Language Information Syste'm: Final Report. Report tf2378, Bolt Beranek and Newman, Cambridge"]},{"title":",","paragraphs":["Mass. [woods 19731 ~illiam A. Woods, \"An Eqerirnental Parsing Sy\\stem for \"Transition Network Grammars."]},{"title":"' In","paragraphs":["Natural Language Processing, ed. R. Rus tin, Algorithmics Press, New York. [Zwicky 19 651 A. Zwicky, J. Friedman, B. Hall, and D. Walker, h he MITRE Syntactic Analyqis Procedure for Trans formational Grammars. \" Proc. 1965 Fall Joint Computer Conf."]},{"title":",","paragraphs":["Thompson Books, Washington, D. C. SgCURITY%%$%f%%FyTHIS PAGE (W7wn Dara Entered) n r ii","REPORT DOCUMENTATlON PAGE READ STR RUCTIONS BEFORECOMPLETINGFORW 7. REPORT' NUMBER 12. GQVT ACCESSION NO, 3. RECIPIENT'S CA4ACOG NUMBER w M-S 0- 8"]},{"title":"1 4.","paragraphs":["TITLE (md Svbtltds) 5 TYPE OF REPORT PERIOD CQVDRED"]},{"title":"I A","paragraphs":["Survey of Syntactic Analysis Procedures"]},{"title":"I","paragraphs":["Technical Report"]},{"title":"I for","paragraphs":["Natural Language Ralph Gris'hman N08014-63X-0447-P032 drk University unclassified","kJa.. DECLASSl FICATION '0,OWNGRADtNG","SCHEDULE","L 16. DISTRIBUTION STA~T'EMENT (of Ihir Repafrt) 1","nacural language, syntaxt parsing, grammar, computational linguistics"]},{"title":"I 20 ABSTRACT (Continue on teverse side If necessrw wd Ic'antliy bv block number) This","paragraphs":["report includes a brief discussion of the role of automatic syntactic analysis, a survey of parsing proced-dues, past and present, and a discussion of the approaches taken to a number of difficult linguistic problems, such as con j-unction and graded accepkabilitty.. It also contains precise specifications in the pYogramming language SETL of a number of parsing algorithms. FORM 1 ,AN 7, 1473 EDITtON OF 1 NOV 65 IS OBSOLETE","UNCLASSIFIED SECURITY CLASSIFICATION 3F THIS PAGE (When Data Entered,'"]}]}