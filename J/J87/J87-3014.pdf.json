{"sections":[{"title":"ABSTRACTS OF CURRENT LITERATURE","paragraphs":["If you are interested in ordering any of the following University of Waterloo Computer Science Department reports,","please forward your order to: Sue DeAngelis Research Report Secretary University of Waterloo Computer Science Dept. Waterloo, ON CAN N2L 3G1 An Implementation of a Computational Model for the Analysis of Arguments An Introduction to the First Attempt Trevor J. Smedley Research Report CS-86-26 July 1986 The following is a description of a first attempt at a Prolog implementation of a computational model for the analysis of arguments. The implementation of the model can be found in /u/tjsmedley on watdragon. For a detailed description of the algorithms and other theoretical details, see the papers and thesis by R. Cohen. The three different algorithms have been implemented; pre-order, post-order, and hybrid. The code particular to each algorithm can be found under the directories; super_pre, super_post, and super.hybrid. The directory front_end contains code which is common to all three, and there is a symbolic link to this directory in each of the three directories mentioned above. Incorporating User Models Into Expert Systems for Educational Diagnosis Robin Cohen, Marlene Jones Research Report CS-86-37 September 1986 In this paper we study a particular real-world domain, that of educational diagnosis. We argue that expert systems for educational diagnosis require user models, and that these user models should include several components, including the user's background knowledge of both the student and the domain, as well as the user's goals. Our proposal is directed at enhancing the particular expert system of the CGD project. We then propose an architecture for this expert system that separates the knowledge base into relevant components and includes a user model. We further demonstrate that this divided model for the system facilitates providing the best response for a particular user, according to his background knowledge of the domain and of the student, and his goals. Finally, we argue that the techniques outlined here will be useful in general in expert systems. A Model for User-Specific Explanations from Expert Systems Peter G. van Beek Research Report CS-86-42 September 1986 In this thesis we present a computational model for generating non-misleading, user-specific explanations from expert systems. Ideally an expert system should, as an aid in formulating cooperative responses, both maintain a model of the user from the ongoing dialogue and possess knowledge of a user's expectations of cooperative expert behavior. Our model focuses on how knowledge of the user's goals, plans, and preferences should influence a response. Included are two important specifications: what information about the user is needed plus an algorithm for using that information to compute user-specific responses. The explanation model may be seen as extending the work of Joshi, Webber, and Weischedel to include user-specific goals and to specify the algorithm independent of domain.","The algorithm, together with the model of the user, present a general method of computing the responses enumerated by 376 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature Joshi, et al. They also allow us to generate helpful responses that address a particular user's preferences and goals and to recognize cases where a direct, correct response may violate the user's expectations of cooperative expert behavior and thus mislead or confuse the user. This involves, among other things, the ability to: provide a correct, direct answer to a query; explain the failure of a query; compute better alternatives to a user's plan as expressed in a query; and recognize when a direct response should be modified and make the appropriate modification.","While we focus in this thesis on explanations in the context of expert advice-giving systems, we feel the approach is applicable to a broad range of question types and to expert system explanation generation in general. User Modeling Bibliography Paul Van Arragon Research Report CS-87-22 March 1987 A user model can be defined as a computer representation of some aspects of a computer user. Such models have been used in many areas of AI, such as computer-aided instruction, where they are used to represent the knowledge and misconceptions of students [Brown and Burton, 1978]. In natural language processing, the pragmatic component usually contains a kind of user model [Cohen, 1985].","My Ph.D. thesis topic is to build formal tools for modeling users. I am concerned mostly with the representation of a user's knowledge and belief. This bibliography contains the references I have accumulated so far. Since I've chosen articles and books which are related to my specific approach to the problem of user modeling, the bibliography contains several references, which do not directly address user modeling. For example, since my approach is to model a user as a theory-formation system based on Theorist, developed at the University of Waterloo, I refer to the key Theorist references and to the related Philosophy-of-Science literature.","Most references in the bibliography are annotated briefly. Each reference has a few keywords listed in order to classify them. The first keyword of each reference is an acronym that refers to the major areas represented. These keywords have been used to create a short table of cross-references listed by keyword and author. The following areas are included: CAI - Computer-Aided Instruction ES - Expert Systems KR - Knowledge Representation LP - Logic Programming NL - Natural Language PS - Philosophy of Science UM - User Modeling The Design and Implementation of an Evidence Oracle for the Understanding of Arguments Mark Anthony Young Research Report CS-87-33 June 1987 When trying to understand the thrust of another person's argument, it is necessary to determine what his claim is, and what evidence he provides for it. It is necessary, therefore, to be able to recognize evidence relationships in terms of the speaker's beliefs. This essay concerns how one goes about building a system (an oracle) to do that, and provides a working version of a simple oracle. Integrating Connective Clue Processing into the Argument Analysis Algorithm The argument analysis algorithm presented by Cohen was implemented by Smedley. This was a basic implementation Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 377 The FINITE STRING Newsletter Abstracts of Current Literature Implementation Trevor J. Smedley Research Report CS-87-34 June 1987 which did not include any clue processing. This report describes the addition of a basic connective clue processing to the implementation. The following new reports are available and can be ordered free of charge from: Dr. Johannes Arz Universitaet des Saarlandes FR. 10 Informatik IV Im Stadtwald 15 D-6600 Saarbrueken 11 E-mail address: wisber%sbsvax.uucp@germany.csnet Lexical Functional Grammar and Natural Language Generation R. Block Report No. 10 Universitat Hamburg, Hamburg, 1986 Lexical Functional Grammar (LFG) is one of the more promising candidates for a general linguistic theory to emerge from the theoretical upheavals of the seventies. It displays a high degree of formalization and lends itself particularly well to computer implementation. In addition, LFG seeks to shed light on the mental representation of language in humans. This paper addresses itself to three points:","1. How plausible are LFG's claims to \"psychological reality\"?","2. To what extent is LFG superior or inferior to the Standard Theory of Transformational Grammar from which it is ultimately derived?","3. How realistic is LFG as a theory supporting language generation as opposed to language interpretation?","The author concludes that, despite positive features in LFG, transformational operations on canonical structures is a more efficient and realistic method of generating natural language for man and machine. A Two Step Reference Problem Solver R. Hunze Report No. 11 Siemens AG, Muenchen, 1987 The article is based on the discourse representation theory (DRT) of H. Kamp and Chomsky's binding Theory. A mechanism is presented that builds a discourse representation structure (DRS) and determines all referents that are syntactically admissible and in agreement with the accesibility conditions of DRT.","Imposing semantic restrictions would lead to the i~ ::dmization of the set of possible referents, but this has not bee~, investigated yet. Continuing earlier work, unification grammar is used to develop a formalism that allows for a flexible connection between syntax and semantic. This basic idea is to use the equation mechanism LFG provides to encode semantic information and model DRT explicitly. The system is written in InterLisp-D and runs on a Siemens 5815. Repraesentation des Fachwissens einer komplexen Domaene in einer KL-ONEartigen Repraesentationssprache H..G.Siedka-Bauer Report No. 12 SCS, Hamburg, 1987 An essential part of the knowledge base incorporated in the natural language investment consultation system WlSBER is the terminological knowledge of the domain of investment. QUIRKaKL-ONE-Iike representation language - an outcome of the WlSBER - project - was just to do this work.","The specific demands of the domain knowledge with respect to the representation and the possibilities as well as constraints of the representation language are the issues of this report. 378 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature Selected Dissertation Abstracts","Compiled by: Susanne M. Humphrey, National Library of Medicine, Bethesda, MD 20209","Bob Krovetz, University of Massachusetts, Amherst, MA 01002","The following are citations selected by title and abstract as being related to computational linguistics or knowledge representation, resulting from a computer search, using the BRS Information Technologies retrieval service, of the Dissertation Abstracts International (DAI) database produced by University Microfilms International.","Included are the UM order number and year-month of entry into the database; author; university, degree, and, if available, number of pages; title; DAI subject category chosen by the author of the dissertation; and abstract. References are sorted first by DAI subject category and second by author. Citations denoted by an MAI reference do not yet have abstracts in the database and refer to abstracts in the published Masters Abstracts International.","Unless otherwise specified, paper or microform copies of dissertations may be ordered from: University Microfilms International Dissertation Copies Post Office Box 1764 Ann Arbor, MI 48106 Telephone for U.S. (except Michigan, Hawaii, Alaska): 1-800-521-3042; for Canada: 1-800-268-6090. Price lists and other ordering and shipping information are in the introduction to the published DAI. An alternate","source for copies is sometimes provided at the end of the abstract. The dissertation titles and abstracts contained here are published with permission of University Microfilms","International, publishers of Dissertation Abstracts International (copyright 1986) by University Microfilms Inter-","national, and may not be reproduced without their prior permission. PlanPower, XCON, and MUDMAN: An In-depth Analysis Into Three Commercial Expert Systems in Use. DAI V47(09), SecA, pp 3473 John Julius Sviokla Harvard University D.B.A. 1986, 448 pages Business Administration, General University Microfilms International ADG86-29661 The objective of this thesis is to generate knowledge about the effects of ESs on the organizations which use them. Three field sites with expert systems in active use are examined, and the implications for management are drawn from the empirical observations.","This thesis uses a comparative, three-site, pre-post exploratory design to describe and compare the effects of ES use on three organizations: The Financial Collaborative (using the PlanPower system), Digital (XCON) and Baroid (MUDMAN). The study is guided by the notions of organizational programs as defined by March and Simon, and the information-processing capacity of the firm, as defined by Galbraith, to organize, describe, and compare the effects of ES use across the sites. Eleven exploratory hypotheses act as a basis for theory-building and further hypothesis generation.","ESs address ill-structured problems. Ill-structured problems are those problems for which the solution methods and criteria are either ill-defined or non-existent. In investigating three largescale ESs in use, this researcher discovered that these systems seem to create a phenomenon referred to as \"progressive structuring.\" This process alters the nature of the underlying task and the organizational mechanisms which support it. This phenomenon is dynamic and evolves over time.","All the ESs seemed to increase the effectiveness and efficiency of the user firm. The price of the benefits was an increased rigidity in the task. In considering ESs a manager should be concerned not only with the ES itself, but with the process by which the ES is adapted, and the overall process of creating and using the ES. In addition, the manager needs to consider the effects of the ES on the uncertainty associated with the task and should consciously manage that uncertainty to foster the level of adaptation necessary to keep the ES alive and viable in the organization. Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 379 The FINITE STRING Newsletter Abstracts of Current Literature Adaptive Information Retrieval: Machine Learning in Associative Networks DAI V47(10), SecB, pp4216 Richard Kuehn Belew The University of Michigan Ph.D. 1986, 328 pages. Computer Science University Microfilms International ADG87-02684 Foundations of Logic Programming With Equality DAI V47(10), SecB, pp4217. Kwok Hung Chan The University of Western Ontario (Canada) Ph.D. 1986. Computer Science. University Microfilms International This item is not available: ADG05-59521 One interesting issue in artificial intelligence (AI) currently is the relative merits of, and relationship between, the \"symbolic\" and \"connectionist\" approaches to intelligent systems building. The performance of more traditional symbolic systems has been striking, but getting these systems to learn truly new symbols has proven difficult. Recently, some researchers have begun to explore a distinctly different type of representation, similar in some respects to the nerve nets of several decades past. In these massively parallel, connectionist models, symbols arise implicitly, through the interactions of many simple and sub-symbolic elements. One of the advantages of using such simple elements as building blocks is that several learning algorithms work quite well. The range of application for connectionist models has remained limited, however, and it has been difficult to bridge the gap between this work and standard AI.","The AIR system represents a connectionist approach to the problem of free-text information retrieval (IR). Not only is this an increasingly important type of data, but it provides an excellent demonstration of the advantages of connectionist mechanisms, particularly adaptive mechanisms. AIR's goal is to build an indexing structure that will retrieve documents that are likely to be found relevant. Over time, by using users' browsing patterns as an indication of approval, AIR comes to learn what the keywords (symbols) mean so as use them to retrieve appropriate documents. AIR thus attempts to bridge the gap between connectionist learning techniques and symbolic knowledge representations.","The work described was done in two phases. The first phase concentrated on mapping the IR task into a connectionist network; it is shown that IR is very amenable to this representation. The second, more central phase of the research has shown that this network can also adapt. AIR translates the browsing behaviors of its users into a feedback signal used by a Hebbian-like local learning rule to change the weights on some links. Experience with a series of alternative learning rules are reported, and the results of experiments using human subjects to evaluate the results of AIR's learning are presented. An obstacle to practical logic programming systems with equality is infinite computation. In the dissertation we study three strategies for eliminating infinite searches in Horn clause logic programming systems and develop an extension of Prolog that has the symmetry, transitivity, and predicate substitutivity of equality built-in. The three strategies are: 1. Replacing logic programs with infinite search trees by","equivalent logic programs with finite search trees; 2. Building into the inference machine the axioms that cause","infinite search trees; 3. Detecting and failing searches of infinite branches.","The dissertation consists of two parts. General theories of the three strategies identified above are developed in Part I. In Part II we apply these strategies to the problem of eliminating infinite loops in logic programming with equality. Part I. General Theories We introduce the notion of CAS-equivalent logic programs: 380 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature logic programs with identical correct answer substitutions. Fixpoint criteria for equivalent logic programs are suggested and their correctness is established. Semantic reduction is introduced as a means of establishing the soundness and completeness of extensions of SLD-resolution. The possibility of avoiding infinite searches by detecting infinite branches is explored. A class of SLD-derivations called repetitive SLD-derivation is distinguished. Many infinite derivations are instances of repetitive SLD-derivations. It is demonstrated that pruning repetitive SLD-derivations from SLD-trees does not cause incompleteness. Part II. Extended Unification for Equality An extension of SLD-resolution called SLDEU-resolution is presented. The symmetry, transitivity and predicate substitutivity of equality are built into SLDEU-resolution by extended unification. Extended unification, if unrestricted, also introduces infinite loops. We can eliminate some of these infinite loops by restricting SLDEU-resolution to non-repetitive right recursive SLDEU-resolution; this forbids extended unification of the first terms in equality subgoals and has a built-in mechanism for detecting repetitive derivations. The soundness and completeness of non-repetitive right recursive SLDEU-resolution are proved. A Formal Description and Theory of Knowledge Representation Methodologies DAI V47 (09), SecB, pp3847. Nell Cooper The University of Texas at Arlington Ph.D. 1986, 117 pages. Computer Science. University Microfilms International ADG87-O l l O0 The absence of a common and consistently applied terminology in discussions of knowledge representation techniques and the lack of a unifying theory or approach are identified as significant needs in the area of knowledge representation. Knowledge representation viewed as a collection of levels is presented as an alternative to traditional definitions. The levels and their associated primitives are discussed. The concept of levels within each knowledge representation technique provides resolution to many of the controversies and disagreements that have existed among researchers concerning the equivalency of representation methodologies.","A statement of the equivalence of a certain class of frame knowledge representation and a certain class of logic based knowledge representation is presented. Definitions of the classes are included. Algorithms to convert from each class to the other are given as evidence of their equivalence. Input Transformations and Resolution Implementation Techniques for Theorem Proving in First-order Logic DAI V47(09), SecB, pp3848. Steven Greenbaum University of Illinois at Urbana-Champaign Ph.D. 1986, 259 pages. Computer Science. University Microfilms International ADG87-OI496 This thesis describes a resolution based theorem prover designed for users with little or no knowledge of automated theorem proving. The prover is intended for high speed solution of small to moderate sized problems, usually with no user guidance. This contrasts with many provers designed to use substantial user guidance to solve hard or very hard problems, often having huge search spaces. Such provers are often weak when used without user interaction. Many of our methods should be applicable to large systems as well.","Our prover uses a restricted form of locking resolution, together with an additional resolution step. Pending resolvents are ordered using a priority-based search strategy which considers a number of factors, including clause complexity measures, derivation depth of the pending resolvent, and other features.","Also described are transformations that convert formulas from one to another. One is a nonstandard clause-form translation Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 381 The FINITE STRING Newsletter Abstracts of Current Literature Semantic Networks as Abstract Data Types DAI V47(11), SecB, pp4584. Ernesto Jose Marques Morgado State University of New York at Buffalo Ph.D. 1986, 234 pages. Computer Science. University Microfilms International ADG86-29095 An Expert System for Providing Online Information Based on Knowledge which often avoids the loss of structure and increase in size resulting from the conventional translation, and also takes advantage of repeated subexpressions. Another transformation replaces operators in first-order formulas with their first-order definitions, before translation to clause form. This works particularly well with the nonstandard clause-form translation. There is also a translation from clauses to other clauses that, when coupled with some prover extensions, is useful for theorem proving with equality. The equality method incorporates Knuth-Bendix completion into the proof process to help simplify the search.","Some implementation methods are described. Data structures that allow fast clause storage and lookup, and efficient implementation of various deletion methods, are discussed. A modification of discrimination networks is described in detail. Abstraction has often been used to permit one to concentrate on the relevant attributes of the domain and to disregard the irrelevant ones. This is accompanied by a reduction in the complexity of the domain. Researchers have extensively studied the use of abstraction in programming languages to allow programmers to develop software that is precise, reliable, readable, and maintainable. In spite of the amount of research that it has been subjected to, data abstraction has been largely neglected by programmers, when compared with other abstract methodologies used in programming. One problem is that it is not always easy to characterize the correct set of operations that defines an abstract data type; and, although many definitions have been presented, no precise methodology has ever been proposed to hint at the choice of those operations. A second problem is that there is a discrepancy between the formalism used to define an abstract specification and the architecture of the underlying virtual machine used to implement it. This discrepancy makes it difficult for the programmer to map the abstract specification, written at design time, into a concrete implementation, written at coding time. In order to correct these problems, a theory of data abstraction is presented, which includes a new definition of abstract data type and a methodology to create abstract data types.","Because of their complexity, semantic networks are defined in terms of a variety of interrelated data types. The preciseness of the abstract data type formalism, and its emphasis on the behavior of the data type operations, rather than on the structure of its objects, makes the semantics of semantic networks clearer. In addition, the design, development, and maintenance of a semantic network processing system requires an appropriate software engineering environment. The methodology of data abstraction, with its philosophy of modularity and independence of representations, provides this kind of environment. On the other hand, the definition of a semantic network as an abstract data type and its implementation using the methodology of data abstraction provide insights on the development of a new theory of abstract data types and the opportunity for testing and refining that theory. (Abstract shortened with permission of author.). In many interactive systems which provide information, such as HELP systems, the form and content of the information 382 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature of Individual User Characteristics DAI V47(09), SecB, pp3858. Cornelia Marie Yoder Syracuse University Ph.D. 1986, 383 pages Computer Science University Microfilms International ADG87--O1283 presented always seems to satisfy some people and frustrate others. Human Factors textbooks and manuals for interactive systems focus on the need for consistency and adherence to some standard. This implicitly assumes that if the optimum format and level of detail could be found for presenting information to a user, interactive systems would only need to adhere to the standard to be optimum for everyone. This approach neglects one of the most important factors of all-- differences in people. If these individualizing differences in people could be identified, a system could be designed with options built into it to accommodate different users. The role of the intelligent active system should be more like that of a human expert or consultant, who answers questions by first interpreting them in terms of the user's knowledge and the context of his activities and then recommending actions which may be otherwise unknown to the user.","The HELP system developed in this study is an Expert System written in PROLOG which uses logic programming rules to intelligently provide needed information to a terminal user. It responds to a request with a full screen display containing information determined by the request, the user's cognitive style, and the user's experience level. The investigation studies the relationship between some cognitive style and experience level parameters and individual preferences and efficacy with an interactive computer information system. These factors are measured by the ability of an individual user to perform unfamiliar tasks using a HELP function as information source. The format of the information provided by the HELP function is varied along three dimensions and the content of the information is varied by three levels of detail.","Experiments were performed with the system and experimental results are presented which show some trends relating cognitive style and individual preferences and performance using the system. In addition, it is argued that an Expert System can perform such a function effectively. JETR: A Robust Machine Translation System DAI V47(11), SecB, pp4586. Rika Au Yoshii University of California, Irvine Ph.D. 1986, 152 pages. Computer Science University Microfilms International ADG87-03940 This dissertation presents an expectation-based approach to Japanese-to-English translation which deals with grammatical as well as ungrammatical sentences and preserves the pragmatic, semantic and syntactic information contained in the source text. The approach is demonstrated by the JETR system, which is composed of the particle-driven analyzer, the simultaneous generator and the context analyzer. The particle-driven analyzer uses the forward expectation-refinement process to handle ungrammatical sentences in an elegant and efficient manner without relying on the presence of particles and verbs in the source text. To achieve extensibility and flexibility, ideas such as the detachment of control structure from the word level, and the combination of top-down and bottom-up processing have been incorporated. The simultaneous generator preserves the syntactic style of the source text without carrying syntactic information in the internal representation of the text. No source-language parse tree needs to be constructed for the generator. The context analyzer is able to provide contextual information to the other two components without fully understanding the text. JETR operates without pre-editing and post-editing, and without interacting with the user except in special cases involving unknown words. Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 383 The FINITE STRING Newsletter Abstracts of Current Literature Cognitive Processes in Written Translation DAI V47(11), SecA, pp4008."]},{"title":"Atef","paragraphs":["Faleh Youssef University of Houston Ed.D. 1986, 156 pages. Education, Language and Literature. University Microfilms International ADG87-00047 Understanding Digital System Specifications Written in Natural Language DAI V47(11), SecB, pp4609. John Joseph Granacki, Jr. University of Southern California Ph.D. 1986 Engineering, Electronics and Electrical University Microfilms International This item is not available: ADG05-59862. Due to the fact that the purposes of translation are so diverse, the texts are so different, and the receptors are so varied, a person who is familiar with translation difficulties can readily understand why many distinct principles of translation are included in the translation paradigm. Writers who have written on theories of translation agree that translators should know both the source and the receptor languages, should be familiar with the subject matter, and should have great facility of expression in the receptor language.","The many views expressed on translation theory in the past amount to a great deal of conflicting ideas. These ideas have yet to coalesce into a coherent theory of translation. This phenomena has led to a considerable methodological uncertainty as to what particular paradigm of research should be followed.","The purpose of this study was to explore the distinct principles and practices included in translation theory. Another purpose was an establishment of a better understanding of how the science of linguistics and human knowledge of language structures can be utilized in the process of translating. At the educational level, this study aimed at first, explaining the translation strategies, second, indicating their pedagogical implications.","Since the main purpose was to investigate theoretical concepts included in the translation paradigm, no effort was made towards formulating a complete coherent theory of translation. Instead special attention was given to the cognitive strategies that professional translators rely upon in the process of translating. These cognitive strategies were operationalized in a questionnaire format and eight professional translators were asked to state their awareness of the cognitive strategies. Since the cognitive strategies were initially derived from the theoretical requirements that the scholars regard as basic factors in any practical translation, it was hypothesized that the subjects would express an agreement to the cognitive items included in the questionnaire.","The significant aspects of the results obtained from this study lie in the fact that the cognitive strategies on which the theoreticians and the practitioners agreed can be utilized in (a) teaching translation theory and practice, (b) can be used as references in planning and designing a course in translation methodology, and (c) can indirectly contribute to a better understanding of the foreign language teaching and learning. (Abstract shortened with permission of author.). This thesis concerns itself with the specification of digital systems. The specific focus of the work described here has been on understanding system specifications written in natural language. The long term goals of the research are to provide methods and software to assure that the specifications are consistent, correct, and complete.","The research described here differs from previous research in several ways. First, the natural language input is used to construct an internal design representation, rather than just to query about existing design data. Second, using natural language allows a generality of expression not found in formal models. Finally, the natural language is not overly restricted.","A major part of the research described here involves formally modeling the information found in system specifications. An 384 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature extension of the USC Design Data Structure is described, with emphasis on timing and control flow. Then, this extension is used to model various concepts found in system specifications, such as unidirectional value transfers and temporal constraints. These models then provide a basis for the templates against which input specifications are matched.","A semantic parser, PHRAN, is used as the basis for the actual interface software. PHRAN contains a knowledge base of sentence patterns along with associated concepts. PHRAN inputs English sentences and looks for patterns in the sentences. When it finds a pattern match, the concept associated with the pattern is particularized with the information found in the sentence.","After PHRAN has parsed the input, the SPAN (SPecification ANalysis) package constructs fragments of the design data structure described above, and informs the user what design information has been found.","PHRAN-SPAN currently contains 13 concepts, 100+ nouns, and 25 verbs. It can handle ambiguity, nouns used as modifiers, and verbs used as nouns. It has processed a number of sentences which come from actual specifications. (Copies available exclusively from Micrographics Department, Doheny Library, USC, Los Angeles, CA 90089-0182.) Constraints on Gaps in Coordinate Structures DAI V47(11), SecA, pp4076. Carol B. Anderson The Pennsylvania State University Ph.D. 1986, 244 pages. Language, Linguistics University Microfilms International ADG87-05319 This thesis concerns the relationship between grammatical and extra-grammatical constraints on the distribution of gaps in coordinate structures. In a series of experiments subjects were asked to rate the acceptability of sentences such as those in (1), all of which contained relative clauses with coordinate complements. (1) a. That's the chair which Anne bought e and Harry threw e","out.","b. That's a movie which I liked e very much but e isn't","suitable for children.","c. That's the man who e tripped on a banana and everyone","laughed at e.","d. That's the boat which Harry bought e and everyone was","envious.","To determine the role of various factors in the acceptability of (1), three non-structural factors verb transitivity, reversibility of semantic arguments of the verb and the choice of conjunction (but vs. and) -- were systematically varied with four gap configurations: (1) symmetric (la) -- where both gaps are either matrix subjects, or non-matrix-subjects; (2) asymmetric (Ib) and (lc) -- where one gap is a matrix subject and the other is a non-matrix subject; and (3) CSC violations (ld) -- where there is a gap in only one conjunct.","The results indicated that speakers perceive a significant three-way distinction among the symmetric (la), asymmetric (lb)/(lc), and CSC violations (ld). The results also revealed that the acceptability of sentences with adjacent gap configurations (lc) was highly variable and that acceptability was significantly affected by all three of the non-structural variables examined. In addition, the results showed that in some cases, sentences with asymmetric gap configurations are not judged to be significantly different from similar sentences with symmetric configurations.","It is shown how these results do not support the predictions of a number of existing analyses of Across-the-Board Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 385 The FINITE STRING Newsletter Abstracts of Current Literature Categories and Relations in Syntax: The Clause-level Organization of Information DAI V47(09), SeeA, pp3410. William Albert Croft Stanford University Ph.D. 1986, 380 pages. Language, Linguistics University Microfilms International ADG87-O0739 Lexical Cohesion and Text-as-percept DAI V47(10), SecA, pp3749. Joseph Sherril Mattingly The University of Michigan Ph.D. 1986, 235 pages. Language, Linguistics University Microfilms International ADG87-02 789 dependencies which are based on structurally defined grammatical constraints on coordination (e.g., Pesetsky 1982, Goodall 1984, Gazdar et al. 1985).","An alternative analysis is proposed in which only CSC violations are excluded by the grammar. The proposed analysis assumes that the underlying structure for ATB dependencies with relative clauses is different from that of other ATB constructions such as constituent questions. It is shown how the acceptability contrast between symmetric and asymmetric configurations (e.g., (la) vs. (Ib) and (lc)) can be accounted for by extra-grammatical parsing principles. The major syntactic categories noun, verb and adjective and the (nonspatial) grammatical relations holding between a main verb and its dependent arguments represent the basic linguistic structures at the level of a single clause. However, they have resisted attempts to explain language structure in terms of language function. This dissertation proposes functional hypotheses which account for the basic linguistic structures in terms of the organization of the information to be expressed for the purpose of communication.","The empirical evidence consists of typological studies of the structure and linguistic behavior of the major syntactic categories and the casemarking of grammatical relations. Extensions to the theory of markedness permit the analysis of the major syntactic categories as NATURAL CORRELATIONS of commonsense semantic classes and basic discourse functions such as reference and predication. A commonsense model of causality provides the basis for the analysis of verbal semantics, subject and object, and a USAGE TYPE model of linguistic semantic categories accounts for typological patterns found in surface oblique case markers and voice types in terms of the causal model.","The typological evidence argues for the organization of a grammar into complex patterns of the applicability of rules rather than distinct autonomous syntactic levels, and for realization rules linking structure and function rather than derivational rules relating two structures by a purely structural operation. However, the realization rules cannot be completely direct due to typological variation in the linguistic expression of given situations. This is a study of lexical cohesion m cohesive relationships among meaning units -- perceived in English basic writing texts. Lexical cohesion is here considered to be the interfacing of the reader with the meaning units of the text, and is thus approached as \"process.\"","The study argues that we perceive cohesive ties among specific lexical items to be meaningful principally within the context of a greater wholeness of meaning. Several levels of semantic and lexical wholeness are identified within which cohesive specificities are interpreted, including generic semantic categories of \"problemness\" and \"solutionness\" in the texts, within which all specific reiterative and collocational ties may be interpreted.","The entire text is reinterpreted as a percept -- a diagrammatic visualization. Lexical cohesive features are given 386 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature spatial dimensions. The text-as-percept is a spatial metaphor through which we visually think about lexical and semantic complexities and simultaneities of cohesion. Correspondences between visual structures of the text-as-percept and linguistic features of lexical cohesion are considered non-arbitrary. Lexical redundancy is associated with verticality, lexical contrast with horizontality.","The study comes to conclusions concerning linguistic features of reiteration, collocation, lexical item, and the \"textual history\" of a lexical item. Reiterative and collocational relationships are of two types: textual and prior-textual. Textual cohesive relationships derive from the whole text unit in which they occur, and are interpretable within the generic semantic categories of that text. Prior-textual cohesive relationships occur within independent semantic sub-units whose semantic integrity derives from outside the text. The \"lexical item\" is considered to be a discoursal, clausal, and phrasal unit, as well as a single-word item. The \"textual history\" of an item is viewed as its cohesive behavior as a member of a unit in a larger system of lexical patterning in the text. An item's textual history influences its cohesion-forming potential in a subsequent, \"smaller\" level of lexical patterning in the same text. The Formal Semantics of Point of View DAI V47(09), SecA, pp3414. Jonathan Edward Mitchell University of Massachusetts Ph.D. 1986, 187 pages. Language, Linguistics University Microfilms International ADG87-O I 201 It has long been noted that propositional attitudes often involve a special mode of reference to oneself. The sentence (i) \"John thinks he won the raffle\" implies something different from (ii) \"John thinks that the person who holds ticket number 43 won the raffle\", even if John is in fact the holder of that ticket. If John has forgotten his number, (ii) might hold without (i) holding. Sentence (i) implies that John thinks \"I myself won,\" and the \"first person\" or \"self-ascriptive\" quality of such propositional attitudes is not captured in most model theoretic approaches to semantics. It has also long been noted that many property and relation expressions are used with implicit or surpressed argument positions, and that such expressions are interpreted perspectivally, i.e. relative to a point of view. These two phenomena interact, with the result that self-ascription is more pervasive in the language than is usually recognized. The sentence (iii) \"John thinks that restaurant is around the corner\" has a prominent interpretation according to which John thinks","in the special self-ascriptive way -- \"the restaurant is around the corner from here (from where I am now)\".","In the first chapter, self-ascription and perspectivity are explored, with attention to the ambiguities that arise from them. In the second chapter, an analysis of self-ascription is developed within the framework of situational semantics. It is proposed that there be assignments in parallel of two propositional contents to every propositional attitude. This elaboration in the semantics is shown to account for a wide range of complex cases, and to work recursively for multiply embedded propositional attitudes. Here an argument is offered that the restrictions on pronoun interpretation are grounded in variable binding and complex property formation rather than sameness and difference of reference. The third chapter explores the polyadicity issues raised by implicit arguments and point of view. An important claim of this section is that thematic relations should be incorporated into a formal semantics Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 387 The FINITE STRING Newsletter Abstracts of Current Literature Quantification in Syntax DAI V47(09), SecA, pp3415. Taisuke Nishigauchi University of Massachusetts Ph.D. 1986, 290 pages. Language, Linguistics University Microfilms International ADG87-O I 206 Sentence Processing and The Mental Representation of Verbs DAI V47(11), SecA, pp4076. Lewis Philip Shapiro Brandeis University Ph.D. 1987, 102 pages. Language, Linguistics, Psychology, Experimental University Microfilms International ADG87-05 786 approach. Finally, the fourth chapter brings all the proposals together into a formal fragment. The main concern of the present thesis is the nature of constructions which involve WH-phrases in natural language, mostly in Japanese and English. We will address the two questions about this type of construction: (i) What is the nature of the locality principle that governs the syntax and semantic interpretation of constructions involving WH-phrases? (ii) What is the quantificational force of the WH-phrase?","We will develop an analysis of WH-constructions in Japanese, where it is argued that a WH-phrase that occurs in an A-position in S-structure is moved to an A'-position in LF. We will discuss some superficial asymmetry that LF movement in Japanese exhibits with respect to the effects of the locality condition of Subjacency. While it obeys the WH-Island Condition effect, it appears to be free from the Complex NP Constraint (CNPC) effect: sentences which contain a WH-phrase within a complex NP at S-structure are generally grammatical.","We claim in chapter 2 that the WH-phrase in the problematic sentences does not move out of the complex NP, but it moves only within the relative clause. This triggers movement of the entire complex NP to the operator position of the main clause, thus no violation of the CNPC is involved. Chapter 3 will discuss the theoretical apparatus which substantiates the proposal in chapter 2.","As for the second question, we will discuss some sentences in Japanese and English where WH-phrases can be understood as behaving as the universal quantifier.","We argue, in chapters 4 and 5, that WH-phrases are devoid of semantic content and should be treated as 'variables' in the logical representation. The quantificational force of the WH-phrase is determined by a certain class of quantificational elements under certain structural conditions that hold with the WH-phrase that has undergone movement at LF.","Chapters 5 and 6 discuss problems raised by pronominal coindexing that holds between a pronoun and a WH-phrase with reference to the restrictions on Indirect Binding. This study seeks to determine the aspects of verb representations that are relevant to sentence processing, and to determine the operating characteristics of the devices that access information pertaining to verbs during the course of sentence comprehension.","The starting point for this inquiry involves two complimentary accounts of verb representation in the lexicon syntactic subcategorization and argument structure. These accounts are used to address the relation between representational and processing complexity. Verb categories are produced that diverge with respect to syntactic subcategorization complexity and argument structure complexity. Several experiments are then run using a cross-model lexical decision task (CMLD) that taps into the sentence comprehension system in the immediate temporal vicinity of the verb.~","The data generated by these experiments are used to make the following points: 1. The relevant processing complexity metric for verbs must be 388 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature defined in terms of the number of different argument structure arrangements a verb enters into, and not the number of syntactic configurations a verb can dominate as previously hypothesized in the literature;","2. Evidence from morphology and the data obtained in this study show that verbs are organized in the lexicon by their argument structure, and this is presumably why the lexical access device is tuned to argument structure information, and not syntactic subcategorization;","3. All argument structure entries are fair game for lexical access. They are exhaustively accessed and made available for further operations of the sentence processor, like parsing; and","4. Verb access is data-driven, modular, and contextually impenetrable: The access device is oblivious to the structural information contained in the sentence prior to the verb. The Semantics of Destructive LISP DAI V47(09), SecA, pp3449. lan Alistair Mason Stanford University Ph.D. 1986, 292 pages. Philosophy, Computer Science University Microfilms International ADG87-O0788 In this thesis we investigate various equivalence relations between expressions in first order LISP. This fragment of LISP includes the destructive operations rplaca and rplacd. To define the semantics we introduce the notion of a memory structure. The equivalence relations are then defined within this model theoretic framework.","A distinction is made between intensional relations and extensional relations. The former class turned out to have a much more managable theory than the latter. The principle intensional relation studied is strong isomorphism, its properties allow for elegant verification proofs in a style similar to that of pure Lisp. In particular the relation is preserved under many standard syntactic manipulations and transformations. In particular it satisfied a Substitution theorem; any program that is obtained from another by replacing a portion by another strongly isomorphic one is guaranteed to be strongly isomorphic to the original one.","A plethora of verification proofs of both simple and complex programs was given using the intensional equivalence relation. All of these proofs were of the transformation plus induction variety. In contrast, we gave some verification proofs of programs, using the extensional relations. Because the Substitution Theorem fails for these extensional relations, the proofs were necessarily of the hand simulation variety.","In a more theoretical light, we also proved that the equivalence relations introduced here are decidable, and used them to study the expressive powers of certain fragments of Lisp. An Analysis of Searle's Theory of The Intentionality of Speech Acts DAI V47(09), SecA, pp3450. Shashi Motilal State University of New York at Buffalo Ph.D. 1986, 159 pages. Philosophy University Microfilms International ADG86-29096 It is an indubitable fact that our thoughts are always about something or some state of affairs in the world. Again, it is true that we use language to express some of our thoughts, and that in such a use of language which philosophers call a speech act, language also comes to be about something or some state of affairs in the world. E.g., when someone asserts that Peter is married to Mary, the sentence, 'Peter is married to Mary', comes to be about the state of affairs of Peter's being married to Mary. This property of being about something which characterizes our thoughts and speech acts is called \"intentionality\" by philosophers.","In Intentionality, John Searle claims that the Intentionality of Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 389 The FINITE STRING Newsletter Abstracts of Current Literature Grammar and Information: An Investigation in Linguistic Metatheory DAI V47(10), SecA, pp3774. Thomas Alan Ryekman Columbia University Ph.D. 1986, 452 pages. Philosophy University Microfilms International ADG87-03076 language and the Intentionality of speech acts performed by using language is derived from the intrinsic Intentionality of mental states which accompany the speech act. In the dissertation I propose to examine this claim of Searle's.","Searle's view regarding the Intentionality of speech acts is incomplete and wrong. Searle does not show how the Intentionality of referring and predicating in a speech act is to be derived from mental reference and mental predication in the corresponding mental state. In this sense his theory is incomplete. Further, his theory is false. Taking the case of belief, I propose to show that it cannot be the source of the Intentionality of the corresponding assertion. Either a belief is a disposition and does not have any Intentionality or it is a mental act of accepting a proposition in which case the Intentionality of the belief and the Intentionality of the assertion have the same linguistic nature and the former cannot be the source of the latter. We are faced with a dilemma which shows that Searle's view cannot be correct. In the d~ssertation it will be argued that the Intentionality of a speech act is as intrinsic to it as the Intentionality of a mental phenomenon is to the mental phenomenon. The nature of speech act referring and predicating, mental referring and predicating, linguistic concepts and linguistic acts using those concepts will be discussed. This work examines the foundations of linguistic theory, with particular reference to the status and justification of grammars and theories of language structure. A metatheoretical critique of generative grammar is followed by epistemological motivation for, and presentation of, an alternative conception of language structure due to Harris, together with an approach to its justification. It is proposed that grammars have an informational validity as structures comprised of maximally unredundant equivalence classes whose members all demonstrably 'say the same' over a specified domain. Chapter 1 introduces the issues involved and summarizes the argument. In Chapter 2, the metatheoretical situation in American structural linguistics prior to the advent of generative grammar is reviewed. Among the findings are that familiar attributions to the central figures of this period of a goal of providing \"mechanical discovery procedures\" for grammars or of attempting to specify linguistic form without regard to meaning are groundless. Chapter 3 situates the first major work of generative grammar in respect to Quine's contemporary proposals for linguistic theory and finds wanting arguments advanced that linguistic form can be identified independently of considerations of meaning. Chapter 4 charts the evolution of generative grammar from a \"formal systems\" view of grammars and languages to recent proposals concerning \"core grammar\" and \"markedness\". It is argued that in pursuit of \"explanatory adequacy\" generative grammar has increasingly been distanced from the control of empirical evaluation, and that claims seeking a biological locus for abstract grammatical properties are unsubstantiated and problematic in themselves. Chapter 5 provides an epistemological critique of 'information' as employed by recent writers. Grammars -- as unredundant characterizations of combinations of linguistic elements that can occur -- are characterizations of information. Chapter 6 refers to a prior study presenting a ~grammar' of a sublanguage of cellular 390 Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 The FINITE STRING Newsletter Abstracts of Current Literature Reference and Intentionality DAI V47(11), SecA, pp4104. Nathan Tawil Princeton University Ph.D. 1987, 124 pages. Philosophy University Microfilms International ADG87-05016 immunology. It is shown both how and that a theory of language structure can be empirically validated by enabling the construction of formulas of information that compactly summarize and trace the findings and discussions in research reports of a science. This thesis is a consideration of some issues that arise in connection with theories of meaning developed along the lines suggested by H. P. Grice. I address three questions which, left unanswered, diminish the appeal of Grice's program. First, what should the Gricean say about word reference (as opposed to sentence meaning)? I argue in Chapter I that we can explain the role of word reference in sentence meaning only if we recognize, among the linguistic conventions observed by a community of speakers, a conventional compositional semantics for representing their language. Next, what should the Gricean say about understanding (as opposed to meaning)? Chapter II suggests a view of language-mastery that requires of speakers considerably less knowledge about the referents of expressions, particularly of predicates, than ~ome contemporary accounts. Finally, what should the Gricean say to skeptical arguments against the possibility of meaning or intentionality, of the sort recently advanced by Hilary Putnam and Saul Kripke? In chapter III, I argue that semantic theory has available at least three defensible responses to such arguments:","1. The defender of semantics can accept the skeptical conclusion and still talk about meaning","2. Espousing a theory according to which the content of mental states is determined in part by features of the world not intrinsic to the bearers of those states allows us to rebut the skeptical arguments successfully","3. The believer in meaning can plausibly maintain that facts about meaning or intentionality are primitive and unanalyzable. Computational Linguistics, Volume 13, Numbers 3-4, July-December 1987 391"]}]}