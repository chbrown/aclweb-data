{"sections":[{"title":"Incremental Translation Utilizing Constituent Boundary Patterns Osamu FURUSE, Hitoshi IIDA","paragraphs":["ATR Interpreting Telecommunications Research Laboratories 2-2 tlikaridai, Seika-cho, Soraku-gun, Kyoto, 619-02, Japan"]},{"title":"{furuse, iida}@itl.atr.co.jp Abstract","paragraphs":["We have proposed an incremental translation method in Transfer-Driven Machine Translation (TDMT). In this method, constituent boundary patterns are applied to an input in a bottom-up fashion. Also, by dealing with best-only substructures, the explosion of structural ambiguity is constrained and an efficient translation of a lengthy input can be achieved. Through preliminary experimentation our new TDMT has been shown to be more efficient while maintMning translation quality."]},{"title":"1 Introduction","paragraphs":["A system dealing with spoken language requires a quick response in order to provide smooth communication between humans or between a human and a computer. Thereibre, assuring efficiency in spoken-language translation is one of the most crucial tasks in devising such a system. In spoken language, the translation of lengthy utterances can yield a huge amount of structural ambiguity, which needs to be efficiently processed by the system. As a solution for achieving an efficient spoken-language system, several techniques, such as incremental generation (Finkler, 1992; Kempen, 1987) and marker-passing memory-based translation (Kitano, 1994), have been proposed. Many of these techniques adopt a left-to-right strategy to handle an input incrementally and a best-first strategy to avoid the explosion of structural ambiguity. These strategies (:an be achieved with bottom-up processing.","We have already proposed Transfer-Driven Machine Translation (TDMT) for efficient and robust spoken-language translation (Furuse, 1994a; Furuse, 1994b). However, the top-down and breadth-first translation strategy in the earlier versions of TDMT, which yields a quick response for inputs with restricted lengths, may show poor efficiency when processing a very lengthy input or inputs having many competing structures.","In a top-down and breadth-first application, all the possible structures are retained until the whole input string is parsed. This requires many computations and results in inefficient translation. For instance, the sentence below has many competing structures, mainly because of possible combinations within noun sequences. If this expression is combined with another expression, the structurM ambiguity will be further compounded.","With bacon chicken eggs lettuce and tomato on it.","In contrast, if structural ambiguities of substrings are always settled and are never inherited to the upper structures, the explosion of structurM ambiguity could be constrained. Thus, an incremental strategy that fixes partial results is necessary for efficient processing and is achieved by bottom-up processing in left-to-right order.","This paper proposes TDMT using an incremental strategy for achieving efficient translation of a lengthy input or one having a lot of structural ambiguity. In this method, several constituent boundary patterns are applied to an input string in a bottom-up fashion. This bottom-up application, based on the concept of chart parsing, can constrain the explosion of structural ambiguity by dealing with best-only substructures using semantic distance calculations.","In this paper, we will first; outline our new translation strategy. We will then explain how constituent boundary patterns can be used to describe the structure of an input string in TDMT. Then we will describe the bottom-up pattern application, based on chart parsing. Next, we will show how the explosion of structural ambiguity is constrained by dealing with the best-only substructures, based on semantic distance calculations. By comparing the preliminary experimental results from the former top-down method and those from our new method, we will demonstrate the usefulness of our new method. A summary of our approach will conclude the paper."]},{"title":"2 Translation strategy","paragraphs":["In TDMT, translation is performed by applying stored empirical transfer knowledge, which de-412 scribes the correspondence between source language expressions and target language expressions at various linguistic levels. The source and target expressions of tile transfer knowledge in TDMT arc ext)ressed by constituent boundary patterns, which represent meaningful units for linguistic structure and transfer. An efficient application of transfer knowledge source parts to an input string plays a key role in achieving quick translation.","The procedure R)r applying constituent boundary patterns is perfomed after the assignment of morphological information to each word of an input string, and is as follows: (a) Insertion of constituent boundary marker; (b) 1)eriw~tion of possible structures;","(e) Structural disambiguation 1)y semantic dislance calculation.","In the top-down and breadth-tirst pattern application, the above procedure is executed in the described order. Because the selection of the best structure might have to be postponed until all possible structm'es are derived, the costs of translation could be high.","In contrast, the incremental method determines the best structure locally and (-an constrain the number of competing structures fbr the whole input by performing (b) in l)arallel with (c); consequently, translation costs are reduced.","The structure selected in (c) (:ontains its transt~rred result and head word infbrination, which is used for semantic distance calculation when combining with other structures. The output sentence is generated as a translation result Dora the structure for the whole inl)ut, which is composed of best-first substructures.","In the three subsequent sections, we will explain (a), (b), and (c), focusing on the bottoir>up and best-first translation strategy."]},{"title":"3 Constituent boundary pattern","paragraphs":["In this section we will briefly explain how constituent boundary patterns are used to describe the structure of an int)ut string in TI)MT and what procedures arc applied before constituent boundary pattern applications (Furuse, 1994b).","We will show bottom-up pattern application by translating the following sample English sentence into Japanese:","Thc bus goes to Chinatown at ten a.m. First, all the words in this sequence are assigned","the following parts-of-speech. article, noun, verb, preposition, proper-noun,","preposition, numeral, postnominal","A constituent boundary pattern is defined as a sequence that; consists of variables and symbols representing constituent boundaries. A variable corresponds to some linguistic constituent and is expressed as a capital letter (e.g. X). A constituent boundary is expressed by either a functional word or a part-of-speech bigram marker (e.g. noun-verb). Variables in tile source language expression must be separated by constituent boundaries.","For instance, the expression \"goes to Chinatown\" is divided into two constituents, i.e. \"goes\" and \"Chinalown\". The preposition \"1o\" can be identified as a constituent boundary. Therefor(;, in parsing \"goes to Chinatown\", we use the pattern \"X to Y', which has two variables X and Y and a constituent boundary \"to\".","'l'he expression \"the b~zs goes\" can be divided into two constituents \"the bud' and \"goes\". Howeve.r, there is no flmctional surface word that divides the expression into two constituents. In such ('ases, we emt)loy part-of-speech bigrams as boundary markers. \"bus\" and \"goes\" are a noun and a verb, respectively. Thus the marker noun-verb can be inserted as a boundary marker into the input \"the bus goes\", giving \"The bus noun-verb goes\". This sequence will now match tile general transfer knowledge pattern \"X noun-verb Y\".","Of the possible bigrams in the above part-of~ speech sequence, only \"noun-verb\" is an eligible constituent boundary marker (Fro:use, 1994b). This marker is inserted into the above sentence: The bus noun-verb goes to Chinatown at ten a.m.","Indices to possible patterns are obtained from several words and bigrams in the above m~rker-inserted string (Table 1). Table 1 : Retrieved patterns word th c 7~o?tn-vcrb to at retrieved pattern (linguistic level) the X ((:ompound noun) X noun-verb Y (simple sentence) X to Y (verb phrase, noun phrase) X at Y (verb phrase, noun phrase) X a.ra. (compound noun)","The procedure ext)lained so far is the part that; the top-down and bot;tom-up pattern application methods have in common."]},{"title":"4 Incremental pattern application","paragraphs":["In this section, we will show the application of constituent boundary patterns based on the concept of bottom-up chart parsing. 4.1 Linguistic level In order to limit the combinations of patterns during pattern application, we distinguish pattern levels and for each linguistic level, we specify the linguistic sublevels which are permitted to be used in the assigned variables.","Table 2 shows examples of the relationships between linguistic levels. A variable on a given level 413 is instantiated by a string on the lingustic levels in the second column of Table 2. For instance, in the noun phrase \"X of F', the variables X and Y cannot be instantiated by a simple sentence, but can be instatiated by a noun phrase, a compound noun, and so on. Table 2: Possible linguistic sublevels in variables linguistic level sublevels of variables simple sentence VP, NP, ... verb phrase (VP) VP, NP, verb, ... noun phrase (NP) NP, CN, proper-noun .... compound noun (CN) CN, noun,...","According to the regulation of the linguistic levels' relations shown in Table 2, a marker-inserted string is parsed using the constituent boundary patterns. 4.2 Active and passive arcs A chart parsing method (Kay, 1980) can avoid repeatedly recomputing partial results and achieve incremental processing by using a bottom-up and left-to-right strategy. In chart parsing, an input string is parsed by combining active and passive arcs. These can be assigned to a substring of an input string when a pattern is applied to it. If all the variables of the applied pattern are instantiated or a substring can be matched to a pattern whose variables are all instantiated, a passive arc is created for the substring. When a substring can be matched to the left part of a pattern and the right variables of the pattern are not instatiated, an active arc is created for the substring.","In conventional chart parsing, many arcs can be created because every word can create active and passive arcs based on its part-of-speech. Also, many arcs can be chained via non-terminal symbols such as a part-of-speech and NP (noun phrase). For instance, the pronoun, \"f' can create many active arcs relevant to the rules \"Pronoun","1\", \"NP ~ Pronoun\" and \"S --+ NP VP\", which can be chained. Therefore, a lot of computation is required in conventional chart parsing.","In contrast, chart parsing with constituent boundary patterns can constrain the number of arc creations because only an constituent boundary creates active arcs while a variable (e.g. X) never creates an arc. We obtain indices to patterns from each word of the sentence. With these indices, patterns are retrieved and checked to determine whether each of them can create an arc. 4.3 Pattern application algorithm Our algorithm for bottom-up application of patterns is as follows. If the whole input string can be covered with a passive arc, the parsing will succeed and the derivation of the passive arc will be the parsed result.","1. If the processed string is a content word (e.g. noun, verb) create a passive arc.","2. If the processed string is a constituent boundary \"a\", create each kind of arc as follows, according to the pattern I retrieved from the constituent boundary.","2a. If the retrieved pattern is of the type \"X a Y\" and a left-neighboring passive arc can satisfy the condition for X's instantiation, create an active arc for \"X a F', in which Y has not yet been instantiated.","2b. If the retrieved pattern is of the type \"X a\" and a left-neighboring passive arc can satisfy the condition for X's instantiation, create a passive are for \"X a\".","2c. If the retrieved pattern is of the type \"a ~', create an active arc for \"a ~'.","3. If the created passive arc satisfies the leftmost part of an uninstantiated variable in the pattern of neighboring active arcs, the variable is instantiated with the passive arc, and a new passive or active arc is created. If a passive arc is generated in this operation, repeat the procedure until a new arc can no longer be created.","Figure 1 shows how an input string is parsed using our bottom-up chart method. A solid line denotes a passive arc that covers a substring of the input below, while a dotted line denotes an active arc.","The content words \"bus\", \"goes\", \"Chinatown\" and \"ten\" create passive arcs. The functional word \"the\", which is relevant to the pattern \"a X\", creates an active arc. The assignment of the functional word \"a.m.\" to the pattern \"X a\" creates a passive arc by combining another passive arc. The boundary markers \"noun-verb\", \"to\" and \"at\", which are relevant to the pattern \"X a Y\", create active arcs by combining left-neighboring passive arcs.","First \"the\" creates the active arc (1) relevant to the pattern \"the X\". \"bug' creates the passive arc (2). The passive arc (3) is created by combining"]},{"title":"(1) and (2). \"noun-verb\" creates the active arc","paragraphs":["(4), whereby the variable X of \"X noun-verb F' is matched against (3). \"bus\" creates the passive are (5), and the passive arc (6) is created by combining (4) and (5). \"to\" creates the active are (7), whereby the variable X of \"X to ~' at verb phrase is matched against (5).","1There are other types of patterns, such as \"X a Y fl ~', where ce and /3 are constituent boundaries. They can be easily processed by slightly extending the algorithm. 414"]},{"title":"(20)","paragraphs":["(16) .............................."]},{"title":"(12)","paragraphs":["................. (11)"]},{"title":"(lO)","paragraphs":["........... (7)"]},{"title":"(6) .................... (4)","paragraphs":["the bus noun-verb goes"]},{"title":"(9) 18)","paragraphs":["to Chinatown at ten (15)"]},{"title":"(14)","paragraphs":["Figure 1: Chart diagram (19)"]},{"title":"(18)","paragraphs":["(1~) a.n2.","We continue the procedure incrementally. When the rightmost word has been processed, the derivation of the passive arc of the whole input gives the parsed result, in our example the derived process of the passive arc (20), which is the combination of (4) and (19). 5 Preference of substructure The passive arc (19), which is relevant to \"goes to Chinatown at ten a.m.\", h~ two competing rcsuits. One is the combination of (7) and (18), where \"X at F' is a noun phrase. The other is the combination of' (12) and (17), where \"X at 1(\"' is a verb phrase. Thus, (19) has two possible structures by the application of \"X at F'. \"X to F' at the verb phrase level and \"X a.m.\" at the compound noun level are also applied.","The technique for obtaining substructure preference is the determination of the best substructure when a relative passive arc is created. Only the best substructure can be retained and combined with other arcs. 5.1 Semantic distance The most appropriate st~ructure is selected by computing tile total sum of all possible combinations of partial semantic distance values. The structure with the least total distmme is judged most consistent with empirical knowledge and is chosen as the most plausible structure.","The semantic distance between words is calculated according to the relationship of tim positions of words' semantic attributes in the thesaurus. The distance between expressions is the sum of the distance between the words comprising the expressions, multiplied by some weights (Sumita, 1992). 5.2 Head word information The head words within variable bindings serve as input for distance calculations. An input for distance calculation consists of head words in variable parts. The head part is designated in each pattern. Table 3 shows the head parts of the possible substructures for \"goes to Chinatown at ten a.m.\", which corresponds to the passive arc (19). Table 3: Ilead words for (19)'s substructures passive matched designated head","arc pattern head word (9),(19) X to Y X goes"]},{"title":"(17)","paragraphs":["X a.m. a.m. a.m."]},{"title":"(18)","paragraphs":["X at Y X Chinatown (19) X at Y X goes","In \"X at F' for the substring \"goes to Chinatown at ten a.m\" combined with (12) and (17), the variables X and Y are substituted for the compound expressions \"goes to Chinatown\" and \"ten a.m.\", respectively. Thus, in \"X at Y\" for the structure in (19), the input for distance calculation is \"goes\" for \"3;\"' and \"a.m.\" for \"Y\". Since the head of \"X at Y\" is designated as \"X', \"goes\" becomes the [lead word for (19). This information is used when (19) is combined with another substring. 5.3 Structure selection The difference in total distance value between the two possible structures is due only to the distance value of \"X at F'. Table 4 shows the results of the distance calculation in \"X at Y\" for the combination of (7) and (18), and for that of (12) and (17). (goes, a.m.) expresses the bindings for variables X 415 and Y, where X =\"goeg', and Y =\"a.m.\". \"X'\" is the target expression corresponding to \"~'. Table 4: Distance calculation in \"X at F' level input closest example target distance"]},{"title":"(7)+(18) 02)+07)","paragraphs":["noun phrase verb phrase","(Chinatown, a.m.) (goes, a.m.) (morning, a.m.) (depart, a.m.)","V no X' V ni X'","0.50 0.21","According to the distance calculation in the combination of (7) and (18), \"I/' no 3;'\", with the distance value 0.50, is selected as a target expression. In the combination of (12) and (17), \"Y' ni X'\" with the distance value 0.21 is selected as a target expression."]},{"title":"Thus,","paragraphs":["the combination of (12) and (17) is selected as the structure of the passive arc (19). Based on the results of distance cab culations, other partial source patterns for (19), \"X to Y\" and \"X a.m\", are transferred to \"Y' ni 3('\" with the distance value 0.12, and \"gozen X ~ jt' with the distance value 0.00. Thus, the passive arc (19) has its source and target structure through the combination of (12) and (17), the total distance value 0.33, and the head word \"goes\".","Then, the structure of the whole input string, which corresponds to (20), is constructed by combining (19) with (4). In this combination, \"X noun-verb Y' matches the input string and is transferred to \"X' wa Y'\" based on the result of distance calulation. From the combined structure for (20), the sentence below is generated after adjustment necessary for Japanese grammar. The words \"bus\", \"goes\", and \"Chinalown\" are transferred to \"basu\", \"iku\", and \"Chainalaun ''2, respectively.","Basu wa gozen i0 ji ni Chainataun ni iki masu","\"ik~\" is the conjugated form of \"iku\" followed by masu, a polite sentential-final form. 6 Preliminary Experiment In this section, we perform Fmglish-to-Japanese translation to compare the efficiency of the top-down pattern application with that of our new method, based on the bottom-up application and substructure preference in the TDMT prototype system. 6.1 TDMT prototype system The TDMT prototype system, whose domain is travel conversations, is designed to achieve","2The prototype system assigns a default target expression to a surface source expression. Another target expression is selected when a specific example in the transfer knowledge is closest to the input. multi-lingual spoken-language translation (Furuse, 1995). While language-oriented modules, such as morphological analysis and generation, are provided to treat multi-lingual translation, the transfer module, which is a central component, is a common part of the translation system for every language pair. The system is written in LISP and runs on a UNIX machine. Presently, the prototype system can translate bilingually between Japanese and English and between Japanese and Korean. In English-to-Japanese translation, the present vocabulary size is about 3,000 words 3 and the number of training sentences is about 2,000. 6.2 Experimental results We have compared translation times in the TDMT prototype system for two cases. One case utilizes top-down application; the other case utilizes the new application method presented in this paper, which adopts bottom-up pattern application and retains only one substructure using semantic distance calculation. The translation times are measured using a Spare10 workstation.","We have experimented with the translation times of some English sentences into Japanese. The following sentences cause only minor structural ambiguity. Note that a comma is not used in the input sentence, because it is assumed to be a spoken-language input such as the output of speech recognition. (1) 1 have a reservation for tomorrow. (2) Will my laundry be ready by tomorrow? (3) You can walk there in about three minutes. (4) Then may I have your credit card number please?","Table 5 shows the translation time of the above sentences. For these translations, not much difference could be seen between the new bottom-up method and the top-down method. For such inputs TDMT can quickly produce the same translation results with either method. 'Fable 5: 'Danslation time for short sentences input sentence"]},{"title":"(1) (2) (3) (4) #","paragraphs":["of translation time (see)","structures top~ new ~-- 2 0.18 0.17 4 0.17 0.20 4 0.38 0.35 11 0.85 0.70","The following sentences cause much structural ambiguity because of PP-attaehment, relative clauses, conjunctions, etc.","3In the Japanese-to-English translation system, the present vocabulary size is about 5,000 words."]},{"title":"416","paragraphs":["(5) 7'his sales clerk doesn't understand anything 1 say and i'm wondering if you wouhl help me explain what [ want.","(6) Could I please have your name the date of arrival and the number"]},{"title":"of","paragraphs":["persons in your party?","(7) 7bll somcone at the, fl'ont desk what game you want to scc and what type of seat you want and they'll get the tickets for you.","(8) I h,fl somc laundry to be cleaned bul I can't remember where the clcaners is and I was wondering if you could help me.","Table 6 shows the translation time of the above sentences, hi the above translations the same translation results could again be obtained for both methods, llowever the new method can achieve a far more efficient translation than the tol> down metho(t. Table 6: 'l'ranslation time for long sentences it, p U L S(!ll ~oell C(]"]},{"title":"(0) (r) (8)","paragraphs":["[~ translation ti,ne"]},{"title":"] ! 4.oa / / 2.at / 1 le,.to ~.~7_ 3 #","paragraphs":["of","sLrlI(:L ures 312 442 544 696","Average tramslation times in the top-down method were 1.15 seconds for a 10-word input and 10.87 seconds for a 20-word input. Average translation times in the bottom-up method were 0.55 se(:onds for a 10-word input and 2.04 seconds for a 20-word inl)ut. The translation time in the top-down method is considere, d to t)e (:h)sely relate(l to the nnmber of possibh~ stru(;tures, while l,he translation time in our new method is not direcdy retle(-ted by this number. The inc.rease in the. number of substructures retained will, the. new method is much smaller than that of the number of possible structures in the top-down method. Therefore, our new method can efficiently translate a longer input string having many (-ompeting structures.","Also, we have performed a small translation-quality experiment on the two pattern application methods with the 95 untrained sentences within the system's vocabulary. Both the tOl)-down method and the proposed bottom-up method gave the correct translation [br the same 60 sentences with a success rate of 63.2%. ~'o,. only two sentences, difl>rent structures we.re produced by the two methods; however, all of them were incorrect translations. This experimental result shows that our new translation strategy maintains translation quMity."]},{"title":"Similar results,","paragraphs":["which show the llSe~llhlesS of the new TI)MT tbr spokenJanguage translation, were obtained in other tyl)es of translation such as Jal)anese-to-English (or,-Korean) translation. 7 Conclusion We have proposed an increlnental translation method in Transfer-Driven Machine 'lYanslation (TI)MT). in this method, constituent boundary patterns are applied to an input it, a bottom-up and left-to-right fhshion. Additionally, by dealing with best-only substructures, the explosion of structural ambiguity is constrained and eflq(-icnt translation of ~ lengthy input can be achieved. Through preliminary exl)erimentation , our new TI)MT has b('~e.n shown to be efficient and particularly promising for spokendangnage translation.","One important future research goal is tile in- ('orporation of incremental n.orphologieal analysis and generation into the prot)osed translation"]},{"title":"strategy,","paragraphs":["which would provide a sinmltaneous in-terpretation mechanism tbr N)plication to a t)ra('- ti('al spoken-lm,guage translation system. Also important is the introduction of a repair mechanism to correct the I)est-first results. References","W. Finkler and A. S('hauder 1992. FAfects of In. (-remental ()utl)ut on lncrementM Natural ],an guage (~eneration. In IOlh I,]uropean ConferÂ° enee on Artificial Intelligence, [)ages 505- 507, Vienna, Austria.","O. l\"uruse, l\",. Sull'lita, and H. [ida. 1994a. 'l'ransfi:r--Driven Machine 'lYansladon Utilizing l,~mpirical Knowledge (in Japanese). 7'rans~ actions of lnformahon Processing Sot,c@ of Japan, Vol. 35, No. 3, pages 414 425.","O. Furuse, and il. ]ida. 1994b. Constituent Ik)undary Parsing for lCxample-llased Ma('hine Translation. In l)roe. 4 Uoling '9~, pages 105 III.","O. li'uruse, J. Kawai, H. Iida, S. Akamine, and I).B. Kim. 1995. Multi-lingual Spokem l,anguage Translation Utilizing Translation Examples. In Prec. of NLPRS'95, pages 544 549.","M. Kay. 1980. Algorithm Schemata and Data Structures in Syntactic Processing. 7>chnical Report USL-80-1~2, XI~;ROX Pale Alto Research Center.","C. Kempen and l']. lh)enkamt). 1987. An ]n('remental l~rocedural GraHunar for Sentence For-mulation. Co.qnitivc Science, 2(11): pages 20:l 258.","il. Kitano. :1994. The g<DMDIALOG System. In Speech-2b-Spcech 75\"anslation, 11. Kitano, Kluwer Academic Publishers, pages 47 113.","lie Sumita and 1t. 1ida. 1992. Example-Based Transfer of Japanese Adnominal Particles into English. IEICIs' 7'ransaclions on Information and Syslems, F75-1), No.4, pages 585 594. 417"]}]}