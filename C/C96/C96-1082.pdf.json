{"sections":[{"title":"Research on Architectures for Integrated Speech/Language Systems in Verbmobil Gfinther GSrz~ Marcus Kesseler, JSrg Spilker, Hans Weber University of Erbmgen-Nfirnberg IMMD (Computer Science) VIII --- Artificial Inl0elligence Am Weichselgarten 9 D-91058 ERLAN(]EN Emaih {goerz, kesseler, spilker, weber}Oinformat ik. uni-erl angen, de Abstract","paragraphs":["The German joint research project Verbmobil (VM) aims at the deveh)pment of a speech to speech translation system. This paper reports on research done in our group which belongs to Verbmobil's subprojeet on system architectures (TP15). Our specific research areas are the construction of parsers for spontaneous speech, investigations in the parallelization of parsing and to contribute to the development of a flexible communication architecture with distributed control."]},{"title":"1 Introduction","paragraphs":["The German joint research project Verbmobil (VM) 1 aims at the development of a speech to speech translation system. This paper reports on research done in our group which belongs to Vcrbmobil's subproject on system architectures (TP15). The task of this subproject is to provide basic research results on incremental and interactive system architectures for the VM research prototype and to demonstrate their feasibility in the prototypical INTARC system. Our specific research areas are the construction of parsers for spontaneous speech, investigations in the parallelization of parsing and to contribute to the development of a flexible communication architecture with distributed control. The paper is or-ganized as follows: Section 2 reports on the design and implementation of an incremental interactive speech parser which integrates statistics","i","1This work was flmded by the German Federal Mirfistry for Researdl and Tedmology (BMFT) in the framework of the Verbmobil Project under Grant BMFT 01 IV 101 H / 9. The responsibility for the contents of this study lies with the authors. with a chart-parser einploying a unification grammar (UG) formalism. Furthermore, results of experiments on the interaction between the parser and a speech recognizer using expectations, are reported. In section 3 we present experiences with a parallel version of the parser. Section 4 deals with distributed control in modular Natural Language/Speech (NLSP) systems."]},{"title":"2 Design and Implementation of Incremental Interactive Speech Parsers","paragraphs":["In a Left Right Incremental architecture (LRI), higher level modules can work in parallel with lower level modules. The obvious benefits of such an arrangement are twofold: The system does not have to wait for a speaker to stop talking and top-down constraints from higher level to lower level modules can be used easily. 'lb achieve LR! behavior the singular modules must fulfil] the following requirements:","Processing proceeds incrementally along the time axis (\"left to right\").","Pieces of output have to be transferred to the next module as soon as possible.","So far in INTARC-1.3 we have achieved an LRI style coupling of ibur different modules: Word recognition module, syntactic parser, semantic module and prosodic boundary module. Our word recognition module is a modified Viterbi decoder, where two changes in the algorithm design were made: We use only the forward search pass, and whenever a final ttMM state is reached for an active word model, a corresponding word hypothesis is sent to the parser. Itence backward search be-comes a part of the parsing algorithm. The LRI parsing algorithm is a modified active chart parser with an agenda driven control mechanism. The chart vertices correspond to the .frames of the signal representation. Edges correspond to Word or phrase hypotheses, being partial in the case of ac-484 tive edges. A parsing cycle corresponds to a new time point related to the utterance, in every cycle a new vertex is created and new word hypotheses ending at that time point are read and inserted into the chart. In one cycle, a ba(:kwar(| search is performed to the beginning of the utterance or to some designated time point in the past con~ stitnting a starting point for grammatical analysis. Search is guided by a weighted linear combination of acoustic score, bigram score, prosody score, grammar derivation seore and grammatical parsability. The search prodecure is a beam search implemented as an agenda access mechanism. The grammar is a probabilistic typed UG with separate rules for pauses and other spontanous speech"]},{"title":"phelnonmua. 2.1","paragraphs":["Basic Objects In the h)llowing we use record notation to refer to subcoml)oncnts of an object. A chart vertex Vt corresponds to frame number t. Vertices have four lists with pointers to edges ending in and starting in thai; vertex: inactive-out, inactive~ in, active-out and active-out. A word hypothesis W is a quadruple (from, to, key, score) with J}vm and to being the start and end frames of W. W.Key is the name of the lexical entry of W and W.score is the acoustic score of W for the frames spanned, given by a corresponding HMM acoustic word model. An edge i',' consists of flora, the start vertex and to, a list of end vertices. Note that after a Viterbi forward pass identical word hypotheses do always come in sequence, differing only in ending time. E.actual is the last vertex added to t£to in an operation. Those \"families\" of hypotheses are represented as one edge with a set of end vertices. E.words keeps the covered string of word hypotheses while SCORE is a record keeping score components. Besides that an edge consists of a grammar rule E.rule and F,.next, a pointer to some element of the right hand side of l£rule or NIL. As in standard active chart parsing an edge is passive, if E.ncxt = nil, otherwise it is active. E.eat points to the left hand side of the grammar rule. SCORE is a record with entries for inside and outside probabilities given to an edge by acoustic, bigram, prosody and grammar model:","Inside-X Model scores for the spanned portion of an edge.","Outside-X Optimistic estimates for the portion fi'om vertex 0 to the beginning of an edge. For every vertex we keep a best first store of scored edge pairs. We (:all that store Agenda/ in cycle i. 2.2 Basic Operations 'I'here are tive basic operations to detine the operations of the parsing algorithm. The two operations Combine and Seek Down are similar to the well known Earley algorithm operations Completer arm Predictor. Furthermore, there are two operations to insert new word hypotheses, Insert and Inherit. All these operations can create new edges, so operations to calculate new scores from old ones are attached to them. hi order to implement our t)eam search method appropriately but sinq)ly, we define an operation Agenda-Pu~q~ , which selects pairs of active and passive edges to be prmn;d or to be processed in the future. The","Ct (, notation for l)asic operations are given in -' ,' ' simplicity. 2.2.1 Combine","For a t)air of active and passive edges (A, l), if A.next = I.cat and Lfivm ~ A.to, insert edge ti with l','.rule - A.rule, E.cat :-- A.eat, E.nexl --: shifl(A.uext), l£fl~)m.-= A.fl'o,n, l£to = A.to. For X = Bigram, Grammar and Prosody: t£Outside-X = A.Outside-X + I.lnside-X + 7'tans(X, A, 1) l£ lnsidc-X = A.lnside-X 4- 1.1nside-X 4-7'rans(X,A,1) I\"or X =","Acoustic: E. Outside-X = A. Oulside-X[l.from] @ L lnsi&'- X \"Frans(X,A, I) l£1nsidc-X = A.lnsidc-X[1.flvm] (t) LInside-X Trans(X,A,l) 'l)he operator ct) performs an addition o[a nun> her to every element of a set. Trans(X,A,l) is the specilic transition penalty a model will give to two edges. In the ctLse of acoustic scores, the penMty is always zero and can be neglected. In the. bigram c~use it will be the transition from the last word covered by A to the tirst word covered by B. 2.2.2 Seek Down","Whenever an active edge A is inserted, insert an edge E for every rule 1~ such that A.next - E.cat, I','. rule = If, F,.flvm - A. actual, t3. to = {A. actual} • For X --- Acoustic, Prosody and l)igraln: E.lnside-X = 0 I£ Outside-X = A. Outside-X For X == Grammar: 1£ lnside-X = grammar score of II l£Outside-X = A.Outside-X + 7~rans(X,A,l';) + I~.inside-X. This reeursive operation of introduc-ing new active edges is precompiled in our parser and extremely etlicient. 485 2.2.3 Insert","For a new word hypothesis W = (a,i, key, score) such that no W' = (a,i-i,key, score') exists, insert an edge E with E.rule = lex(key), E.cat = lex(key), E.from = Va, E.to = {~} and for X = Acoustic: E.Inside-X = E. Outside-X = { (i, score)}, for X = Prosody and Bigram: E.Inside-X = E.Outside-X = O, for X = Grammar E.Inside-X = E.Outside-X = grammar score of lex(keg). 2.2.4 Inherit","For a new word hypothesis W = (a,i, key, score) such that a W' = (a,i-l,key, score') exists: For all E in Vi_l.inactive-in or Vi_l.active-in: If last(E.words) = key then add {~} to E.to, add (i,E.Inside-Acoustic[i-l]- score' + score) to E.Inside-Acoustic and add (i,E.Outside-Acoustic[i-I]- score' + score) to E.Outside-Acoustic. If E is active, perform a Seek-Down on E in ~. 2.2.5 Agenda Push","Whenever an edge E is inserted into the chart, if E is active then for all passive A, such that A.from 6 E.to and combined-seore(E,A) > Beam-Value, insert (E,A, combined-score(E,A )) into the actual agenda. If E is passive then for all active A, such that E.f~vm 6 A.to and combined-score(A,E) > Beam- Value, insert (A,E, combined-score(A, E)) into the actual agenda. Combined-Score is a linear combination of the outside components of an edge C which would be created by A and E in a Combine operation. Beam-Value is calculated as a fixed offset from the maximum Combined-Score on an agenda. Since we process best-first inside the beam, the maximum is known when the first triple is inserted into an agenda. Agenda-Pop will remove the best triple from an actual agenda and return it. 2.3 A simple LRI lattice parser The follwing control loop implements a simple LRI lattice parser. 1. T = 0. Create VT","2. Insert initial active edge E into VT, with E.next = S 3. Increment T. Create VT","4. For every W with W.end = 7': Insert(W) or Inherit(W) 5. Until Agenda[T] is empty: (a) Combine(Agenda-Pop) (b) When combination with initial edge is","successful, send result to SEMANTICS 6. Communicate with PROSODY and go to 3 2.4 The Grammar Model The UG used in our experiments consists of 700 lexical entries and 60 rules. We used a variant of inside-outside training to estimate a model of UG derivations. It is a rule bigram model similar to PCFG with special extensions for UG type operations. The probability of future unifications is made dependent from the result type of earlier unifications. The model is described in more detail in (Weber 1994a; Weber 1995); it is very similar to (Brew 1995). 2.5 LRI Coupling with Prosody In INTARC we use three classes of boundaries, B0 (no boundary), B2 (phrase boundary), B3 (sentence boundary) and B9 (real break). The prosody module, developed at the University of Bonn, classifies time intervals according to these classes. A prosody hypothesis consists of a beginning and ending time and model probabilities for the boundary types which sum up to one. A prosodic transition penalty used in the Combine operation was taken to be the score of the best combination of bottom-up boundary hypothesis Bx and a trigram score (lword, Bx, rword). Here lword is the last word of the edge to the left and rword is the first word spanned by the edge to the right. Prosody hypotheses are consumed by the parser in every cycle and represented as attributes of vertices which fall inside a prosodic time interval. In a couple of tests we already achieved a reduction of edges of about 10% without change in recognition rate using a very simple trigram with only five word categories. 2.6 Experimental Results In a system like INTARC-1.3, the analysis tree is of much higher importance than the recovered string; for the goal of speech translation an adequate semantic representation for a string with word errors is more important than a good string with a wrong reading. The grammar scores have only indirect influence on the string; their main function is picking the right tree. We cannot measure something like a \"tree recognition rate\" or \"rule accuracy\", because there is no treebank for our grammar. The word accuracy results cannot be compared to word accuracy as usually applied to an acoustic decoder in isolation. We counted only those words as recognized which could be 486 built into a valid parse from the beginning of the utterance. Words to the right which could not be integrated into a parse, were counted as deletions --- although they might have been correct in standard word accuracy terms. This evaluation method is much harder than standard word accuracy, but it appears to be a good approximation to \"rule accuracy\". Using this strict method we achieved a word accuracy of 47%, which is quite promising.","Results using top down prediction of possible word hypotheses by the parser work inspired by (Kita et. al. 1989) have already been published in (Hauenstein and Weber 1994a; ltmlenstein and Weber 1994b), (Weber 1994a), and (Weber 1995). Recognition rates had been improved there for read speech. In spontaneous speech we could not achieve the same effects. 2.7 Current Work Our current work, which led to INTARC-2.0, uses a new approach for the interaction of syntax and semantics and a revision of the interaction of the parser with a new decoder. For the last case we implemented a precompiler for word-based prediction which to our current experience is clearly superior to the previous word-class based prediction. For the implementation of the interaction of syntax and semantics we proceed as follows: A new turn-based UG has been written, for which a context-sensitive stochastic traiuing is being performed. The resulting grammar is then stripped down to a pure type skeleton which is actually being used for syntactic parsing. Using full structure sharing in the syntactic chart, which contains only packed edges, we achieve a complexity of"]},{"title":"O(n3).","paragraphs":["In contrast to that, for semantic analysis a second, unpacked chart is used, whose edges are provided by an unpacker module which is the interface between the two analysis levels. The unpacker, which has exponential complexity, selects only the n best scored packed edges, where n is a parameter. Only if semantic analysis fails it requests further edges from the unpacker. In this way, the computational effort on the whole is kept as low as possible. 3"]},{"title":"Parallel Parsing","paragraphs":["One of our main research interests has been the exploration of performance gains in NLP through parallelization. To this end, we developed a parallel version of the INTARC parser. Although the results so far are yet not as encouraging as we expected, our efforts make for interest-ing lessons in software engineering. The parallel parser had to obey the tbllowing restrictions: Running on our local shared memory lnnltiprocessor (SparcServerl000) with 6 processors, parallelization should be controlled by inserting Solaris-2.4 thread and process control primitives directly into the code. The only realistic choice we had was to translate our parser with Chestnut Inc.'s Lisp-to-C-Translator"]},{"title":"automatically","paragraphs":["into C. Since the Lisp functions library is available in C source, we could insert the necessary Solaris parallelisation and synchronization primitives into key positions of the involved fnnctions.","3.1 Parallelization Strategy and Preliminary Results For effective parallelization it is crucial to keep communication between processors to a minimum. Early experiments with a fully distributed chart showed that the effort required to keep the partial charts consistent was much larger that the potential gains of increased parallelism. The chart must be kept as a single data structure in a shared memory processor, where concurrent reads are possible and only concurrent writes have to be serialized with synchronisation primitives. An analysis of profiling data shows that even the heavily optimized UG formalism causes between 50% -and 70% of the compntational load in the serial c~e. Therefore we provide an arbitrary number of"]},{"title":"unification workers","paragraphs":["running in parallel which are fed unification tasks from the top of an agenda sorted by scores. Due to the high optimization level of the sequential parser, load-balancing is faMy poor. Namely, the very fast type check used to circumvent most unifications, causes large disparities in the granularity of agenda tasks. Further-more, pathological examples have been found in which a single unification takes much longer than all other tasks combined."]},{"title":"I ~::~ :: \"~- ~'~1","paragraphs":["4~","-IM","•",",",",","• ,",",",",",",",",","3ttxl","~2","~tz3","~t4 ~5","Sta6","$*1z7","Sstz$","~lz9","r,~tlO Figure 1: PercentuM gains and losses over at-tained over 10 ditferent sentences (Spilker 1995) 487"]},{"title":"4 Distributed Control in Verbmobil","paragraphs":["The question of control in VM is tightly knit with the architecture of the VM system. As yet, the concept of architecture in VM has been used mostly to describe the overall modularization and the interfaces implied by the data flow between modules. This socalled dornair~ architecture is in-complete in the sense that it does not specify any interactio~ strategics. Within our research on interactive system architectures we developed a modular communication framework, ICE ~, in co-operation with the University of Hamburg. Now, ICE is the architectural framework of the VM research prototype. 4.1 The INTARC Architecture The INTARC architecture as first presented by (Pyka 1992) is a distributed software system that allows for tile intcrconncction of NLSP modules under the principles of incrementality and interactivity. Figure 2 shows the modularization of INTARC-1.3: There is a main broad channel connecting all modules in bottom-up direction, i.e., from signal to interpretation. Furthermore, there are smaller channels connecting several modules, which are used for the top-down interactive disambiguation data flow. Inerementality is required for all modules. ICE assumes that each module has a local memory that is not directly accessible to other modules. Modules communicate explicitly with one another via messages sent over bidirectional channels. This kind of communication architecture is hardly new and eonl¥onts us directly with a large number of unresolved issues in distributed problem solving, ef. (Durfee et al. 1989). In the last 20 years there have been numerous architecture proposals for distributed problem solving among computing entities that ex-change information explicitly via message passing. None of these models include explicit strategies or paradigms to tackle the problem of distributed control. 4.2 Structural Constraints of Verblnobil Modularity, being a fundamental assumption in VM (Wahlster 1992), does still leave us with two problems: First, modules have to communicate with one another, and second, their local behaviors have to be somehow coordinated into a coherent global, possibly optimal, behavior. Unfortunately, the task of system integration has to obey some structural constraints which are mostly pragmatic in natnre: 2based on PVM (parallel virtual madfine) semRnb~ represenl~(m"]},{"title":"t I","paragraphs":[". ............. / -.. ~-?a,fi~f~.~ ~,,"]},{"title":") ~ho.. ~'~z,- Ol~mb~g~ogonDet*lFIow(TopDo~n)","paragraphs":["MoJtl Da~ Flo* (l-lottom Ui)) Figure 2: 'l)he interactive, incremental INTARC-1.3 architecture Some of the modules are very complex software systems in thelnselves. Highly parameterizable and with control subtly spread over many interacting submodules, understanding and then integrating such systems into a common control strategy can be a very daunting task. Control issues are often very tightly knit with the domain the module is aimed at, i.e., it is very difficult to understand the control strategies used without sound knowledge of the underlying domain. The problem even gets worse if what is to be fine-tuned is the interaction between several complex modules. These two arguments are similar in nature, but diflhr in the architecturM levels that they apply to. 'File former is implementation related, the latter algorithm arid theory related. 4.3 Layers of Control Modules have to colnmunicate with one another and their local behaviors have to be coordinated into a coherent global, possibly optimal, behavior. In highly distributed systems we generally tind the following levels of control: System Control: The minimal set of operat-ing system related actions that each participat-ing module must be able to per[brm which will 488 typically include means to start up, reset, moni tot, trace and terminate individual modules or the system as a whole. Is()lated Local Controh The control strategies used within the module, disregarding any in-teractions beyond initial input of data and final output of solutions. 'Fhere is only one thread of control active at any time. lnteraetiv(; Local Controh ll.oughly, this can be seen as isolated local control extended with interaction cal)al/ilities, lncr~\"mentalitp is given by the l)ossibility of control flowing back to a certain internal stake aftex an outl)ut operation, lligher mtcraclivily is made possible by entering a state more often fl:om w~rious points within the rood-tile and by adding a new waiting lool/to cheek for any tot)-down requests. The requirement for any. time behavior is a special case of that (G6rz and Kesseler ]994).","in ore: experience ~he change to interactive COl> trol will tremendously increase the complexity of the resulting (:ode. But we are swill making the simplifying assumptions that tile algorithm can be used increnlentally - but there are algorithms m~suitable for incremental processing (e.g. A*). h~crementality can lead to the ([elrlalld for a eolni)]ete redesign of a lnodule. Furthexmore we as-sume that simply by exchanging data and doing simple extensions in the control [tow everything will balan(:e out nicely on the system scale which is enorlnously naiv(:. Even for the sequential architecture implied by the case of isolated local control, we have to solve a whole plethora of uew problems that corne along with interaetivity: * Mutual deadlock - Mutual live-lock - Race conditions (missing synchronization) ,, Over-synchronization Dialogue Controh In systems like VM there is a module that comes close to possessing the \"inte-- grated view\" ot'a centralized blackboard control: the dialogue module. So it seems the right place to handle some of the global strategic control issues, like: - l)omain error trundling . Observe timeont constraints . ll,esolve, external ambiguitie.s/unl(nowns The fact that tile dialogue module exercises a kind of global control does not invalidate what has bee, n said about the unfeasability of central control, be.. cause the control exercised by it is very coar.',e grained. To handle liner grained control issues in any rood ule would take us back to memory and/or eomm,mication system contention. References","Chris Brew. Stochastic t]I'SG, l)roccx,dings of l.he ]'hn'ol)ean ACI, Conference 1995, b;din/)urgh, 1995","l';dnmnd 11. I)urfec, Victor I{. I,cssev, and I)anM I). Corkill. Coop~rative l)istribut{d Probh:m Soh.,ing, pages 83 147. Volume 4 ot: Aw'on I{arr et al. (b;d.). The ll.ndbook of Arlifi'ciul lntclli.qence l{eading, Mass.: Addison-Wesley, 1989.","(',iitdher G6rz and Marcus I<esschw. Anytime AL gorithms for Speech Parsing? Proceedings of (]OIAN(L94, Kyoto, 19{)4","Andrcas llauensl,eiu and [laus Weber. An invesligao tion of tightly coupled time synchronous speech language inlcEfaccs usin 9 a unification grammar. In: l'. McKevitt (Ed.): Proceedings of tile Workshop on Integration of Natural Language and Speech Pro- (:esslng, AAAI-94, Seatde, [994, 42 49","Andrcas lIauenstein and Hans Weber. An lnveatigalion of Tightly Coupled Time Synchronous Speech Language hderfaces. Proceedings of K()NVI']NS 94, Vietma: Springer, September 19!)4, 141 150","Marcus Kcsseh!r. l)istribvted Control in Vcrbmobil+ Uniwwsil.y of Erlangen-N iit'nberg, IMM D V[ l 1, Verbmot)il l{el)Ort 24, 1994.","Kit.a, K., I<awabata, T. and Saito, [I. HMM conliuous speech recognition usin9 predictive L 1~ parsiwI. IEEE IC,4,S'SI ~ Proceedings , 1989, 703 706.","(]laudius [)yka. Management of hypotheses in an iutc~ .qralcd spccch-la~*guage architecture. Proceedings of EUAl-92, 1992, 558 560","36vg Spilker. Parallclisicrun 9 eines inkrcmc.nlellcn, aklivcn (]hartparscrs. Diploma thesis, Uniw~rsil;y of F, rlangen-N6rnberg, l\",rlangen, December 1995.","Wolfgmlg Wahlstcr and Judith l';ngelkamp, editors. Wissenschafllichc Ziele und Nctzpldnc filr das VERBM 0 BlL-Projekt. I)FK 1, SaarbriM~en, ] 992.","Ilans Weber. Time Synchronous Uhart Parsing of ,5'pccch lntcgratin 9 UniJication Grammars wilh Statistics. Speech arid l,anguage l~]ngineering, Proceedings of {;he l';ighth Twente Workshop on Language Technology, (1,. Bores, A. Nijholt, Ed.), Twentc, 1[)94, 107-119","tlans Weber. I,R-inkrcmcntclles probabilistisches Chartparsing yon Worthypothcsenmengcn mit Unifikations.qrammatiken: Eine engc Kopplung yon Suche und Analyse. Ph.l). Thesis, University of Hamburg, 1995, Verbmobil Report 52. 489"]}]}