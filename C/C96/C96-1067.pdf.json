{"sections":[{"title":"Word Completion: A First Step Toward Target-Text Mediated IMT George Foster, Pierre Isabelle, and Pierre Plamondon Centre for hfformation Technology Innovation (CITI) 1575 Chomedey Blvd. Laval, Quebec, Canada, H7V 2X2 {foster, isabelle, plamondon}@citi,","paragraphs":["doc. ca"]},{"title":"Abstract","paragraphs":["We argue that the conventional approach to Interactive Machine ~Ih-anslation is not the best way to provide assistance to skilled translators, and propose an alternative whose central feature is the use of the target text as a medium of interaction. We describe an automatic word-completion system intended to serve as a vehicle for exploring the feasibility of this new approach, and give results in terms of keystrokes saved in a test corpus."]},{"title":"1 Introduction","paragraphs":["Machine translation is usually significantly inferior to human translation, and for most applications where high-quality results are needed it must be used in conjunction with a human translator. There are essentially three ways of organiz-ing the process by which a person and a machine cooperate to produce a translation:"]},{"title":"prccdition, in","paragraphs":["which the person's contribution takes the form of a source-text analysis and occurs before the MT system is brought to bear;"]},{"title":"postedition,","paragraphs":["in which the translator simply edits the system's output; and"]},{"title":"interactive","paragraphs":["MT (IMT), which involves a dialog between person and machine. Of the three, IMT is the most ambitious and theoretically the most powerflfl. It has a potential advantage over postedition in that information imparted to the system may help it to avoid cascading errors that would later require much greater effort to correct; and it has a potential advantage over preedition in that knowledge of the machine's current state may be useful in reducing the number of analyses the human is required to provide.","Existing approaches to IMT (Blanchon, 1994; Boitet, 1990; Brown and Nirenburg, 1990; Kay, 1973; Maruyama and Watanabe, 1990; Whitelock et al., 1986; Zajac, 1988) place the MT system in control of the translation process and for the most part limit the human's role to performing various source language disambiguations on deman& Although this arrangement is appropriate for some applications, notably those in which the user's knowledge of tile target language may be limited, or where there are multiple target, languages, it is not well suited to tile needs of professional oi' other highly skilled translators. The lack of direct human control over the tinal target text (modulo postedition) is a serious drawback in this case, and it is not clear that, for a competent translator, disambiguat, ing a source text, is much easier than translating it. This conclusion is supported by the fact that true IMT is not, to our knowledge, used in most modern translator's support environments, eg (Eurolang, 1995; I,'rederking et al., 1993; IBM, 1995; Kugler et al., 1991; Nirenburg, 1992; ~li'ados, 1995). Such environments, when they incorporate MT at all, tend to do so wholesale, giving the user control over whether and when an MT component is invoked, as well as extensive postediting facilities for modifying its outtmt, but not the ability to intervene while it is operating.","In our view, this state of affairs should not be taken as evidence that IMT for skilled translators is an inherently bad idea. We feel that there is an alternate approach which has the potential to avoid most of the problems with conventional IMT in this context,: use the target text as a medium of communication, and have the translator and MT system interact by making changes and extensions to it, with the translator's contributions serving as progressively informative constraints for the syste,n. This arrangement has the advantage of leav-ing the translator in full control of the translation process, of diverting his or her attention very little from the object of its natural focus, and of necessitating a minimum of interface paraphernalia beyond those of a word processor. It can in principle accomodate a wide range of MT proficien-"]},{"title":"394","paragraphs":["cies, frolil very high, in which the system inight be called ut)on to propose entire translations and Inoditly them in response to changes Inade by the translator; to very low, in which its chief contril)ution will be the reduction of typing labour.","The aim of this paper ix to explore the feasibility of this"]},{"title":"target-tezt mediated","paragraphs":["style of IMT in one parti(:ularly simph; form: a word-(:onq)h',tion system which ai;temltts to fill in the sutlixes of target-text words from manually typed prefixes.t We describe a prototype completion system for English to l~¥ench translation which is based on simple statistical MT techniques, att(t give mea-StlFenlents el: its performance ill terms of (;}laracters saved in a test cortms. The system has not yet been integrated with a word processor, st) we (;annot qltantify the anlollnt of a(:tual time and (;fl'ort it woul(t save a translator, t)nt it seems reasonable to expect this to lie faMy well correlated with total character savings."]},{"title":"2 Word Completion","paragraphs":["Our scenm'io for wor(1 completion SUl)t)oses that a translator works on some designated segment of the source text (of attproxinmtely sentence size), and elaborates its (;ranslation from left to right. As each target-text character is tylted , a t)rot)osed (:omttletion for tit(; currenl; word is (tisttlayed; if this is (',orreet, the translator ntay a(',cept it att(l l)cgin typing the next word. Although inore elaborate comi)lel;ion schemes are imaginable, in(:lud-ing ones that involve the use, of alternate hyI)othesos or 1)revisions for morl)hologieal repair, we have ot)ted against these for the time t)eing because they necessitate st)eeial commands whose benetit in terms of characters saved would t)e diilicult to estimate.","The heart of ore\" system is a comltletion engine for English to t~'ench translation which finds the best completion for a [,¥eneh word prefix given the current English source text segment utnler translation, attd the words which precede the prefix in the corresponding l~¥eneh target text segment. It comprises two main components:"]},{"title":"an cvaluatot","paragraphs":["which assigns scores to completion hypotheses, and a"]},{"title":"generator","paragraphs":["which produces a list of hyp(tthesos that match the current prefix and picks the one with the highest score.","1This idea is similm to existing work on tyl)ing ae(:elerators for the disabled (Demasco and McCoy, 1992), but our methods differ signitieantly in many aspects, chief among which is the use of bilingual context."]},{"title":"3 Hypothesis Evaluation","paragraphs":["Each score produced by the evaluator is an estilnate of"]},{"title":"p(tl{, ,st,","paragraphs":["the probability of a target.- language word t given a preceding target text t, anti a source text s. For etticiency, this distribution is modeled as a silnple linear combination of SOl)re'ate tn'edietions fl'om tit(; target text and the sottree text:"]},{"title":"p(tlE, s) = Ap(tl{ ) + (1- A)p(tls ).","paragraphs":["The vahte of /~ was chosen so as to maximize e, otnpletion lterforInanee over a test text; (see s(!c-tion 5). 3.1 Target-Text Based Prediction The target-text based prediction p(tlt) comes t¥om an interpolated trigranl language model for l%:ench, of the type commonly used in speech recognition (Jelinek, 11!190). It; was trained on 47M words fiom the Canadian Hansard Corpus, with 750/o used to make relative-fl'equency I)arameter estintates and 25% used to reestimate interpola-tion coefticients. 3.2 Source-Text Based Prediction The source text prediction p(t[s) comes fl'om a statistical model of English-to-l,¥ench translation which is based on the IBM translation models 1 and 2 (Brown el; al., 1993). Model 1 is a Hid.- den Markov Model (HMM) of the target language whose states correspond to source text tokens (see figure l), with the addition of one special"]},{"title":"null","paragraphs":["state to account for target text words that have no strong direct correlation to any word in the source text. The output distribution of any state tie the set of probabilities with which it generates target words) deitends only on the correspondit~g source text"]},{"title":"word,","paragraphs":["and all next-state transition distributions are uniform. Model 2 is similar to model 1 except that states are attgmented with a target-token t)osition cotnponent, attd transition probabilities depend on both source and target token positions, '2 with the topographical constraint that a state's target-token t)ositioll component must always match the current actual position. Because of the restricted form of the state transition","UAlong with source and target text lengths in l/town et al's fornmlation, lint these are constant for arty particular HMM. The results 1)resented in this palter are optimistic in that the target text lengl;h was assumed to be known in advance, which of course is unrealistic. IIowever, (Dagan et al., 1993) have shown that knowledge of target-text length is not crucial to the model's i)ertbrmanee. 395 J' ai d' autres cxcmplcs d' autres pays 3 c ~ 1 :4 5 counlrics 8 8 Figure 1: A plausible state sequence by which the HMM corresponding to the English sentence"]},{"title":"I have other cxamples from many other countries","paragraphs":["might generate the French sentence shown. The state-transition probabilities (horizontal arrows) are all 1/9 for model 1, and"]},{"title":"depend","paragraphs":["on the next state for model 2, eg"]},{"title":"p((froms,","paragraphs":["6} I') = a(516). The output probabilities (vertical arrows) depend on the words involved, eg p(d' I"]},{"title":"{from~,","paragraphs":["6}) = p(d' I from ). matrices for these models, they have the property that- unlike HMM's in general they generate target-language words independently. The probability of generating hypothesis t at position i is just: Isl"]},{"title":"p(tls, i ) = EP(tlsi)a(j li)","paragraphs":["j=0 where"]},{"title":"sj","paragraphs":["is the jth source text token (so is a null token),"]},{"title":"p(tlsj)","paragraphs":["is a word-for-word translation probability, and"]},{"title":"a(jli )","paragraphs":["is a position alignment probability (equal to 1/( M + 1) for inodel"]},{"title":"1).","paragraphs":["We introduced a simple enhancement to the IBM models designed to extend their coverage, and make them more compact. It is based on the observation that there are (at least) three classes of English forms which most often translate into Fk'ench either verbatim or via a predictable transformation: proper nouns, numbers, and special atphanuineric codes such as"]},{"title":"C-~5.","paragraphs":["We found that we could reliably detect such \"invariant\" forms in an English source text using a statistical tagger to identify proper nouns, and regular expressions to match immbers and codes, along with a filter for frequent names like"]},{"title":"United States","paragraphs":["that do not translate verbatim into French and Immbers like"]},{"title":"10","paragraphs":["that tend to get translated into a fairly wide variety of forms.","When the translation models were trained, in-variant tokens in each source text segment were replaced by special tags specific to each class (different invariants occuring in the same segment were assigned serial numbers to distinguish them); any instances of these tokens found in the corresponding target text segment were also replace(] by the appropriate tag. This strategy reduced the nmnber of parameters in the inodels by about 15%. When ewfluating hypotheses, a siufilar replace-ment operation is carried out and the translation probabilities of paired invariants are obtained from those of the tags to which they map.","Parameters for the translation models were reestimated fl'om the Hansard corpus, automatically aligned to the sentence level using the method described in (Simard et al., 1992), with non one-to-one aliglmmnts arid sentences longer than 50 words filtered out; the ret~fine(l material consisted of 36M English words and 37M Fren(:h words."]},{"title":"4 Hypothesis Generation","paragraphs":["The main challenge in generating hypotheses is 1;o balance the opposing requirements of completion accuracy and speed the former tends to increase, and tile latter to decrease with tile nmnber of hypotheses considered. We took a number of steps in art effort to achieve a good compromise. 4.1 Active and Passive Vocabularies A well-established corollary to Zipf's law holds that a minority of words account for a majority of tokens in text. To capitalize on this, our system's French vocabulary is divided into two parts: a small"]},{"title":"active","paragraphs":["component whose contents are always used for generation, and a much larger"]},{"title":"passive","paragraphs":["part which comes into play only when the active vocabulary contains no extensions to the (:urrent t)refix.","Space requirements for the passive vocabulary were minimized by storing it as a special trie in which conlnlon Srl[~cix patterns are represented only once, and variable-length coding techniques are used for structural information. This allows us to maintain a large dictionary containing over 380,000 forms entirely in memory, using about 475k bytes.","The active vocabulary is also represented as a trie. For efficiency, explicit lists of hypotheses at'(; not generated; instead, evaluation is performed during a reeursive search over the portion of the trie below the current coinpletion prefix. Repeat searches when the prefix is extended by one character are ol)viated in inost situations by memo]z-ing the results of tile original search with a"]},{"title":"best-child","paragraphs":["pointer in each trie node (see figure 2). 4.2 Dynamic Vocabulary To set the contents of the active vocabulary, we borrowed the idea of a"]},{"title":"dynamic vocabulary","paragraphs":["from (Brousseau et al., 1995). This involves using 396 f\" Figure 2: Menioized port;ion of t;]l(; a(:i, ive vocal)ulary trie for i;he l~i'en(;h preiix parhJv hea,vy liues show 1)esl;-child links and sha, ded nodes rcpr(',scnt vidid word ends. The, currelii: best; (:andidalm is pa'dc'co'~Z; if an a is ap1)cnded l)y i,h(; t:ranslal;or~ |;he new 1)esl; can-didal;(; po, rlc'rait (:~ui 1)e r(',t;ri(;ved froln i, he t)esl;-(;liild links wii;houi; having 1;o i'e-evahlai;c all 6 1)ossil)le hyl)oi;heses. l;rmislai;ion rood(;1 1 Ix) (;olnl)ul;(; ;~ ]isl, of tim 'n, nlosl: prob~fl)le I;arg(,t: l;(;xl; words (in('hl(ling t, rmisla.lJon invm'ianl;s), given th(; curr(;nl; sour(',(; l;(;xt; s(;gliCieilt. As figur(; 3 illusl;r;.rlx;s, (:ompar('(l to ;l~lt ~c[l:(;ril~d,(~ reel:hod of sl;;tl;i(:;dly ('.hoosing t, he n m()st; frequenl: tornis in l;he ti;IJning (:orlms , use of a, (lyna,mic vo-- (',abul~ry (h'amal;i(:a,lly r(;(lu(:(;s l;h(; a v(!rage, a(:l,iv('~ vo(',~l)ulm'y size r(',(tuir(;(1 t;o iu',hi(w(! a, given levc, l of i;a, rgel: ix~xi: covcra,g(;. Mol:ivalxxl by t:he Im:i, th;~t r(;(;(!nl; words l;en(l 1;o recur in l:cxt;, wc ~dso a,d(led all t)reviously (;ncounl;ered l;m'g(;l;-t;(;xl; t, ol(ens 1;o i;ho dynami(', vo(:ttl)ul<%y. 4.3 Case Handling The l;re.~l;nlcnl: of ](;l;lx;r ca.s(; L'-; ;~ 1Mcky l)r()/)i(!ni for hyi)oi;l/(;sis general;ion mid one tlta.l; cil~llll()l; })(; ig;llor(;(] ]11 kill inl;(~ra.('.l;iv(; al)l)li(:id;ion. IVlt)st; words can al)pc, ar in ;L llllllli)(!l' ()[' (liffer(;nl; ('.;/os(!-v;rli;l,Iil, ['orllt,~ gbll(l [;h(~l'(! ~%1'c, llO sit[It)l(', ;)dl(1 ;d)solul,(~ l/l[(',,q l;lii~t spec, i[i7 which iS al)t)rot)ria,l;c i/l a t);u'l;ic, ula, r (:onlx'.xl;. To (x)pe wii,h I;his ,sil:ll;d;i()n~ w(; axh)l)ix;d a. ]i(;urisl;i(: sl,ra,1;(%y I)as(;(t on an idealiz(;(l nl()(l(;I of Fr(;n(:ti case c()iiv(~,ll{;iOllS in which w(irds m'e dirt(led into l;wo (:lass(;s: (:lass ;I words m'(; those which are normally wrii:l:en in low(we;me; (:lass 2 words are t, hose H/t(',h ;;~S ])rOl)(',r ltoittls whi(;h liornmlly 1;~dce a, Sl)e(:i;fl case lml;Ix;rn (',onl;a,inin/r ~d; ](]~-IoS/; ()IIC llt)])(~I'CktS(~ c, tmra,c,l;er. Class 1 words gO, If. ('r;m; ('.ai)italiz('d hyt)ol;}i.(;s(!,~ ;i J: Lhe [)el,;innillg o[' gt S(',Ill~(',it(;(', O1' wh(',ll l;h(; (;Ollll)](',I;iOll l)r('fix is (;;~l)- ita,liz(,d; llI)I)(;rt:;tso hyi)othos(;,q when the (:oml)le-1 oo 08 96 94 92 90 88 a6 134 82","t~o","-","- g --","1","_","J 200O 4OO0 6000","average aciive voc;ahulafy size o y- ,' ........... i; ; × i:l .,×","dynalnic *","dynamic wilh histoly","14 slatic with hisloly ,~..","static x L Boo0 100o0 [?i~ur(', 3: Targel; I:e×t coverag(; versus acl;ive vocal),o lary size, lot st;at,it and (tynmni(: met;hods. The wiU~, hi,~4,o'qq (:urv(,.s reilex:i~ (;he addiiiion of previously cn-- (:omd;(u(~d (:aq4(',I, t,(~xl, tokens l;() the act;ive voc~l)ulary, l;ion l)r(~tix is upt)(;r(:ics(; mid al: [(;asl; i,wo (:}l;rra, cix~rs lon G and ]()w('.F(;;t,q(; hyl)ot;hesc,~ ol;h(!rwis(,. (7lass 2 w()rds ~(',II(!I'}IJ,C upl)('.r(;as(; hyl)ol,hes(;,~ ml(h;r 1;h(' ,~mn(; con(lilJolis ~ts (',lass I words, ol;h('mwise verlml;ini hyt)ol;hcses. 5 l.[esults \\¥e lx~stx~d ill(; (Ximl)letfion (;ligiii(,, (m [;wo differ(;ni ][mism'd lx;xlis nol: in ()ill' l;raJnlng (',ortms. Texl, A, (:Olll;~inint[ 786 ([~lll;onlld;it;ilJly) ic|iEll(;(l pa.il's~ 19/157 English ;aid 21 ,] 30 Frent:h ix)kens, w~m used 1,o del;e, rufil~c ol)lJnuun lia,rmnt;lx',r sel, i;ings; t;exl: ] 1, (:onl;~lJning lid0 (mtlxmiatica.lly) aligned tmirs, 29,886 English and 32,] 38 Frcncii 1;okens, was used I,o tx)rrol)or;iAx~ the. l'(;Sltll;s. Tests wcr(.' COlithl('l;(,.ti wiiJl ~ 3000-word dynmnic acl;ivt, vocabulm'y mlg-Ili(;tit(;d wilJi all en(:ount;er(xt l;m'get;-l, cxl; t7)rlns.","Four lil(~SUl'C,s o[\" (',oint)lelJon t)p,r['orlna,lic,(! w(;l() used. All ll,SSlllllO l;tl~l, i;iic 1;ra, lisl~tl;or will a,c,c, epl; a ('.orr(;('.l; ¢'.Oml)letion prot)osa.1 a.s SOOli ¢i.s it is mad(; (it,, wil;houl: l;yping [llrl;hc, l). Th(~ lll()~ql; direcl: iu- (lex is l;iu', l)roporlJon of (Jl0d~%(;t(!rs in (:orl(!t'.t;lycoiui)lcix;d ,quflix(;s. [/,cla, t;ed 1:o this is i;lm pro-portion of (:orrc,(:l;ly-mll;icip~tt,d chltl'~K;l;(;i'S: l;}i()S(~ itt COI'I'(W.I; sutIixes phls rely /;h;d; ln;~t;cli /.it('. lICK|, ch~racl;er the l,rmisl;~l;or will tiave l;o tyl)c. The fililt.| l;WO lll(~;tsur(!s ;IAo inlxmdcd Ix) ~t)prt)xiimd,t~ i,hc IIIIlHI)CF o[\" ]¢eysl;rokes s;tved within words. The firsl; ooSSIllliCS l]ud; l, he, lirlmslal;()r TlS(',S ~ Slmcial COllil[igblid> ('.OSl,iug OIIC k(;ysi;rok(', lx) ~r(:c(;i)t; ;L pro t)()S;-I[, r|~h(] s(',COlI(t 0~S,SlllllCS |;h0ol; ~t(;(;(',t)l;};~ll(:(~ COllsisl;s merely ill l;yping l;h(', chm'~mlx;r whit:h follows i,he word either a st)~me or a punci;ua, I;ion [ll}~l'k. 3 Complel;ions m'e free in this i~ccoIlltl;hlt,~> :;S()lne IDri!nch lirt!lixes si1ch &,q"]},{"title":".jusqu'","paragraphs":["\\vhich elide 3 9 V 75 70 65 60 55 50 45 40 ; o",",/ Sa'\"\" anticipated characters ~,--","completed characters -*--.","keystrokes saved 2",",.:: ..... ~e.t,o~ ..... edld :~\"","......","~","..................","x",".̧",".........","~",".......... ~ .........","x","..........","~","..............","x","•","_","..... ×.. l","0.2 0.4 0.6 0.8 trlgram weight Figure 4: Combined trigram/translation model performance versus trigram weight 1. but all punctuation must be manually typed, and any spaces or punctuation characters in hand-typed prefixes are assessed a one-keystroke escape penalty.","Figure 4 shows the performance of the system for various values of the trigram coefficient A. A noteworthy feature of this graph is that interpola-tion improves performance over the pure trigram by only about 3%. This is due in large part to the fact that the translation model has already made a contribution in non-linear fashion through the dynamic vocabulary, which excludes many hypotheses that might otherwise have misled the language model.","Another interesting characteristic of the data is the discrepancy between the number of correctly anticipated characters and those in completed suffixes. Investigation revealed the bulk of this to be attributable to morphological error. In order to give the system a better chance of getting in-flections right, we modified the behaviour of the hypothesis generator so that it would never produce the same best candidate more than once for a single token; in other words, when the translator duplicates the first character of a proposal, the system infers that the proposal is wrong and changes it. As shown in table 1, completion performance improves substantially as a result. Figure 5 contains a detailed record of a completion session that points up one further deficiency in the system: it proposes punctuation hypotheses too often. We found that simply suppressing punctuation in the generator led to another small incre-ment in keystroke savings, as indicated in table 1. letters are not normally followed by either spaces or punctuation. We assume the system can detect these and automatically suppress the character used to effect the completion. nleasure (% chars) anticipated completed keystrokesl keystrokes2","method","text A text B std PBHR P+NP P+NP 77.2 80.0 79.2 78.9 67.1 73.6 72.6 72.2 65.1 71.8 72.3 71.9 49.8 54.6 55.1 55.1 Table 1: Final performance figures. PBHR stands for"]},{"title":"previous-best-hypothesis rejection,","paragraphs":["and P+NP for PHBR without punctuation hypotheses."]},{"title":"6","paragraphs":["Conclusion The work described in this paper constitutes a rudimentary but concrete first step toward a new approach to IMT in which the medium of interaction is simply the target text itself. In contrast with previous interactive approaches, the translator is never expected to perform tasks that are outside the realm of translation proper (such as advising a machine about common sense is-sues). In line with the spirit of truly interactive approaches, the translator is called upon early enough to guide the system away from a \"raw machine translation\" he or she would rather not have to revise. And in fact the machine is now the one required to revise its own copy, making use of every keystroke entered by the translator to steer itself in a useful direction.","This strikes us as the \"proper place\" of men and machines in IMT, and we intend to contiime exploring this promising avenue in our future research. References","Hervd Blanchon. 1994. Perspectives of DBMT for monolingual authors on the basis of MDIA-1, an implemented mock-up. In"]},{"title":"COLING-9/~,","paragraphs":["pages 115-119, Kyoto, August. Christian Boitet. 1990. Towards personal MT. In"]},{"title":"COLING-90,","paragraphs":["pages 30 35, Helsinki, August.","J. Brousseau, C. Drouin, G.Foster, P. Isabelle, R. Kuhn, Y. Normandin, and P. Plamondon. 1995. French speech recognition in an automatic dictation system for translators: the TransTalk project. In"]},{"title":"Eurospeech 95,","paragraphs":["pages 193- 196, Madrid, Spain, September.","Ralf D. Brown and Sergei Nirenburg. 1990. Human-computer interaction for semantic disambiguation. In"]},{"title":"COLING-90,","paragraphs":["pages 42-47, Helsinki, August.","Peter F. Brown, Stephen A. Della Pietra, Vincent Della J. Pietra, and Robert L. Mercer. 1993."]},{"title":"398 gous + /Nous rfialisons r~al+ /avons r/endre rfi/aliser r4a/lise r4al/isons tous t+ /des t/ous que q+ /les q/ue le + /le Canada C+ /gouvernement C/anada co~e","paragraphs":["~+ /, clothe bien bi+ /un b/eaucoup bi/en d' + /d' autres + /autres pays p+ /, p/ays","+ /, riches r+ /, r/iehes OU + /OU pauvres + /pauvres a a+ /les beaucoup b+ /6t~ b/eaucoup trop t+ /de t/rop de + /de ses se+ /temps s/ervices se/s citoyens c+ /trop c/itoyens qui q+ /. q/ui Figure 5: A sample completion run Ibr the English source sentence We all realize that like many other countries, rich or poor, Canada has too many citizens who cannot afford deeent"]},{"title":"housing.","paragraphs":["The first column contains the French target sentence; the second the prefix typed by the translator, followed by a plus sign; and the third the record of successive proposals for each token, with a slash separating prefix from proposed completion. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2) :263- 312, June.","hto Dagan, Kenneth W. Church, and William A. Gale. 1993. Robust bilingual word alignment for machine aided translation. Ill Proceedings of the Workshop on Very Large Corpora (A CL 93), Columbus, Ohio.","Patrick W. Demasco and Kathleen F. McCoy. 1992. Generating text froin coinpressed input: An intelligent interface for people with severe motor impairments. CACM, 35(5), May.","Eurolang. 1995. Eurolang Optimizer, product description.","Robert Frederking, Dean Grannes, Peter Cousseau, and Sergei Nirenburg. 1993. An MAT","9 tool and its etfectiveness. In [ roceedings of th, e DARPA HLT Workshop, Princeton, NJ.","IBM. 1995. IBM 35\"anslation Manager, product description.","F. Jelinek. 1990. Self-organized language modeling for speech recognition. [n A. Waibel and K. Lee, editors, Readings in Speech Recognition, pages 450 5{)6. Morgan Kaufmaim, San Mateo, California.","Martin Kay. 1973. Tile MIND system. In R. Rustin, editor, Natural Language Processing, pages 155-188. Algorithmics Press, New York.","M. Kugler, G. Heyer, R. Kese, B. yon Kleist-Retzow, and G. Winkelmann. 1991. The Translator's Workbench: An environment for multilingual text processing and translation. In Proeeedings of Mr1 ' Summit IH, pages 81 83, Washington, July.","Hiroshi Maruyama and Hideo Wataimbe. 11990. An interactive Japanese parser for machine translation. In COLING-90, pages 257-262, Helsinld, August.","S(xge, Nirenburg. 1992. Tools for machine-aided translation: The CMU TWS. META, 37(4):709 720.","Michel Simard, George F. Foster, and Pierre Isabelle. 1992. Using cognates to align sentences in bilingual corpora. In TMI-4, Montreal, Canada.","Trados. 1995. 3]'ados ~lk'anslators Workbench, product description.","P. ,l. Whitelock, M. McGee Wood, B. J. Chandler, N. Itolden, and H. J. Horsfall. 1986. Strategies for interaetiw ~. machine translation: the experience and implications of the UMIST Japanese project. In COLING-86, pages 329 334, ]~Oliil.","l{dlni Zajae. 1988. Interactive translation: A new approach. In COLING-88, pages 785 790, Budapest. 399"]}]}