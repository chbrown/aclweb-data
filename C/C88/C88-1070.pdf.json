{"sections":[{"title":"Schema Method: A Framework for Correcting Grammatically Ill-formed Input Ikuo KUD01) , Hideya KOSHINO2) , Moonkyung CHUNG2) and Tsuyosi MORIMOTO1)","paragraphs":["1)ATR Interpreting Telephony Research Laboratories Twin 21 Building MID Tower 2-1-61 Shiromi, Higashi-ku","Osaka 540, Japan 2)CSK Research Institute","3-22-17 Higashi-Ikebukuro, Toshima-ku","Tokyo 170, Japan Abstract"]},{"title":"The schema method is a framework for correcting grammatically ill-formed input. In a natural language processing system ill-formed input cannot be overlooked. A computer assisted instruction (CAD system, in particular, needs to show the user's errors. This framework diagnoses ill-formed input, corrects it and explains the error, if an input is ill-~'ormed. The framework recognizes a sentence at two steps: first parses weak grammar, and then strongly filters the parsed sentence. When it is known what sentences are passed by the filter, it can be used even if it is imperfect. As the strong filter, a new method is used: an interpretation schema and an interpretation rule. An interpretation schema collects input information schemata and then an interpretation rule judges whether the collected schemata are correct or incorrect. This approach overcomes the problem of relaxation control, the major drawback of the previous syntactically-oriented methods, and is also more efficient. 1° Introduction Ill-formed input cannot be ignored when a natural language processing system such as a computer assisted instruction (CAD system or a machine translation system is built. Particularly in a CAI System, students often make mistakes, such as mispunctuation, lack of agreement, misplaced/improperly-used words, etc. In these cases, a CAI system needs to point out input errors, and show why the input it~ wrong. In order to do so, the system needs to diagnose and correct ill-formed input to explain the errors. The schema method as a framework for correcting grammatically ill-formed input is suggested and the diagnosis and correction of errors is discussed. There have been many studies for processing ill-formed input for English. The point of those studi.es is the diagnosis: how does the system find an error? The approaches are classified into two groups: the syntactically-oriented group and the frame-based group. The syntactically-oriented group includes robust parsers based on Augmented Transition Networks (ATN) which Use the relaxation technique/Kwansny 1981./or the meta-rule/Weisehedel 1980, 82, 87/, and the EPISTLE system which addresses the problems of the checking grammar and style of texts, such as letters, reports and manuals, written in ordinary English/Heidorn 1982/, /Jensen 1983/. The frame-based group attempts to deal with ungramnmtical input through extensions to pattern matching parsing/Hayes 1981/, through conceptual case frame instantiation/Schank 1980/and through approaches involving multiple cooperating parsing strategies /Carbonell 1983/. The target of that study is dialogue phenomena in communication with limited-domain systems, such as data-base systems, electronic mail systems, etc. The aim of this study is error-correction of non-native speakers written English text. This approach is syntactically oriented. The syntactically-oriented approaches/Kwansny 1981/ /Weischedel 1980,82,87/,/Heidorn 1982/,/Jensen 1983/are very similar. Their basic idea is relaxation. They first attempt to parse the input, using fully grammatical rules. If the sentence is not parsed, some of the conditions are relaxed. However these approaches have two major drawback. (1)Relaxation control strategies: when inputs are ill-formed, some means of ranking alternatives is appropriate. The number of relaxed configurations may be large.","paragraphs":["One of the most critical problems is control. The need to relax the very rules that constrain the search for an interpretation is like opening Pandora's box./Weischedel 1987(PP.117)/"]},{"title":"(2)Computational inefficiency: the relaxation approach cannot recognize ill-formed input before the analysis with well-formed grammar is finished. Furthermore, fully well-formed grammar is needed. To make fully well-formed grammar, subcategorization of parts of speech is needed and other conditions are added. As a result, there are too many rules. In comparison to previous approaches, this approach does not use the relaxation technique. The difference between previous approaches and this one is the method of recognizing an ill-formed sentence. Previous approaches first use a strong filter, then relax the conditions. This approach, however, first uses weak grammars, and then strongly filters the passed sentence. This approach recognizes a sentence at two steps. An attempt is made to expand lexical-functional grammar (LFG) /Kaplan 1982/to deal with ill-formed input. LFG has two drawbacks: (1) LFG can't deal with errors of omission and (2) LFG has no framework for error correction. If an input sentence is well-formed, this framework obtains an LFG f-structure. If not, the sentence is corrected. Examples of error correction are given in the next section. In the section following the basic idea is described","paragraphs":["3~i and the problem of a unification mechanism for processing ill-formed input is discussed. This framework is shown in section 4. 2. Non-native speaker's ill-formed phenomena","In this section, treated examples of non-native speaker's ill-formed phenomena are given. The application is a CAI system for Japanese junior high school students in a primary English course. Their errors are different from a native speaker's. Typical errors are shown in Table 1.","English is very different from Japanese in parts of speech, word-order, tense, etc. For a Japanese, there is no concept of(l) countable and uncountable nouns ~:> ~ ~> in Table 1, (2) singular and plural forms <~ (3) articles ~> ~> (4) agree-merit between subject and verb @ (5) adverb word-order ~.","Japanese interfered with the students' acquision of English. The following errors are often made by Japanese adults as well. (4)verb style <~ (5) category mistakes, word misuse ~>. Furthermore, junior high school students are reading and hearing a foreign language (English) for the first time, and thus have no concept of foreign language whatsoever. (6) Logical error @: the student who made the mistake explained that \"are + not -* aren't\", \"is + not -* isn't\" so\" am+ not --* amn't\". (7) Primary students are not familiar with English grammar and can't distinguish between \"Who\" or \"Where\" @ @. (8)Surface error: letter or punctuation problems","Table 1. Examples of errors by junior high school students <~*He plays piano. <~*He plsy the baseball. He plays the piano. He plays baseball. @*some good advices '<~*I am student. some good advice I am a student. @*A moon is smaller than an erath. The moon is smaller than the earth. ~*He is one of those men who is difficult to please. He is one of those men who are difficult to please. <~*I have finished my homework already. I have already finished my homework . ~>*He is listening music on the radio now. He is listening to music on the radio now. <~*We cannot play baseball in here. We cannot play baseball here. @*Yes, I amn't. Yes, I am not. Yes, I'm not. ~*Who does cook breakfast? ~*Where they live? Who cooks breakfast? Where do they live? @*Does mr. brown have a book Does Mr. Brown have a book? @*We must stop to complain. We must stop complaining. Grammatical errors ~ @ are treated, but not","semantic errors ~> and absolutely ill-formed sentences","which are not comprehensible. The aim is to diagnose","grammatical errors and show a reason for the error. For","example: Input sentence; Mr Brown has a pen, correction; Mr. Brown has a pen. the reason; A period is needed after\" Mr\".","The comma after \"pen\" should be a period. 342"]},{"title":"3. Basic idea","paragraphs":["In this section, the basic idea of the frsmework and ~be problem of the LFG unification mechanism in dealing with ill-formed input is described. 3.1 Two -level filter","The framework uses two-level filters for input sentence classification: a well-formed sentence, a relatively ill-formed sentence or an absolutely ill-formed sentence as shown in Figure 1. (1)First an attempt to parse the input, using normal context-free grammar (Filter I ) is made~ Both a wello formed sentence and the relatively illoformed sentence which includes feature errors are passed through the filter (Filter I ). (2)Secondly, these inputs are checked with a strong filter (FilterII). A well-formed sentence passes, but a relatively ill-formed sentence does noL (3)An input which is not passed through the first filter (Filter I ), includes word-order or omitted-word errors~ or unnecessary words @ @. The input is classified by a filter (~), called Improper Grammar, as relatively ill-formed or absolutely ill-formed. j al~essed ~Iniut ..... \"~.-.. ~'--~rejected Filter ( I ) ]"]},{"title":"F-S:iltor( ) 1","paragraphs":["[ Improper Grammar /"]},{"title":"7","paragraphs":["Well-formed error corection failure (relatively ill-formed} (absolutely ill-formed) <~<~ <~ ~@ :sentence ~>~ number in Table1 Figure 1 Two-level filter 3.2 Filter test","Filter ( I ) is a context~free grammar. This filter is a weak filter. Therefore some relatively ill-formed inputs are passed. Consider how many sentences are derived from the grammar rules in Figure 2. 25 (5 × 1×5) sentences are generated by the grammar rules and dictionary entries. Of course, not only well-formed sentences as in (1) below, but also ill-formed sentences as in (2), (3), (4) below~ are included. Grammar rules"]},{"title":"Dictionary","paragraphs":["S--*NP VP : Verbal Phrase (VP) pronoun-*this VP--~verb NP verb -~is NP-*pronoun : Noun Phrase (NP) det ~an NP-~det noun noun -~apple NP-*noun noun --,apples","The generated sentences (1)This is an apple. (2)This is apple. (3)This is an apples. (4)This is apples. Figure 2 The generated sentences 3.3 The problem of the LFG unification mechanism f~o"]},{"title":"ill-formed input","paragraphs":["Relatively ill-formed sentences, as well as feature errors, pas;~ t~rough Filter( I ). Filter(II) must work as a strong grammatical filter. LFG contains such a strong filter, callc,d the unit'ication mechanism, '\"front F-. Descriptions to F-Structures fKaplan 1.982 (pp.203)/\". For exmnpl%","\"This is a apple\" In LFG a-disagreement, \"a apple\", is rejected because","the following equations are not unified. .;"]},{"title":"(t","paragraphs":["~]PEC) :a froma ( 1' SPEC) = an from apple","I~owever~ for diagnosis and error-correctlon there are :~ome drawbacks in LFG framework : (1)LFG canq: check an error of omission as in the noun phrase '~ apple' in the sentence","\"This is apple\". As tile sentence lacks the article \"an\", there is no determiner equation and the unification mechanism does not work. Thus the sentence is recognized as a well-formed sentence.","f O from (h :lack of article","( 1' iIPEC) = an from apple (2)LFG has no error-correction framework. It only rejects the ill-formed input. Addition of an error-correction mechanism i'~ thus necessary. 304 Improper Grammar [Filter (liD]","In this application, users are non-native speakers unfamiliar with English grammar. Thus, a user often makes word-order errors, includes unnecessary words, or leaves out words @ @. A teacher could show why \"does\" is not necessary in the sentence @ \"*Who does cook breakfast'S\", or wily \"do\" is needed in @ \"*Where they live?\". If a :~ystem diagnoses such sentences, it needs to provide the grammar rules tbr analysis. The type of error shown in Figure 3 is called improper grammar. *S *S q-pron *AUX VERB3 NP q-adv NP VERBI ( ~ SUBJ)= 4 ( t OBJ)= ~ I ( t SUBJ)="]},{"title":"I I I 1","paragraphs":["*wire doe~ cook breakfast ? *where they live ? Figure 3 Examples of improper grammar 4, '~?he fl°am(~wo~'k","In Ibis section an overview of the framework is explained. Unificagon approach has some drawbacks for diagnosis as we described in 3.3. A new method is used as a filter (lI). The idea is to compare input style with proper m, rfi~ce sty]~.s which are synthesized from lexical and grarmmaticai conditions. An interpretation schema collects l:he conditions (surface schema and LFG schema) and an L~[erpretation rule synthesizes proper styles and judges whether the sentence is ill- or well,formed as shown in Figure 4. In this section, at first, new schemata are notated: surface schema (4.1), surface constraint (4.2), in~e~°pre~ation schema, interpretation schema with condition, conditional schema and kill schema (4.3). And then the ins~mnfiation mechanism and interpretation of Input sentence .................... Jnpu~[q)ParsingPl'oce s sing .......... ~IFG schema'U\" rfaee s cjlem a .... wm,~{ I ~ l@Instantiation *"]},{"title":"J","paragraphs":["Surface constraint Filter( II ) J ~\"~T ~~"]},{"title":"I","paragraphs":["I mlnputsty le i-----~ (~Synthesize styles (= Proper styles) Success Error lfDCorrect sentence f-structure ~ Explanation of the errors","Figure 4 A schema method overview new schemata are described (4.4) (4.5). Finally error-correction is illustrated (4.6). 4.1 Inl~ut processing [Surface schema[","A capital letter and a punctuation indicate surface of an input sentence. In this framework such inibrmation is represented as a schema, called a surface schema. In the input processing, the input sentence is converted into surface schemata. The schema is notated as follows.","(gn f-name) =value \"gn\" is the designator which shows the word-order \"n\". \"f-name\" is a function name of schema, like word, letter or mark, etc. \"value\" is its schema's value.","For example, tile ill-formed input, \"MR.Brown have eat a apple,\" is represented as surface schemata in Figure 5. \"MR.\" is represented as lout-surface schemata:","\"(gl word) -- mr\"; the word is \"mr\".","\"(gl mark) =period\"; the mark after the word is a period.","\"(gl letter) = 1\"; the first letter of the word is a capital (\"M\").","\"(gl letter) = 2\"; the second of the word letter is a capital (\"R'). Input sentence: *MR. Brown have eat a -apl~ieV--I /","I","I I","I","I","*",", MR. , Brown , have , eat , a , apple,","designators L ..... ~ ......... J ...... ~_ ..... _L ...... ~ .......... r .....","-v","....... ~ .....","\"I-",".....","-r",".....","c",".........","ga ', gl ', g2 ', g3 I g4 *, g5 I g6 Surface schemata Word = [(gl word) = mr, (g2 word) = brown, (g3 word) = have,","(g4 word) = eat, (g5 word)-- a, (g6 word) = apple] Mark = [(gl mark) = period, (g6 mark) =comma] Letter -- i(gl letter) = 1, (gl letter) = 2, (g2 letter) = 1] Figure 5 Examples of surface schema 4.2 Lexicon [Lexical surface constraint[","In the lexicon, lexical features and constraints are involved as schemata. A constraint for a surface schema is called a surface constraint. A surface constraint is notated as follows:","(IT f-name) = ¢value. \"IT\" means meta-vm:iable. \"It\" is substituted for \"gn\", when the surface constraint is instantiated.","There are two kinds of surface constraints: lexical and granmaatical. The capital letter \"M\" in \"Mr.\" is a lexieal 343 constraint, because it is capitalized regardless of sentence position. A lexical surface constraint is assigned to the dictionary (Figure 6). (IT word) =cmr; the word must be \"mr\". (IT mark) = cperiod; the mark after the word must be a period. (IT letter) =el; the first letter of the word\"mr\" must be a capital.","Lexicon Lexical surface constraints and LFG schemata","neun3 Mr. (IT word) =cmr (t PRED-1) =mr","(IT mark) = cperiod ( t GENDER) = male","(IT letter) = cl ( 1' CATEGORY) = noun3","nounl Brown (ITword)=cbrown (~PRED)=Brown","(IT letter) = cl ( 1' PERSON) = 3","( 1' NUM) = SG","( 1' CATEGORY) = nounl Figure 6 Lexicon 4.3 Grammar ]Grammatical surface constraint]","The first letter in a sentence is always a capital letter and the last punctuation in a sentence is noted as a mark ( a period, a question mark or an exclamation point, etc.). These are regarded as grammatical constraints. In our h'amework these grammatical constraints are represented as grammatical surface constraints. They are assigned to grammar rul~ as shown in Figure 7.","(ITF letter) = ¢1; This means the first letter in the sentence must be","acapital letter. ITFshows firstorderinthesentence.","(ITL mark)=cperiod; This means the last mark in the sentence","must be a period. IT L shows last order in the sentence.","Grammar rule","S --* NP VP ( 1' SUBJ)= $ 1' = (ITF letter)=cl (ITL mark)=cperiod","Figure 7 Grammar rule with surface constraints [Interpretation schema]","In order to diagnose and correct errors, our framework has three steps; (1)collecting information on the input sentence, (2)synthesis of interpretation and (3) comparison of(l) and (2).","The interpretation schema collects LFG schemata and surface schemata. It is assigned to lexicon or grammar rules. In the parsing process, it is instantiated and collects schemata. The schemata corrected by interpretation schema are conveyed to the interpretation rule. This schema is notated as follows.","( T f-name) = i{values} T is a meta:variable as well as LFG notation and \"f- name\" is a functional name of the interpretation schema. Its Values are sets of schemata•","For example an interpretation schema for agreement between determiner and noun is notated as follows.","(~) ( t DET-NOUN)=i{[DET],[NOUN]} [DET] means set of schemata from determiner, and [NOUN] means from noun.","(Example 1) For the correctly-formed noun phrase \"an apple\", the interpretation schema, DET-NOUN, is attached to grammar rule (1) as shown in Figure 8. In instantiation, the interpretation schema collects LFG schemata in lexicon and surface schemata as its values below. 344 Grammar Rule and Interpretation schema (1)NP -* DET NOUN","( 1' DET-NOUN) =i{[DET],[NOUN]}",".....................................................","NP:fn ( 1' DET-NOUN) = i{[DET],[NOUN]} DET z / NOUN ~ 1 ! I x","~exico. I(t SPEC)='an' I"]},{"title":"I(1'","paragraphs":["PRED)='apple' '~ LFGschemata"]},{"title":"I¢*","paragraphs":["NUM)=SG"]},{"title":"I I¢t","paragraphs":["NUM)=SG ["]},{"title":"....... J , , lJ(t SPECl)='an/the'|","paragraphs":["An instantiated interpretation schema (~fn SPEC)='an' [fin PRED)='apple' -","(fn DET_NOUN)=i~[ (fn NUM)= SG |(fn NUM)=SG U (giwOrD)=an I/(t. SPEC1)='an/the'","A, [(gi+ 1 WORD) = apple _ Figure 8 An example of interpretation schema of\"an apple\"","(Example 2) In another case, the ill-formed noun phrase \"0 apple\", lacks an article. As above, an interpretation schema collects schemata in Figure 9.","Other examples of interpretation schemata and their attached grammar are shown in Figure 10.","Grammar Rule and Interpretation schema (2)NP -, NOUN","(~' DEW-NOUN) = i{[ ~],[NOUN]} An instantiatsd interpretation schema"]},{"title":"(fn","paragraphs":["DET-NOUN)=i O"]},{"title":"1 [fin NUM)=SG | / I(t-","paragraphs":["SPEC1)='ar~the'"]},{"title":"| /","paragraphs":["• J2Lg j WORD):apple A J Figure 9 An example of interpretation schema of \"0 apple\" [Interpretation schema with a condition","and conditional schema]","An interpretation schema with a condition, and its conditional schema are a pair and act as an interpretation schema. An interpretation schema with condition can act when there is a conditional schema. These schemata are notated as (a) an interpretation schema with a condition:","( ~' f-name) = i- CON{Values} and (b) a conditionalschema:","( 1' f-name) = CON{Values}.","For example, this schema (~) means that if a noun phrase [NP:f2] is a pronoun [PRONOUN], it checks whether the case of pronoun is subjective [subj[. If the noun phrase is not a pronoun, such as \"an apple\", there is no need to check.","(~ (f2 CASE) = i-CON[[NP:f2l,[subj]}.","The following schema (~) is its conditional schema. It is attached to grammar rule (5) and means the noun phrase is a pronoun.","(~ (f2 CASE)= CON{[PRONOUN]} [Kill schema]","A kill schema is the instantiation inhibition mechanism. It works to kill the interpretation schemata and is notated as follows:","( ~ f-name)=k{( ~ f-name-l), ( t f-name-2) ........ }.","(3)N~P ~-> D~T .... AOJ .~ ' NOUN","~(~' ~I)ET2ADJ-NOUN) = i{[I)ET],[ADJ],[NOUN]}","(4)NP -~ ADJ NOUN","(~' DET-ADJ-NOUN) = i{[O ],[ADJ],[NOUN]}","(5)NP ~ PRONOUN (~ CASE) :~ CON{[PRONOUN]}","(6)S:f1 --~ NF:f2 VERB3:Q NP:~","(fi SUBJ) :~ i'2 (h oBJ) = 5","(ITF letter) :: ¢1 (ITL mark) = cPeriod","(Q SUBJ&V-.FORM) = i{[NP:f2],[VERB3]}","(f2 CAGE) = i--CON{[NP:f2],[subj]}","(f3 CAGE) :: i--. OON{[NP:fa],[obj/poss]}","(7)S:fl .-~ NP:t2 AUX:Q VERB3:fI NP:f3 (il SUB J) ~: i2 (it onJ) = i'a (IT F letter) = cl (ITL mark) = cperiod (f~ SUBJ&A-FORM) = i{[NP:f21,[AUX]} (fl AUX&V-FORM) = i{[AUX],[VERB3]} (f2 CASE) =i._CON([NP:f2],[subj]} (f3 CASE) =~i~- C0~{[NP:f~l,[obj/poss]}","(8)S:it -,~ NP:f2 VERB-be:fl NP:f 3","(fl SUBJ) = f2 (fl COMP) = f3","(ITI,, letter) = c I (IT L mark) = cperiod","(t' 1 SUBJ&V-FORM&COMP) = i{[NP:f2I,[VERB~be],[NP:f3] }","(h SUBJ&V.-FORM&COMP) = k{(f2 DET-NOUN),","(f2 DET-ADJ-NOUN)} Interpretation Schemata Grammar rule ~) (T DET~NOUN)=I{[DET],[NOUN]} Rule(I)(2) (~ (I' DET-AI)J-NOUN)=i{[DET],[A1)J],[NOUN]} Rule(3)(4) (~ (t'I SUBJ&V-FORM)=i{[NP:f2],[VERB3]} Rule(6)(8) (.4) (fl SUBJ&A-FORM) =i{[NP:f2],[AUX]} Rule('/)","(f~ AUX&V-FORM) = d[AUXI,[VERB3]} Rule(7)","(fl SUBJ&V-FORM&COMP) = i{[NP:f~],[VERB-be],[NP:fs]}","Rule(8) knterpretation Schemata with condition Gramlnar rule ~) (f2 CASE) = i.~ CON{[NP:f?.],[subj]} Rule(6)(7)(8) Conditional ~chema Grarmnar rule (0_) (1\" CASE)=cON{[PRONOUN] } Rule(5) Kill schema Grammar rule (9) (f2 SUBJ&V-FORM&COMP) = k{(f2 DE'r-NOUN), Rule(8)","(f2 I)V.T-A~)J-NOON)}","@)This schema checks agreement between determiner, adjective and noun such as 'the same name', '*some good advices', '*a good jobs', and '*a interesting book'.","®This schema checks whether verb ibrm (V-FORM} is a proper tbrm for subject style (SUBJ). [NP:f2] is subject. For example \"Tom gives...\", \"*He laugh ...\", \"You made _..\" and \"*Mr,and Mrs. Brown laughs ...\".","(~)This schema checks whether auxiliary verb form (A-FORM) i¢,; a proper form for subject ~tyle (SUBJ). [NP:f2] is subject. For example \"*Tom have given...\" and \"He can laugh ...'.","@ This schema checks whether verb form (V-FORM) is a proper titan for auxiliary verb. For example '~l~om has given...\", '~*Tom has give..,\", \"*You can laughed ...\" and \"He is speaking ...\"","@This ~chema checks agreement between subjective","\"be\" noun phrase, verb . and compliment. [NP:f2] is subjective ~aoun phrase and [NP:fS] is compliment. For exaraple \"*These is apples.\" , \"*He is students.\" and \"*They are a student.\"","Figure 10 Examples of grammar and interpretation schema 1' is a metaovariable and \"f-name\" is a kill-schema's name. Its value in { ....... } is the killed schmnata's name.","There are hierarchy and priority between interpretation schemata. A kill schema is used to keep interpretation schemata independent. The schema attached to noun phrase can collect schemata only wiflfin the noun phrase, while the schema attached to sentence level can collect schemata in the sentence. Thus, the former is local and the latter is global. For example,","\"* This is a apples. \"","Tile noun phrase, \" a apples \", is wrong and should be \"an apple\". But the local interpretation schema ~ (Figure 10) can't determine which is correct, \"an apple\" or \"apples\", while the global interpretation schema @ can judge that \"an apple\" is correct. The global interpretation schema ® checks ibr agreements within [NP:fS] instead of the local interpretation schemata (~) or ®. Therefore, the local interpretation schemata (J) and (.2), are not necessary. Thus, the kill schema @, which corresponds to the global interpretation schema @, kills local interpretation schemata Q) and ®.","@ (f2SUBJ&V-FORM&COMP) = k{(f2 DET-NOUN),","(f2 DET-ADJ-NOUN)}","(~) (f2 DEW-NOUN) = i{[DET],[NOUN]}","(~ (f2 DET-ADJ-NOUN) = i{[DET],[ADJ],[NOUN]} 4.4 lnstantiation","How to instantiate schema is explained. Both t and ~ - meta-variables are assigned to actual variables (f l, f2....) as well as LFG.","A surface schema, a surface constraint and an interpretation schema include \"IT\" meta-variables. \"IT\" recta-variables are assigned as follows. (Din input processing, the designator \"gn\" which shows the word-order in the input sentence is assigned to surface schema. (2)When' the dictionary is looked up, surface constraints in the lexicon are instantiated. \"IT\" meta-variable in a surface constraint is bound to the designator \"gn\" in surface schema. (3)When a grammar rule is fitted, surface constraints in the S: fl Grammar","NP:f2 AUX:It VERB3:fl NP:fa (fl SUBJ)=f2 (fl SUBJ&A-FORM)=i (it OBJ)=fa"]},{"title":"~","paragraphs":["(gl letter)~-¢l {[NP:f2],[AUX]} (g6 mark) =cperiod CASE)=i-CON (fl AUX&V-FORM)=i f(f3 CASE)---i--CON {[NP:f2],[subj]} {[AUX],[VERB3]}/ {[NP:fa],[obj]}","noun3 nounl l det noun","! ~( f3 DET-NOUN) = i ] | [ [ ~ {[DET],[NOUN]} \\ : Lexicon \\ : (~. (gl word) --cmr ~ : ~ : ~ ~ ~ ~\" ~'~ 6 wOrd)-~ capple (~) (gl word) = mr g2 g3 g4 g5 (g6 word) = apple","Mr. Brown have eat an apple Figure 11 An example of a parsing tree and instantiation mechanism 345","grammar rule are bound to tire designator \"gn'. An example is shown in Figure 11. 4.5 Interpretation (Filter It)","After the parsing proces.% interpretation schemata, interpretation schemata with a condition, conditional schemata and kill schemata are instantiated. Interpretation schemata are interpreted by interpretation rule. Input is judged for consistency or inconsistency.","The interp,'etation schemata are independent, thus the interpreted order is free. The interpretation flow is as follows. (1)check conditional schema: if it is an interpretation schema with condition, find the paired condition. If conditional schema are not paired, inhibit the instantiated interpretation schema with a condition. (2)check kill schemata: if the kill schema includes interpretation schemata which should be killed, inhibit the instantiated interpretation schema. (3)Interpretation rule: if it is not included, interpret it. [Interpretation rule I","An interpretation rule diagnoses the input sentence. The schemata collected by an interpretation schema are checked by an interpretation rule. An interpretation rule synthesizes the word by using collected schemata. The diagnosis process is as follows. (1)Find input style from an interpretation schemata. (2)Synthesize correct style by •using an interpretation rule. (3)Compare input style with synthesized style, if consistent, the input style is right. If not, correct the input style to the synthesized correct style.","An interpretation rule synthesizes the result with conditions from interpretation schema. For example, the I)ET-NOUN rule is Shown :in Table 2. This rule determines if the noun is corrected and synthesizes the specification (SPEC) tbrm as adapted for the noun.","(Example 1) In the case 0f correctly-formed noun phrase \"an apple\", the interpretation rule is shown in Figure 8. (1)input style: (gi word)=an, (gi+l word) = apple from surface schemata in Figure 8. (2)synthesized style: conditions are (~'NUM)=SG, ( '~ SPEC1)= 'an/the' from noun and ( i\" SPEC) ='an' from determinant in Figure 8, the result is (~ SPEC)=an from Table 2 Interpretation Rule for DET-NO_ UN Rule No. I 1 2 3 4 5 7 --, 9 10 I"]},{"title":"I__!L_A","paragraphs":["Conditions NUM SPEC1","From noun From noun PL the PL a PL an PL ~D SG a/the SG a/the SG a/the SG an]the SG an]the SG an]the SG X","Result SPEC I SPEC","Frem dot ~-- I the \"- I O *- I O a i a the I the -\" I a an , an the I the -- I an I X Rule B in Table E. (3)Compare '(gn word)== an' with '( t SeEC)=an '. Th~ value is the same. Thus this noun phrase is correctly.-ibrmedo","(Example 2) In the case of' the ill~tbrmed noun phrase \"(D apple\" which lacks an article, the interpretation rules are shown in Figure 9. (1)input style: ~, (gj word) :--= apple fYom surface schemata. (2)synthesized style: conditions are (]'NUM):=::[~G, ( 1\" SPEC1) =: ~an/the' from noun, the re~';ult is ( ~ SPI~C)---- an from rule 10 in Table 2. (3)Comparison O with ( $ SI'EC)=an, as a result it lacl~:s the article \"an\". Add the surface constraint \"(gn -0.5 wo, rd):::c an\" beibre \"(gn word) = capple\". 4.6 Error eorrecLion","The error correction phase explains the erroz to the user. For example, \"*MR. F, rown have eat apple/~ the f:low of'error correction is shown in Figure 12. input sentence i~ converted into surface schemata and parsed. Surface constraints and interpretation schemata are then obtained. These interpretation rules are diagnosed and three errors found; (1)SUBJ&A-FORM, (2)AUX&V.FORM and (3)DleT-.i'~OUN Input sentence: *MR. Brown have eat apple, ....... -~-- - - (Input processing) ............................... Surface schemata Word = [(gl word):= mr, (g2 word) = brown, (g3 word) =: have,","(g4 word) :: eat, (g5 word) =: apple] Mark-: [(gl mark) : period, (g5 mark) : comma] Letter = [(gl letter) := 1, (gI letter) == 2, (g2 letter) : 1]",":~ (Parsing and instantiation) Surface constraints from lexicon and grammar rules Word: ¢[(gl word) := cmr, (g2 word) : thrown, (g3 word) : ehave,","(g4 word) :: coat, (g5 word) : eapple] Mark: c[(gl mark) = cperiod, (g5 mark) =: cperiod] Letter: c[(gl letter) --- ¢1, (g2 letter) : ¢1 ] ...... -~- .... (Interpretation) \"-~ .......................... Convert (1)SUBJ&A-FORM: (g3 word) = chave -~ (g3 word) :=(:has (2)AUX&V-FORM: (g4 word) = coat ~ (g4 word) =ecaten (3)DET-NOUN: (g5 word) ~: apple","~-~ (g4.5 word) = can, (g5 word) = apple (4)MARK: (g5 mark) : comma-+ (g5 mark) =:cperiod (5)LETTER: (gl letter) --~ 2 -~ ....... -~- .... (Error corection) ........................... Surface constraints replaced by synthesized schemata Word = e[(gl word) = cmr, (g2 word) := ebrown, (g3 word) = ehas,","(g4 word) = eeaten, (g4.5 word) = can, (g5 word) ::: eapple] Mark-- e[(gl mark) = epcriod, (g5 mark) = cperiod] Letter =~ ¢[(gl letter) --- el, (g2 letter) =: el ]","the correct sentence : )]/r. Brown has eaten an apple.","the reason : 1)\"have\" must be \"has\". 2)\"eat\" must be \"eaten\". 3)\" an\" is needed befbx'e \"apple\". 4)\"W' in \"MR\" must be a small letter. 5)\"comma\" af~er \"apple\" mu~t bc \"period'*.","Figure 12 An example of error correction 346, (;,Vigure 10), Fmih~('w_ore, surface errors, (4)MARK and (5)I,ETTER, a~'e l~rlmd by the difference between surface :~chen-mta at~d surface constraints. The surface constraints are replac¢~d by ~;ynthesized schemata. The corrected seaten,:e, \"Mr. Brown has eaten an apple. \", is then synthe~:.;zed ~Yom surface constraints. The explanations 1) ~ °5) are g, mcrated by tim result of interpretation rule.","This i}'m~,ework to a CAI ~;ystem, called\" :],~ :,i{}(English) (JA[\"~ was applied and designed to teach English to junior hiKh ;-mimol students. This :.~y~tem has two main modules; (l)machine translation/Kudo 19g(i/and (2)this Crm,lework. If stm!e~t~: p~'oda(:¢~ ill..fiwmed English int)nL, the sy~tem corrects the errors arid shows"]},{"title":"why","paragraphs":["they are wren F. If there are no erro~'s~ gi~e sentence i.~ translated into Japanese.","This sy,~i.em was implemented i~ Prolog (about 120KB). Performam~e is reul-.tir~,e (answers within 5 seconds). Actually t,his system was ilscd by junior high school st,dents° We collected mistakes and then ted back to th,; system°","This ~Lystem is one of applications of this ]Yamework in a limited d(m) aii). The framework is easy to apply to another domain. To construct a m',,v system, only need be changed the grammar, dictionary and interpretation rulcs. 6, i~imitati,, m and futm,e worl~","The ti'a:mework/b.c grammatically ill...Ibrmed input was described~ (1'he following problems remain unsolved: (1)The _ Im ui(m of semantically illdbrmed input: in this framework a semantically ill-..formed sentence is passed. A scma~,~.ic iii ~er mast be added alter filter ( l I ). (2)The problem of interpretation: interpretation is often changed by context and situation. Human beings correct ill-formed sentences by recognizing context and situation. Fo~\" example, I1, is a boy?","Which ic Lerpre~ation is right, dialogue situation, word.. order error Cls he a boy ?) or misimnctuation (He is a bay.)? A system wil) need a context recognizer and a situation recognizer~ C(meiasio~ ~","This paper has suggested the schema method, a new i~amework tbr correcting ill-formed input. This fl'amework recognizes input at two steps with weak and strong filters. When it is known what sentences are passed by the filter, it ca~ be u:~ed even if' imperfect. This method has the tbllowing ad vantages: Cl)the proL([cul of control strategies for relaxation can be avoided beet tase the relaxation teelmiqae is not used, and (2)comfmtational efficiency°","The LF(i~ floamework tbr correcting grannaatically illfi)~-med input was extended; a. mlrface schema and an i~terpretation schema have bee~ proposed. This fl\"arnework ca~, correct enters without breaking LFG fi'amework, because these schm~mta, as well as LFG schema, cab be treated. Therefbre to make an applied system is very easy. This tYamework was implemented in Prolog to devise.a ~J~ef'ul CAI system° Acknowledgment","We would like to thank Akira Kurematu, president of ATR Interpreting Telephony Research Laboratories (ATR) and Mr.Yada, president of CSK Research Institute (CRI) for their constant encouragement. And we would also like to acknowledge the helpful comments of Hitoshi Iida (ATR). Many thanks also to Hideo Kobayashi (Nishi-Sugamo Junior High School), Kenji Okamoto, Yoshio Ooyama, Kei Okabe and Syuuichi Tanaka (CRI).","References","Carboneli, J.G.&IIayes, P.J. (1983)' Recovery Strategies for Parsing Extragramnmtical Language' American Journal of Computatienal Linguistics, Volume 9, pp.123-146.","/iayes, P.J & Mouradian, G.V. (1981) 'Flexible Parsing' American Journal of Computational Linguistics, 7(4), pp.232-242.","lteidorn, G.E. (1982) 'Experience with an Easily Computed Metric for Ranking Alternative Parses' Proceeding of 20tll Annual Meeting of the ACL. Totont, Canada, pp.82-84.","lleidorn, G.E,, Jensen, K., Miller, L.A. Byrd, R.J. and Codoro, M.S. (1982} 'The EPISTLE Text-Critiquing System' IBM Systems Journal 21 (3), pp.305-326.","Jensen, K., IIeidorn, G.E., Miller, I,A. and Ravin, Y. (1983) 'Parse Fitting and Prose Fixing: Getting a Hold on ill-formedness' American Journal of Computational Linguistics, Volume 9, Number 3-4, July-December, pp.147-160.","Kaplan, R.M.& Bresnau, J. (1982) 'Lexical-Functional Gramnmr: A Formal System for Grammatical Representation' In:Bresnan, d. (ed) 'The Mcmtal Representation of Grammatical Relations', The MIT Press, Cambrige, Massachusetts, pp. 173-281.","Katie, 1. & Nomura, H. (1986) 'LexicaLfunctional Transfer: A Transfer Framework in a Machine Translation System Based on LFG', Proceeding of 11th International Conference on Computational Linguistics, Bonn, August, pp.112-114.","Kwasny, S.C. & Sondheimer, N.K. (1981) 'Relaxation Techniques for Parsing Grammatically Ill-formed Input in Natural Language Understanding Systems' Ammqcan Journal of Computational Linguistics, Vol. 7, Number 2, April-June, pp.99-108.","Matmnoto, I.& Matumoto, Y. (1976) 'A Practical IIandbook of Common Mistakes in English among Japanese Students and Businessmen', ltokuseido","Schank, R.C .& Leboeitz, M. & Birnbaum, L. (1980) 'An Integrated Understander' American Journal of Cmnputational Linguistics, Volume 6, Number 1, January-March, pp.13-30.","Schuster, E.(1985) 'Grammar as user models' Proceedings of the Nineth International Joint Conference on Artificial Intelligence, August, Los Angeles, California, pp.20-22","Weischedel, R.M. & Black, I.E. (1980) 'Responding Intelligently to Unparsable Inputs' American Journal of Computational Linguistics, Volume 6, Number 2, pp.97-109.","Weischedel, R.M. & Sondheimer, N.K. (1982) 'An hnproved Ileuristic for Ellipsis Processing' Proceeding of 20th Annual Meeting of the ACL. To(on(, Canada, pp.85-88.","Weischedel, R.M. &'Sondheimer, N.K. (1987) 'Meta-rules as a Basic for Processing Ill-formed Input' ln;R.G.Reilly (ed.) Cmnmunieation Failure in Dialogue and Discourse, Elsevier Science Publishers B.V. (North-Holland), pp.99-120. 347"]}]}