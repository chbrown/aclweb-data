{"sections":[{"title":"19","paragraphs":["1965 International Conference on Computational Linguistics PUSHDOWN STORES AND SUBSCRIPTS Jacob Mey Lingvistisk Institutt Universitetet i 0slo PoBo 1012, Blindern, Oslo 3, Norway."]},{"title":"t-~,,%% \\ ,,,.o.,tt<><~/ ' -_Si\" Mey 2","paragraphs":["PUSHDOWN STORES AND SUBSCRIPTS Abstract Va~rious devices for the imp rovement of phrase structure grammars (PSG) have been suggested recently. In particular, the PSG model with a pushdown store (PSG/PDS) a s described by VoYngve, and the PSG with subscripts (PSG/S) as described by G oHarman are considered. It is contended that such devices, even if they may do away with some of the difficul_ ties of PSG, do not contain sufficient gene_ rative power to produce the structurally corn_ plicated sentences that are generated by other gramma rs (e.g., of transformational type). The handling of multiple disco,Ltinuous con_ stituents (DC) in PSG/PDS, as well as the use of :leletion rules in PSC./S is examined and criticized. It is shown that the improvements on PSG will not allow the grammar to generate a ii the sentences of the language that a trans_ formational grammar (TG) does; moreovdr, the improvements on PSG a re obtained only at the cost of introducing too much power at the PS level, so that the improved gr;~mmars in some cases will exceed the requirem@nts of the de_ scription, i.e. generate non_grammatical sent_ ences. Mey 3 O. Introduction NoChomsky has argued that a PSG is not suff_ icient to generate all the grammatical sent_ ences of a language (Chomsky 1957:3~ ff.). Recently, this conceotion of PSG has been criticized as being too primitive (Yngve 1960:445a, Harman 1963:604 fro), and several ways of improving such a grammar have been suggested: a PDS has been connected with a PSG (Yngve 1960, 1961, 1962); the use of subscript notation has been recommended to give PSG a fair chance in competition with TG (Harman 1963). i. PSG/PDS l.lo PSG and DC The problem of the so_called discontinuous sonstituents (for a detailed treatment, see Wells 1947:96 ff.) has always been a crux in IC analysis. One of the drawbacks of PSG as described by Chomsky, is that it is not able to handle these constituents in a way that satisfies both the formal criteria of the grammar and the intuitive feeling that call and up in, e.g., I called him u~, belong to_ gether and should be treated accordingly in the analysis. Chomsky, in his discussion of PSG limitations, admits the possibility of \"extending the notions of phrase structure to account for discontinuities\" (Chomsky Mey 4 1957:41), but, he adds,"]},{"title":"\"...fairly","paragraphs":["serious difficulties arise in any systematic attempt to pursue this course.\" An attempt in this direction is described by V.Yngve in several articles (see especially Yngve 1960); a lthough the presence of DC is the most annoying of the complications under the PSG model (Yngve 1960:448a), the solution ~ffered to this particular problem implies a wider claim, namely, that \"any shortcomings /of PSG, JM/ can be overcome\" (Ib.:445a). Accordingly, I will discuss be_ low not only the problem of DC, but also the more general one of structure in a PSG/PDS. 1o2o DC and PDS The crucial step in the derivation of DC by the automaton (for a full description, see Yngve 1960:448_9) is the question asked: Does the right half of the grammar rule in question (GRi) contain the symbol \"...\" ? (where \".. o\" stands for \"discontinuity in rewriting the symbol on the left hand side of the rule\") If the answer is Yes, we have to roll out the temporary memory (TM) ta~e one space (in a flow chart, one woul~ sym_ bolize this by the index notation 1 --I --> i, where 1 stands for \"leftmost\": \"rolling in\" tape would then be indicated by 1 + • --> i, see Fig. ~). During this"]},{"title":"operation,","paragraphs":["the original content of TM 1 (the leftmost loca_"]},{"title":"Mey 5","paragraphs":["tion of TM) has to be kept in place, that is, the blank has to occur after the original TM 1 (on the right side, if the tape is thought of as moving from the left, see Fig° ~). If, how_ ever, the answer is No, we have to make sure that we have space for all the symbols on the right hand side of the rule and roll out tape accordingly. Let ~ be the number of symbols on the right hand side of GRi: then we can symbolize the rolling out by the index formula i -- (n -- ~ the first symbol always goes to the computing register. Let further ~ be the subscript for right hand side symbols of GR i. The rest of the operation","is then performed as routine counting on GRi. , 3 i being set at 2 (the first symbol has already been taken care of). There should, of course, be a proviso for the symbol \"...\" itself, so that it will not be copied onto the TM taoe. The method as described here will work neatly even in those cases where DC are \"nested~ that is, if the expansion of some DC turns out to be another DC (and so on, at least theoretical_ ly). As an example, one may try out the doubly discontinuous as far as the corner, where all the necessary rules are sDeclfied by Yngve himself (1960:449a). An implicit assumption throughout the descrip_ tion of the mechanism is that DC can be repres_ ented by the simple formula A --> B + 9,o + C. It follows that there are two cases that cannot Mey 6 be handled directly by the machine: the first one can be symbolized by A --> B + ... + C + ... + D (\"mul~ple discontinuous constituents\"); this reduces easily to double discontinuity by a suitable manipulation of the inout rules. The other case could be labeled \"discontinu_ ous multiple constituents\": formula A --> B + C + ..o + D (or some variation on this theme), which would imply that the blank has to occur two spaces from leftmost ins~ad of one. Foll_ owing the instructions given by Yngve we would not obtain the right string of symbols in this case (as examples, one may try: He's not that bin a fool, or: As nice a little parlor as ever you did see, or the Soanish sentence: Habla mas de lo que sabe 'He talks more than what he knows' (Bolinger 1957:63), where common sense would prefer the analyses"]},{"title":"that","paragraphs":["bi~ ... fool, as nice"]},{"title":"(","paragraphs":["• .. ~arlor, mas de ... que see diagrams in Fig. 2), thus pre3erving analogy with construc_ tions like such a fool etc. The program could be accommodmted to perform this by combining a counting operation with the check on \" \" o.o , whereafter the continuous part of GRi's right hand side could be thrown in with the non_DC rules. Derivation being different, there would be no interference from constructions like that big fool, that are treated in the normal way by the machine. A device like the one described here will, within its obvious limitations, be able to randomly generate sentences that are for the most part quite"]},{"title":"grammatical","paragraphs":["(Yngve 1962:70). Mey 7 The question is: will it generate all, and only, the grammatical sentences of a fang_ uage? I will try to answer this question in the next paragraph. 1.3. Limitations of PSG/PD ~ Although the model as proposed by Yngve in its original form only uses the PDS technique to solve a minor problem in syntactic analysis by the machine, the scope and use of PDS are by no means limited to this particular pro_ blem of DC (For a detailed discussion, see Oettinger"]},{"title":"1961:126_7).","paragraphs":["The elegancy and sim_ plicity of PDS algorithms make them well_ suited for procedures of automatic syntactic analysis of languages. There are, however, some inherent limitations. Common to all PDS techniques is the fact that information stored in this way only is access_ ible in accordance with the formula \"last in, first out\". Being essentially a linear array of information (Oettinger 1961:i04), the user (the machine) will not be able to draw on other information than is given by the leftmost sym_ bol in a left_to_right production (the temDo_ rary memory tape in Yngve's machine, see Fig.l). Since, on the one hand, the machine output is past control (what is Drinted, is no longer available to the machine for inspection) and, on the other hand, the internal state of the machine is entirely determined by the current input symbol, one has to keep careful account"]},{"title":"Mey 8","paragraphs":["not only of the current derivatlonal steps, but also of the \"left_overs\" from earlier steps. This is exactly what a PDS can do, and the ~roblems in connection with this technique are, as shown above in the case of the so_called discontinuous multiple constituents, are mainly technical (provid_ ing indexes etc.) The linear character of the memory, however, together with the finite state oroperties of the model itself give rise to a~other problem that seems unsolvable under the following ass_ umptions for our machine: a finite number of states, a linear temporary memory, and a transition from one state into anether by one_ symbol inout. The problem is the following: given any internal state of th~achine that is determined by more than one symbol simultane_ ousiy, will the supplementary device of a PDS be able to suDply the necessary instructions to the machine that are not contained in the current symbol? The answer is in the negative, precisely be_ cause the memory is linear, and there is no \"look_up\" for items in the memory° What is stor_ ed in the memory can only be brought up to the surface by something outside the memory itself, that is, I have to create an \"expectancy\" that is specific for each item in the PDS. Only under these conditions the state of the machine can be defined as determined by the current symbol plus the oontents of the temporary mem_ ory (Yngve 1960:~49). This is essentially the"]},{"title":"Mey 9","paragraphs":["procedure described by Harris for keeping track of nested constructions (\"incurrence and discharge of requirements\", Harris 1962: 53). The reason why the machine is able to handle DC is that this \"nesting\" occurs in one level, so that the symbols involved can be uniquely determined as belonging to the same dimension of analysis. Where \"surface structure\" is explained only by underlying \"deed structure\" (Hockett 1959: 246 ff.), the machine will not be able to carry out the analysis correctly. The structure that underlies a symbol X 1 may be bound up with a special PS derivation, so that rules concern_ ing structures like, say, X 1 + X 2 + X~ will be ambiguous in their a~plication. One could place restrictions (in Harris' sense) on (one of) the symbols, thus creating a multiple path through the derivation, possibly combined with a cycling device: this is what the subscriot technique does, see 2.4 for a detailed discuss_ ion. Some of the difficulties are removed in this way, but others persist, like those cases where pairs of symbol formulae are involved (the so_called \"~eneralized transformations\" of early TG, Chomsky 1957:113); this point is also discussed below. While placing too many restr_ ictions on the symbols has serious disadvant_ ages (some of which will be discussed in sect_ ion 2 of this paper), it certainly exceeds the capacity of the model as described by Yngve: his rules are all of the context_ free form. Mey I0 Thus, structure in a sufficiently powerful PSG is not only a matter of specifying the right rules, but also of choosing the right rules and combining them at the right places. There is still another factor that we have left out of consideration so far: the order_ ing of the rules. Yngve states that any order will do: an alphabetical order may be conven_ lent"]},{"title":"(1960:445)o","paragraphs":["NOW this has two consequen_ ces: first, all of the rules have to be run through every time a symbol is expanded (per_ haps only a minor drawback in a computer_ oriented analysis), second, the advantages of ordered rules (economy, elegancy, accuracy) are lost (\"forcing all kinds of low_level detail into the rules\" , Bach"]},{"title":"1964:53)","paragraphs":[". Besides, ordering of the rules is indispensable in cases where complicated high_level structural descriptions are involved: thus an immediate derivation of each non_terminal symbol all the way down to word level would not be permitted in any kind of PSG, not even the most context_ sensitive ones. Being es~entially context_free, Yngve's grammar will 6~enerate what is usually called \"kernel sentences\" (Chomsky 1963:152): unambiguous derivation of more complex struct_ urea (derived sentences) will only be feasible under a careful specification of the order in which the rules have to apply (as an example, cf. the discussion of w__hh_transformations as depending on the interrogative transformation in Chomsky"]},{"title":"1963:140).","paragraphs":["Mey ii There is another way out of the difficulties that have been sketched in this section: phrase_ structurizing at different levels, these being kept together by the representation relation (see Sgall 1964b). This solution is based on a somewhat different interprd~tion of PSG functions (not only syntactic, but also semant_ ic rules az'e included); a PDS is coupled with the PSG of the lowest level. A detailed dis_ cusslon of this system will have to wait for more details, but it seems that grammars based on dependency relations have received too little attention so far (for a compalison of IC and dependency theories, see Hays 1964:"]},{"title":"519_22)o","paragraphs":["1.4. Grammar and psycholqgy Referring to experiments performed by G.Ao Mill~r, Yngve establishes an analogy between the \"depth\" of memory ~n the human brain and the depth of sentence construction in the model (1960:452). The human brain is not capable of stvrlng more than, say, seven plus minus two items a t a time (for references, see Yngve ibid.). In other words, the human brain has a limited capacity, just like the temporary mem_ ory of Yngve's machine. One of the conditions to be put on a flawless handling of \"deep\" constructions is that the storage capacity is not exceeded by the number of symbols to be developed later on. In this connection Yngve makes the in~ere~ting observation that senten_ ces and constructions in general actually do Mey 12 have a sort of limited depth, i.e. the number of regressive nodes is bound by more or less the same uoper limit as that for human memory's simultaneous storage caoacity. Now, I think that the analogy between the two kinds of \"storage\" should not be overstressed. It rests primarily on the tacit assumption that the model should, or could, be considered as a more or less true_to_life representation of human linguistic activity. As I have remark_ ed before, this supposition is altogether groundless, and will at best hamper an exola_ nation of such activity in truly linguistic terms. A remark made by Yn{~ve in this connect_ ion may clarify the issue. Yngve says (1960: 452b; see also 1961:135_6 for an even more ex_ plicit commitment): \"The depth limitation does not apply to algebra, for example, because it is not a spoken langua_ ge. The user has paper available for tempmrary storage . \" But so has the user of any other language, e.g, human everyday sooken language. The fact that we do not use paper actually when speaking has nothing to do with greater or lesser depth of sentences (or, if it does, the depth differences occur only to one side, namely that of decreas_ ing depth). One could pursue this analogy ad ab_ surdum by assuming two kinds of depth, one un_ limited, for written languages, and one limited, for spoken languages. The results would be dis_ astrous for any description of any language: sentences of the type: \"That that that they are Mey 13 both isosceles is true is obvious isn't clear\" (Yngve 1960:458b) are as ungrammatical in written as they are in spoken English. Of course Yngve is perfectly right in attribut_ ing the difference between the above non_ grammatical (deep regressiv~ that_clause and its grammatical (progressive) counterpart: \"It isn't clear that it is obvious that it is true that they are both isosceles\" to ex_ cess depth. So, there is a depth limitation and this limitation is gramatically relevant. But this linguistically fruitful concept should not be confounded with hypotheses from des_ criptive psychology. That the claim for descriptive similarity be_ tween psychology and linguistics is latent in Yngve's model can be seen from another instan_ ce. ]Iis second assumption for the model"]},{"title":"(1960:","paragraphs":["445) is that \"the model should share with the human speaker o.. the prooerty that words are {~roduced one at a time in the proper time se_ quence, that is, in left_to,right order ...\" (the first assumption, vim. that any shortcom_ ings of the PS model can be overcome, has Dart_ 1y been dealt with above, and will be treated at length in the second half of this paper). This restriction, I think, on a model (or a grammar, insofar as the grammar is based on the model) is unnecessary and self_contradict_ ory. It is unnecessary, since the model should only copy relevant traits in the speech pro_ duction of the individual; and even though it may be true that words are produced in a linear Hey 14"]},{"title":"sequence (as already Saussure has remarked), it","paragraphs":["has not yet been shown how this linearity is to be interpreted in human speech production: I think it is only weakly relevant, that is to ssy, linearity alone will never suffice to give a complete picture of the speech event. For a full_fledged description of speech I suppose the assumption that we speak in senten_ cesra ther than in words will have many advant_"]},{"title":"ages.","paragraphs":["Moreover, the claim that the model should du_ plicate the property of left_to_right product_ ion in the human speaker cannot be brought to harmon2ze with the model. In fact, the model can only examine one symbol at a time: the machine may erase or delete or read only that section of the memory tape that is closest to the roll, i.e. the leftmost symbol only (Yngve 196o:446). Now, the limitation of human memory is on re_ I)roducing more than a certain number of items at the same time. The analogy clearly does not hold between human memory and machine storage: the explanation is that the machine produces symbols, whereas the speech of humans is struct_ ured. In other words, a left_to_right product_ ion may in many cases be explained by a linear structure in the oroducer; the pushdown store is a linear memory device. But there are other left_to_right productions that are structured in such a way that a PDS or other left_to_right arrangements will not suffice. It is of course true that a structural description is not alto_ gether absent from a PSG/PDS: Yngve's machine produces as its output a string of symbols Mey 15 containing both syntactical markers (\"flattened_ out trees\") and terminal symbols. This will suffice to \"infer the derivational history of each string from that string in a single way\" (S~all 1963:41), but only insofar as the struct_ ure can be described in one_level terms, cf. discussion above (see also Sgall 1963; 1964a). The question will be treated at length in part two of this paper."]},{"title":"2 p so/s","paragraphs":["2.1. The subscript notation The subscript method referred to here is not in the first place thought of a s a machine v program (even though its close affinity ~ith the computer language COMIT is asserted, see Harman 1963:608fn.). Accordingly, it has a more general scope: namely, to offer a full_ fledged alternative, in PS form, to other grammars (e.g. of transformstlonal obedience), thereby proving that \"transformational gramm_ ar has no adva ntage over the phrase struct_ ure grammar\" (Harman 1963:598). • ubscripts are added to the PSG rules in two ways: first, to introduce restrictions on such rules, second, to s:~ecify where those restr_ ictions apply. An example of the first kind is the rule S --> S1/NUMBER_SG (Harman 1963:609), and, in general, any rule of the type A --> B/J + o,o . The second case obtains e.g. in the following rule: NP/NOT_WI{ --> DETERMINER + NOUN, and, of course, in all rules where subscripts Mey 16 a re \"lost\" during expansion. I think there will be a third type as well, even t|iough this is not expressly mentioned in the articLe, namely, sub_ scripts that do both: introduce new subscripts at places indicated by old ones; but this is on_ ly a minor point. More important is the obser_ vation that subscripts can take care of all sorts of const itueJlts, both continuous and dis_ continuous. For the latter, the generation ru_ les are adapted Prom rules suggested by Victor Yngve (IIarman 1963:606; the reference quoted is Yngve 1960). Like in Yngve's model, the rules of PSG/S are unordered: all necessary informa_ tion about when and where to a'iply a rule is contained in the subscripts (which, by the way and perhaps afortiori, are said to occur in an unordered sequence). But, as will be seen from the following paFsgraphs, this \"when\"and \"where\" is not only a notational problem: in fact, it is one of the big underlying differences be_ tween PSG and TG. (0n the difficulty of ordering rules in a PSG, see Chomsky 1957:35). A further important difference from other PSG interpreta_ tions is the admission of deletion rules, that is rules of the form A --> @ (Harman"]},{"title":"1963:60~);","paragraphs":["also this point will be discussed at length below. 2.2. Subscripts And Transformations In general, One cannot deny the possibility of incorporating (by means of subscripts or other devices) some of the information that is con_ tained in a transformational grammar into a Mey 17 ~ne_level grammar of PS type. But the grammar thus constructed will never generate all and only the grammatical sent_ enc~s of the language. Either it will generate too little (the normal case for PSG without subscripts or similar devices) or, if it gen_ erates more, it will also generate some non_ grammatical sentences (Harman 1963:611:\"... not all sentences constructed in accordance with this grammar 'are well_formed.\") A very simole example will show this. Supoose we ~ant to transform optionally a sentence in_ to its question counterpart. To do this in the PSG/S according to Harman, we have to choose an appropriate expansion of the symbol $2 (the same paths hold for number_ and mode_ restricted S : S1, resp. S2, Harman:600), na_ mely either the second or the fourth rule in 3., the set of expansion rules for $2. We choose the second rule (normal question, the fourth rule concerns wh_questions): S2 --> VP/TYPE_QUES,NOT_WH + NP/CASE_NOM,NOT_WH. Now, note two things: in order to conform to the rules for this grammar, we have already added some of the subscripts from Rules 1 and 2 to the symbol $2 (e.g., NUMBER_SG and MODE_ACT). These subscripts, together with the new ones, are to appear on every symbol that is contained in every rule from now on (unless a delete sub_ script is introduced, cf. below). This is nec_ essary, since we cannot let any information that is conveyed by the subscripts be lost, even if Mey 18 it be irrelevant to the symbol in question (such as, say, a MODE restriction on a NP). One can easily imagine that rewrite rules of this type soon become very unwieldy ( even if we do not allow ,urselves to be frightened by the prospects of \"millions of rules\", Harman:605). Thus, in rule 7 of this comparatively simple grammar we already have 6 subscripts to each symbol. This number is substantially increased in the more elaborate version of the grammar (see Appendix to Harman's article). This is certainly not what one would call simplicity of description. [Jut objections of this kind can be met by the following consideratiun: even if the multiDli_ cation of entia, i.c. symbols and subscripts, seems without rationale for humans, one can conceive of it as 8 necessity for computer data handling, and the computer certainly does not mind going through all the subscripts, adding some, deleting others, etc., every time a sym_ bol is mentioned or expanded. So, if one has a working program in which these restrictions can he written out as subroutines, and if the com_ i)uter space needed does not exceed that avail_ able, the objection just made does not hold (cf. Harman:61Ofn.: \"Many of these grammars are in the form of computer programs for generating actual sentences.\") The other question is far more important. It can be split up into ~¢o"]},{"title":"parts:","paragraphs":["i. Can all the data of the grammar be put into the subscript_restriction schema? 2. Will the subscript_restriction schema not Mey 19 put more data into my grammar than wnnted? The first question concerns the adequate re_ presentation of the structure, the other ex_ presses the fear that I may add structure to my grammar, thus oroducin~ sentences that are not grammatical (see Chomsky 1962:514ff.) Adoptin~ a distinction made by Chomsky, I make the following assertion: A PSG/S will serve as a more or less adequate observational and descriptive representation of the facts covered by a normal PSG; as far as TG is concerndd, the structure of the transformational model (how trees mad into trees) will not be represented adequately on the descriptive (and perhaps not even on the observational) level by a PSG/S. In no case the PSG/S will attain the level of explanatory adequacy. The first Dart of my assertion can easily be proved from the observation that a normal PSG and a PSG/S are strongly equivalent grammars, the only difference being the notation. (On the notion of equivalence, of. also Hays"]},{"title":"1965:519).","paragraphs":["In fact, it makes no difference whether one ex_ pands a symbol on the basis of a rule to be af_ fixed to the constituent by means of a sub_ script, or on the basis of a rule contained so_ mewhere else in the grammar. The essential is that ~eration proceeds from left to right, and one symbol is F)roduced at a time. (See discuss_ ion above, 1.2). To Drove the other half of the assertion male above, I will try to give an answer to the two_ MeT 20 fold question about representation of struct_ ure. Let's go back to the elementary example of the optional T , and try to imagine how this q is handled in a PSG/S. The main difference be_ tween PSG and TG is that the rules in PSG oper_ ate on symbols, in TG on strings of symbols. When I put a subscript on a symbol that is part of a string, and I want to mark off a struct_ ure that is based on several symbols occurring in a certain order, I will have to mark a Ii the symbols of my string in the same way, and this way of :~larking must be unique, i.e. de_ fine a unique path through the rules. This path may, in due course, require additions, deletions,"]},{"title":"permutations","paragraphs":["and the like. Now, in TG these op_ erations are carried out after the PS deriv&tion has been completed. In PSG/S, ho~Tever, the cleavage between affirmative and interrogative sentences occurs already in the third rule, where $2 is expanded into NP + VP, VP + NP, respectively (omitting the subscripts). The two derivations follow separate paths through the rules: in terms of tree diagrams, what is left in the one is right in the other of the two trees, In this way, many PSG rules are un_ necessarily duplicated (see above); moreover, the relationship between interrogative and de_ clara~ive sentences, as defined in TG, is reduced to a remote common source of derivation, namely $2. It is not true that \"Sentences are ~rans_ formationally related' to the extent that the Mey 21 same choice of restrictions is made in their derivations and if the same lexical c',oices are made where i~ossible\" (Harman:608{ sincle quotes are his), unless one takes \"'transfor_ mationally related'\" in a sense rather differ_ ent from Chomsky's, namely: sentences that have a (partial) oath through the rules in common. This is, in fact, the only 'transformational relation' that it is possible to define in a PSG/S, but unfortunately, it is not transfor_ mational. Even in the case that two paths coin_ cide, and coincide altogether, we do not have 'transformational relatedness', but \"grammatical similarity\" (Harman:6OS). Lexieal choices have nothing to do with this relation: both in PSG and in rG the choice on the lexical level is made after the aoDlication of expansion, reso_ ectively transformational rules. (This is not altogether cor~.ect: lexical choices may be made earlier and thus affect the derivation, but this is beside the point; complex symbols (see Klima"]},{"title":"1964)","paragraphs":["are not taken into consideration here, but they could be built into a PSG as well as into any other generative grammar. I think, e.g., that some com,~lex symbol could be devised to prevent sentences like The man walks the men, that could easily be generated in accordance with the rules described on TIp. 609_10 of Harmsn's article.) In my opinion, a PSG/S will never be able to show transformational relationships as formally defined and described by Chomsky and oZhers; hence such a grammar, even though it may attain Mey 22 a certain descriptive adequacy, will never give an explanation of the fact that precisely this, and not some other sentence, is t~ansformed into another structure. 2o3. Deletion in a PSG Another difficulty in PSG/S concerns the problem of deletion rules. In normal PSG, no deletes are permitted (Chomsky 1961:9)o Harman gives as reason for this restriction that trees must be uniquely recoverable in a I~SG (p.603). This is, however, only part of the motivation. Deletes are not symbols: they cannot be expanded (un_ less one chooses to ex~)and them into deletes, which is obviously useless in a description)° Whenever a deletion rule occurs, the structure of the derivate is altered in such a way that rules may a~ply which originally should not. One could say that deletes are extremely con_ text_sensitive: in !{at;nan's PSG/S, which in reality is a highly restricted PSG, the number of rules having the form A--> Z is very limited indeed, even though the author advocates their use (9.605). In passing, I would like to remark that nearly all of the deletion rules have to do with the ex,oansion of NP/I~H (this subscript occurs only once in the smaller ~rammar,"]},{"title":"p.609,","paragraphs":["and should therefore be rejected by the machine, since there are no constituents on which the rule could a~ply.) The real reason why a delete cannot be admitted in a PSG (especially a highly context_sensitive Hey 23 one) is that the rules following the deletion rules should be modified or alte~'ed completely , otherwise it would not be possible to keep the distinction between not_rewritten and re_ written symbols clear: the rules following de_ letion might thus operate on symbols orif~inally belonging to the context. (Note, by the x¢ay, that in the case of wh_words the context l~ro_ blem is somewhat simplified by the fact that these words normally stand at the beginning of a sentence, so that the left context can be thought of as zero.) In our example, the transformational rule for interrogative sent_ ences to be generated from declarative ones operates on a string of symbols that may be symbolized X 1 _ X 2 _ X 3 (Chomsky 1957:i12), carrying it into the shade X 2 _ X I - X 3. Now, suppose that in the course of the deriv_ Rtion to non_terminsl symbols (the kernel string) we have a deletlon rule operating, say, on \"( Suppose moreover that the non_terminal","i ° symbol following X 3 qualifies for the condi_ tions originally put on X 5. The transformatio_ nal rule will then operate on a string X 2 _ X~ _ X4, and carry it into X 3 _X 2 _ X~, thus generating a non_grammatical sentence. I do not pretend that the actual PSG/S as Drooosed and described by Harman in his article ~,,ill generate these sentences: as already sai~l, the grammar makes a very cautious use of deletions, so that sentences like the ones mentioned will not occur. This does not, ho~,yever, invalidate the criticism. Mey"]},{"title":"24","paragraphs":["Subscripts may not only be added in A PSG/S, but also deleted. In this manner a restriction that has been put on a certain rule can be re_ moved (this deletion of subscripts is of course quite another matter than the deletion of sym_ bols discussed above). Subscripts may be su)er_ fluous, such as in Rule 8.1 (p.609), where the subscript AUX_MODAL is removed from the constituent INFINITIVE by the subscript --AUX_MODAL, even though the lexicon would offer no ambiguous rewrites in the case of a non_ removal of the superfluous subscript. One could perhaps wonder why this precaution is taken, since in many other instances superfluous sub_ scripts persist all the way through the deriva_ tion (see discussion above). In other cases, the removal of subscripts can be motivated by the desire to orevent ungrammatical \"loops\", i.e. endless recursive expansions that have no justification in the grammar. Thus in Rule 8ol the symbol VP3/AUX_MODAL is expanded into INFINITIVE/°.. + VP3/AUX_HAVE,--AUY_MODAL, thus preventing another expansion by the same rule of VP 3. If, on the other hand, we wish the symbol in question to be expanded recursively (and according to the latest develo,)ment in TG there should be no difficulty in admitting recurslvity for all symbols, S not excluded: see Klima 1964), we can restart the cycle by wiping our slate, i.e. deleting all the sub_ scripts by means of the instruction ERASE.0TIIERS, to be incorporated as a subscript on the right Mey 25 hand side of the ruleo Naturally, we would ex_ pect a subscript of this kind to occur in those cases where a whole sentence is to be embedded into another hy means of what in early TG was called \"generalized transformations\" (Chomsky 1957: 113) o Th~ominalizing transformation is an instance i~ind\" under ~g in the extended PSG/S (p.613), we find, among others, the entry: NP8 --> Sl/CLAUSE. TYPE:NOMINALIZATION, SUBJ. INo GENITIVE, B, C ,D,E, Z,Y, ERASEoOTHERS This means that all the subscripts originally found on NP8 are to be deleted; the new sub_ scripts deal exclusively with the derivation of the embedded clause (as can easily be veri_ fled from the rules of the PSG/S as given in the Appendix of the article). 1~'hereas TG keeps track of the chan~es to be made by means of a structural description of the pair of kernel sentences involved, together with a formula for sh~/ctural change, in PSG/S we have only a con_ stituent NP to be expanded by means of DS rules° How this NP fits into the stmucture of the ori_ ginal kernel sentence (being essentially its path through the PS derivation) can be fo] low_ ed in .nSG by tracing back the nodes of the tree representation. In PSG/S, this path is marked by the subscriots added to the NP in question. Now, all this information is struck from the record by the removal of the subscripts in ac,:ordance with the instruction ERASE OTHERS° ~struCtural descri!)tion of the sentence as a whole is not available: the expansion of NP8 destroyed our bridge back to the original So It is as if we ha~een expanding a constituent while forgetting what it was we were expanding. Mey 26 2o Conclusion Of the two models discussed here, the first one (PSG/PDS) has not actually been proposed as a full_scale grammatical mo:Iel, but I have tried to show that the implications of the claim that any shorgcomings of PSG can be ow:rcome lead to difficulties of about the same nature as those encountered in the second molel (PSG/S). Descriptive adequacy is not attained in those cases where structural descriptions are rele_ vant for the operation of the rules: neither PSG/PDS nor PSG/S permits one structural descr_ iption to be carried over into another. As one will have noticed, the argument in both cases runs a lon~ the same lines. Moreover, of the several devices proposed by Har:~an to boost the .)ower of PSG, the deletion rule was explicitly rejected on the ground that it would add too much power to the ~rammaro On the other hand, the use of subscripts, no matter how carefully chosen, will not help enlarge the descriptive Dower oi\" the gramm,~r (Harman 1963:605) enough to account for all the grammatical sentences of the language. Thus, one_level grammars like the ones discussed above will not attain explanatory adequacy in any case, and in some cases not even descriptive adequacy. \"Dieser Versuch /namely, the defense of phrase structure, JM/ verfehlt den entscheidenden Punkt abet in zweifacher }{insicht: Erstens uberschreiten die Regeln Harmans die Kapazitat einer PSGo Und zweitens losen such sie nicht das Problem einer geigneten Zuordnung yon Stammbaumen.\" (I~ierwisch"]},{"title":"1964:","paragraphs":["49fn. ii )"]},{"title":"Mey 27 References Chomsky 1957: Chomsky 1961: Chomsky 1962:","paragraphs":["]larman 1963:"]},{"title":"Harris 1962: Hays 1964: Hockett 1959:","paragraphs":["Bach 1964: E.Bach, An Introduction to Trans_ formational Grammars t Ne,~' York etc., 1964"]},{"title":"Bierwisch 1964:M.Bierwisch, Auf~aben und Form der Grnmmatik (Preorint IId Internatio_ nal Symposium \"Zeichen und System der Sprache, Magdeburg, Germany, Seotember 1964) Bolinger 1953: Dwight LoBolin~er, Addenda to the Comparison of Inequality in Spanish Lg. 29 (1953), 62_6° N.AoChomsky, Syntactic Structures The Hague,1957 Id., On the Notion Rule of Grammar, in: Structure of Language and its Mathematical Aspects, ~SAM XII (1961), 6_24, Providence, RoI., 1961 Id., A Transformational Approach to Syntax, in: ThiFd Texas Confersnce on Problems of Linguistic A/~aiysis (1958), Austin, Tex., 196~, 124_58 Gilbert II.Harman, Generative Grammar without Transformation Rules: A De_ fense for Phrase Structure Grammar, Lg. 39 (1963), 597_616 Zellig S.Harris, Strin 6 Analysis of Sentence Structure, The }{ague, 1962 David GoHays, Dependency Theory: A Formalism and some observations, Lg 40 (1964), 511_25 Charles F.Hockett, A Course in Modern Linguistics, Ne~, York, 1959 Mev 28 Klima 1964: EoSoKlima, Current developments in Generative ~rammar (in press). A MS coDy of this 0a0er, which was originally read before the 1764 Colloquium on Algebraic Linguistics, Prague, Czechoslovakia, was kindly put at my disposition by the author. Oettinger 1964:A.G.Oettinger, Automatic Syntactic Analysis and the Pushdown Store, in: PSAM XII (1961), 104_29 Sgall 1963: U°Sgall, The Intermediate Language in Machine Translation and the Theory of Grammar, in: American Documentation Institute, 26th Annual Meeting, Chica_ go, Ill., 1963, 41_2. Sgall 1964a: P.Sgall c.s., Cesty moderni jazykovedy, Praha 1964 Sgall 1964b: PoSgall, Zum Verhaltnis yon Grammatkk und Semantik (PreDrint IId Intez'n. Symp., Magdeburg, Germ,, 1964) Yngve 1960: VoH.Yngve, A Model and an Hypothesis for Language Structure, in: Proceed_ ings of t~, American PhilosoDhical Society 104 (1960), 444_66 Yngve 1961: Id., The De~th Hypothesis, in: PSAM XII (1961), 130_8 Yngve 1962: Ido,, Random Generation of English Sentences, in: 1961 International Conference on Machine franslation of Languages and ADplied Language Analysis, London 1962, 65_81 Wells 1947: Rulon SoWells, Immediate Constituents, Lg 2~ (1947), 81_117 Mey 29 I ] l+i I+2 \"~OLL.IN\" i--~ I \"ROLL.(N/T\" FIG.I. THE T~I~MPORA~y MEMORY th@~ big as nlce -] a fool j ! ~ j little parlor m~s de Io que sabe FIG. 2. DISCONTINUOUS ~IULTIPLE CONSTITUENPS","paragraphs":[]}]}