{"sections":[{"title":"BUILDING AN MT I)ICTIONARY FROM PARAI~LEI~ TEXTS BASED ON LINGUISTIC AND STATISTICAL INIi'ORMATION Akira Kumano ltidcki ltirakawa R & D Center, Toshiba Corporation","paragraphs":["1, Komukai Toshiba-cho, Saiwai-ku, Kawasaki, 210, JAPAN { km n,hirakawa} @ist.rdc.toshiba.co.jp"]},{"title":"Abstract","paragraphs":["A method for generating a machine translation (MT) dictionary from parallel texts is described. This method utilizes both statistical information and linguistic information to obtain corresponding words or phrases in parallel texts. By combining these two types of information, translation pairs which cannot be obtained by a linguistic-based method can be extntcted. Over 70% accurate translations of compound nouns and over 50% of unknown words are obtained as tbe first candidate from small Japanese/Englisb parallel texts containing severe distortions. 1 INTRODUCTION","Parallel texts (corpora) are useful resources for acquiring a variety of linguistic knowledge (Dangan, 1991; Matsumoto, 1993), especially for machine translation systems which inherently require customizations. Translation dictionaries are, needless to say, the most basic and powerful knowledge source for improving and customizing translation systems. Our research interest lies in automatic generation of translation dictionaries from parallel texts. In this perspective, finding corresponding words or phrases in bilingual texts will be the fundamental factor for accurate translation.","Statistics-based processing has proven to be very powerful for aligning sentences and words in parallel corpora (Brown, 1991; Gale, 1993; Chen, 1993). Kupiec proposes an Mgorithm for finding ~loun phrases in bilingual corpora (Kupiec, 1993). In this algo o rithm, noui~-phrase candidates are extracted from tagged and aligned parallel texts using a noun phrase recognizer and tile correspondences of these nonn phrases are calculated based on the EM algorithm. Accuracy of around 90% has been attained for the Imndred highest ranking con'espondenccs. Statistics-based processing is effective when a relatively large amount of parallel texts is available, i.e. when high frequencies are obtained.","On the other hand, existing linguistic knowledge can be used for finding corresponding words or phrases in parallel texts. For example, possible target expressions for a source expression provided by a translation system (linguistic knowledge source) can be a key in searching the corresponding expressions in a corpus (Nogami, 1991; Katoh, 1993). Yanramo-to (1993) proposes a method for generating a translation dictionary from Japanese/English parallel texts. In this method, English and Japanese compound noun phrases are extracted from parallel texts and their correspondences are searched by matching their possible translations generated by tile existing translation dictionary. However, acquirable noun phrases are limited by tile linguistic generative power of the translation dictionary. Furthernlore, tiffs method utilizes no sentence alignmeat information which can reduce errors in finding noun phrase correspondences.","This paper proposes a new method for generating an MT dictionary from parallel texts. It utilizes both statistical and linguistic information to obtain corresponding words or phrases in parallel texts. By combining these two types of information, translation pairs which cannot be obtained by the above linguistic-based method can be extracted, and a highly accurate translation dictionary is generated from relatively small par:dlel texts.","2 APPROACtt TO BUILDING AN MT 1)ICTIONARY","Our goal in building an MT dictionary from parallcl texts is to develop a robust method which enables highly accurate extraction of translation pairs from a relatively small amount of parallel texts as well as from parallel texts containing severe distortions.","In real-world applications, generally it is extremely difficult especially for MT users to obtain a large amount of high quality parallel texts of one specific domain. If source and target languages do not belong to the same linguistic family, like Japanese and Fnglish, tile situation becomes grave.","As one typical example of MT dictionary compilation, we have selected Japanese and English patent doemnents which contain many state-of-the-m~t technical terms. Althougb thes~ documents are not cul-76"]},{"title":"Japanese [--English 1 Text l Text ; ,,nit extractio,, I [Corresponding ]-.. ~--->","paragraphs":["'"]},{"title":"L~nil Table","paragraphs":["[ \\ I"]},{"title":"Linguistic --r+-- '°d°° List [ ~l candidate v_~- ~-[ j ____._j-'-'-----~ generation ~_____~ /","paragraphs":["I statistical I/"]},{"title":"j/ f , .mation J [ Translation Pairs Fig. 1:","paragraphs":["Flow of building an MT dictionary from paralh.q"]},{"title":"texts","paragraphs":["turally biased, in many cases, tile organization"]},{"title":"between","paragraphs":["Japanese and English greatly differs and extensive changes are made ill translating from Japanese to English text and vice vm.~a. Hence, tile difficulty of word extraction from patents.","To solve this problem, we explored the appropriate integration method considering the use of linguistic information and statistical information to this end. Lingt, istic information is useful in making an intelligent judgment about correspondence between two languages even from partial texts because of its lexical, syntactic, and semantic knowledge; statistical information is characterized by its robustness against noise because it can tnmsform many actual examples into an abstract fom~.","Below is the flow of ot, r method illustrated in Fig. 1 :"]},{"title":"(1)","paragraphs":["Unit Extraction: Pmls of documents (\"units\") are extracted from both Japanese and English texts.","(2) Unit Mapping: I&mh Japanese nnit is mapped into English units.","(3) Term Extraction: Japanese term candidates are extracted by the NP recognizer.","(4) Translation Candidate Generation: English translation candidates for Japanese terms are extracted from English units.","(5) English Translation D;timation: Tim translation candidates are evah, ated to obtain the best one,","Tim subsequent sections show tim details of each processing.","3 FORMING UNIT CORRI{SPON-DENCES","The plausible hypothesis that parallel sentences cont,,in corresponding linguistic expressions is the major premise in Kupiec (1993). This type of info,- mation should be wklely used. The problem is that tim alignment method based on tile sentence bead model (Brown, 1991) is not applicable to patent documents due to their severe disto,fions in doculnent strtlctures and selltence correspolldences. Conse-- quently, we have introduced a concept called \"unit\" which corresponds to a pa~t of sentence and adopted a new method to extract corresponding units by using linguistic knowledge as a primaxy source of hi formation. 3.1 l,:xh'aclion of Units","First, units are extracted from parallel texts. The unit corresponds to sentences or phrases ill tile text. Terms which should be extracted can be found within a unit. \"File rest of words in the unit is called contextual infommtion for tile extracted term. Tile size of units determines tile effectiveness of the st,eceeding unit mapping process. For exa,npie, if we set noun phrases (enny words in a dictionaly) as :.1 unit, no contextual information is available, and thus tim probability that corresponding relations hold decreases. In our present implementation, we set sentences as a unit for tile first approximation. 3.2 Mal)ping of Uniis","Next, the unit mapping process creates a conesponding unit table from Japanese ~,nd English vails. This table stores the correslmndenee relation-ship between milts and its likelihood. The likeli.. hood is calculated based on the linguistic information in an MT bilingual dictionary,","Our trait mapping algorithm is given below:","(1) l,ct ,1 be a set of all content words in tile Japanese unit JU."]},{"title":"(m","paragraphs":["iS tim number of words) ,1 ={ Jl'J2 ..... lm}","(2) l.et E be a set of all content words in the","F, nglish unit [{[J. (n is tile number of words) E=:{ E 1,1{2...F; n}","J","(3) .v is the number of .li's whose translation candi-77 date list includes some Ej in E. (4) y is the number of Ej's which is included in the translation candidate list of some Ji in J. (5) The correspondence likelihood CL is given by"]},{"title":"CL(JU,","paragraphs":["EU) = - x + y m+n","For each JU, M (currently 3) English units with the highest CL(JU, EU) are stored in the corresponding unit table.","4 GENERATING TRANSLATION CANDIDATES 4.1 Extraction of Japanese Terms","Errors in the extraction of terms and phrases from parallel texts eventually lead to a failure in acquiring the correct term/phrase correspondences. In Kupiec (1993) and Yamamoto (1993), term and phrase extraction is applied to both of parallel texts. In contrast, we extract from units only Japanese terms, thereby reducing the errors caused by term/phrase recognizer. Japanese NP's can be recognized more accurately than English NP's because Japanese has considerably less multi-category words.","In the current implementation, the following two types of term candidates are extracted by the NP recognizer:","(A) Compound nouns (including verbal nouns)","Examples: \"~- 7\" y e\" :, l- ~'~3i~\"","(=open bit line colfiguration)","\"/i~4-/JiJm~l-fJ~\"","(=minimum featuring size)","(B) Unknown words (nouns, verbal nouns)","Examples: \"~-J- ~\" (=to laminate, to form)","\" ,l-t 1.1 .~, 9 :.\" \"Y'\" (=polishing) Our NP recognizer utilizes the sentence awdyzer of a practical MT system. The word dictionary includes approximately 70,000 Japanese entries. 4.2 Finding Translation Candidates","Generation of English translation candidates for a Japanese term is essentially based on the following hypothesis:","Hypothesis 1 The English translation of an extracted term in a Japanese unit is contained in the English corm-sponding unit.","Now an arbitrary word sequence in corresponding units can be a translation candidate of the Japanese term. We extract English translation candidates in two steps: Step 1 : Select English corresponding units. Step 2: Extract n-gram data from the units. Step 1 :","When the extracted term appears in N Japanese units, N×M English units will be stored in the corresponding unit table with their correspondence likelihood. The N highest corresponding units within N×M combinations are extracted. When N is less than M, the M highest combinations arc selected. Step 2:","Suppose that tile correct English translation of the Japanese term JW is EW, and that the mnnber of Japanese units in which JW appears is FJU(JW) (= N). From ltypothesis 1 that the translation is contained in the corresponding units EU I, EU 2 ..... EUFJU(JW ), EW would be a word sequence which often appears in corresponding units. In order to get such EW, we use n-gram data.","The frequency of each n-gram (1 <_ n _< 2 x (the number of component words in JW)) data in FJU(JW) English units is calculated and then EW candidates are ranked by the frequency as EWC 1, EWC 2 .... EWCj. Because EWC with a low frequency in the corresponding units is unlikely to be the correct wanslation, the data with a frequency less than"]},{"title":"FJU(JW)","paragraphs":["4 are heuristically excluded from the candidates. The data containing be verb and the data which starts or ends with a preposition or an article are also excluded from the candidates.","5 ESTIMATING ENGLISH TRANSLA-TIONS","The translation likelihood (TL) of one translation candidate EWCi for the term JW is defined as:","TL(JW, EWCi) = F(TLS(JW, EWCi), TLL(JW, EWCi)) where TI~S(JW, EWCi) is \"'Franslation Likelihood based on Statistical information,\" and TLL(JW, EWCi) \"Translatiou Likelihood based on Linguistic info rmat ion 2 5.1 Statistical hfformation","TLS(JW, EWCi) is the frequency score based on the statistical information from Hypothesis 1 that a word which appears as often in tile corresponding units as JW in Japanese units is more likely to be EW. It is quantitatively defined as tile probability in which the translation candidate appears in the corresponding traits. That is, 78 vrsu0~.wc?~_"]},{"title":"TLS(JW, EWCi)","paragraphs":["= F3U(JW) where FEU(EWCi) is the number of corresponding units in which EWCi appears. 5.2 Linguistic Information","TLL(JW, EWCi) is tile word similarity score based on the accuracy of the correspondence term JW and the translation candidate EWCi obtained by using linguistic information in tile MT bilingual dictionary. Suppose one translation candidate of term JW=WJl, wJ2 .... wJk is EWCi=we 1, we 2 .... we I. Then we use the following hypottmsis."]},{"title":"Hypothesis 2","paragraphs":["(a) If the length of EWCi is close to the length of JW, JW and EWCi are likely to correspond each other.","(b) JW and EWCi with more word translation correspondences are likely to correspond each other.","Under this hypothesis, the following correspondence relation (1) is the best. Term JW and translation candidate EWCi have the same length k(-I), and all of their component words correspond in the dictionary, wJi:~we i indicates that we i is included in wJi's translation candidates in the MT bilingual dictionary. (1) wJl=*we 1, wJ2~we 2 ...... wJk~We k","More generally, tim relation of each word (w j) in term JW and each word (we) in translation candidate EWCi is classified into the following four classes: i) wj~ we ii) wj --* we iii) wj -4 iv) ~ ---> we (qb indicates no word)","it) shows a pair whose correspondence is not described in the bilingual dictionary, iii) and iv) indicate that the corresponding word for wj or we is missing. In iii), JW is longer than EWCi; and vice versa in iv).","In order to estimate correspondence between JW and EWCi, i) and it) are scored by similarity to the virtual translation which holds the relation (I). When the nmnber of words is the same, score Q (constant) is given, c~Q (ct>0) is added to Q when there is a translation relation to reflect higher reliability of i). Therefore, Q+aQ=(I-,c~)Q is given to the word pair of i), and Q to the word pair of it).","Now since we disregard the word order of a term, JW and EWCi are represented as sets of words: JW = wJl, wJ2,.., wJk ~- {wJl, w j2,.., wJk } EWCi = we I , we2,.., we I - {wel, we2,.., wel}","The number of words with a lexical correspondence relation in wj and we, the number of words in wj without a relation and the number of words in we without a relation are counted as x, y, z respectively. That is, x -~ y = k and x + z= l.","T[.I.(JW, EWCi) is given as the ratio of tile score of the vmual translation to the score of FWCi.","When y>_z,","x(l-t ct)Q t-zQ TI2_.(JW, EWCi) = (x l y)(l -t a.)Q Otherwise, Thus, Tl.l.(JW, EWCi) =","x(1-I a)Q + yO - (z - y)Q (x-ly)(l-~ c*)Q TI.I.(JW, Ewci) -. x(l -t ~) + z","(y_>_z) (x-~y)(l q cQ x(l-~ ~x) + 2y - z (x+y)(1-tcx) (otherwise) By definition, TI.L(JW, t!WCi) < 1. The value of c~ is determined as 2 by evaluating sample tnmslalion pairs.","Followings are the TLI,'s of three EWC's for JW:vk -- 7\" :./ ff .:t I. ~Jy:,~ which consists of four component words (k=4); \":,l--- 7\" :/(=open),\" \"tf .~, I- (-bit),\" \"~(=line),\" and \"Jj3~.(-method, process).\" bit line configuration x:2,y-2, z=l .'.T[.I~ - (2x3+l)/4x3 =0.58 open bit line x::3, y: 1, z:-O .'. Tl.l. = (3x3)/4x3 = 0.75 open bit line configuration x=3,y:l,z-I .'. TLL = (3×3+1)/4x3 =0.83","5.3 Combination of Statistical and Linguistic Information","We define the translation likelihood TL(JW, EWCi) as below: TL(JW, EWCi) -:","m TLS(JW, F.WCi) + n TLL(JW, EWCi) m-{ tl","Examining the value with the ratio n/ttl constant, a low value of TI.S(JW, EWCi) ill affects the total score, especially when the frequency 79 FJU(JW) is 5 or less. This shows that TLS(JW, EWCi) should be much weighed for JW's which appear often, but not for JW's with a low freqt,ency. Therefore we tentatively define ~ = n/m as a function of frequency FJU(JW), because !3 sbould be higher when FJU(JW) is low.","]3 = G(FJU(JW)) P + s {FJU(JW)} q - r where r is a possible minimum frequency, aqd s is limit of 13 as the word frequency is high enough. Values"]},{"title":"p=4, q=l, r=l, and s=0.5","paragraphs":["are used in tile following experiments. By introducing 13, F is rewritten as: F(TLS(JW, EWCi), TLL(JW, EWCi) ) =","_TLS(JW, EWCi) + 13 TLL(JW, EWCi) 1+13","In case {FJU(JW)} q is equal to or less than r, is meaningless, For such JW's, TL(JW, EWCi) is redefined as simply: TL(JW, EWCi) = TLL(JW, EWCi). Finally the translation candidate EWC i with","the largest value of TL(JW, EWCi) is assumed to be","the correct English translation. Table 1 shows the translation candidates for JW: ~ 7\" >\" ~\" ~, I- ,~jY~ with the best three TL's. Its","frequency in Japanese text is FJU(JW) = 19 (13","4 + 0.5 = 0.72). Consequently, the correct","19-1 translation EWC 3, open bit line cotfiguration, is obtained."]},{"title":"Table 1:","paragraphs":["Estimation of English translation EWCi FEU 'I'LS TLL 'I'L bit line configuration 19 1.00 0.58 0.82 open bit line 18 0.95 0.75 0.86 open bit line configuration 18 0.95 0.83 0.90 6 EVALUATION AND DISCUSSION","To evaluate this method, we have estimated English translations of Japanese terms in seven parallel texts (Japanese specifications of patents on semiconductors and their English translations by human translators) and compared the translations with the correct data given by experts in building an MT dictionary. The size of a Japanese text is 7,508 to 26, 927 characters in 127 to 616 sentences; 99,286 characters in 2,148 sentences in total. Examples of correct translation pairs estimated with the highest TL","Compound nouns: ]'~-'J\")3ll ~-\" J\" ~./2 minimum featuring size ~ -j'-5}l~f[i~.t~t~ element separation region 71- -- ':7\" :-\" t::\" 'u I\" ~7,t)':,:~ open bit line configuration","cohtmn address strobe -e )t, 3\" ~.4 cell array","Unknown words: ~lt I) ,~, ,~ >, p\" polishing","1/~ # collector ~I~-Y ~ to form Fig. 2: Correct translation pairs are listed in Fig. 2.","Table 2 shows the ranking of the correctly estimated translation pairs in seven sample texts. The upper row shows the average of seven individual texts; the lower shows the result using all seven texts in one time. The translation of over 70% of compound nouns is obtained as the first candidate, and over 80% in the top three. The result for unknown words is 54.0% and 65.0%. Though the accuracy for tile unknown words is relatively low, the estimation has been impossible for Yamamoto (1993). itere, tile terms whose cor,ect translations are not found in English texts are excepted from evaluation. .Such data occur when human experts give a noun translation for Japanese verbal noun term which is translated as a verb in the actual text. Tile ratio of this kind of translation pairs is abot, t 3%. Tile rate of the correct data is calculated by the ratio of the total occurrences.","The accuracy for the average of unknown words is 52.4% in the top three. The result using all texts is significantly better than tile average because tile statistical information is the major factor in the current implementation. Use of more linguistic information such as in Dangan (1991) and Matsumoto (1993) would improve the total performance.","Linguistic information has proven effective to estimate translations of low-frequency terms. Of terms which appeared only once in a Japanese text, 215 translations are obtained correctly as the first candidate from 327 terms (65.7%) in seven texts.","The fourth example of compound nouns in Fig. 2 shows the advantage of statistical information because the correct translation was obtained in spite of the wrong word segmentation. The Japanese term really consists of three words (~J 9 A, 7\" F 1t ~, .z ]. ~ - .7\" ), each of whicb corresponds to \"cohtmn,\" \"address\" and \"strobe\" respectively. But word segmentation output four word.~ (~J 5' ],, T F 1t ~, l., ~ - .7\") because \":< I. ~-- 7\"\" is unknown and \"-~ 80 Table 2: Aeeur'lcy of transl'dion estimates Compound nouns (occurrences)"]},{"title":"-total","paragraphs":["Tl-i~'t"]},{"title":"cstq,n--at~'~ to,;~-e~-tq m:ZteT\" 1","paragraphs":["text ,, 7 {ext_s~ 3,224_~.9% (2,349) 83.3% (2,680) Unkilown words occtnrences) -t-ot~al--[- first estimate top 3 estimates","• I O --- 55 6 I 30.1~, (16.7) 52.4% (29.1)"]},{"title":"I","paragraphs":["389 | 54.0%, (210) 65.0% (253) k 1-\" is known as \"strike.\"","The CASES where no correct translatkm has been obtained needs to be examined. The major reasons for faih, res are: 1. Errors in mappi,lg conesponding units. 2. Errors in word segmentation of unknown","compound wo,ds.","Mapping unit errm.'s occur when the one-to-one nnit correspondence does not exist. The experiment using one text shows that 12 out of 98 Japanese sentences have no onE-to-one corresponding English sentence. For better unit correspondence, the trails should be smaller, for example, a clause or a verb phrase, so as to make the corresponding accuracy and frequency in text higher and statistical infornmtion more effective. It would improve the unit mapl)ing when one Japanese sentence is tnmslatcd into several English sentences or vice vmsa.","ThE segmentation errors of unknown words arise often in case of Katakana compotmd word. Katakana is the phonetic alphabet in Jal)anese for spelling foreign words• Since many compound nourLs in a technical field consist of Katakana's with no space between component words, much larger lexicon will contribute to more accurate segmelltation."]},{"title":"7 CONCLUSION","paragraphs":["An MT dictionary has been generated from Japanese and English parallel texts. The method proposed in this paper assumes t, nit correspondence and utilizes linguistic information in an MT bilingual dictionary as well as statistical information, namely, word frequency, to estimate the English translatio,L Over 70% accun~te translations for compound nouns are obtained as the first candidate from small (about 300 sentences) Japanese/Fnglish parallel texts (patent specifications) containing severe distortions. The accnracy of the first translaticm candidates Ior unknown words, which calmot be obtained by a linguistic-based method, is over 50%•","Tim current implementation shows promising results for a cliff let, It target (patent texts) despite relatively shnple linguistic knowledge• The overall lmfformance will be imlnOved by using more linguistic knowledge and optimizing panuneters calculated by sh~tistical information•"]},{"title":"References","paragraphs":["Brown, P. F.; l,ai, J. C.; and MErcer, R. 1, (1991). \"Aligning sentences in parallel corlx),a.\" In Proe. of the 29th Annual Meeting of the ACL, 16%176.","Chen, S. F. (1993). \"Aligning sentences in bilingual corpora using Iexical informatio,L\" In Proc. of the 3 lxt A tmual Meeting of the A CL, 9-16.","Dagan, I.; ltai, A.; and Schwall, U. (1991). \"Two languages are mo,'e intkmnative than one.\""]},{"title":"In","paragraphs":["Proc. of the 29th Ammal Meeting of the ACL, 130-137.","Gale, W. A., and Chnrcb, K. W. (1993). \"A program for aligning sentences in bilingt,al corpora.\" Computational Linguistics, 19(1 ), 75-90.","Katoh, N. (1993). \"Word selection by searching the translation candidates on monolingnal texts in target language.\" 7>chuieal Report of IEICE, NLC93-32. (in Japanese)","Kupiec, J. (1993). \"An algorithm for finding noun phrase correspondences in bilingual corpora.\" In I'roc. e( the 31st Ammal Meeting rg\" the ACL, 17-22.","Matsumoto, Y.; [shimoto, ll.; and Utsuro, T. (1993). \"Structural Matching"]},{"title":"of","paragraphs":["Parallel Texts.\" In I'roc. of the 31st Annual Meeting of the ACL, 23-30.","Nogami, lI.; Kumano, A.; Tanaka, K.; and Anmno, S. (1991). \"l.earning of translation words using target-hmguage documents.\" In Proc."]},{"title":"(f","paragraphs":["42rid A m~ual Meeting of II'S.I, 2C- 6. (in Ja panes E)","Yamamolo, Y., and Sakamoto, M. (1993). \"Extraction of teclmical te,'m bilingual dictionary from bilingual corpus.\" IPSJ SIG Notes, N1,94-12. (in Japanese) 81"]}]}