{"sections":[{"title":"PRINCIPAR--An Efficient, Broad-coverage, Principle-based Parser","paragraphs":["Dekang Lin Department of Computer Science, University of Manitoba Winnipeg, Manitoba, Canada RaT 2N2, lindek@cs.umanitoba.ca"]},{"title":"Abstract","paragraphs":["We present an efI]cient, broad-coverage, principle-based parser for English. The parser has been implemented in C++ and runs on SUN Sparcstations with X-windows. It conrains a lexicon with over 90,000 entries, constructed automatically by applying a set of extraction and conversion rules to entries from machine readable dictionaries."]},{"title":"1. Introduction","paragraphs":["Principle-based grammars, such as Government-Binding (GB) theory (Chomsky, 1981; Haegeman, 1991), offer many advantages over rule-based and unification-based grammars, such as the universality of principles and modularity of components in the grammar. Principles are constraints over X-bar structures. Most previous principle-based parsers, e.g., (Dorr, 1991; Font, 1991; Johnson, 1991), essentially generate all possible X-bar structures of a sentence and then use the principles to filter out the illicit ones. The drawback of this approach is the inefficiency due 1;o the large number of candidate structures to be. filtered out. The problem persists even when w~rions techniques such as optimal ordering of principles (Fong, 1991), and corontining (Dorr, 1991; Johnson, 1991) are used. This problem may also account for the fact that these parsers are experimental and have limited coverage.","This paper describes an efficient, broadcoverage, principle-based parser, called PRINCIPAR. The main innovation in PRINCIPAR is that it applies principles to descriptions o17 X-bar structures rather than the structures themselves. X-bar structures of a sentence are only built when their descriptions have satisfied all the pri ncil)les.","O dynamic data","[~ static dala l)rocegsing module data flow Figure 1: '.Pile architecture of PRINCIPAR","Figure I shows the architecture of PRINCIPAR. Sentence analysis is divided into three steps. The lexical analyser first converts the input sentence into a set of texical items. Then, a message passing algorithm for OB-parsing is used to construct a shared parse forest. Finally, a parse tree retriever is used to enumerate the parse trees.","The key idea of the parsing algorithm was presented in (tin, 199:1). This paper presents some implementation details and experimental results."]},{"title":"2. Parsing by Message Passing","paragraphs":["The parser in PIHNCIPAR is based on a message-passing framework proposed by ],in (1993) and l,in and Ooebel (1993), which uses a network to encode the grammar. The nodes in tile grammar network represent grammati-cal categories (e.g., NP, Nbar, N) or subcategories, such as V:NP (transitive verbs that take NPs as complements). The links in the network re.present relationships bel;ween the categories. GB-principles are implemented as local constraints attached to the nodes and"]},{"title":"482","paragraphs":["percolation cormtraints attached to links in the network. Figure'2 depicts ~ port:ion C\" tile gr;unmar network for |Dnglish."]},{"title":"'2\\","paragraphs":["I t \" \"IP"]},{"title":"cpspe~.. , -/~/\\~ i AAI ~ I'P \" NI i VI : 1 t.. \".,.... \"...\".. ....\" \"\".... A ul , P","paragraphs":[",, ,. ' .......... ':","'....\".v.v.v.v.v.v.v; ................. .'\"' \"\" ,~","V:N~ V:(,~x ' adjullct dominance conlplement domln:lnce specialization specifier doininailce head donlinanee barrier Figure 2: A Grtunma.r Network","Th(;re ~u'e two types of links in 1,he network: subsumption l{nks and dominance links.","• [l.'here is a SlXi)sttln[)tiOlX link ['rotn (v l;o fl if a subsume.s ft. For exa,ini)le , since V subsumes V:NP and V:CP, l;here is a, sul)smnption link from V to ca.oh ()11o, of them.","• There. is a donxhia.nce link frolil node (v i.o /7 if/7 cfl, ll })e imme.dia.tely doininal~ed by O& l.'~Ol ' CXi/dllplc, SillCC a.IX Nl)a.r lii&y iltlmedia£cly dominate a. PP adjimct,, t;here is a dominance link from Nbar to pp. A dominance link fi:om a to fl is a.ssoci~ted with an integer id that determiiles tile linear order between fl and other cat;egories dolnim~t(xl t)y a, and a, binary att;ril)ute to specify whether fl is optional or oblig~l;ory. I","t ln order to simplify the diagrain, we did nol. label tile links with their ids in l\"igure 2. [nstead, the precedence between dominance links is ilMie~t>ed l)y their","Input sentences a.rc p;u'sed by passing me.ssa.ges iu t,he gramm;u' network. 'l.'he nodes ill the nel, wor]( are compul, ing agents t;lxi~t comnulnica.t.e wil;h e;~ch oilier 1)y sending messa,ges in tile rcv(HJso direcl, ion of the links ilx the. network. I']acll node ha.s a. local nlemory tlxa.t, sDol'es a. set of it;ellx.~. Ail il;em is a triplet thai; represe.nts a. (possibly intern plei, e) X-ba, r strltci>ll I'(? [t:","<str, art, src>,where ~tr is an intx_'ger interva.l"]},{"title":"[i,j]","paragraphs":["denoi, ing t:ixe i'i~h Lo j'l, tl word ill I, he ill[)llt; still;el]eel art is the al;trilml,c vMues of the. reel; node o[ the X-bar"]},{"title":"st;rtlCtAll:(':;","paragraphs":["~Uid src is i'~ set o[ St)Ill'CO mess~.~ges Prom which this item is combined. The source i~lessa,ges represent inlinedi~te constituctlLs o[ the reel; node. li',a.ch node in l, he grannillu: network has a. conll)letion I)redicate tllal, detertllillCS whether a.n ilieln a.t l;lie node. is \"coinplete,\" ilx wilMi ca.se the it;elXl is sent a.s a, inessltge 1;o el;tier ll()dOS ill 1~110 ]X}VOI'SC direction of the links.","~Vilen a, node receives mi itcnl> il; adiLel31pts {o (:onll)ine the itenl with il;ems ['rein other nodes 1,o forln Hew il;enis. 'l~wo it;ores","<[i,,jl], A,, S,> a.nd <[i2,j2], A,2, S~,> can I)e combilxed if • ' \" a,(Ijacent to each ] l, heir Slll'[a.ce sl, riilgs Arc el, her: i7-:"]},{"title":"jl-I-1.","paragraphs":["2. tiieir a.tl, ribute vMues At mid A~ a.re t lHifli~ble..","{{. tile SOtlrc(~ lTxessa,~es COTHe Vii/~ diffe.rent Ii,,ks: li,,ks(,g,) r~ li,,ks(S,~) =-- (k, where links(,q) is a. I'illlC~iOlX {hal,> given i~ set o[ nlessa.ges, returlis the sel; of links via which the iiicssa.ges a, rrived. {l'he result o[ I~ixe colnbinM;ion is a. [leW il;Oll;l:"]},{"title":"<[il,.i~],","paragraphs":[",mil'y(A,, A2), S, U S.~>. The new il;em represelxt:s a, la,rger N-ba, r sl;ruc-t,u re result;i ng from t, hc combination of the two snla.ller cues. 111 1;lie new it;era s<%isfles the loca.l constraint, o[ I;he node it is considered valid a.nd sa.ved inl;o the local lnOIxlory. ()l:herwise, ig is disca.rded. A valid ito.nl si~t;isfying i;he comsLarting poinl, s, e.g, (J precedes IP under Char since the link leading to (J is to I;he left, of t.he link leading 1,o 1 P. 48.7 pletion predicate of the node is sent further as messages to other nodes.","The input sentence is parsed in the following steps. Step 1: Lexieal Look-up: Retrieve the lexical entries for all the words in the sentence and create a lexical item for each word sense. A lexical item is a triple: <[i,j], av~lf, av ..... p>, where [i,j] is an interval denoting the position of the word in the sentence; av~lf is the attribute values of the word sense; and av,:o,,,, is the attribute values of the complements of the word sense. Step 2: Message Passing: For each lexieel item <[i,j], av~lf, av ..... p>, create an initiM message <[i,j], av~r, 0> and send this message to the grammar network node that represents the category or subcategory of the word sense. When the node receives the initial message, it may forward the message to other nodes or it ma,y combine the message with other messages and send the resulting combination to other nodes. This initiates a message passing process which stops when there are no more messages to be passed around. At that point, the initial message for the next lexical item is fed into the network. Step 3: Build a Shared Parse Forest When all lexieal items have been processed, a shared parse forest for the input sentence can be built by tracing the origins of the messages at the highest node (CP or IP), whose str component is the whole sentence. The parse forest consists of the links of the grammar network that are traversed during the tracing process. The structure of the parse forest is similar to (Billot and Long, 1989) and (Tomita, 1986), but extended to include attribute values.","The parse trees of the input sentence can be retrieved h'om the parse forest one by one. The next section explains how tile constraints attached to the nodes and links in the network ensure that the parse trees satisfy all the principles. 3. Implementation of Principles GB principles are implemented as local and percolation constraints on the items. Local constraints are attached to nodes in the network. All items at a node must satisfy the node's local constraint, l?ercolation constraints are attached to the links in the network. A message can be sent across a link only if the item satisfies the percolation constraint of the link.","We will only use two examples to give the reader a general idea about how GB principles are interpreted as loc, al and percolation constraints. Interested reader is referred to Lin (1993) for more details. 3.1. Bounding rpheory The Bounding Theory (Subjaneency) states that a movement can cross at most one barrier without leaving an intermedia~te trace. An attribute named ~hbarr±0r is used to implement this l)rinciple. A message containing the attribute value -whbarrier iS used to represent an X-bar structure contMnlng a position out ol7 which a wh-constituent has moved, but without yet crossing a barrier. The wdue +whbarrier means that the movement has Mready crossed one barrier. Certain dominance links in the network are designated as barrier links. Bounding condition is implemented by tile percolation constraints attached to the barrier links, which block any message with +whbarrier and change -whbarrior to +whbarrier before the message is allowed to pass through. 3.2. Case Theory","Case. Theory reqlfires tha.t every lexicM NP be","assigned an al)stl'act case. ']'he implementation","of case theory in PI{,INCII~AII, is based on the","following attribute vaJues: ca, govern, cm. +ca the head is ,~ c~se assigner -ca the head is not a case assigner +govern the head is a governor -govern the head is not a governor -cr~ an NP m-commanded by the","head needs case marking The case filter is implemented as follows:","1. LocM constraints attached to the nodes assign +ca to items that represent X-bar structures whose heads are case assigners (P, actiw.' V, and tensed I). 484 . . .","-No&~. Local C<mstraint","-- l ) ] assign +ca to every item","[ assign +ca to items with","-passzve","assign +ca to items with tense","attril)nte ]';very item at NI' node is assigned an a.ttribute value -cm, which means that l;he NI' represented by l, he item needs 1,o be case-marked. The -cm al;tril)ute then propagates with tile item as it is sent to el;her nodes. ']'his item is said t<) be the origin of the -cm attribute. Barrier links do not Mlow any item with -cm l;o pass through, ])ceause, once the item goes beyond the 1)arri<:r, the origin Of-era will not be governed, let alone case-marked. Since each node in X-1)ar strncture has at most one governor, if the governor is not a case assigner, the node will not l)e case-marked. Therei'ore, a case-filter violation is detected if +govern -cm -ca cooccur in an item. On the other han<l, if +govern +ca -cm co-ocetlr itl all item, +,;lien the head daughter of th<; it<,m governs and case:marks the origin of-cm. 'l'he case-filter condition on the origin of -cm is met. ']'he -cm attril)ute is cleared. The local constraints attached to all the nodes check for the ('.o-occurrences el ca, cm, and govern to ensure <:ase-filter is not violated by any item. 4. Lexicon The lexicon in PRINCIPAl{ consists of two hash tables: a primary one in memory and a secondary one on disk. Tile secondary hash ta.= ble contains over 90,000 entries, most of which are constructed automatically by applying a set of extraction and conw:rsion rules to etP tries in Oxford Adwmced ],eaner's l)ictionary and Collins English I)ictionary.","When a word is looked up, t;he F, rimary hashtable is searched first. If a,n entry for the word is found, the lexical search is done. Otherwise, the secondary hash table is searched. The entry retrieved from the secondary LaI)Ie is inserted into the primary one, so, tha,t when the word is encouutered again only in-memory search will be necessary.","The primary hash table is lc, aded from a file a.L l;he system start-up. The file also serves as a buffer for changes to the secondary hash tM)le. When a lexical entry is ad(led or ]nc, dified, it is saved in the file for the prhnary hash table. The entry in the se<:(mdary hash tal)le remains unchanged. Since the i)rimary hash tM)le is a lw~ws consulted first, its entrios override the (;orresponditlg entries in the seco[ldary La})]C. The reason why the buffer in needed is that the secondary hash table is designed ill such a way that update speed is sacrificed for the sake of ef[icie.t retriewd. Therefore, updates to the secondary hash tal)le should I>e done in batch and relatively infrequently.","The tw(>tier organization of the lexicon is transparent to the l)arser. That is, as far as the. parser is concerned, the lexic<m is an o1> jec{, that, given a word or a phrase, returns its lexical entry or nil if the entry (lees not exist in the lexicon. I,cxical rctrievM is very el[icient, with over 90,000 entries, the average l;ime to retrieve an entry is 0.002 secon<l. 4.1. Lexical Entries All, hot@l the lexicon currently ttsed in I)I{IN - C'II>AI{, contains only syl~.tactic information, it; may also be used to hoM other types of ilffof mation. Each lexical entry consists of ai1"]},{"title":"eIltry","paragraphs":["word or phrase and a, list of functions with a,r- ~tllllClltS:","(< en~;ry-~ord-or-phras e> (<tune-name> <arg> ... <arg>) (<gunc-name> <arg> ... <art>) (<-June-name> <arg>. .. <art>)) For exanq)le, (acknowledge (subcat ((cat v)) (((cat i) -bare inf))) (subcat ((cat v)) (((cat n) (case acc)))) (subcat ((cat v)) (((cat c)))) q']le f'/ltlctioII subcat t'eturt/s a stll)c&|,egoriz&- Lion frame of the word. The first argtltneIl(; of t}te function is the attrHmte va,lues of the word 485 itself. The second argument of the function is a list of attribute value vector for the complements of the word. For example, the above entry means that acknowl edge is a verb that takes an IP, NP or CP as the complement. The lexicon is extensible in that users can define new functions to suit their own needs. Current implementation of the lexicon also includes functions ref and phrase, which are explained in the next two subsections. 4.2. Reference Entries The lexicon does not contain separate entries for regular variations of words. When a word is not found in the lexicon, the lexleal retriever strips the endings of the word to recow~'r possible base forms of the word and look them up in the lexicon. For example, when the lc'xieal retriever fails to find an entry for \"studies,\" it searches the lexicon for \"studie,\" \"studi\" and \"study.\" Only the last one of these has an entry in the lexicon and its entry is returned.","Irregular variations of words are explicitly listed in the lexicon. For example, there is an entry for the word \"began.\" IIowever, the snbcatgorization frames of \"begin\" are not listed again under \"began.\" Instead, the entry contains a ref fimction which returns a reference to the entry for \"begin.\" (began (ref ((cat v) (vform ed) -prog-perf-passive","(tense past))) (begin (cat)))) The first argument of ref is the attribute values of \"began.\" The second argument contains the base form of the word and a set of attribute names. The lexical items for the word \"began\" is obtained by unifying its attribute values with the attribute wdues in the lexiea] entry for \"begin.\" The advantage of making references to the base form is that when the base form is modified, one does not have to make changes to the entries for its variations. 4.a. Phrasal Entries ]'he lexicon also allows for phrases that consist of multiple words. One of the words in a phrase is designated as the head word. The head word should be a word in the phrase that can undergo morphological changes and is the most in frequent. For example, in"]},{"title":"the","paragraphs":["phrase, \"down payment,\" the head word is \"payment.\" In d~e lexicon, a phrase \"wl ... wj .... w,,/' is stored as a string"]},{"title":"\"'Wh","paragraphs":["... 'tOn, 101 ... 'U,~h_l.\" That is, the first word in the string is always head word and the words Mter \",\" should appear before the head word in texts. The runedon phrases converts il, s arguments into a list of phrases where tile entry word is the head. l,'or example, the lexical entry for \"paymenC' is as follows: (payment (subcat ((cat n) (nform norm))) (phrases","(payment, down)","(payment, stop)","(payment, token)","(payment, transfer))) After retrieving the entry for a word, each phrase in the phrase list is compared with the surrounding words in the sentence. If the phrase is found in the sentence, the entry for the phrase is retrieved froin the lexicon. 5. Reducing Ambiguities One of the problems with many parsers is that they typically generate far more parses than humans normally do. I\"or example, the average number of parses pet' word is 1.35 in (l]lack et al., 1992). That means that their parser produces, on average, 8 parses for a 7-word sentence, 3d parses for a, l%word sentence, and ld4 l)a.rses for a 17-word seiRe.nce, rphe la.rge number of parse trees make tim l~roe(,ssing at later stages more dillicult and error l)ruTte.","PI{INCII)AI{ defines a weight for every parse tree. A weight is associated with every word sense and every link in the parse tree. [Pile weight of the parse tree is the total weight of the links and the word senses ~tt the leaf nodes of the tree.","The packed shared parse forest in PtUN-CIPAI{. is organized in such a way that the parse tree with minimum weight is retrieved first. I~IUNCIPAII, then uses the minimum weight and a predetermined number called BIGWEIGHT, which is currently arbitraryly defined to be 20, to prune the parse forest. Only 486 the parse trees whose weights are less than (minimum weiglit -F BIGWEIGHT/2) are spared and output.","The weights of the links and word senses are determined as follows:","e 'I'he links fi'om Xbar to an ad,imlct YP have weight=nlGWEIglIW and all the~ other links have weight=l.0.","• The words in the lexicon ma,y have an attribute rar% which takes wdues from {very, very-very}. If a word sense has the attribute value (rare"]},{"title":"very),","paragraphs":["its weight is BIGWEIGIIT. Ifa word sense has the attribute value (rare very-very), its weight is 2×BIGWEIGIIT. Otherwise, the weight is 0, Note that the att;ribute rare is used to indicate the relative frequency among different stmses of the same word. /II~ /I L"]},{"title":"bigwe!ght L ', John John V /~; NP'~/N p /~N~, about Kim read a/ ~b~r read /NP.","paragraphs":["a /)N bar N I~P"]},{"title":"story/X N story about Kim (a) (b)","paragraphs":["Figure 3: Adjunct links ha,re higher weights Example 5.1. Comparing the two parses of the sentence \"John read the story a,bout Kim\" in Figure 3: in (a), lee about Kim] is the co,nplement of \"story\"; in (b), it is the a.djunct of \"read\". Since the adjunct dominance link from Vbar to PP has much higher weight than the complement dominance link from Nba.r to PP, the total weight of (a) is much smaller them the weight of (b). Therefore, only (a) is output as the parse tree of the sentence. Example 5.2. The lexical entry for tlm word \"do\" is as follows:"]},{"title":"7% 7% \" .p v/,. Who Z_~ /bar Who (traCe)V Kim \\~, bigweight \\ /v% did NP NP love (trace) A A (a) (b) Kim love","paragraphs":["Figure 4: l,exical items have diffc,'ent weights (do (subcat ((cat i) -passive -per~ (auxform do)","-prog (cgorm fin) (tense present))) (subcat ((cat v) (rare very))","(((cat n) (case acc) (nform norm)))) (subcat ((cat v) (rare very-very))","(((cat n) (case ace) (nform norm))"]},{"title":"((cat n) (case acc) (nform norm))))","paragraphs":["']'ha.t is \"do\" (:a.n bc an auxiliary verb, a transitive verb or a (li-trmlsitive verb. [,'igure el shows two parse trees for the sentence \"Who did Kim love?\" The parse l;ree (a) corrcsI)onds to the correct; understanding of the sentence. hi (b), \"did\" is analyzed as a bi-tra,nsitive w,'b as in \"Who did Kim a fawn'?\" lloweww, since the latter sense of the word has an attribute value (rare very-very), tree (17) has much higher weight tha,n tt'ee (a) and only (a,) is otd.lmt, by the i)ai's(~l ..","6. Irnplementation and Experimental Ftesult;s PRINCII~AR lms been implemented in C-I--I ~. The graphica,1 user interface is developed with a toolkit called interViews. The program runs on SUN Spa.rcstatlons with X-windows. A version without; gral)hica, l user interface can also be run on most Unix machines with GNU g-f-t-compiler.","l,iu m~d Coebel (1993) showed that the COml)lexlty of the message passing algorithm"]},{"title":"is O(ICl',,.:' ) ro,. co.l;(.xt-f,:ee gra,,~,nars, wl.',',' ~. is the length of input sc'utenco, [C[ is size","paragraphs":["487","Table 1: Experimental Results","Example sentences Who do you think Bill saM Mary expected to see I asked which books he told me that I should read The petition listed the mayor's occup~ttion as attorney and his age a,s 71 lie said evidence was obtained in violation o[' the legal rights of citizens Mr. Nixon, for his part, wouhl oppose intervention ill Cllba without specific provocation The ~Lssembly la.ngu~tge provides a means for w,'iting a progra.m and you are, not concerned with actual memory addresses \" Labels can be assigned to a particular instruction step in a source program that identify that step as an entry point for use in subsequent instructions * time (in seconds) taken on a Sparcstation ];~LC.","-- .",",","I","words"]},{"title":"[","paragraphs":["tmte* p~trses :10 - 11 0.76 i3 0.60 t4 13 0.55 4 ]3 0.51 6 19 O.80 2 26 4.13 32 of the grammar (measure by the number of the total length of the phrase structure rules). When attribute values are used in messages, the complexity of the Mgorithm is not yet known. Our experiments have shown that the parser is very fast. Table 1 lists the parsing time and the number of parses for several example sentences. The correct parses for all the sentences in TM)le 1 are returned by the parser. Even though the lexicon is derived from machine readable dictionaries and contains a ]a.rge number of senses for many words, the ratio between the number of parse trees and the sentence length here is well bellow the ratio reported in (Black et al., 1992). Acknowledgements The author wishes to thanl¢ Bonnie Dorr for comments about Sections 1, 2, and 3. This re'- search was supported by NaturM Sciences and Engineering Research Council of Canada grant OGP121338. References","Berwick, I1.. C., Abney, S. P., and Tenny, C., editors (1991). Principle-Based Parsing: Computation and Psyeholinguislics. Kluwer Academic Publishers.","Billot, S. and Lang, B. (1989). The structure of shared forests in ambiguous parsing. In Proceedings of ACL-80, pages 143-151, Vancouver.","Black, E., L~dDrty, J., and Roukos, S. (:1992). l)evelopment and ewduation of a broadcoverage probM)ilistic grammar of englishlanguage computer manua.ls. In Proceed-in:is of ACL-92, pages 1185-1192, Newark, l) alaware.","Chomsky, N. (:1981). Lectures on Government anti Binding. Foris Publications, Cinnaminson, USA.","Dorr, B. J. (1991 ). Principle-based pa.rsing for nla,- chhm translation. In (Herwick et al., 1991), p~ges 15a <18,1.","Fong, S. (i 991). The computationM implementation of principle-based parsers. In (Berwiek el, al., 1991), pages 05-82.","lla.egeman, L. (11997l). lnl,roductio'n to Government m,f Binding Theory. Basil ]~Ia.ckwell Ltd.",",]ohnson, M. (199l). 1)eductiw~ l>a.rsing: The use of knowledge o[' la.ngua.ge. In (l~erwiek el, al., Ig.Ol), pages 39 64.","l,in, 1). (199\"{). Prhlciple-based parsing without ow'.rgeneration. In Proceedings of A 6'13-93, pages :112--120, Columbus, Ohio.","Lin, I). and Coebel, R. (1993). Context-free gramm~r parsing by message passing. In Proceedings of l,he Fi'lwZ Cm@renee of the Pacific Association for Comw.tational Linguistics, pages 203-211, V~mcouver, British Columbia.","Tomit',~, M. (1986). l'Jffieient Parsing for Nal,ural Language. Kluwer Ac~u[emic Publishers, Norwell, Massachusetts. 488"]}]}