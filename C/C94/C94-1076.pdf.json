{"sections":[{"title":"Minimal Change and Bounded Incremental Parsing Mats Wirdn Fachrichttmg 8.7, Computcrlinguistik Universit,~t des Saarlandes Postfach 1150 D-66041 Saarbr/icken, Germany wiren~coli.uni-sb.dc Abstract","paragraphs":["Ideally, the time that an incremental algorithm uses to process a change should be a fimction of the size of the change rather than, say, the size of the entire current input. Based on a formalization of \"the set of things changed\" by an increInental modification, this paper investigates how and to what extent it is possibh~' to give such a guarantee for a chart-ba.se(l parsing frmne-work and discusses the general utility of a tninlmality notion in incremental processing)"]},{"title":"1 Introduction 1.1 Background","paragraphs":["Natural-language computing has traditionally been understood as a \"batch-mode\" or \"once-only\" process, in which a problem instance P (shy, a text) is mapped as a whole to a solution S (such as air analysis of the text). IIowever, in highly interactive and real-time applications -- for example, grammar checking, structure editing and on-line translation -- what is required is efficient processing of a sequence of small changes of a text. Exhaustive recomlmtation is tber, not a feasible alternative. Rather, to avoid ms much recomputation as possible, each update cycle must re-use those parts of the previous solution that are still wdid. We say that an algorithm is incremental if it rises information from an old solution in computing the new solution.","The problem of incremental processing can be stal.ed its follows, using a notation similar to that of All)ern et al. [1]: Assume given a problenr instance P (a representation of the current input), a solution S (the current output), and a modification Ap to p.2 The modification results in a new problem instance P' = P • At,, where • is a composition operator. The task of an in-","1I would like to thank Ralph RSnnqulst as well as Gregor Erbach and other colleagues in Snarbrfieken for discussions on the material presented here, Peter Fritzson for originally alerting my attention to Ramalingam and tleps' paper, and the anonymous referees. This research has been flmded by the Cerman Science Foundation (DFG) through the Sonderforschnngsl)erelch 314, project N3 (BiLD).","~A terminological note: we use \"input change\" and \"modification\" as well as \"output cllange\" and \"update\" synonymously. z~ p ~ P'=P(DAp","As S. ~- S' -- S (I) A s l;'igure 1: Batch-mode versus incremental cornlmtation. cremental algorithm is then to produce an upd~te As in the old solution such that .5' • As is a solution to P(DAp (see figure 1). At this point, nothing is stipulated about tim amount, of information it, S tlmt should be re-used in S'. To show properties such im correctness and complexity of incremental algorithms, it is necessary to establish a formal measure of \"the set of things changed\". This me,inure sllouhl capture tim minimal change resuiting from a modification and, moreover, should be independent of any particular algorithms R)r incremental update. One way of achieving this is to compare the results obtained by batch-mode processing of the inputs before and after the change, respectively (Wirfin and l~.Snnquist [15, 17]): By forming tile \"difference\" l)el.ween the lmtch-mode soh,tions S and £,1 obtained before ;tlt(] after a modillcation At, to P, we obtain a parameter As,m ' which captures tin.' minimal change in a way which is indeed imlependent of the incremental ul)date. Given that A.s,,,i\" corre.sl)onds precisely to what any sound and complete incremental algorithm must do, it, can be used as a blmis lbr correctness proofs for suclt algorithms"]},{"title":"(given","paragraphs":["tl,at the batch-rhode algorithm is correct).","Fnrthermore, Asmi\" can be used ms a basis of complexity analyses: Ideally, each update cycle of an incremental algorithm slmuld expend an amount of work which is a polynomial fimction of the size of the change, rather than, say, tile size of tl,e entire current input. However, making this notion precise in a way which is independent of particular incremental algorithms is not 461 always straightforward. Two early approaches along these lines are Goodwin [3, 4] (reason maintenance) and Reps [11] (language-based editing). More recently, Alpern et al. [1] and Ramalingam and R.eps [9, 10] have provided a framework for analysing incremental algorithms, in which the basic measure used is the snm of the sizes of the changes in the input and output. This framework assumes that the modification of the input can be carried out in"]},{"title":"o(IAPI)","paragraphs":["time, where the generic notation"]},{"title":"IXI","paragraphs":["is used for the size of X. Furthermore, it assumes that ]As,m,] denotes the minimal"]},{"title":"IAsl","paragraphs":["such that S (9 As solves P (9 Ap. Alpern et al. then define"]},{"title":"= lapl + IzXs,~. I","paragraphs":["as the intrinsic size of a change. The choice of 6 is motivated as follows:"]},{"title":"IAph","paragraphs":["the size of the modification, is in itself too crude a measure, since a small change in problem instance may cause a large change in solution or vice versa."]},{"title":"IAs..,,I","paragraphs":["iv then chosen as a measure of the size of the chauge in the solution, since the time for updating the solution can be no less than this. The 5 measure thus makes it possible to capture how well a particular algorithm performs relative to the amount of work that must be performed in response to a change.","An incremental algorithm is said to be bounded if it can process any change in time O(f(5)), that is, in time depending only or, 5. Intuitively, this means that it only processes the \"region\" where the input or output changes. Algorithms of this kind can then be classified according to their respective degrees of boundedness (see Ftamalingam and Reps [10, section 5]). For exampie, an algorithm which is linear in 5 is asymptotically optimal. Furthermore, an incremental algorithm is said to be unbounded if the time it takes to update the solution can be arbitrarily large for a given 5.","It might seem that what has been discussed so far has little relevance to natural-language processing, where incrementality is typically understood ,as the piecemeM assembly of an analysis during a single left-to-right a pass through a text or a spoken utterance. In particular, incrementality is often used as a synonym for interleaved approaches, in which syntax and semantics work in parallel such that each word or phr~me is given an interpretation immediately upon being recognized (see, for example, Mellish [7] and lladdock [5]). llowever, the two views are closely related: The \"left-to-right view\" is an idealized, psycholinguistically motivated special case, in which the only kind of change allowed is addition of new material at the end of the current input, resulting in piecemeal expansion of the analysis. Moreover, the interleaving is just a consequence of the fact that every piece of new input must, in some sense, be fully analysed in order to be integrated with the old analysis. To distinguish this special case from the general case, in wtfich arbitrary changes are allowed, Wirdn [15] refers to them as left-to-right (Lll) incrementality and 3Strictly speaking front-to-back or beginMng-to-end. full incremenlalily, respectively. The former case corresponds to on-line analysis -- that each prefix of a string is parsed (interpreted) before any of the input beyond that prefix is read (llarrison [6, page 433]). The latter case has long been studied in interactive language-based programming environments (for example, Ghezzi and Mandrioli [2]), whereas the only previous such work that we are aware of in the context of natural-language processing is Wirdn and R.gmlqnist [14, 15, 16, 17]. 1.2 The Problem The aim of this paper is to begin to adapt and apply the notion of bounded incremental computation to natural-language parsing, using a method for establishing minimal change previously introduced by Wir6n and RSnnquist [15, 17]. To this end, the paper shows how the 6 parameter can be defined in a fully incremental, chart-based parsing framework, briefly describes a previous, unbomMed algorithm, and then shows how a polynomially bounded algorithm can be obtained."]},{"title":"2 Batch-Mode Chart Parsing","paragraphs":["An incremental problem can be defined by specifying its batch-mode version and the set of allowable modifications. We thus begin by specifying batch-rhode chart parsing, restricting ourselves to a standard context-free grammar without cyclic or empty productions. Definition 1 (Chart) A chart is a directed graph C = (V, E) such that V is a linite, non-empty set of vertices and E C V x V x R is a finite set of edges, where R iv the set of dotted context-free rules obtained from the grammar. 4 The vertices vl,...,vn+l G V correspond to the linear positions between the tokens r = tl ... t, of an n-token text. 5 All edge e G I'; hetween vertices vl and vj carries information al>out a (partially) analysed constituent between the corresponding positions.","The algorithm makes use of an agenda (see Thompson [12]). Agenda t;~sks are created in response to tokens being read and edges being added to the chart, and may be ordered according to their priorities. To define the agenda, we make use of the set of possible tokens 7'kns and the set of possible edges Edgs. Definition 2 (Agenda)We define the agenda as Agda C Tkns U Edgs U ( Edgs x Edgs). We refer to the three types of tasks that it contains as scanning, prediction and combination tasks, respectively.","4For brevity, we omit a fourth edge component corresponding to tile set of (partial) parse trees according to the grammar and lexicon (assuming that only the topmost portion of a tree corresponding to the (lotted rule needs to be stored in an edge).","5We shall use ~\" interchangeably to denote a sequence a~td a set of tokens. 462 Each agenda task is executed by a ste 1) of the algorithln below. We specify two versions of batch-nmde chart parsing -- the basic bottom-up (strictly speaking, leftcorner) and top-down (Earlcy-stylc) strategies - . aSSll~ ruing that the one or the other is chosen. Algorithm 1 (Batch-mode chart parsing) Input: A seqnence of tokens r = t1 .. • t,. Output: A chart. Initialization: If tile tOll-down strategy is used, then add an agenda task corresponding to ail initial top-down prediction (Vl, Vl, S --~ .c~) for each rule S --+ ~v, where S is ttle start category of tile grammar. Method: For each token, create a scanning tm~k. While tile agenda is not empty, remove the next task and execute tile corresponding step below:","Scan: Given a token I at position j, lbr each lexical entry of the form X -> t, add all edge (vj,Vj+l,X --+ l.). d Add restllting new t~sks to the agenda.","Predict 1 (Bottom-up): If tile edge is of the form (vj, vk,X --* c¢.), then, for each rule of the form Y --+ XT, add an edge (vjivj,Y ~-+ .XT) unless it already exists. Add resulting new tasks to tile agenda.","Predict 2 (Top-down): If the edge is of tile form (vl, vj, X--+ oe. gfl), tlien, for each rule of the form Y \"-* 3', add an edge (vj,vj,Y -+ -7) unless it already exists. Add resulting new tasks to the agenda.","Combine: If tile first edge is of tim form (vi, vj, X --* ~.Yfl} and the second is of the form (vj, vk, Y -, 7.), then add an edge (vi,vk,X -+ aY.fl). Add resulting new tasks to the agenda."]},{"title":"3 Incremental Chart Parsing","paragraphs":["a.1 The Problem ]'lie overall incremental process can be thought of ~Ls a cliange-update loop, where each chalige of the input is immediately followed by a corresponding update of the output. To completely specify the state of this process, we shall make use of a conliguration consisting of (a reI)resentation of) an input text r, a cliart C and an edge-dependency relation 79 (to be &dined in section 4). The problem of incremental chart parsing can then be specilied abstractly as a mapping f((r,C, 79),Ar) ~ (r',C',79') from an old configuration and a modillcation Ar to a new configuration. We shall allow two kinds of change, namely, insertion and deletion of w > 1 contiguons ~We refer to the new edge as a"]},{"title":"lezical'edge.","paragraphs":["tokens. We assume that a modification A~ is given as a vertex pair vj, Vj+m G V defining the update interval and, in the cILsc of an insertion, a seqnence of tokens T ~ lj • • • tit m . We fiirthernlore ;ussume that either the bottom-up or top-down strategy is chosen throughout a change-ul)date session, and, in tile latter case, that tile toll-down initialization is made before the session is started. 3.2 A C, eneral Vertex Mapping flow can tile minilnal change ASh, in be defined il, a chart-b~sed framework? One way of doing this is to colnpare the charts C = (V, E} and C' = (V', I',\") that are obtained by batch-mode parsing of tile texts before and after a change, respectively. We thereby obtain a measure which is independent of particular increniental update algoril, hms. hltnitively, only those edges that are in E but not in lq re,st I)e relnoved, and only those elites that are in 1'; ~ Ilut not in E must lie generated anew. If the change is snlall, then a large fraction of the edges are in /q gl I'Y (I.hat is, are unchanged).","llowever, to be able to colnpare the edge sets in the two ('harts, we nmst first establish a one-to-one mapping between their vertices, l,et us consider the case in wlfich a single token ti is (Meted from an n-token text. The probleln is that, becanse of tile remove(l token, the two vertices vl and vi+l would seem to correspond to a single w~rtex in V ~. llowever, we can regard this single vertex as consisting of a \"left half\" and a \"right half\", which we assign diffe.rent indices. In other words, after having increase(l each index of v~_l.1,... , v~, G V' by one, we \"split\" vertex v~ and assign the index i+1 to its \"right half\". The incoming non-predicted edges ms well as (looping) top-down predictions at tile split vertex are then associated with its left half, and tile ontgoing non-predicted edges as well ~us (looping) bottom-up predictions are associated with its right half. 7 q'he reason for dividing the pre(licted edges in this way is that a tOll-down prediction is made at (,tie ending vertex of the i,riggcril, g edge (that is, froln tim left), wllereas a /)ol.toln-up pre(liction is lnade at tim starting veri,ex of the triggering edge (that is, from the right).","The lnapping Call I)e geIieralized to tile cruse ill whil:]l Ill COlitiguoiiS tokelis are deleted. Ttlis is done by iilc.reasilig the index of eax:h w~rtex froin the \"right half\" of tile split wn'tex an(I oilwards by m (instead of one). Fnrtherinore, by nsing the salile lnlq)ping but in the opposite direction, we can ills() cover insertion of m contiguous toke[is. To express this generalized inal)- ping, m'-ISlliln~ that !) is the set of vertices of the larger chart and V is that of the smaller chart. A deletion of m contiguous tokens then involves a mapping frona to V and an insertion of rn tokens involves a real/ping from V to V. In terms of tile indexing that holds before the vertices in V are renumbered, and assuniing that l)","7A,u lllentloiled above, we aSsulne that only the one or the other st, i'ategy is ilsed, so that ii, is kllowli llefOl'ehllnd which kind of predi<:tlons the cltal't COlttliillS, 463 ,m3m"]},{"title":"'\" r.__~2","paragraphs":["wls ........... =17 ................ -\"' ."]},{"title":"I It, '","paragraphs":["....."]},{"title":".............. ~ /r .... -',l lit .............. , r .....","paragraphs":["..... ' ......",":::zc-: -"]},{"title":"_.. :-1¢:.","paragraphs":["~a wx~","~al veal",".,]","wx~","~aa","vP}0 Figure 2: Chart of the sentence \"The old man the tall ships\" under bottom-up parsing. Inactive edges are drawn using continuous lines, active edges using dashed lines, and predicted (looping) edges are depicted below the vertices. ,S36 ~';,; i ~- ......................."]},{"title":"l ....................... , Ii ....","paragraphs":[".r\"\"\" ................... ~ f-\"~'--\\ / ,--'~'~'- ~a wla Ne2a ve2~"]},{"title":"slooP3","paragraphs":["Vel4 N~] V~2B Figure 3: Chart of the sentence \"The old man tile ships\" under bottom-up parsing. has n + 1 vertices, we obtain the following bidirectional mapping:","• Vertices vl,..., vi-1 C V correspond to vl, • •., vi-1 G V, respectively.","• Vertex vi corresponds to the \"left half\" of vertex Vi.","• Vertices vi+l,...,Vi+m-t E ~\" do not correspond to any vertices in V. • Vertex"]},{"title":"~i+m","paragraphs":["corresponds to the \"right half\" of vertex vl.","• Vertices 91+re+x, • •., ~.+1 correspond to vi+l, • •., vn+l-m, respectively. The mapping is thus established with respect to inset-tion or deletion of an arbitrary number of contiguous tokens, s 3.3 Minimal Change Assume that E and E' are the sets of edges of the charts C and C' obtained by batch-mode parsing of a text before and after a modification Ar, respectively.","8 Presumably, it is possible to generalize the mapping to more complex (non-contiguous) operations such as replacements or reversals. However, we do not pursue that here. S --~ NP VP the *-- Det NP ---* Det N old ,--- N, A NP ~ Del A N man ,--- N, V VP --* V ships +-- N, V 171) --~ V NP Figure 4: Example grammar and lexicon. We can then define the minimal ontput change on the b~is of two edge sets as follows: Definition 3 (Minimal output change) We define the set of missing edges as tile set difference M = E\\E j and the set of new edges as tile set difference N = E' \\ E. We then define the minimal output change as Ac,,i, = M U N. Next, we can define the size of tile minimal change as follows: Definition 4 (Size of minimal change) We define the size of the minimal change as/~ = [A~I + ]Ac,,,,I, the sum of the number of inserted or deleted tokens and the number of edges in Ac,,,i,. 3.4 An Example As an illustration, tile chart in tigure 2 is obtained under (batch-mode) bottom-up parsing, given the grammar in figure 4 and the sentence 'q'he old man the tall ships\". If the token \"tall\" is removed, the chart in figure 3 is obtained. Vertex v~ in figure 2 then col responds to the left half of vertex v~ in figure 3, and vertex v6 corresponds to the right half of vertex v~. Furthermore, v7 corresponds to v~. Clearly, tile input change A~ consists of the token \"tall\". The output change A¢,,i, consists of the missing set M, which contains the three edges A26, NP27 and NPa4 in figure 2, and the new set N, which contains the singh. edge NPau in figure 3. ']'he size of the change is then 6= I~Xrl + IZXC,,,.,I := t+a+l =5.","If instead \"tall\" is inserted before the last word in the sentence in figure 3, then the input change still eonslsts of the token \"tall\". ]lowever, the two sets making up the output change are reversed: the missing set contains the single edge NPa2 in figure 3 and the new set contains the three edges A26, NP2r and NP34 in figure 2. Thus, the size of the change is again 5."]},{"title":"4 An Unbounded Algorithm","paragraphs":["A key idea of the incremental chart-parsing algorithm put forward by Wir&, [14, 15] is to use edge dependencies for keeping track of edges that ]lave to be removed in response to a change. An edge e' is said to depend upon another edge or token e if it is formed (derived) directly on the b~usis of e. Furthermore, if e' is redundantly proposed by an edge f, then d can be said to 464 15 14","01 \" , 1 l* Figure 5: Edge-dependency graph induced by 1). q'he nodes of tl|e gral)h correspond to the chart edges in figure 3. A dummy root node 0 is shown instead of nodes corresponding to the tokens. depend (also) on f. By e' being \"redundantly propose(l\", we mean that the parser attempts to add an edge that is equivalent to # to the chart, but thai, that edge is rejected by the standard redundancy test in chart parsing. In effect, f provides an additional \"justifica-tion\" for #.","Given a chart C = (V, E) and a set of tokens r, these conditions correspond to the following dependency relation on E and r: Definition 5 (Edge dependency) We define 79 as a binary relation on the set of chart edges and the set of tokens E U r such that 79(s, d) hohts if and only if d G E is formed, or is redun(lantly proposed, directly using s C EU r according to a chart-l)arsing algorithm. We say that d is a dependent (or derivative) edge of s, and tl|at s is a source edge (token) of d. 7) can be ilh|strated by a graph. The dependency graph corresponding to the chart in figure 3 is shown in [i-gure 5.","On the basis of the dependency relation, WirSn and RSnnqnist [15, 17] define different disturbance sets, given as fimctions t'rom tokens to sets of edges, and containing edges that need to be removed from the chart in response to a token-level change. The simplest such set is 7)*(tj), the transitive closure of 79(tj). Wirdn and Rfnnquist [15, 17] discuss this and other alternatives and show completeness of 79* with respect to the missing set.","The algorithm performs an update essentially by removing the entire disturbance set an([ then generating all possible edges. The latter set includes not only the new edges, but also disturbed, non-missing edges, which have to be generated anew. q'he coml)lexity analysis of the algorithm yields that it is unbounded incremental in both its botto|n-up and top-down version (see Wir6n [16]). The source of this is that the algorithm removes the entire disturbance set, whose size depends on n, the size of the entire input."]},{"title":"5 A Bounded Algorithm 5.1 Intuitive Idea","paragraphs":["Intuitively, a bounded incremental algorii.hm only processes the region where the input or output changes during an update cycle. In our c~se, the problem in achieving this is that the missing and new edges are not a priori known -- when the incremental update begins, only a set of potentially missing edges (the disturbance set) is known. Ilowever, the ul)date can be limited by using a change-prol)agation algorithm (compare Itamalingam and l{.eps [10, page 21]): By initially retaining the disturl)ance set, new and old edges can be coml)ared during reparsing. If a new edge e' is different from the corresponding old edge e (if this exists), then the dependants of c are regarded ms disturbed (potentially missing). If # is equivalent to e in the sense of giving rise to the sltme derivative edges, then the dependants of c are known not to be missing, and hence tim reparsing process does not have to proceed beyond this point in the search sl)ace, in order to avoid extra computation, the disturbed edges should be visited in the order given by the dependency graph.","llow can the points aL which a change \"(lies out\" be characterized? Since we are interested in characterizing the conditions under which two edges give rise to the same derivtLtive edges, the contents part of an edge (that is, the rigltt-hand side before the dot of the dotted rule) is irrelevant. For example, we want to say that the new edge Nl):~2 in fig||re 3 to be reparsing-equivalent with edge NP:~4 in figure 2 although their dotted rules and parse trees are different: the dotte(I rule of the former is NP -~ Dcl N. and that of the latter is NI\" ~ l)cI A N.. We can summarize this in tile following delinition: Definition 6 (Reparsing-equivalent edges) Assume given a proposed edge e and a disturbed edge e' C- C. Wesay that e = (vi,vj,X-.*o~.fl) and # = (v,, vt, Y-*tt.v) are equivalent from the point of view ofreparsingifi=s,j=t,X=Y andfl=v. Inactive (combined or lexical) edges and predicted edges are special cases under this definition. Ill the former case, fl and u are empty, and thus two inactive edges are reparsing-equivalent if i = s, j = t and X = Y. In the latter case, (v and i t are empty, and thus two predicted edges e and c' are reparsing-equivalent if e = d. 465"]},{"title":"5.2 The","paragraphs":["Algorithm We now specify a bounded incremental chart-parsing algorithm that handles one update cycle. 9 In comparison with the unbounded algorithm, the differences are in the reparse and remove steps. Algorithm 2 (Incremental Chart Parsing) Input: A configuration (r,C,:D) and a modification Ar corresponding to insertion or dcletlon of m tokens ti , . . •, ti+m. Output: An updated configuration"]},{"title":"(r', C ~, D').","paragraphs":["Method: Do the following steps:","Modify the problem instance: Insert or delete the modified tokens given by A~ into or from"]},{"title":"r.","paragraphs":["Prepare the chart: Do one of the following steps in the case of insertion or deletion, respectively: Insertion: Renumber edges as follows: First, replace each edge (vj,v~,r} where j _> i and k i with an edge (vj+m,vk,r}. Secondly, replace each edge (vj,v~,r) where k > i with an edge (vj, vk+m, r). Looping edges at the \"modification vertex\", which have the form (vi, vi, r), are dealt with differently depending on where their sources are located, which in turn depends on the prediction strategy:","• Bottom-up case: If the looping edge depends on an outgoing, non-looping edge ((vi, vj, r) such that j > i), then the looping edge is replaced with an edge (vi+,n, Vi+m, r) (in effect, it is moved).","• Top-down case: If the looping edge depends on an incoming, possibly looping edge ((vi, v~, r) such that k < i), then do nothing. Finally, update the depemlency relation 79 so that any edge (vj,vk,r) such that j < i and k > i is made dependent on ti. Deletion: Renumber edges ms follows: First, replace each edge (vj, vie, r) where j > i with an edge (Vj-m,vk,r). Then replace each edge (vj, vk, r) where k > i with an edge (vj, vk ..... r).","Reparse: Do the following steps: In the ease of insertion: create a scanning task for each new token; create a combination tmsk for each active-inactive edge pair meeting at vl and vi+m. In the case of deletion: create a combination task for each active-inactive edge pair meeting at vi. Reparse while visiting the disturbed edges in the order given by the dependency graph and treating the disturbed edges as \"sleeping\" (that is, they do not play any role in the parsing process ms such). 9The algorithm is currently being implenlented. Whenever a new edge is proposed, check if an equivalent edge exists in the disturbance set according to definition 6. If so, install the new edge, update 2) by letting the new edge inherit the dependencies from the old edge. Do not add any agenda items for the new edge (thereby discontinuing reparsing along this path). Mark the new edge as re-created (with respect to a reparsing-equivalent one).","Remove edges: Remove each edge that is in the disturbance set but not in the dependency set of any re-created edge. 5.3 Incremental Complexity For the purpose of analysing the incremental complexity of algorithm 2, we assume that adding or removing an edge takes unit time. We also assume that no edge h,'~ more than a constant munber of sources or dependants and, hence, that the time required to install or examine the depemlencies of k edges is O(k). t°","We first focus on the reparsing step. 11 Consider the case of a deletion within a text. The set of new edges N are generated ;ks a result of joining two subcharts, which we assume have length i and j and contain O(i 2) and O(j 2) edges, respectively (disregarding the grammar constant ]G D. The joined chart thus has length i + j and consists of"]},{"title":"O((i + j)'-')","paragraphs":["edges. The number of uew edges resulting from joining the subcharts is then INI -- O((i + j)2) _ (O(i 2) + O(j2)) = O(i. j) cages. Since the algorithm generates these edges by invoking a O(n 3) reparsing algorithm, the new edges require O((i+j)a) - (O(i a) + O(jJ)) = O(i.j. (i+ j)) = O(i ~. j2) = O(IN2[) time. The insertion case can be obtained in a similar way and gives the same result. In the remove step, the missing edges are found by following dependency chains originating from tokens until a reparsing-equivalent edge is found or the chain ends. This step can therefore be executed in O(IM]) time. The algorithm as a whole then requires 0(/~ 2) time."]},{"title":"6 Conclusions","paragraphs":["The boundedness criterion used here provides a guarantee that tile next update state is never more than an amount of computation away from the current state that is limited by the size of the change. This criterion is very strong. It can be thought of as constituting one l°Thls assmnption is considered too strong in reason maintenance, where, in the worst case, all formulas can be directly connected (see Goodwln [4, page 110 f.]). However, it seems approprlate here, since nmler a context-free grammar of the kind 'ased here only predicted edges may have mu|tlple sources. Moreover, the number of these sources is limited because of the llnearlty of the problem instance (the text). ll Since we take addition and removal of edges to be the pl'i-mary tasks of incremental update, we disregard the chart-preparation step. Although a more thorough analysis might take this step into &ccotlnt both in the definition of g and in the complexity analysis, we do not believe that anything fundamental would be altered by this. 466 extreme point of a continuum of ways in which to measure tile complexity of incremental algorithms. At. the other extreme, we have the option of using 11\"1 +"]},{"title":"I,~\"1,","paragraphs":["the cost of discarding the ohl solution and invoking a hatch-mode algorithm on the moditied problem instance. This measure might be used for showing that an algorithm with poor worst<ase incremental behaviour is still practical: Poor incremental behaviour means that the algorithm does not respond quickly to (some) small changes, tlowever, it may still perform better than discarding the old solution and invoking a hatch-mode algorithm. In other words, even if the algorithm is unbounded in ~, it may have a lower time bound in IP'[ + 1,9'1 than the batch-mode algorithm, q'he unbonn(led algorithm described ilk section 4 is an example of this: it is clearly more ellicient than the batch-mode algorithm for the lmrpose of incremental update.","Several interesting topics for further research present themselves: One is to generalize the notions of minimal change and hounded incrementality to other processing frameworks that make use of a table or a chart, for example, pseudo-parallel LR. parsing (Tomita [13]) or taMlar generation (Neumann [8]). Another interesting topic is to translate the slmre notions to a unificationbased grammar formalism. Defining minimal change then requires a definition of the dill'erence between two feature structures. An immediate observation is that this is itself hardly a feature structure, but rather the set of (suh)structnres that are not present in both feature structures (in analogy with our delinition of the difference between two charts)."]},{"title":"References","paragraphs":["[1] llowen Alpern, Roger [loow'.r, Barry K. Rosen, Peter F. Sweeney, and 1\". Kenneth Zadeck. Incremental Evaluation of Computational Circuits. In Proc. First Annual A CM-SIA M Symposium on Discrete Algorithms, l)ages 32 42, San l\"rancisco, California, USA, 1990.","[2] Carlo Ghezzi and Dino Mandrioli. Incremental l'arsing. ACM 7)'ansaclions on Prv qramming Languages and Systems, 1(1):58-70, 1979.","[3] James W. Goodwin. An hnproved Algorithm for Non-Monotonic l)ependency Net, Update. Research Report LiTII-MNI'-R-82-23, Department of Computer and lnfornaation Science, Link6ping University, Link/3ping, Sweden, 1982.","[4] James W. Goodwin. A 'l'heory and Systom for Non-Monotonic Reasoning. LinkSping Studies in Science and q'eehnology, l)issertation 165, l)epartment of Computer and Information Science, Linkgping University, LinkSping, Sweden, 1987.","[5] Nicholas a. Iladdock. Comlmtational Models of Incremental Semantic Interpretation. l, angnage and Cognitive Processes,"]},{"title":"4(3--4):aar-a68,","paragraphs":["1989.","[6] Michael A. Ilarrison. introduction to l\"ormal Language Theory. Addison-Wesley, Reading, M~ssachuset, ts, USA, 1978.","[7] Christopher S. Melllsh. Computer lnlerprelalion of Natural Language Descriptions. Ellis llorwood, Chiehester, England, 1985.","[8] G/inter Neumann. A Tabular Uniform Algorithm for Parsing and Generation. Chapter of forthcoming Ph.l). thesis, Universit~[t des Saarlandes, Sitarbriicken, Gerrnany, 1994.","[9] O. l{amalingam. Bounded Incremental Computa-tion. Technical l~.eport (Ph.D. Thesis) 1172, Computer Sciences l)epartment, U'niversity of Wisconsin, Madison, Wisconsin, USA, 1993.","[10] (]. l~.amalingam and 'l'hom~. W. l/.el)s. On l, he. Comlmtational Complexity of Incremental Algorithms. Technical li.eport 10a'.l, Computer Sciences I)epartmeut, University of Wisconsin, Madison, Wisconsin, USA, 1991.","[1 I] Thomas W. Reps. Optimal-Time Incremental Se-- mantle Analysis lbr Syntax-Directed Editors. ILk Proc. Ninth ACM Symposium on Principles of Programming Languages, pages 169-176, Alhuquerque, New Mexico, USA, 1982.","[12] IIenry S. Thompson. MClIAItT: A Flexible, Mo- (htlar Chart l'arsing System. In Proc. Third National (;onfeTvnce on Artificial Intelligence, pages 408--410, W~kshington, I).C., USA, 1983.","[I 3] Masaru qbnfita. An EIficient Context-l,'ree Parsing Algorithm for Natural Languages. In Proc. Ninth International Joint Conference on Artificial Intelligence, pages 756-764, Los Angeles, California, USA, 1985.","[14] Mitts Wirdn. lnteractiw'~ Incremental Chart Parsing. In Proc. Fourth Co,ferenee of the European Chapter of the Association for Compnlalionol Linguistics, pages 241-248, Manchester, li}ng - land, 1989.","[15] Mats Wir6n. Stutlies in lncrenmntal Natural-Language M,alysis. l,ink6ping Stndies ilk Science and q~chnology, Dissertation 292, l)epartment of Computer and Information Science, LinkSping University, LiukSping, Sweden, 1992.","[16] Mats Wirdn. l/ounded Incremental Parsing. In PTvc. 6th 7'wente Workshop on Language 7'echnology, pages 145--156, I,'mschede, the Netherhmds, 1993.","[17] Mats Wir(n and Rall)h Rgnnquist. l\"ully Incremental Pro'sing. In Proc. Third International Workshop o11 Parsing 7~chnologies, Tilburg, the Netherlands and Durlmy, IMgium, 1993. 467"]}]}