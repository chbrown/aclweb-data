{"sections":[{"title":"Towards","paragraphs":["a"]},{"title":"Dynamic Theory of Belief-Sharing in Cooperative Dialogues","paragraphs":["Hisashi Komatsu Norihiro Ogata Akira Ishikawa The Toin Corporation University of Tsukuba Sophia University"]},{"title":"1 Introduction","paragraphs":["In this paper, we propose a dynamic theory of belief-sharing which dens with certain processes of forming and revising shared beliefs during cooperative dialogues.","Since Clark & MarshNl(1981) the problem of de-termination of the referents of referring expressions has been discussed in relation to mutual knowledge. In natural language processing, there haw~ also been several studies treating this problem of referent-determination in terms of mutuN knowledge (Perrault &: Cohen, 1981; Joshi, 1982; Nadathur & Joshi, 1983; Appelt, 1985). In this paper, we conceive referent-determination as a process of belicfsllaring in dialogues, and propose a formal theory of dialogue in which referent-determination can be characterized as part of belief-sharing processes. We use Discourse Representation Theory (DRT) to model the characteristics of referents in discourse (Kamp, 1981, 1990; Asher, 1993), and propose a model of dynamic maintenance of the mutual beliefs of tile participants in diNogues based on Clause Maintenance System (CMS) (Doyle, 1979; Levesquc, 1989; Poole, 1988; Reggia, 1983; de Kleer, 1986; Rciter & de Kleer, 1987). By this nmdel, we characterize the relationships between a diMogue process and its successfulness, which is mainly illustrated by examples of referent-determination but can be applied to any type of belief-sharing."]},{"title":"2 Dynamic Maintenance Shared Beliefs of 2.1 DRS","paragraphs":["However cooperative, real-world dialogues are fraught with hedges, understatements, or even white lies, which would necessitate introducing a distinction between what is literally conveyed by an utterance, and its real intent on the part of both speaker and hearer. In this study, however, we restrict ourselves to those cases without such complications, and assume that an utterance reflects the speaker's intent in a straight manner, and is taken as such by the hearer. The content of an utterance is represented in tile following style: (1)"]},{"title":"K: a,b,x,y,z .... Bel(a, K) ~cl( b, IO","paragraphs":["......................................."]},{"title":"A(~:), B(v), C(~), ...","paragraphs":["We call K discourse representation structure (DRS),"]},{"title":"{a, b, x,y,z .... } K's","paragraphs":["domain (UK), the elements of UI< discourse referents, tile boxed area below tile unbroken line K's condition part (CA-), and CK's elements conditions. K is represented as (UK,CK}. The broken line divides"]},{"title":"CK","paragraphs":["into the self-referentiN part SRP (above the line), and the dialogue database DB(K) (below the line). A condillon is the result of an n(_> 0) times application of"]},{"title":"Bel(ct,.)","paragraphs":["to a first-order formula p."]},{"title":"Bel(c~,.)","paragraphs":["is called a belief operator, where c~ designates the utterer. Given ¢ as a condition,"]},{"title":"Bel(ce,","paragraphs":["¢) reads \"the partMpant a believes ¢.\" n is called the rank of ¢ with regard to its embedding within belief operators. Conditions of rank O are called bare formulas, while those with a rank greater than 0 belief formulas. K represents the shared beliefs formed through a dialogue between the two participants a and b. The conditions in SRP indicate a recursive embedding of self-referentiN belief sturueture with regard to eo,nmon knowledge, and are assumed throughout the dialogue. By contrast, DB(K) is empty when a dialogue starts off. Thus, at the outset of a dialogue, the DRS"]},{"title":"Ko = ({a, b}, {Bel(a, Ko), Bel(b,","paragraphs":["K0)}). As an utterante is made, new discourse entities may be introduced, making it necessary to add new conditions to DB(K) and sometimes to retract or negate part of the conditions in DB(K). With the progress of the dialogue, the DRS changes front K0 ~ K1 ~ ... =~"]},{"title":"Kn =:~ ...","paragraphs":["Since only cooperative dialogues are considered, the goal is to arrive at a DRS in which no contradictory beliefs arc held by the participants. But this goN is not Mways achieved. We Nso assume that at certain points of a dialogue, the participants can hold contradictory beliefs, and that tile same pariticipant 1164 Call hold contradictory beliefs at dill?rent points of a dialogue, whereas the s;Hne particip~mt cannot hold contradictory beliefs ¢tt any partic:ular point.","In what follows, we just indicate DB(K) unless otherwise noted. 2.2 How shared belieig are registered An utterance made by ~ 1)~rticipmlt in a. diMogue is transformed into a condition(s) and registered in DB(K), folh)wing the constrMnts stetted beh)w.","First, discourse referents m'e taken to be epistemological entities without counterparts in snrfacc senten('es, but introduced into the DRS by the participants of ~ diMogue, and of which prot)erties corresponding to surface linguistic expressions are l)redicared. Thus, an utterance"]},{"title":"(2) a:","paragraphs":["Sato is a student is not anMyzed ~s (3)"]},{"title":"student(Snto)","paragraphs":["but as (4)"]},{"title":"Sato(x), student(x)","paragraphs":["with the discourse referent a\" introdu(:ed into U~¢ 1)y a, and the predicates corresponding to expressions in the utterauce.","Second, an utterance is registered not in the form of a bare formula., but in the fl)rm of a 1)elief forlnula indicating the t)elief agent. (4), tbr example, is registered as (5)"]},{"title":".Bcl(a, Sato(x) ), Bel(a, student(x))","paragraphs":["because at (2), b has not agreed with or opl)osed a's utterance. Note theft (5) is nevertheless ;t shared belief t~t this point. Suppose (6) is uttered folh)wing"]},{"title":"upon (2):","paragraphs":["(6)"]},{"title":"b:","paragraphs":["Yes, he is. This utterance is interpreted as (7)"]},{"title":"Bet(b, Sato(x)), BelCh, stu.dent(x))","paragraphs":["and so registered in DB(K). At this t,oint, both (5) and (7) are shared beliefs, which me,ms (4) is a belief shared by a and b. This transition is tbrumlated as the axiom of shared belief: (8) The axiom of shared belief"]},{"title":"Whet, DUCK) cont~ns P,q(,*,v), ,~nd 13~l(b, v),","paragraphs":["DB(K') obtained from DB(K) 1)y the substitution of p for them is equivahmt to DB(K). DB(K) can bc derived fl'om DB(K') without using this axiom, since K tt~us the self-referential part SRP. But the converse does not hold. The ttxiom of shared belief Mlows the rank of shared beliefs to be zero, while the conditions in general are initially registered with a rtmk higher than zero.","Third, there is involved a step of identification in the transition front b's utterance of (6) to the condition (7). Just as the discourse referent x was introduced by a's utterance of (2), b introduces a (listinct discourse referent y, in terms of"]},{"title":"which","paragraphs":["(9)"]},{"title":"BelCh, S.to(y)), Bed(b, student(y))","paragraphs":["is registered in DB(K). We ~uSSulne that"]},{"title":"a","paragraphs":["and b ~gree to tiu', identity of x and y ~Lt this point.","To sum up, in dialogue (2), (6), DB(K) is composed of (5) ahme when (2) is uttered, hut is extended by the utterance of (6) as follows:"]},{"title":"0()) wt(,,,:,: = y),B,~t(~,.~ = v), Bed(a, Sato( x ) ), Bel( a, Sato(y) ), ~l(b, s,,to(,) ), ~l(b, S~to(v) ), Bel(a, student(:r) ), Bet(a, student(y)), Bel( b, student(a,)), BelCh, student(y)).","paragraphs":["By applying the axioin of shared belief, mid x =: y, we obta.in (11)"]},{"title":"Sat@c), student(x)","paragraphs":["By contr~st,","(12) l.a: Satoisastudent. 2.b: No, he is an otfice clerk now. can only h~vc its DB(K) reduced to"]},{"title":"(13) Sato(:,:), lJel(a, ,st~dcm.t(x)), Bel(h,oJlice_cle, rk(x)). 3 Diachronic analysis of dialogue","paragraphs":["In this section, we consider the changes DRS's undergo in the course, of ~t dialogue. In (2), (6) in the previous section, we saw a case where a DRS with nothing but shm'ed beliefs is successfiflly obtMned in one inning, so to speak, without incurring any conflict. We will look at the other three kinds of cases in which conflicts are treated in particular ways which tMlnit of formMization in terms of CMS."]},{"title":"3.1","paragraphs":["Direct solution of conflicts Consider the following dialogue.","(1.4) 1. I~: Sato is ~t good guy. 2. b: By no means, he is a liar. 3. a: No kidding. Just after"]},{"title":"(14.2)","paragraphs":["is uttered, DB(K) looks as follows:"]},{"title":"(1~) w~t(.,:,; : :,j),Vel(b,. = y), B a(c,, s~,to(.)), u~t(c~, st, to(v)), Uet(*,, S.to(.~-)), ~et(b, Sato(v ) ), .~t(,,,,oo(t0,,)), .c~l(t,,/i(,.(v)). 1165","paragraphs":["The utterance of (14.3) is considered as the consequence of an inference such as this: (16) 1. x = y"]},{"title":"2. Sato(x) 3. Bet(a, good(x)) 4. Bel(b, liar(x))","paragraphs":["is derived from (15), (16.3-4) do not bring about an inconsistency since they are belief formulas with different propositions inside. But obviously, a has drawn an inconsistency by taking off the belief operators, and carrying out the following inference."]},{"title":"(17) 1. x=y 2. liar(y) 3. liar(x) 1, 2 4. Vx(liar(x)-*-,good(x)) 5. -good(x) 3, 4 6. good(x)","paragraphs":["7. [] 5,6 Suppose (14) is continued as follows:","(18) a: I meain the Sato in tile linguistics department. b: ()it, I thougtit you were talking about the Sato in the AI department. The one you mean is in-deed a good guy.","(19) a: He does sometimes. But you can't dislike him. b: I guess not. In this case, in order to avoid the conflict, one traces its causes, and retracts the weakest one (16.1) for (18), and (17.4) fro' (19), or replaces it by its negation. As a result, (18), for examle, is associated with"]},{"title":"(20) Bel(a,-~x = y), B~l(a, Sato(x)), Bel(a, Sato(y)), Bel(b,-,x = y), nd(~,Sato(x)), ~el(~,Sato(y)), Bel(a, LiD(x)), Bel(a, AiD(y)), Bd(a, Vx(li~,'(x) -, ~good(x))), Bel(b, LiD(x)) , Bel(b, AiD(y)), Bcl(~, Vx(liar(x) -* ~qood(x))), B~l( ~, good(x)), ~el(~, liar(y)), Bel(b, good(x)), Bcl(b, liar(y)).","paragraphs":["All"]},{"title":"Bel's","paragraphs":["can be taken off in (20), resulting in"]},{"title":"(21) ~x = y, Sato(x), Sato(y), LiD(x), AiD(y), Vx(liar(x) -* ~good(x) ), 9ood(x),liar(y),","paragraphs":["which is shared by a and b. 3.2 Indirect solution of conflicts Consider the following dialogue.","(22) 1.a: Today's meeting is held at 203, isn't it? 2.b: No, I heard it is at the small conference rooln, 3.b: Who toht you that'? 4.a: Sat() told me yesterday. 5.b: That's strange. I'll call the office. 6.b: They say it was changed fl'om 203 to the small coifference room today. 7.a: I see. The inference of (22) is formalized as follows: (23) 1."]},{"title":"Sato 2. Sato ~","paragraphs":["203 3. 203"]},{"title":"4. office 5. office-* s.e.r 6. s.c.r 4, 5 7. s.c.r -*","paragraphs":["-~203 8. -1203 6, 7 9. [] 3~8 In this case, the conflict between (22.1) and (22.2) 1, 2 cannot be solved between themselves. (22.3) to (22.6) reflects the process of deciding which is to be preferred by tracing the source of each condition. That is~ when one cannot choose between two conflicting conditions Pl and p2 on their own account, one replaces Pl and p2 by ql, ql --* Pl and q2, q~ '~ P2~ respectively, and decide which of ql, q2 is to be preferred so that one can avoid the conflict by retracting the weaker condition in favor of the stronger. 3.3 Conflicts ending in a draw Consider the following case.","(24) 1.a: That's Muranishi over there. 2.b: No, it's Hokuto. 3.a: Really? This case is formalized ~s follows: (25) 1. x = y"]},{"title":"2. Hokuto(y) 3. Hokuto(x)","paragraphs":["1, 2"]},{"title":"4. Muranishi(x) 5. Vx(Muranish.i(x)-*-,Hokuto(x)) 6. -~Hokuto(x) 4, 5 7. []","paragraphs":["3,6 As (24.3) indicates, there is no retractable belief in DB(K), which caused the diMog to end in a breakdown.","3.4 Formalization of diachronic analysis The processes of belief revision illustrated in 3.1 through 3.3 can be h)rmalized as in (27). First, we define some terms: 7166","(26) i) I,et c~ be one of the partieilmnts a and b in a dialogue, and/3 the other. ii) Given p in DB(K), substitute"]},{"title":"Bel((e,p) and Bel(fl,p)","paragraphs":["for it. When"]},{"title":"Bel((e,p)","paragraphs":["is replaced by"]},{"title":"Bel((e, \"~p),","paragraphs":["it is called p's self-denial by (r. When"]},{"title":"Bel(c~,p)","paragraphs":["is simply retracted, it is called p's selfwithdraw,'d by (e. iii) When"]},{"title":"Bel((~,p), Bel(/J,p),","paragraphs":["and p are substituted for by ~p, it is called p's strong-denial. When they are simply retracted, it is (:ailed p's strong-withdrawM. iv) Let E be a set of Horn-clauses,"]},{"title":"PI(E)","paragraphs":["the set of its prime implieants. When ~p {-~p~, ..., ~p,,} for any"]},{"title":"qV-~p~","paragraphs":["V...V~p,~ e PI(E), q is subordinate, ~o p.","(27) Whenever a new condition is added to DB(K) in response to a dialogue ntove, the participant (e starts her CMS, calculates a way of resolving any contlict, and revises DB(K) dymunically: 1) a) When a condition is explicitly registered in DB(K), strip off its belief operator (if any), add it to CMS as an atomic formula. b) Add implicitly assumed conditionals such as"]},{"title":"Vx(Muranishi(x) --~ ~Hokuto(x))","paragraphs":["to CMS as an atomic formula. c) Add the implicit inference ruh!s in the (lial()gue to CMS ~s a conditional formula. (E.g., the inference rule a,"]},{"title":"b/c","paragraphs":["eorresl)onds to the conditional formula c ~- a, b.) 2) Let E be tit(! set of CMS-cbmses obtained in 1). Change E into PI(E) (the set of its prime imI)licants). a) If PI(E) V El, then the dialogue suc(:eeds. Either terminate it, or go on to another. h) If PI(E) F D, mdess there is a retractabh~ or deniable assumption"]},{"title":"1 >","paragraphs":["in E, go to c). If dmre is, try to make either p's strong-denial or strongwithdrawal. If it fails, go to c). If successful, for all q such that q is subordinate to p, m~d(e q's self-withdrawal, and call the result E ~. A) If PI(E') V"]},{"title":"D,","paragraphs":["then the dialogue suceeds. Either terminate it, or go on to another. B)If"]},{"title":"PI(E') ~- ~,","paragraphs":["then S := E' all(L gO to b). e) If every assulnption p in E is well justified, the dialogue fails. If any p has negotiable justifications"]},{"title":"q,,..., q,,","paragraphs":["replace p by p ~-"]},{"title":"ql,...,%;ql,...,qn","paragraphs":["altd call the result E'. Set E :-- El, and go to b)."]},{"title":"4 Synchronic analysis of dialogue","paragraphs":["Next, according to Ogata(1993), we consider a classification which characterizes the degree of belief sharing for the t)articipmtts at a l)articular point of the conversation, and the eorre(:tness of the shared beliefs. (28) 1) The beliei~ are all shared by the participants:"]},{"title":"see (2), (~) above. DB(K) ,:o,,tai,s ~o eo,dilions","paragraphs":["l)re, tixed with"]},{"title":"Bcl.","paragraphs":["Since the set of belie, fs of either partMpant is .considered to be consistent,"]},{"title":"I'I(E) V [] fi)r","paragraphs":["tile CMS corresponding to the DRS. 2) There remain some conditions prefixed with"]},{"title":"Be.l","paragraphs":["in DB(K), but"]},{"title":"PI(E) y []","paragraphs":["for the CMS corresl)on(ling to the DRS. A typical c~use, is when /~'s ~ussertions prol)erly inchtde (~'s t)eliefs and about the rest of ~'s assertions (~ has not been able to decide in one way or another. 3) There remain some (:onditions prefixed with"]},{"title":"BeI","paragraphs":["in DB(K), and"]},{"title":"PI(E) I- E~.","paragraphs":["This is a case of breakdown ,'~s seen in (25). We call titese three ('~uses, respectively, 1) obserw~tionally susscessful, 2) observ~Ltionally consistent, and 3) obserw~tionally unsuccessful. Take the ease of (2), (6) again. Tit(, dMogue was successfiflly terminated because the Sato a had in mind and the Sato b had in mind were both students. But suppose a's Sato was a student in the linguistics de-1)artm(mt, and b's Sato in the AI department, (.hat is, they were different persons. Or suppose a and b had the same Sato in rain(|, but that he was no longer a student ;~t the time. These two eases are obscrwttionally suc(:essfifl, hut the partMpants end a 1) with the wrong beliefs. In order to meet this gat) ~ we introduce a standard of correctness that might be eml)odied by God's viewpoint, the reality, or the conventions of the language community to which the 1)articipants belong. We call this standard the facts. The categories in (28) are further broken down relative to the facts as in (29):","Detine K' as the result of adding the Nets to tim DB(K) of a DRS"]},{"title":"K,","paragraphs":["and extending UI¢ accordiugly. Let"]},{"title":"PI(E I)","paragraphs":["be the set of prime implicants fi)r the CMS corresponding to DB(K/). The facts are a set of bare formub~s. Then (28) is subclassifled as follows:","(29) 1) ol)servationally su(:c, essfui a)"]},{"title":"m(~') V u, b) m(s') ~-","paragraphs":["u. 2) observationally consistent a) m(E') V El, 1,) m(s') ~ u. 3) obserwttionally unsuccessful"]},{"title":"PI(E I) F ~.","paragraphs":["We cM1 la) strongly successful, 2a) strongly consistent, and the rest (the cases where"]},{"title":"PI(N ~) F n)","paragraphs":["strongly unsuccessful. A comparison of (28) and (29) suggests the folh)wing implications whose converses do not hold:","(3(I) a) strongly successfltl ~ observationally success-tiff 1)) obserwt.tionally m~suc('.essful -~ strongly unsu(:cessful c) strongly consistent -~ observationally consistent 1167"]},{"title":"4.1 Characterization of expressions referring to individuals","paragraphs":["We consider the problem of how the concepts of success introduced in the previous section might be applied to the dialogues identifying the denotation of individual terms, especially proper nouns.","(31) a: That's Sato over there. b: Yes, it is. DB(K) for (31) is"]},{"title":"(32) a) x = y,","paragraphs":["b)"]},{"title":"Sato(x), Sato(y).","paragraphs":["If a and b believe there is only one Sato in this situation, (32b) becomes (33)"]},{"title":"Bel(a, tx.Bel(a, Sato(x)) = x), ~el(b,,x.Bcl(~, Sato( x ) ) =","paragraphs":["~ ),"]},{"title":"Bel(a, tx.Bcl(b, Sato(x))","paragraphs":["= y),"]},{"title":"~el(b, ,~.Bel(b, Sato(x) ) = y),","paragraphs":["which gives rise to (34)"]},{"title":"tx.Bel(a, Sato(x)) = x, ,x.Bel(b, Sato(x)) = y.","paragraphs":["From this, we obtain by (32a)"]},{"title":"(35) ,x.Bel(a,","paragraphs":["Sato(x)) ="]},{"title":",x.~el(~,","paragraphs":["Sato(x)). If (31) is a case of strong success in which \"Sato\" correctly refers to the unique Sato, DB(K t) contains (36) x = z,"]},{"title":"tx.Sato(x) = z.","paragraphs":["From (323), (34), and (36), we ca,, derive (37)"]},{"title":"tx.Sato(x)= tx.Bel(a, Sato(x)) = ,x.Bel(b, Sato(x)).","paragraphs":["In general, of an atomic formula"]},{"title":"T(x),","paragraphs":["we call"]},{"title":"tx.Bel(a, T(x))","paragraphs":["a's intended referent,"]},{"title":"tx.Bel(b,T(x))","paragraphs":["b's intended referent, and"]},{"title":"tx.T(x)","paragraphs":["the semanite referent. Thus, a strongly successful dialogue with regard to an identification of an individual referent is a case where a's intended referent, b's intended referent, and the semantic referent all coincide.","However, if in (31) the individual referred to is Kinoshita rather than Sato, DB(K t) will contain (38)"]},{"title":"~(z = x),,x.Sato(x) = z.","paragraphs":["If a and b have different Sato's in mind, DB(K ~) will contain (39)"]},{"title":"tx.Sato(x) = t, ~(~ = x).","paragraphs":["In either case, the result is strongly unsuccessflfl: (40)"]},{"title":"-~(tx.Sato(x) = tx.BeI(a, Sato(x) ) ), -~(tx.Sato(x) = tx.BeI(b, Sato(x))).","paragraphs":["A case of being observationally unsuccessful such as (24) will be (41)"]},{"title":"-~(tx.Bel(a, Sato(x)) = tx.Bel(b, Sato(x))).","paragraphs":["By indicating a's intended referent, b's intended referent, and the semantic referent by Ta, Tb, and Tcom, respectively, we can summarize what has been discussed above as follows:","(42) strongly successful: Tcom = Ta = Tb, observationally successful: Ta = Tb, strongly unsuccessfld: Tcom ¢ Ta, Tcom ~ Tb, observationally unsuccessful: Ta ~ Tb."]},{"title":"5 Conclusion","paragraphs":["In this paper, we proposed a system which combines DRS with CMS, and an Mgorithm for the dynamic revision of shared beliefs in cooperative dialogues. Further, the degree of success in dialogues was formalized.","Still, the following problems remain to be solved: 1) The treatment of background knowledge must be","made precise. E.g.,"]},{"title":"'Sato ~","paragraphs":["203' in (23), or"]},{"title":"'Vx(Muranishi(x) -~ \"~Hokuto(x))'","paragraphs":["in (25) is implicitely introduced into the inference without explanation of its origin.","2) The translation procedure of an utterance into the condition of DRS must be formalized.","3) It's necessary to give a semantic foundation to our systenl.","4) hnplelnentation of a system which simulates our dialogue mechanism."]},{"title":"References","paragraphs":["[1] Appelt, D. (1985). \"Planning English referring expressions\"."]},{"title":"Artificial Intelligence,","paragraphs":["26, 1-33. [2] AsheL N. (1993)."]},{"title":"Reference to Abstract Objects in Discourse,","paragraphs":["Dordrecht: Kluwcr.","[3] Clark, H. & Marshall, C. R. (1981). \"Definite reference and mutual knowledge\". In Joshi et al."]},{"title":"Ed., Elements of Discourse Understanding,","paragraphs":["Cambridge University Press.","[4] Kleer, J. de (1986). \"An assumption-based TMS'."]},{"title":"Artificial Intelligence, 28,","paragraphs":["127-162. [5] Doyle, J. (1979). \"A truth mMntenanee system\"."]},{"title":"Artificial Intelligence,","paragraphs":["1.2, 231-272. [6] G£rdenfors, P. (1988)."]},{"title":"Knowledge influx: modeling the dynamics of epistemie states,","paragraphs":["Cambridge: The MIT Press.","[7] Joshi, Aravind K. (1982), \" MutuaJ Beliefs in Question-Answer Systems\". In Smith, N. V."]},{"title":"Ed., Mutual Knowledge,","paragraphs":["pp. 181-197, London: Academic Press."]},{"title":"1168","paragraphs":["[8] Kamp, H. (:[981). \"h Theory of truih and semzmtic representation\". In Groenendijk et al. Ed., t;'ormal Methods in the Study of Langua.gc., pp. 277-322, Amster&ml: Mathemal;isch Centrum Tracts.","[9] Kaml), H. (1990). \"Prolegon~ena to st Structural Ae(:ount of Belief and Other Attitudes\". In Anderson, C. A. & ()wens, J. l','d., Propositional Attitudes: The Role of Content in Logic , Language, and Mind, pp. 27-9(), Stanford: CSLI.","[10] I,evesque, II. J. (1989). \"A k,mwiedgeqevel account of abduction\". 1.1CA1-89, 1061-1068.","[11] Nadathur & aoshi (1983). \"MutuM belief in conversational systems: their role in referring expressions\"."]},{"title":"IJCAI-83, 603-6o5,","paragraphs":["Karlsruhe.","[12] Ogata, N. (1993). \"Koymnei, Shiji, .lohe) Kyoyii\" (\"Proper Names, Reference, and inform~tion-Sharing\"). S@tto-uea Bunsho no tameno Nihongo Shori no Kenkyii (Study of Japanese l'.r'ocessing for Software Documents), 12, 257-310, Tokyo: hfformation-Technology Promotion Agency (IPA).","[13] Perrault, C. 1/,. & Cohen, P. 1{. (1981). \"It's for your own good: a note on illtLCellrsLte reference\". In aoshi et al. Ed., ],lie.merits of Discourse Understanding, Cainbridge University Press.","[14] Poole, D. (1988). \"A methodology for using a default ai,d abdu(:tive reasoning system.\" Technical report. Dept. of Computer Science. Univ. of Waterloo, W;Lterloo. [15] Reggbt, 3."]},{"title":"(198a).","paragraphs":["\"Diagnostic expert systems ln~sed on a set-covering model\". International Journal of Man Machi'ne 3tudies, 19(5), 437-460.","[16] Reiter, R. & Kh, er, J. de (1987). \"FomMations of s~sSUml)tiolM)ased truth tlls'dnteltan(:e systenls: preliminary report\", ddAg87, 18a-188, Seattle, WA. 1169"]}]}