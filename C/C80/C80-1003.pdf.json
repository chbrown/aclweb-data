{"sections":[{"title":"","paragraphs":["A SYNTAX PARSER BASED ON THE CASE DEPENDENCY GRAMMAR AND ITS EFFICIENCY Toru Hitaka and Sho Yoshida Department of Electronics, Kyushu University, Fukuoka, Japan S UMMARY","Augumented transition network grammars (ATNGs) or augumented context-free grammars are generally used in natural language processing systems. The advantages of ATNGs may be summarized as i) efficiency of representa-tion, 2) perspicuity, 3) generative power, and the disadvantage of ATNGs is that it is difficult to get an efficient parsing algorithm becuase of the flexibility of their complicated additional functions.","In this paper, the syntax of Japanese sentences , based on case dependency relations are stated first, and then we give an bottom-up and breadth-first parsing algoritbxnwhich parses input sentence using time O(n 3) and memory space O(n2), where n is the length of input sentence. Moreover, it is shown that this parser requires time O(n2), whenever each B-phrase in input sentence is unambiguous in its grammatical structure. Therefore, the efficiency of this parser is nearly equal to the Earley's parser which is the most efficient parsing method for general context-free grammars. 1. FUNDAMENTALS OF JAPANESE SENTENCE","The Japanese sentence is ordinarily written in kana (phonetic) letters and kanji (ideographic) characters without leaving a space between words. From the viewpoint of machine processing, however, it is necessary to express clearly the units composing the sentence in such a way as to leave a space between every word as in English. We have no standard way of spacing the units though the need for this has been demanded for a long time.","We give some examples in Figure i. The first sentence in the figure is of ordinary written form.","The second indicates a way of spacing (i.e. putting a space between every word).","The third indicates another way of spacing (i.e. putting a space between every B-phrase).","Nowadays, many other spacing methods have been tried in several institutes in Japan.","In this paper, input sentences are given in colloquial style in which a spacing symbol is placed between two successive B-phrases. In Japanese sentences,"]},{"title":"BUNSETSUs(B-","paragraphs":["phrase) are the minimal morphological units of case dependency, and the syntax of Japanese sentences consists of (i) the syntax of B-phrase as a string of words, and (2) the syntax of a sentence as a string of B-phrases.","A B-phrase usually pronounced without pausing consists of two parts --main part [or equally an independent part in the conventional school grammatical term] and an annex part which is post positioned. We denote the connec-tion of two parts in a B-phrase by a dot if necessary. A main part, which is a conceptual word [or equally an independent word] (e.g. noun, verb, adjective or adverb) provides mainly the information of the concept. On the other hand, an annex part, a possibly null string of suffix words (e.g. auxiliary verbs or particles) provides the information concerning the kakariuke relation and/or the supplementary information (e.g. the speaker's attitude towards the contents of the sentence, tense, etc.)","A word w has it's spelling W, part of speech H and inflexion K. We call (W,H,K) the word structure of w.","Suppose that a string b of length n be a B-phrase. Then, there exist an independent word w 0 and suffix words Wl, w z, ... , w~, and b=w0w I . • • w~ Cont(Hk,Kk,Hk+1) (0=k<i) ...(i) Termi (H£,K Z) • • • (2) where (Wi,Hi,Ki) is the word structure of w i (0~i~£), Cont(Hk,Kk,Hk+1) means a word whose part of speech and inflexion are Hk, K k respectively can be followed by a word whose part of speech is Hk+lin -15-- B-phrases and Termi(HQ,Kz) means a word whose part of speech ~nd inflexion are H£, KZ respectively can be a right-most subword of B-phrases.","(i), (2) are called the rules of B-phrase structure, and","(W0,H0,K 0) (Wi,HI,K ~) \"''(Wz,H~,K ~)","• .. (3) is called B-phrase structure of b. If (3) satisfies the condition (i), w0wlw • ..w Z is called to be a left partial 2 B-phrase.","The kakariuke relation is the dependency relation between two B-phrases in a sentence. A B-phrase has the syntactic functions of governor and dependent. The function of governor is mainly represented by the independent word of B-phrase. The function of dependent is mainly represented by the string of particles which is the right-most substring of B-phrase and by the word in front of it (right-most non-particle word).","Every particle has the syntactic and partially semantic dependent function with its own degree of power. The particle whose power of dependent function is strongest of all particles appearing in the string of particles is called the representative particle. Therefore, the syntactic function of dependent of a B-phrase is mainly represented by the representative particle and by the right-most non-particle word.","Let (W0,H0,K0) , (Wi,Hi,Ki) , (W~,H~,K~) be the word structures of independent J word, right-most non-particle word and representative particle of a B-phrase, respectively. Then, <W,̂H>̂_, <W..,Hi, u u ~ & Hj> d are called the inrormatlon or governor and the information of dependent of the B-phrase respectively, and the pair (<W0,H0>~,<Wi,Hi,Hj>d) is called dependency~informati6n of the B-phrase.","There are many types of dependency relation such as agent, patient, instrument, location, time, etc. Let C be the set of all types of dependency relation. The set of all possible dependency relations from a B-phrase b l to a B-phrase b 2 is founded on the information of dependent of b I and the information of governor of b 2. There-fore, there is a function 6 which computes the set of all possible dependency relations ~(a,8) between a B-phrase of dependency information ~ and another B-phrase of dependency information 8. The function ~ is realized by the dependency dictionary retrieved with the key of two dependency informations.","The order of B-phrase is relatively free in a simple sentence, except for one constraint that the predicative B-phrase governing the whole sentence must be in the sentence's final posi-tion. Japanese is a post positional in this sense.","The pattern of the dependency relations in a sentence has some structural property which is called the rules of dependency structure, and the dependency relations in a sentence are called the dependency structure of a sentence. The dependency structure of a sentence is shown in figure 2, where arrows indicate dependency relations of various types. The rules of dependency structure consist of following three conditions.","i Each B-phrase except one at the","sentence final is a dependent of","exactly one B-phrase appearing","after it. ii A dependency relation between any","two B-phrases does not cross with","another dependency relations in a","sentence. iii No two dependency relations","depending on the same governor","are the same.","Let N be the number of B-phrases in a input sentence, and all B-phrases are numbered descendingly from right to left (see figure 2). We shall fix an input sentence, throughout this chapter. Let DI(i) be the set of all dependency informations of i-th B-phrase.","Definition: A dependency file DF of a sentence is a finite set of 5-tuples. (i,j,ai,ej,c) 6 DF .... _~ { N=i>j=l, a i E DI (i), cde . ~j 6 DI(j) and c E~(ai,aj).","Definition: If a subset of DF satisfies following conditions i) to 5), it is called a dependency structure from the Z-th B-phrase to the m-th B-phrase (N~Z>m~i) and denoted by DS(£,m) or DS' (i,m).","i) If (i,J,ei,~j,c) 6 DS(£,m), then £~i>jAm.","2) For arbitrary i(ZAi>m), there exists unique j,ai,ej,c such that (i,j,ai,ej,c) ~ DS(Z,m).","(Uniqueness of Dependent)","3) If (i,j,a~,a~,c) 6 DS(£,m) and , , ~ o (j,k,~j,~k,C) % DS(Z,m), then ~ = ~ ~, O J\"","(Uniqueness of B-phrase structure) , 4) If (i,J,~i,~j,c) ~ DS(£,m), (i ,j,~f ,~j, ,c ) E DS(£,m) and i>i'>j, then j,hj.","(Nest Structure of Dependency) 16 ̧","5) If (i,j,@i,~,c) e DS(£,m) (i',j,a i, ,~j,c') ~ D~(£,m) and ~i', then c ~ c'. (Inhibition of Duplication of a Case)","The set of all dependency structur~ from i-th B-phrase to m-th B-phrase is denoted by ~(~,m). Any DS(N,i)~ ~(N,i) is called a dependency structure of the input sentence. The dependency information of j-th B-phrase is unique in DS(i,m), since 2) and 3) hold. Let JDiDS(Z,m) and jGDS(Z,m) be the dependency information of the j-th B-phrase inD~£,m) and~set of all the dependency relations that the j-th B-phrase governs in DS(£,m), respectively.","def ~i,~,C) JGDS(i,m) u__. {c I (i,J~Ds(~m) }","Definition: If the k-th B-phrase (i~k~_m) in DS(£,m) has the following property, k(the k-th B-phrase) is called a joint of DS(£,m):","For any (i,j,ai,~j,c)~ DS(~,m) , k~i or J~k.","Let j~(=£) > j, > Jl > \"'\" > j (=m) be u",", the descendlng sequence of ale the joints of DS(i,m) (see figure &). Then, the Jk-th B-phrase is called the k-th joint of DS(£,m). There is a dependency relation from k-th joint (dependent) to k+i-th joint(governor) in DS(£,m). Let J.DS(£,m) be a set of all the joints of DS(£,m). DS(£,m/i,j) a subset of DS(Z,m), is defined as follows:","DS(£,m/i,j)-~{ (p,q,av,~o,c) I (p,q,ap,aq,C) ~ DS(~,my, i~p>q~j}. Lemma i. For any positive integer","£, i, j, m (N~£~i>j~m), the following","propositions hold.","(i) DS(i,m/i,j)6 ~(i,j), if j is a","joint of DS(i,m).","(ii) DS(I,j) U DS(j,m)~ ~(£,m), if and","only if JDiDS(Z,j) = JDiDS(j,m) .","(iii) { (Z+i,j ,~, ~,c) }uDS (~,~) 6 ~(Z+i,","m) if and only if (i+l,j,e,8,c)","E DF,8=JDiDS(Z,m), j E J.DS(£,m)","and c~ jGDS(Z,m).","(iv) If (jk,Jk+1,ak,ek+1,c) ~ DS(j ,m)","(k=0,1,2,-..), then Jk is the k-","th joint of DS(J0,m).","Syntax analysis of a Japanese sentence is defined as giving B-phrase structures and dependency structure of the sentence.","2. THE PARSING ALGORITHM","AND ITS EFFICIENCY In this chapter, we shall give a","parsing method which will parse an","input sentence using time O(n ~) and space O(n~), where n is the length of input sentence. Moreover, if the dependency information of each B-phrase is unambiguous, the time variation is quadratic.","The essence of the parsing algorithm is theconstruction of B-phrase parse list BL and dependency parse list DL which are constructed essentially by a \"dynamic programming\" method. The parsing algorithm consists of four minor algorithms that are the construction of BL, the obtaining of B-phrase structure, the construction of DL and the obtaining of dependency structure.","13-PHRASE PARSE LIST Let b be a string of n length and","b(i) denote the i-th character from","the left end of it.","b=b(1) (2) ... b(n). The B-phrase parse list of b","consists of n minor lists BL(1), BL(2), • .. , BL(n).","[]Form of items in BL(j)","(i, WS, DI)","where, IL_i < j~n, WS is a word","structure and DI is a dependency","information.","[] Semantics (i, WS, DI)EBL(j) of","(i, WS, DI)E BL(j), if and","only if there exists a sequence of","words w o, w l, ... , w£ satisfying","following two conditions:","i) b(1)b(2) ... b(i)=w0w I .. • w~_ I,","b(i+l)b(i+2) ... b(j)=w£, and","WS is the word structure of w£.","2) The string of word w_w I ... w Z is • D","a left parclal B-phrase of depen-","dency information DI. ALGORITHM FOR THE CONSTRUCTION OF BL"]},{"title":"Input.","paragraphs":["An input string b=b(1)(2) • • .b(n) ."]},{"title":"Output.","paragraphs":["The B-phrase parse list BL(1), BL(2), ... , BL(n)."]},{"title":"Method.","paragraphs":["Step i: Find all the independent word which are the left-most subwords of b, using independent word dictionary and for each independent word w=b(1)b(2) ''. b(j), add (0, (W,H,K),a) to BL(j) where, (W,H,K) is the word structure of w and ~= (<W,H>K, <W,H,-> d) . Then, set the controI word i to 1 and repeat Step 2 until ~ = n •","Step 2: Obtain all the suffix words which are the left-most subwords of B(i+l)B(i+2) ... b(n) and for each suffix word w=b(i+l)b(i+2) ... b(k) of word structure (W' ,H' ,K') , and for each item (j, <W,H,K>,a) # BL(i), add (i,(W',H',K'), (W',H')oe) to BL(k) if --17","C(H,K,K'). (W',H')0a is a dependency","information defined as follows.","i If H' is a auxiliary verb• then","(W',H')o~ def (<~>g,<W,,H,,_>d) where• <a>g is the information of governor or a.","ii Let <W\",H\",H\"' > be the information of dependent of ~. When H' is a particle,","(W,,H,)o a def ....","(<a>g,<W\",H\",H'>d) if the power of dependency function of H' is stronger than that of H\"' , and else","(W,,H,)o ~ def ~.","There exists upper limit in the length of words and there exists upper limit in the number of dependency informations of all left partial B-phrase of a(1)a(2) ... a(i). Therefore, there exists upper limit for the necessary size of memory space of BL(i) and the theorem 1 follows.","Theorem i.","Algorithm for the construction of BL requires O(n) memory space and O(n) elementary operations.","We shall now describe how to find a B-phrase structure of specified dependency information from BL. The method is given as follows. ALGORITHM FOR OBTAINING A B-PHRASE STRUCTURE OF AN INPUT STRING"]},{"title":"Input.","paragraphs":["The specified dependency information ~ and BL."]},{"title":"Output.","paragraphs":["A B-phrase structure of dependency information a or the error signal \"error\"."]},{"title":"Method.","paragraphs":["STEP i: Search any item (i,(W,H,K),a) in BL(n) such as Termi (H,H). If there is no such item, then emit \"error\" and halt. Otherwise, output the word structure (W,H,K), set the register R to (i,(W,H,K),a) and repeat the step 2 until i = 0.","STEp 2: Let R be (i,(W,H,K),e). Search any item (i',(W',H',K'),a') in BL(i) such as C(H',K',H) and (W,H) o~=a. There exist at least one element which satisfies above conditions. \"Output the word structure (W',H',K') and R÷ (i',(W',H',K'),a').","It is easy to know theorem 2 holds.","Theorem 2.","A B-phrase structure of specified dependency information is output by the above algorithm, if and only if the input string has at least one B-phrase structure of specified dependency information and it takes constant memory space and O(n) elementary operations to operate the above algorithm.","The set of all the dependency informations DI of input string b is obtained from BL(n), since DI={a I (i, (W,H,K) ,a)£SL(n) , C(H,K) }.","DEPENDENCY PARSE LIST DL","Let s be a input sentence of N B-phrases. The set of all the dependency informations DI(i) of the i-th B-phrase is obtained by operating the algorithm of construction of BL on the string of the i-th B-phrase.","The dependency parse list DL of s consists of N-i minor lists DL(2), DL(3) , ''- ,DL(N) .","[] of items in Form DL(i).","(ai,J,aj,~,P) I","(ai•J,aj, ,P)","where, N~i > j~l, aie DI(i), ajE DI(j),","ce ~, P~ and $ is a specially intro-","duced symbol.","I~ Semantics of (ai,J,aj,c,P)6DL(i).","(ai,J,aj,c,P) ~ DL]i) • if and","only if there is a dependency struc-","ture DS(i,i) of s, where (i,J,ai,a~,c) ~ DS(i,i), jGDS (i,l) < P.","~ Semantics of (ai•j•~,S,P)6DL(i).","(ai•J,?j ,$,P) e Dn(1), if and","only if there is a dependency structure","DS(i,i) of s, where ai=iDiDS(i i) a. :JDiDS(i,i), • r J j is a joint of DS(i,i) except","O-th or 1st joint, jGDS(i,i) =P. ALGORITHM FOR THE CONSTRUCTION OF DL"]},{"title":"Input.","paragraphs":["The sequence of the sets of all dependency informations DI(1) , DI(2) , ''\" •DI(N) ."]},{"title":"Output.","paragraphs":["Dependency list DL(2), DL(3) , ''\" ,DL(N)."]},{"title":"Method.","paragraphs":["STEP 1 (Construction of DL(2))~ For each a e DI(2)• a16 DI(1) and cE ~ such that ~ e6(c~2,c~i) , add (a2,l,al,c,{c}) to DL(2)• set i to 2 and repeat the STEP 2 and the STEP 3 until i = N.","STEP 2 (Registration of items of the form (ai+l,j,aA,c,P)) : For any (ai,J,aj•c,P) ~ DL(i) and ~i+16 DI(i+l) , compute 6 (ai+ I,~i) and add every (ai+l,i,ai,c',{c'}) to DL(i+i) such that c'6 6(ei+1,~i). And, for any (c~i,J,aj,A,P) 6 DL(i) where A~ ~ ~'{$} and ai+1£ DI(i+l), compute ~(c~i+1,aA) and add every (ai+l,j,c~j,c',PU {c'}~ to DL(i+i) such that c'6 ~(ai+1,a j) and c'} P. Go to Step 3. 18","STEP 3 (Registration of items of the form (ai+1,j,ej,$,P)): For any (ai+1,j,al,c,P) ~ DL(i+i) and (al,k,ek, A,P') # DL~j), add (ei+1,k,ak,$,~') to DL(i+i). Then, set i to i+; and go to STEP 2.","Theorem 3.","If there exist no ambiguity in the dependency information of B-phrases of input sentence, then the step 3 in the above algorithm can be replaced to the following step 3'.","STEP 3': For each (~Ki+!,j,~A,A,P) 6 DL(Ki+~), add (~i+~,j,aj,~,P) £o DL(i+i), where","de----~ max{k I (ai+l k ~k,C,P) Ki+l , ,","DL ("]},{"title":"i+l )}.","paragraphs":["Then, set i to i+l and go to STEP 2.","The efficiency of each step of above algorithm is as follows.","The memory size of DL(i) is O(N).","The step i, the step 2 and the step 3 take constant, O(N) and O(N ~) elementary operations, respectively.","The step 3' takes O(N) elementary operations since it takes O(N) elementary operations to compute Ki+ ~ . Therefore, the theorem 4 holds.","Theorem 4.","The algorithm for the construction of DL requires O(N ~) memory space and O(N ~) elementary operations. Moreover, if there exist no ambiguity in the dependency information of each B-phrases, the algorithm requires O(N ~) elementary operations by replacing the step 3 with the step 3'","We shall now describe how to find a dependency structure of input sentence from DL. To begin with, we shall explain items of partial dependency structure list PDSL.","Form of items in PDSL","(i,j,a~,a~,P#) where, Nhi ~j ~i a# ~ DI(i) ~ {#}, ~ % DI(j) U {~, P~ i~ a subset of C or #Oand# is specially introduced symbol.","~ Semantics of (i,j,~#,e#.p#)",".~ i j-","The item (i,j,a~,e~,P#) % PDSL means to be a dependenceS- structure DS(i,j)~ ~(i,j) such that following conditions i),2) and 3) hold. i) If a~=~i(%#), then iDiDS (i,j) =e i • 2) If e#=aj(~#!,~ then JDiDS(i,j)=aj. 3) If P~=P(~#). then JGDS(i,j)=P. Therefore, (N,i,#,#,#) means to be a dependency structure of the input sentence. ALGORITHM FOR OBTAINING A DEPENDENCY STRUCTURE FROM DL"]},{"title":"Input.","paragraphs":["DL."]},{"title":"Output.","paragraphs":["A dependency structure of input sentence or the signal \"error\"."]},{"title":"Method.","paragraphs":["STEP i: If DL(N) is empty, emit the message \"error\", else, initialize PDSL to {(N,i,#,#,#)} and repeat step 2 until PDSL becomes empty.","STEP 2: Take an item freely out of PDSL and delete it from PDSL. According to the form of the item, execute i) or 2) or 3).","i) If the item is (N,i,#,#,#) of the form and (aN,J,ej,c,P) ~ DL(N) , then output (N,J,eN,ej,c), add (N-i,j, #,aj,P/{c}) to PDSL i~ N-i ~ j and add (j,l,aj,#,#) to PDSL if j ~ i.","2) If the item is (i,l,ei,#,#) of the form and (j,~i,ej,c,P)E DL(i), then output (i,J,ei,e~,c), add (i-l,j, #,aj,P/{c}) to PDSL i~ i-i @ j and add (j,l,a~,#,#) to PDSL if j @ 1","3) aIf the item is (i,j,~,e~,P) of the form, where ~#=~= or #, anda(ai,j, ~,c,P) E DL(i), then±output (i,J,~i, e~,c) and add (i-l,j,#,~j,P/{c}) to PDSL if i-i % j. When there is not such item in DL(i), searcha pair of items (ei,k,ak,C,P') E DL(i) and (ak,J, ej,A,P) ~ DL(k), then output (i,k,ei,ak, cy , add (i-l,k,#,~k,P'/{c}) to PDSL if i-i @k and add (k,j,~k,ej,P) to PDSL.","PDSL needs O(N) memory space and STEP i, STEP 2 take constant, O(N) elementary operations, respectively.","Theorem 5.","A-igorithm for obtaining a dependency structure from DL requires O(N) memory space and O(N 2) elementary operations. PARSING ALGORITHM"]},{"title":"Input.","paragraphs":["A Japanese sentence in colloquial style."]},{"title":"Output.","paragraphs":["A dependency structure DS(N, i) of the input sentence and a B-phrase structure of the j-th B-phrase, whose dependency information is JDiDS(N,i), for every j(j=l,2, \"'\" ,N)."]},{"title":"Method.","paragraphs":["STEP i: Construct N B-phrase parse lists of all B-phrases of the input sentence and get the sets of dependency informations DI(1), DI(2), • .\" , DI(N).","STEP 2: Construct dependency parse list DPL from DI(1), DI(2), ... ,DI(N).","STEP 3: Obtain a dependency structure DS(N,i) of the input sentence from DL.","STEP 4: Obtain a B-phrase structure of the j-th B-phrase, whose dependency information is JDiDS(N,i), for every j (j=l,2, ... ,N) and stop. -19--","Let n~ be the length of j-th B-phrase (~=i,2, •-- ,N), and N,n denote the number of B-phrases and the length of input sentence, respectively. Then, n1+n2+ ... +n N =n N Ln","By theorem i, theorem 2, theorem 4 and theorem 5, next theorem holds.","Theorem 6.","The parsing algorithm requires O(n 2) memory space and O(n 3) elementary operations. Moreover, if the dependency information of each B-phrase is unambiguous, it requires O(n 2) elementary operations.","3. CONCLUSION","Syntax of Japanese sentences is stated and a efficient parsing algorithm is given. A Japanese sentence in colloquial style is parsed b Y the parsing algorithm, using time O(n ~) and memory space O(n2), where n is the length of input sentence. Moreover, it is parsed using time O(n 2) whenever dependency information of every B-phrase is unambiguous.","REFERENCES","i. Aho, Ullman : \"The Theory of Parsing, Translation, and Compiling\", Prentice Hall vol. 1 (1975).","2. Woods : \"Transition Network Grammars for Natural Language Analysis\", Communication of the ACM, 13 (1970).","3. Pratt : \"LINGOL -- A Progress Report\", Proc. IJCAI 4 (1975)."]},{"title":"(~) (~s) (s) (2) 0-)","paragraphs":["J0 =5) Jl (=4) J2 (=3) J3 (=i)",": main part a: agent --: annex part p: patient J0,Jl,J~,J3 : the sequence of joint Figure 2. Dependency Structure","Example: Taro read the composition written by Hanako. Figure i. Ways of Spacing 20"]}]}