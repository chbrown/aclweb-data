{"sections":[{"title":"TOWARDS COMPUTER-AIDED LINGUISTIC ENGINEERING Vers une m~thodologie et des outils pout\" ie g~nie linguistique","paragraphs":["RI~MI ZAJAC","GRIL","Universit6 Blaise Pa~al, 34 avenue Carno!","F-63037 Clermont-Ferrand"]},{"title":"cedex remi@ucfsl.uucp Dans cet article, nous proposons une m6thodologie de g6nie logiciel pour le traitement automatique des langues fond6e sur la g6n6ration (semi-) automatique de programmes de TALN it partir de sp6cifications formelies. Cette m6thodologie est concue pour favoriser la r6utilisation de sp6cifications linguistiques dans la g6n6ration de diff6rentes applications de TALN, ainsi que le d6veloppement incr6mental de ces sp6cifications linguistiques. Le langage de spdcification fomlelle est fond6 sur les structures de traits typ6s. La r6utilisation de spdcifications linguistiques est favoris6e par l'organisation de ces sp6cifications darts un style par objets, en plusieurs niveaux de sp6cificit6 croissante. Ce langage est suffisement puissant pour pouvoir d6crire tout type d'objet linguistique, et a l'avantage d'utiliser une notation largement r6pandue en TALN, L'acquisition de connaissances linguistiques formalis6es au moyen de ce langage peut 6tre automatis6e en utilisant des outils d'exploration de corpus et des 6diteurs sp6cialis6s fond6s sur ce langage et directement com~ect6s ?a la base de connaissances linguistiques.","paragraphs":["ACRES DE COLING-92, Nnt, rrE~s, 23-28 ao~r 1992 8 2 7"]},{"title":"La g6n6ration de progrmlmaes sp6cifiques d'aualyse ou de g6n6ration peut ~tre automatis6e dans la mesure ou les langages de programmation cibles sont des langages de programmation logique ~t contraintes dont les structures de donndes sont des structures de traits typ6s. I.es diffdrents 616merits constituant cette approche sont actuellement darts un 6tat d'avancement vari6, qbutefois, cette approehe est d6ja partiellement utilis6e par diff6rents groupes clans plusieurs projets nationaux et europ6ens, en particulier dans le domaine des dictioImai~Tes 61ectroniques.","paragraphs":["Pltc~c. o1: COLING-92, NAbrIES, AUTO, 23-28. 1992"]},{"title":"TOWARDS COMPUTER-AIDED LINGUISTIC ENGINEERING","paragraphs":["RI~MI ZAJAC","GRIL","Universit~ Blaise Pascal, 34 avenue Carnot","F-63037 Clermont-Ferrand cedex remi@ucfsl.uuep We outline a framework for computer-aided linguistic engineering based on the automatic generation of NLP programs from specifications, mid an automated construc-tion of reusable linguistic specifications. The specification language is based on Typed Feature Structures, and the target programming language is a constraint logic programming language which data structures are typed feature structures. Reusability of linguistic specification is enhanced by the organization of the specifications in an object-oriented style in several Myers of increasing specificity, supporting for example the incremental development of grammar specification for sublanguages."]},{"title":"1 A framework for NLP Software Engineering","paragraphs":["The development of reliable high-quality linguistic software is a time-consuming, error-prone, and costly process. A parser used in an industrial NLP system is typically developed by one person over several years. The development of a linguistic engio neering methodology is one of the major in the development of a language induslry. The process of developing an NLP application is an application and an adaptation of the classicalsoftware engineering development methodology and follows three major steps: the initial requirements and specifications expressed in natural language, the formal specification of the system, and finally the implementation of the system [Biggerstaff/Perlis 89]. The requirements specific to a linguistic engineering methodology are:","1. The initial requirements are complemented by a corpus giving typical examples of the texts and linguistic phenomena contained in these texts to be treated by the system;","2. The set of formal specifications constitutes a standardized repository of formalized linguistic knowledge reusable across different NLP applications - a crucial property given the sheer size of granrmars and dictionaries; executable - to be able to test the specifications against corpora.","3. NLP programs are generated (semi-) automatically from formal specifications. These particularities have the following implications:","1. The availability of a corpus allows to develop a methodology based on sublanguages and corpus analysis, automating the knowledge acquisition process.","2. The linguistic specification does not include any information specific to some application (especially, it does not contain any control information), thus the same specification can be reused for different applications (genericity). A specification language for describing linguistic knowledge could be based on a feature logic and has an object-oriented inheritance style that makes it possible to distinguish formally between generic knowledge and specific (e.g., sublanguage) knowledge, thus enabling the reuse of specifications in the development of the specifications tllemselves. The expressive power of the specification language (a non-decidable subset of first order logic) allows to remove the conventional distinction between dictionaries and grammars, providing a single homogeneous framework for an integrated development of linguistic knowledge bases. The use of a feature-based language also favors standardization, as feature structures become a \"lingua franca\" for computational linguists. Several modem specialized linguistic programming languages can be the targets of the automated generation process. Since the specification language is based on typed feature structures, natural candidates are ~unification-based grammar formalisms.. 3. Ac~lzs DE COLING-92, NANTEs, 23-28 AO~r 1992 8 2 8 Prtoc. OV COLING-92, NANTES, AUG. 23-28, 1992 A Computer-Aided Linguistic Engineering inethodology should also address the 1011owing poinls:","• strict separation between pure linguistic knowledge and knowledge about strategies tor its use in a particular application, a condition sine qua non for reusability;",", concepts of modularity for lingnistic description, e.g., formal separation of knowledge pertaining to different levels of linguistic description, organization of linguistic knowledge in hierarchies (from generic to specific);","• team organization of linguistic development projects."]},{"title":"1","paragraphs":["Reusable linguistic descriptions In software engineering, the use of the tenn <<reusability>> covers two main trends: the composition-based approach and the generation-based approach. In the first approach, software components can be plugged together with no or smaU modifications in order to build software systems: programming langnages such as ADA or object-oriented languages are designed to support this type of reuse. This approach is successful when the components are small and perform very precise functions, as li3r numerical analysis [Biggerst,'fff/l'erlis 891. In NLP, this approach is exemplified by the reu~ of various ,<engines>> such as parsers. In the second approach, software components are generated (semi-automatically) from a ~t of formal specifications, instantiating these specifications in a programming language by choosing appropriate data representations and control structures: the knowledge expressed in the specification is reused in various contexts to generate different applications. This approach is successful when a fair alnount of domain knowledge is built into the specilication and the generation environment, e.g., business knowledge in 4GL (Fourth Generation Languages) environments. Tiffs is the approach we envisage for producing NLP programs. To support reusability and incremenlal development of specifications, we organize and describe linguistic knowledge using partial specifications and controlled degrees of abstraction in the overall design. Tiffs approach should of course be supported by a specification language which will be based on the concept of partial information and provides the means of stmcturing a specification in a hierarchy of subspecifications of increasing specificity. We envisage three basic levels of abstraction. The i~titial design of the linguistic domain is rather abstract and largely free of details. It establishes the basic buildings blocks, the basic structures and the foundations of the linguistic domait~. At that level, we could aim at providing a eonsensual formal deft o nition of tbese basic building blocks as a first step towards the definition of standards for representiug linguistic knowledge. For example, the initial level of abstraction could start from basic descriptive classiticalions, e.g. at the categorial level nouns, verbs, etc., and li'om the basic syntactic dependencies between these categories, and give them a fnrmal delinition. A second level of specialization makes choices as for the distribution of linguistic properties into more line grained categories. At that level, we observe the emergence of linguistic theories, where choices are triggered by tlleoretical assumptions. Given the relative freedom of structuration, the choice between competing representations should be guided by the concern for modularity and reusability (internal consla'aints) and by the external constraints on the coverage and the adequacy of the linguistic representation to the needs of NLP of applications. Linguistic specifications should be developed as a set of independently defined nmdules with well-defined interconnections: modularity is essential in supporting reusability aud team work in the development of specilications. At the third level of specialization, the lingnistic organization principles are instantiated in the fully detailed description of specilic linguistic phenomena. This level is sufficiently detailed to test the specification against actual sentences (strings of word tbnns). Previous levels can 'also be tested but only against abstract descriptions representing sets of sentences. Tius is also tile level at which we have several diflerent i~tstances corresponding to diflerent sublanguages, each sublanguage description reusing the same first mid second levels of specification, freeing the linguistic of redoing the same design decisions for each instance. There could also be a smlcturation among sublanguages which could introduce finer levels of abstraction, thus achieving a higher degree of reusability. This overall framework in winch each level sets partial cxmstraints on the most specific instances is able to support the incremental developnrent of linguistic knowledge by successive refinements and thus, fartiler reusability. ACTf!S t)'~COLING-92, NN̂-I~.s, 23-28 ôtJr 1992 8 2 9 I'v:o~:. oI:COLING-92, Nl̂'rrgs, AUG. 23-28, 1992"]},{"title":"2 A linguistic description language","paragraphs":["The crucial issue in the generation-based approach to reusability is the nature and the definition of the specification language. A specification language has to be defined and implemented as pure logic to fully support reusability. It should be suitable to describe the knowledge of a particular domain and should build on well-accepted notions and notations for that domain: here, natural language processing. In NLP, the emergence of unification-based grammar formalisms promoted the use of feature structures as a ,dingua franca>, for representing linguistic information. Although some work on unification-based grammar formalisms is motivated by reusability of linguistic specifications (e.g., ,<reversible grammars,,), such work does usually not address the problem of specifications in engineering terms. Furthermore, these formalisms make strong assumptions about the nature of linguistic representation 1 thereby limiting severely the expressive power of these languages. The linguistic specification language is based on a typed version of a logic for feature structures which allows to define specifications at different levels of abstraction. Using this language, it will be possible to eliminate the conventional division between lexical and grammatical knowledge, and also the division between generic and specific (e.g., 8ublanguage) knowledge. Such a specification language is executable (although it is potentially infinitely inefficient), and it should be executable for two reasons. First, since the formal specification is the first level of formality in the conception of a software system, correcmess cannot be proved by formal means. However, an executable specification language allows at least to test the specifications against examples. Second, it should be possible to derive an actual program (e.g., a parser) from a specification. An executable specification language ensures the basic feasibility of an automated generation of NLP programs. The specification language is formally based on a subset of first-order logic. In order to make it manageable and intuitive, it employs syntactic constructs called Typed Feature Structures (TFSs). The ,~vocabulary~ of the language, its signature, consists of unary predicates (sorts) and binary predicates (features). Moreover, there is an ordering on the sorts (yielding a lower semi-lattice). The structures over which the language is interpreted are determined in that they have to satisfy certain axioms: the features give partial functions, and the ordering on the sorts is 1. Which are sometimes only motivated by processing considerations. reflected as subset inclusion (unary predicates give sets). They are not fully specific, however, which reflects the situation in knowledge representation where the domain of discourse is not completely specified. By adding new axioms, this domain is made more and more specific; in the extreme case, one structure is singled out. The sort signature is extendable through (recursive) definitions of new sorts; these are done by defining explicit constraints which come from the language itself (the TFS constraint language). The sorts are organized into an inheritance hierarchy, with a clean (logical, algebraic and type-theoretic) semantics of inheritance in the object-oriented programming style. The subset of first-order logic can be made more complex by adding logical connectives, such as negation and quantification. Given the signature, which defines the constraints available to the user, the user has the option to extend the language by specifying new predicates. These are interpreted as relations between the elements of the domain of the respective interpretation structure. The language is still a subset of first-order logic; thus, its syntax can be chosen like the one of definite clauses, but with TFS's instead of first-order terms. The specification language thus obtained allows the user to create partial specifications that can be incrementally extended, and to express controlled degrees of abstraction and precision. Although of consider-able expressive power, this specification language is executable, but the control information is be abstracted; that is, formally the execution is nondeterministic, and there will be no explicit programming feature to express control. This has a good reason: control information coded in programs is specific to particular applicatiorts. For grammars for example, for the same underlying logical specification the control will be different in parsing or in generation, or even in different parsers (e.g., for indexing or for granunar checking). Thus, abstract-ing from control is important for gaining genericity: logical specifications apply to more problems than programs. The knowledge specification language is used in a first step in the generation of correct programs."]},{"title":"3 Automating the acquisition of linguistic descriptions","paragraphs":["We assume that the acquisition of linguistic information will build upon the definition of broad linguistic AcrF.s DE COLING-92, NANTES, 23-28 AOt~T 1992 8 3 0 PROC. OF COLING-92, NAbrrES, AUG. 23-28, 1992 categories formalized as the initial and secondary level of linguistic abstraction described above. In a Computer-Aided Linguistic Engineering fnunework, the acquisition of linguistic inibrmation is targeted towards the needs of specific applications: we also assume that the linguist uses for testing purposes a set of examples of the kind of text Ire describes (test case). These exanlples (fire <~corpus>~) can be constmcted (as a way for example to specify file kind of dialogue envisaged fox\" a natural language man., machine interface) or can come from existing texts, for example, existing teclmical documentation, The acquisition of linguistic iulonuation coltsists in describing in lull detail the set of linguistic phenomena occurring in the corpus as a specialization of linguistic axioms and principles. The acquisition is performed in two steps. First, the linguist uses corpus analysis tools to characterize the particularities of the sublanguage phenomena occurring in the corpus and to define the coverage (sel ot' linguistic categories) that should be reached, q~en, the linguist describes formally (i.e., using the specification language) in all details phenomena occun'ing in the col pus, using corpus analysis tools to lind examples and to refine the categorization [Ananiadou 90, Tsujii et al. 901. This approach to tim acquisition of linguistic knowledge leads to the delinition of a precise methodology (basic concepts and working procedures) supported by a specific set of sollware tools:",". Concepts. The basic concepts underlying this methodology are the notions of sublanguage and coverage [Grishman/Kittredge 86, Kittredge/ Lehrberger 82, Gristmlm~lirsclnnan/Ngo 86]. Given a corpus, a linguist should be able to give a high level description of it in terms of its linguistic particularities which are not lkmnd m other kinds of texts, and in terms of the set of lingttistic phenomena which are occurring in it: these concepts should be defined operationally to allow the linguist to apply them to actual texts.",". Working procedure. A working procedure delines the steps to be taken in the acquisition of linguistic knowledge, both in larger steps (characteriza-tion of the corpus, then acquisition) and in details such as how to document the phenomena described, to link a formal description to exampies of the corpus, to check the consistency o1' the description with other parts of the specification, etc. It also gives examples of, e.g., how to detine new lexical semantic classes using a cluster analysis tool (see below).","o Software tools, q he concepts and working procedures are suppo~ted by a set of specialized linguistic software tools integrated in a Computer~ Aided Linguistic Engineering workstation. These ~ltware tools suplx)rling the acquisition of linguistic knowledge should have tire tollowiug functio~mlities:",". Taggh~g. A first set of fmictionafities is to tag a corpus using linguistic markels such as the category of word forms, their inflection, etc. Several levels of sophistication will be distinguished depending on the availal~ility of the appropriate set of pat~uneters: sels of closed categories, sets of word fonns, sets of nlorphemes, definition of phrase boundaries, etc. Text DBMS. A tagged coq)us is be loaded into a text DBMS for further exploitation, and accessed through a specialized linguistic interlace (using a specialized query language).",". Statistics and cluster analysis. Two kinds of inl2mnation can be extracted linm a tagged corn pus: statistical inlbnnation and concordance and clustering ildbnnation. Statistical and clustering aualysis algorithms will be implemented and incorlxn'ated ,as l~unctionalities of the linguistic interlace of the text database. Semantic editor The essential operation in linguistic acquisition is the creation of specializafinns of existing categories. A semantic editor takes into account the delinition of existing classes and interactively guides the user in the creation of instances. 4 Automating the generation of NLP programs In the development process sketched above (Section I) the last step is the implementation of the system. Automatic gencratinn of NI.P soltware Ires been locused to the (crucial) domain of lexical resources (how to build generic rcsom~;es and compilers that can extract electronic dictionaries from a lexical knowledge base lbr NLP systems) and to the domain of ,~reversible grammars,, 1. The process of transfomfing a specilication into an elficient program is very similar to compilation. If the structure of a set of specilication is stable, a compiler can be built to genelate a program. This is the approach envisaged for lexical infnnnation 2. Lexical ]. Seefor exmnple file I)taw.eedings of the ACL Workshop on Reversible Grammars, Berkeley, June 1991. Acq3/s DE COLING-92, NANTES, 23-28 An(n 1992 8 3 I l'r~oc. O1: (5OLINGO2, NANTES, AU¢;. 23-28, 1992 information is here considered as <<static, information: once the structure of the lexicon is defined, adding or removing an entry will not modify the compilation process. This is less tree for grammatical information which defines how the basic linguistic buildings blocks, i.e., lexical entries, are combined into larger structures. Here, the needs may vary depending on the processing requirements of different NLP applications. For example, a grammar checker and an indexing system will most probably not use the same parsing scheme: they will treat differently errors and ambiguities. Thus, a general approach is needed. Since the knowledge specification language is executable, this means that, to generate a program, there are two basic choices to be made: the selection of data structures and the selection of control structures. The nature and the complexity of these choices depend on the distance between the specification language and the targeted programming language. As a programming language into which the specifications are derived, we envisage to use the Constralnt Logic Programming (CLP) language LIFE developed at DEC-PRL [Ai't-Kaci/Meyer 90, Ai't-Kaci/Podelski 91]. The reason is that its formal foundation has parts in common with the Knowledge Specification Language; in particular, its basic data structures are also Typed Feature Structures, thus ensuring a basic level of compatibility between the two. Another reason is its descriptive power, its efficiency and its flexibility in execution (~data-driven.): LIFE subsumes the two main programming paradigms (logic programming, as in PRO-LOG, and functional programming, as in LISP or ML). That is, a .logic. (or ~functional>>) program-mer may stick to his favorite programming style and still write code in LIFE. Since the data model is the same, to generate an efficient program form a specification, the user will only have to select appropriate control structures, For example, to generate dictionaries for a parsing program, the only refinement the user will have to develop is to define an efficient indexing mechanism that allows a parser direct access to a lexical entry. In generating NLP parsers or NLP generators, the user will have to choose between a functional control structure (as in ML) or a relational control structure. as in PROLOG. For the latter, additional choices have to be made, such as the ordering of clauses, the introduction of cuts, etc. [Deville 90]. Research in computational linguistics has identified a few central 2. This is also the approach envisaged in the ESPRIT project Multilex and in the Eurotra-7 study. computational concepts appropriate for NLP, among them regular grammars and regular transducers, augmented context-free grammars and tree transducers. In particular, augmented context-free grammars are the framework of the research in so-called ~<reversible grammars>,. This research can be used in the development of NLP processing schemes defined as annotations to the specification [Deville 90, Uszkoreit 91]. Assuming that a set of specifications is stable, it is possible to write a specialized compiler to generate a LIFE program for, e.g., parsing or generation. This compiler will embed the control choices that a designer of a parser makes when developing a parsing algorithm. This kind of generation has been shown practically feasible for lexieal information, and research on ,<reversible grammars~> has demonstrated the feasibility for grammatical information as well (see for exanlple [Dymetman/Isabelle 88] who present a prototype of a machine translation system capable of translating in both directions using the same grammars and dictionaries). However, we have also a long term more ambitious goal, which is to develop methods and tools for fi.dly automating the generation of a program. Using these tools, the user will interactively guide the system in the generation of a program, experimenting with various choices and recording the design decisions for control to be used in a fully automatic step once the design is completed [Biggerstaff/Perlis 89]."]},{"title":"5 Towards","paragraphs":["Computer-Aided"]},{"title":"Linguistic Engineering","paragraphs":["we have outlined a frmnework for Computer-Aided Linguistic Engineering based on the concepts of reusability and automatic programming [Biggerstaff/ Peflis 89], and showed that we have already all the basic ingredients (although at various degree of elaboration):","• aTFS based specification language [Emele/Zajac 90a, Emele/Zajac 90b];","• a TFS based constraint logic programming language [Ai't-Kaci/Meyer 90, Ai't-Kaci/Podelski 91];","• a methodology for the generation of NLP programs [Devine 90, Uszkoreit 91];","• a methodology for linguistic acquisition [Ananiao dou 90, Tsujii et al. 90]. Acaxs DE COLING-92, NAMES, 23-28 AOt~T 1992 8 3 2 PROC. OF COLING-92, NANTES, AUG. 23-28, 1992 To arrive a a fully detailed framework tlmt could be implemented in a Computer-Aided Linguistic Engineering workstation, the major parts that need to be researched and developed are the elaboration of an annotation system to bridge the gap between the specification language and the programming language, and the development of adequate tools for the automated acquisition of linguistic knowledge. Of course, this approach has to be tested on a larger scale than what have been possible using the partial implementations available at present. Part of the framework described in this paper is presently used in several on-going projects or proposed in several projects proposals. In the current projects, the primary domain of application of this framework is in the area of lexical representations (e.g., the MULTILEX ESPRIT project, the EUROLANG EUREKA project, the DELLS LRE proposal), Acknowledgments. This paper was written while I was working in the Polygloss project at the IMS (University of Stuttgart). Many of the ideas presented in this paper have been discussed during the preparation of an ESPRIT project proposal on Computer-Aided Linguistic Engineering. I would especiaUy like to thank Hassan Ai1-Kaci, Gabriel B~s, Ulrich Heir, Andreas Pedelski, and Harts Uszkoreit."]},{"title":"References","paragraphs":["[All-Kaci 84} Hassan Al't-Kaci. A Lattice Theoretic Approach to Computation based on a Calculus of Partially Ordered Types Structures. Ph.D Dis~rtation, University of Pennsylvania.","[Ail-Kaci 86] Hassan Al't-Kaci. ~<An Algebraic Semantics Approach to the Effective Resolution of Type Equations>>. Theoretical Computer Science 45,293-351.","[Ai~-Kaci/Meyer 90] Hassan Al't-Kaci and Richard Meyer. ,~Wiid LIFE, a user manual>>. DEC-PRL Technical Note PRL-TN-l, Rueil-Malmaison, France, 1990.","[AiVKaci/Podelski 91 ] Hassan Alt-Kaci and Andreas Podelski. <<Towards a meaning of LIFE~. DEC-PRL Research Report PRL-RR-11, RueiI-Malmaison, France, June 1991.","[Ananiadou 90] S. Ananiadou. ,<The use of statistical techniques in identifying sublanguage patterns,. Eurotra Research Report, 1990.","[Biggerstaff/Perlis 89] Ted J. Biggerstaff and Alan J. Perlis (eds). Software Reusability, 2 volumes. ACM Press - Addison-Wesley, 1989. [Carpenter 90] Bob Carpenter. ~'I~yped feature structures: inheritance, (in)equality and extensionality)>. Proc. of the Workshop on Inheritance in Natural Language Processing, Institute for Language Technology and AI, Tilhnrg University, Netherlands, August 1990.","[Deville 90] Yves Deville. Logic programming. Systematic Program Development. Addison-Wesley, 1990.","[Dymetman/lsabelle 88] Marc Dymetman and Pierre Isabelle. ,~Reversible logic grammars for machine translation>>. Proc. of the 2nd International Conference on Theoretical attd Methodological Issues in Machine 7)'anslation of Natural Language, June 1988, Pittsburgh.","[Dymetumn et al. 90] Marc Dymetman, Pierre Isabelle and Franqois Perrault. ~(A symmetrical approach to parsing and generation,. Prec. of the 13th International Conference on Computational Linguistics - COLING'90, Helsinki, August 1990.","[Emele 1988] Martin Emele. <<A typed feature stmc° tare unification-based approach to generation>,. Proc. of the WGNLC of the IECE, Oiso University, Japan, 1988.","[Emele 1991] Martin Emele. <<Unification with lazy non-redundant copying>>. 29th Annual Meeting of the ACL, Berkeley, June 1991.","[Emele/Zajac 90a] Martin Emele and Rdmi Zajac. aA fixed-point semantics for feature type systems,. Proc. of the 2nd Workshop on Conditional and :l)~ped Rewriting Systems - CTRS'90, Molltrdal, June 1990.","[Emele/Zajac 90b] Martin Emele and Rdmi Zajac."]},{"title":"<<Typed","paragraphs":["Unification Grammars>>. Proc. of the 13th International Conference on Computational Linguistics - COLING'90, Helsinki, August 1990.","[Emele et al. 90] Martin Emele, Ulrich Heir, Stefan Momma and R~mi Zajac. ,<Organizing linguistic knowledge for multilingual generation>>. Proc. of the 13th International Conference on Computational Linguistics - COLING\" 90, Helsinki, August 1990.","[Franz 90] Alex Franz. ,~A parser for HPSG,. CMU report CMU-LCL-90-3, Laboratory for Computational Linguistics, Carnegie Mellon University, July 1990.","[Grishman/Kittredge86] R. Grishman and R. Kittredge. Analyzing Language in Restricted Domains. Laurence Edbaum, 1986.","[Grishrnan/Hirschman/Ngo 861 Hirschman L. Grishman, R. and T.N. Ngo. ,,Discovery procedures for Ac'r~ DE COLING-92, NAturES, 23-28 AO~\" 1992 8 3 3 PROC. OF COLING-92, NANTES, Autl. 23-28. 1992 sublanguage selecfional patterns: initial experiments~. Computational Linguistics, 12(3):205-215, 1886. [Kittredge/Lehrberger 82] R. Kittredge and J. Lehrberger. Sublanguage: Studies of Language in Restricted Semantic Domains. De Gruyter, 1982.","[Pollard 90] Carl Pollard. ~Sorts in unification-based grammar and what they mean~. In M. Pinkal and B. Gregor (eds.), Unification in Natural Language Analysis, MIT Press. (in press)","[Pollard/Moshier 90] Carl Pollard and Drew Moshier. ~Unifying partial descriptions of sets,>. In P. Hanson (ed.) Information, Language and Cogni-tion, Vancouver Studies in Cognitive Science 1, University of British Columbia Press, Vancouver. (in press)","[Pollard/Sag 87] Carl Pollard and Ivan A. Sag. Information-Based Syntax and Semantics. CSL1 Lecture Notes 13, Chicago University Press, 1987.","[Pollard/Sag 91] Carl Pollard and Ivan A. Sag. Agreement, Binding and Control. Information-Based Syntax and Semantics. Volume 2. To appear.","[Smolka 88] Gert Smolka. ~A Feature Logic with Subsorts.. LILOG Report 33, IBM Deutschland GmbH, Stuttgart.","[Smolka 89] Gert Smolka. ~Feature Constraint Logics for Unification Grammars>~. IWBS Report 93, IBM Deutschland GmbH, Stuttgart.","[Smolka/A'ft-Kaci 88] Gert Smolka and Hassan Ai't-Kaci. ,dnheritance Hierarchies: Semantics and Unificatiom~. J. Symbolic Computation 7, 343-370.","[Strzalkowski 90] Tomek Strzalkowski. ~How to invert a natural language parser into an efficient generator: an algorithm for logic grammars>>. Proc. of the 13th International Conference on Computational Linguistics - COLING'90, August 1990, Helsinki.","[Tsujii et al. 90] Tsujii, J., Ananiadou S., Carroll J., and Phillips J.D. ,~Methodologies for the development of sublanguage MT systems~. CCL Research Report CCL/90-10, UMIST, Manchester, 1990.","[Uszkoreit 91] Hans Uszkoreit. ,~Strategies for adding control information to declarative grammarsh. In Proceedings of the 1991 Annual"]},{"title":"Meeting of the","paragraphs":["Association of Computational Linguistics, Berkeley, 1991.","[Zajac 89] R6mi Zajac. ~A transfer model using a typed feature structure rewriting system with inheritance~. Proc. of the 27th Annual Meeting of the ACL, 26--27 June 1989, Vancouver.","[Zajac 90a] R6mi Zajac. ,~A relational approach to translatiom,. Proc. of the 3rd International Conference on Theoretical and Methodological Issues in Machine Translation of Natural Language, 11-13 June 1990, Austin.","[Zajac 90b] R~mi Zajac. ,~Semantics of typed feature structures~. Presented at the International Workshop on Constraint Based Formalisms for Natural Language Generation, Bad Teinach, Germany, November 1990. ACTES DE COLING-92, NANTES, 23-28 AOC'r 1992 8 3 4 PROC. OF COLING-92, NANTES. AUG. 23-28, 1992"]}]}