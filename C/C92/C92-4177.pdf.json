{"sections":[{"title":"Degrees of Stativity: The Lexical Representation of Verb Aspect Judith L. Klavans and Martin Chodorow IBM T.J.Watson Research Yorktown Heights, NY and ~Hunter College of the City University of New York Abstract L'acqnisition automatique de connaissance lexicale h partir de larges corpus s'est essentiellement oceup& des phfinom~nes de co-occurrence, aux dfipens des traits lexicaux inh~rents. Nous prfisentons ici une m&hodologie qui permet d'obtenir l'information sfimantique sur l'aspect du verbe en analysa~t automatiquement un corpus et en appliquant des tests linguistiques h l'aide d'une stifle d'outils d'anrdyse structura]e. Lorsque ces deux t~:hes sont accomplies, nous proposons une rfipresentation de l'aspect du verbe qni associe une valeur de mesure pour les difffirents types d'fiv~nements. Les mesures zefl~tent l'usage typique du verbe, et par consfiquent une mesure de rfisistance ou de non-r~sistance h la coercion dans le eontexte de la phrase. Les rfisultats que nous rapportons ici ont fitfi obtenus de deux mani~res: en extrayant l'information n&essrSre h partir du corpus &iquetfi de Francis and Ku~era (1982), et en fais~nt tourner un analyseur syntaxlque (MeCord 1980, 1990) sur le corpus du Reader's Digest afin d'extraire une information plus pr&ise sur l'usage du verbe dans le texte. Notre travail iUustre deux aspects: 1. Les ptopri6t6s lexicales inh6rentes peuvent fitre dfitermin&s en appliqurmt aux textes une s&ie de tests llngnistiques bien &ablis. Cela donne l'analyse de corpus une dimension suppl~mentaire qui va au-delh des ph~nom~nes de coocurrence (eomme par example information mutuelle, substitutabilitfi). 2. Une propri~t~ lexieale n'a pas be-soin d'etre discrete mats peut &re repr~sent~e en tant que valeur ~ in-terprdter comme une tendance ou probabilitY; de cette mani~re, ]e oh- .jet lexieal exprime la propri~t~ donn~e darts un contexte non-marqu& Les valeurs der/v~es du corpus sont variables, e'est-h-dire des valeurs h degr~s. Des tests linguistiques ont &~ automatiquement appliques aux corpus analys~s de mani~re k d&erminer la valeur initiale de l'aspect pour la stativit~, et ce, pour un ensenble de verbes frequents, repr~sentant plus de 90% des occurrences de verbes dans un corpus d'un million de roots. ACTES DE COLING-92, NArTr~. 23-28 AOl~r 1992 1 1 2 6 PROC. OF COLING-92. NANTES, AUG. 23-28, 1992 Degrees of Stativity: The Lexical Representation of Verb Aspect Judith L. Klavans and Martin Chodorow t","paragraphs":["IBM T.J.Watson Research Yorktown Heights, NY","amd","~Hunter College of the City University of New York"]},{"title":"Abstract","paragraphs":["The automatic acquisition of lexiced knowledge from large corpora has dealt primarily with coocurrence phenomena, at the expense of inherent lexic~l features. We present here u method-ology for obtaining semantic information on verb aspect by parsing a corpus and automatically upplying linguistic tests with a set of structural analysis tools. Once applied, we propose a representation for verb aspect that associates a value with weights for event types. Weights reflect typical verb use, and thus represent a measure of the resistance or ease of coercion in sentential context. The results we report here have been obtained in two ways: by extracting relevant information from the tagged Brown corpus (Francis and Ka~era 1982), and by running ~ parser (McCord 1980, 1990) on the Reader's Digest corpus to extract more accurate information on verb usage in text."]},{"title":"1 Overview","paragraphs":["Our work illustrates two points:","1. Inherent lexical properties can be deterufined by applying a battery of established hnguistic tests to corpora~ This adds to the utility of corpus analysis a dimension beyond coocnrfence phenomena (e.g. mutual information, substitutability).","2. A ]exical property need not be discrete bat can be represented as a value to be interpreted as a tendency or probability for the lexical item to exhibit the given property in an unmarked context. Corpus-derived values are variable, i.e. DEGREE ValU~ Linguistic tests have been automatically applied to parsed corpora to determine an initial aspectual value for stativity for u set of frequent verbs, coveting over 90% of verb occurrences in a one million word corpus."]},{"title":"2 Event types","paragraphs":["Aspect can be informally defined as a property which reflects the temporal organization of an event, such as duration (whether an event involves change over time), telicity (whether it has a definite endpoint or is ongoing), iteratlvlty (whether or not it is repetitive) and so on (see Comrie 1976.) We assume three event types, following Vendler 1967, refined by many others, and recently recast from the perspective of computational lexicon building by Pastejovsky 1991, and Pustejovsky and Boguraev (to appear) 1: State(S): knon, resemble, b~, love Process(P): run, walk, eviM Transition(T): give, open, build, destroy A verb can enter into u construction which may change the overall phrasal or sentential event structure, as ttte result of event-coercion. Coercion can be defined as the process by which verbs in context appear to demonstrate some regular ambiguities, i.e. they appear to change categories. Pustejovsky argues that u verb is inherently (lexfealty) specified as being of a certain event type (e-type).","Schema: e-type(Verb) - SIPIT e-type(reeenble) ~ S e-type(run) ~ P e-type(give) - T Figure One","INolice that accomplishment verbs (e.g. ~palnt • pieture\"), and Itchleveme, t veltbw (\"reach a goM\") are both considered tr~neition verbi, AcrEs DE COLING-92. NANIJ£S. 23-28 AO~I 1992 1 1 2 7 PnOC. OF COLING-92, NAhrrgs, AUG. 23-28, 1992 We call this the NON-DEGREE APPROACH, since there is no degree specified. Our claim is that, rather than the representation in Figure One, the event structure is a vector of values, e-type (Verb) = (S,P,T). We deal here only with the statics/non-statics distinction, since there are regular differences between states versus activities and accomplishments (Lakoff 1965). We propose a simplified representation e-type(Verb)=Vo(x) with a single value for stativity, Vs, the non-statics value being merely the complement, i.e. 1I, + V~s = 1. Our position can be summarized as: Schema: e-type(Verb) ~ Vs(Z) where 0 < Vs(X)< 1 and nhore VH + V~s = 1 . Figure T~o We call our position the DEGREE APPROACH since a numeric value or DEGREE iS specifted. We agree with the notion of assuming basic verb types, with coercions, rostra the position proposed by Dowry 1979 that there be different entries for different usages. To allow the process interpretation in sentences like: (i) The child iv being a fool today. (2) She i~ resembling her mothez","more and more each day. the phrase \"more (and more)\" in (2), a temporal expression, acts to \"coerce\" or force a non-stative event (in this case a process). ~ In fact, the verb \"be\", often touted as fundamentally the most statics verb in the language is frequently coerced into process and transition."]},{"title":"3 Computational Lexicons","paragraphs":["The work reported here is part of an ongoing project in the bexical Systems Group at IBM Research to extract and represent lexical knowledge in CompLex, a computational lexicon which will be able to provide information to natural language processing systems. The seeds of this project are presented in Klavans 1988, where it is argued that the building of a computational lexicon requires ~Our position might be viewed in terms of ~signing probabilities to the arc tranmltions in ~ system luck as that proposed by Moths and Steedman 1988, in which coercions ~re recursive but carefully constrained along several key par~neters defining possible transitions within a finite-state trtmsition network. mapping of resources into a common central lexicat datu base, rather than being dictionary bound. The view is further expanded in Byrd 1989. Pustejovsky and Boguraev (to appear) argue that a the~ ory of lexlcal semantics making use of a knowledge representation framework offers an expressive vocabulary for the representation of such lexical information. They outline a concrete framework consisting of four levels of lexlcal meaning: (1) Argument Structure; (2) Event Structure; (3) Quails Structure; and (d) Lexical Inheritance Structure. Pustejovsky 1991 provides formal details of the event structure specification for verbs, with a for-real explanation of semantic type coercion. Specification of verb and phrasal aspect matter to NLP systems in several ways. For example, when a stative verb is used in the present tense, it involves only one occasion of the event. In contrust, a non-stative usage involves a frequentative, iterative, or repetitive interpretation. Thus: John knous the answers. (single) John runs. (repetitive) Sue builds houses. (repetitive) It is necessary to understand the interpretation of statlvity for several reasons. In language generation, adverbial adjuncts which have a durational interpretation are, under most circumstances, disallowed: *John knew the answers for three days. John ran for three hours. Sue built houses for three decades. For text analysis, if a verb which is usually stative is used with a non-statlve adverb, such as \"deliberately\", it can be inferred that the event is non-stative, and not the reverse. If the event is non-statics, then it can be inferred that it could be a repetitive or iterative event. This can effect not only the semantic interpretation of the text itself, but also translation and the choice of adverb. 3","3Many of these issues are discussed in the CL Special Issue on Tense and Aspect (June, 1988) in articles by Hinniche, Moens and Steedman, Nakhimovsky, Passoneau, and Webber. For example, Passoneau demonstrates how, with-out an ~ccurate specification of the ~pectual tendencies of the verb coupled with the effect of temporal and aspectual adjuncts, messages, which tend to be in the present tense, ttre not correctly understood nor generated in the PUNDIT system. For instance, \"the pressure is low\" must be interpreted at statlve, whereas \"the pump operates\" must be interpreted as a process. In machine translation, for example, the verb parecerse meaning 'to resemble one another' is even leHs statics in Spanish than in English. Thus, sentence (2) above should be translated into Spanish ACRES DE COLING-92, NAntES, 23-28 AO'dr 1992 1 1 2 8 PRec. OF COLING-92, NANTES. AUG. 23-28, 1992 Aspect is complex. Stativity is not u simple feature such as animate(+/-). To ob ..... this, it suffices to look in any comprehensive grammar, for example, Quirk et al. 1972, in wtfich lexieal verbs are divided into the classes \"dynamic\" and \"stative\", with the caveat that \"it would be more accurate to speak of 'dynamic' and \"stative' uses of verbs\" (p. 94-95). Dowty 1979 observes that the issue of interpretation and aspect involves \" the thorny problems of polysemy and honrophony\"(p. 62). Since some verbs are \"more statlve\" than others, meaning that the most common unmarked use is as a marker of sentential or event stativity, the lexicon must embody this lexieal fact. Our proposal provides the capability in the lexicon of representing that variability, combined with automatic means of inducing variability values."]},{"title":"4 Procedure","paragraphs":["Some standard tests for the stative/nou-statlve distinction are given in Dowty 1979, such as the progressive, imperative, cmnplement of force/persuade, intentionM adverbs, and pseudocleft, as in: 4 Progressive : non-statives * John is kneeing the anuuer. John in running. John in building s house. Complement of force/persuadu: * flail forced John to know the ansner. flail pursuadud Amy to run. John forced Bill to build a house, Adverbs, e-g- deliberately, carufully: * Gull doliburatuly knou the anBeer. Evelyn ran carefully. Sue carefully built a house. Even though tests for stativity involve interactions between semantic and syntactic facets of a sentence, we have chosen three tests for stativlty, the most robust being the tendency for a verb to occur in the progressive. Unlike other tests, the progressive itself is a statement of duration and process. We hypothesized that degree of stativity, i.e. a value for stativity Vo, conld be inferred by determining the ratio of total frequency of occurrence of a verb in a progressive usage, past or present, in the simple present, not the progre,mive, a~ i*t EngllJh. eada d~a .lla se parsee I~s a ¢~ ~dre. For activity verbs, the progressive in EngliJh translates to the progressive in SpalfiJh. 4 Activltes and accompllshmentl are subject to other dimtinguilhing tests which are not the wubject of this paper. over its frequency as a verb in the same corpus: F(Verb(X) whore 0 < V, < 1 A value closer to 0 indicates that a verb prefers stativlty. ]'his basic value can be modified by other tests, such the force/persuade test, and the deliberately/carefully test. We are aware that this is an overMmplificatlon of the property of stativity. Ilowever, our goal is to search for the most robust and pragmatically possible tests to start with. Our technique has given results which concur with our intuitions, although there are limitations discussed below, s In order to do this, we needed u text tagged for part of speech. Otherwise, instances such as \"hearing aid\", '% knowing look\" would be taken as instances of progressive verbs."]},{"title":"5 Results Tagged Ku~era and Francis Data","paragraphs":["The Brown corpus s provided a convenient starting point, since words are tagged for part of speech. ltowever, a closer look at the tag set itself reveals a weakness which could bias our results. The tag VBG is used to tag \"verb, present participle, and gerund.\" Thus, there is no distinction in the label for the different usages of the \"-ing\" form, although some \"-ing\" forms are labelled NN for noun or JJ for adjective. Despite this problem, we chose to use the Brown data, knowing that the numbers aright be distorted. We started with a list of the 100 most frequent words labelled as verbs (i.e. the 100 most frequent verbs, which account for over 90verbs which have been discussed in the literature on stativity (such as \"resemble\", \"matter\", \"intend\"). Figure Three lists some results, ordered by degree of stativity. e-type(try)= Vs(.3326) u-type(work)= V0(.3064) e-typu(nit)= V,(.2929) u-type(run)= V, (.2853) e-typu(play)- Vs(.2552) aPustejovsky, personM communication, hem pointed out some problem cases where the progressive fMsely indicates that root is non-Jtative, such as lie/sit verbs (The book is lying on the shelf, The c~p is sitting on the cownteO, and mental attitude verbs (John il thinking that he should 90 home now, Sdohn is knowing that he should go home note, Marll is suspecting that John will propose tonight. ) Such problemt van be rewolved by fine-tuning testJ. °We thank Slav~ Kate for pointin[ us to this resource. ACTES DE COLING-92, NANTES, 23-28 AOt~V 1992 1 1 2 9 PROC. OF COLING-92, NANTES, AUO. 23-28, 1992 e-type(move)= Vs(.2326) e-type(go)= 11,(.2304) e-type(follow)= V,(.1234) e-type(give)= V,(.0783) e-type(become)= V,(.0718) e-type(hoar)= V,(,0669) e-type(~eel)= V,(.0637) e-type(uppettr)= V,(.0481) e-type(know)= 1/',(.0332) e-type(vent)= V,(.0253) e-type(need)= Vw(.0197) e-type(be)= V,(.0173) e-type(eeem)= V,(.Ol20) Figure Three As can be seen, the ranking roughly reflects intuitions about stativity, so, for example, seem is more stative than hear, which is in turn more st~ tire than run. Parsing with English Slot Grammar The second more refined method utilizes a parser to analyze text, and to record verb usages. For this purpose, we used the English Slot Grammar (Me-Cord 1980, 19901 a broad-coverage parser written in PKOLOG. 7 To obtain counts of verb usages from the representations produced by ESG, we used a tool for querying trees (QT), built by the second author, also in PROLOG. The corpus is the Reader's Digest (RD) corpus, consisting of just over one million words. We took the same llst of the 115 most frequent and most frequently discussed verbs that was used for obtaining values from the Brown corpus. We extracted all sentences under 30 words containing the inflectional variants of these verbs from the RD corpus. We then ran the parser on this sub-corpus, ran QT, and obtained values for the different verb usages. Unlike the Brown data, distinctions are made between the gerundive and participial usages. Figure Four gives results for some verbs, listed in the same order as in Figure Three, with n indicating the number of tokens: e-type(try)= V,(.2167) (n = 286) e-type(york)= V,(.1311) (n ffi 244) e-type(sit)= Vs(.1506) (n = 146) e-type(run)= V,(.1565) (n = 230) e-type(play)= V,(.2315) (n = 95) e-type(move)= V,(.0798) (n = 2131 TAn exception to the quality it imperatives, **here there were some errors in the parsing; they were removed from our cMculationt. e-type(go)= 1I,(.2901) (n = 107t) e-type(foiler)= 1I,(.0375) (n = t33) e-type(give)= V,(.0209) (n = 430) e-type(become)= V,(.0507) (n = 493) e-type(hear)= V,(.OO00) (n = 242) o-type(feel)= V,(.0317) (n = 315) e-type(uppenm)= V,(.0272) (n = 147) e-type(knov)= V,(.OOO0) (n = 630) e-type(want)= V,(.0000) (n = 466) o-type(need) = V,(.O000) (n = 258) e-type(be)= V,(.0124) (n = 12482) e-type(seem)= V,(.0000) (n = 260) Figure Four"]},{"title":"Additional Syntactic Tests","paragraphs":["The progressive test is only one of several tests, and in and of itself is certainly inadequate. Several tests mast be run, and then event values must be computed for each linguistic test. Two parameters are involved: the strength of each test as an indicator of e-type, and the sparsity of data. We have preliminary results on two tutditional tests: the force/persuade test and the deliberately/carefully test. Synonyms and taxonyms were collected for each (ad)verb, data were extracted frmn the corpus and parsed. For example, the following shows how a sentence with \"force\" was analyzed. However, more datais needed, from a larger corpus, for the results to be significant. The same applies for the adverb test. Difficultiue forced him to abandon ... verb(force) inf_ camp_verb (abandon) Figure Five - Verb \"Force\" Results of running and computing the weights of different tests on larger corpora will be reported in future publications."]},{"title":"6 Discussion","paragraphs":["As expected, the results from each corpus differ considerably; we believe this is due primarily to surface tagging vs. full parsing. The results from the second method using ESG do not carry the noise from the ambiguous VBG tag from the Brown corpus. However, there are two important points to be made: (1) One million words is simply not enough. More data need to be (and will be) run to get a more complete and accurate count. These are to be viewed as preliminary data, us~ able but not complete. (2) The value V,(.0000) AcrEs DF.COLING-92, NANTES, 23-28 Aour 1992 l 1 3 0 PREC. OV COL1NG-92, NANTES, AUG. 23-28, 1992 cannot be considered categorical. Verbs are generally adaptable in context, s It is a known fact that value* either for words with low frequencies or words in low frequency constructions must be computed on very large corpora (Liberman 1989.) The current limitations of this approach must be clearly stated. First of all, this method conrates the polysemons usages of certain verbs and, in English, of the verb-particle construction. It could be argued that with enough corpus data, this would become unimportant, but we believe this position not correct. What is required is a fuller analysis of adjuncts in order to know if n verb has been coerced. For example, it could be the case that a verb which is S in the an-marked case (i.e. in a neutral context) tends to appear as a T verb frequently, since that verb might not occur frequently in a null context at all. As another example, consider the case of a typical stative verb \"know\". With the object \"answer\", \"know\" becomes typically inchoative, e.g. \"know the answer by tomorrow\" meaning \"become knowledgeable of the answer\", or it could be used in the transition sense, e.g. \"he will know the answer by tomorrow\" meaning \"he does not know now and will know then.\" Thus, it could be underlying semantic structure, and not surface syntactic behavior, that determines coercion possibilities. 9 In conclusion, The DEGREE APPROACH captures the fact that verbs have degrees of e-type, i.e. that some verbs are more pliable than others. Thus, rather than the non-degree values in Figure One, we argue for entries like: e-eype(reeeablo) = V,(.0740) e-typo(go) = V#(.2304) e-type(seem)= V,(.012O) A corpus-breed method can be used to antomatlcally derive values for e-type, i.e. under n certain cut-off, the verb is stative, but alternbh in context. More importantly, it gives a degree of likelihood that given any context, the verb will be used statively or non-statively. *This is a tact which any semanticist who is trying to argue a firm point can at*el* to. tAho, there appear to be some clashes on the resulting values and intuitions, thus leading to the suggeJtion that either our intuitions are not correct or that the method it unreliable. We have not, in fact, addressed the issue of underlyin~ semantic representation (e.g. in terms of prim. itivea) in this paper. It has been suggested that syntactic tests [or aspect might be flawed, and that the only way to distinguish aspectual classes it via the semantic consequences ot a restive vs. non0tative proposition. If correct, the approach of extracting values based on syntactic tests will fail by definition, regardless of whether the value, are assigned manually or automatically."]},{"title":"7 References","paragraphs":["1. Byrd, Roy. 1989. \"Discovering Relationships unsung Word Sense*\","]},{"title":"Dictionaries in the Electronic Age: Proceedings of the Fifth Annual Con-Jerenec o] the University of Waterloo Centre ]or the New Oxford English Dictionary","paragraphs":["2. Comrie, Bernard 1976."]},{"title":"Aspect.","paragraphs":["Cambridge University Press: Cambridge, English. 3. Dowry, David. 1979."]},{"title":"Word Meaning and Mon. *ague Grammar.","paragraphs":["Dordrecht: tlolland. 4. Francis, W. Nelson and Henry Ku6era. 1982."]},{"title":"Frequency Analysis of Enlglish Usage: Lexicon and Grammar.","paragraphs":["tlonghton Mifflin: Boston. 5. Klavaas, Judith L. (1988) \"Building a Cornputs*loaM Lexicon using Machine Readable Dictionaries\","]},{"title":"Proceedings of the Third International Congress of the European Association for Lexicography.","paragraphs":["Budapest, Hungary. 6. Lakoff, George. 1965. \"On the Nature of Syntactic Irregularity\", PhD Dissertation, Departmeat of Linguistics. Indiana University: Bloomingtoa, Indiana. 7. Liberman, Mark. 1989. \"How Many Words Do People Know?\" Invited Talk delivered at the 27th Annus.l Meeting of the Association for Compata~ *tonal Linguistics. Vancouver, B.C., Canada. 8. McCord, M. C. 1980. \"Slot Grammars\""]},{"title":"Computational Linguistlcs,","paragraphs":["Vol 6:31-43. 9. MeCord, M. C. 1990. \"SLOT GRAMMAR: A System for Simpler Construction of Practical Natural Language Grammar*,\" in R. Sender (Ed.),"]},{"title":"International Symposium on Natural Language and Logic,","paragraphs":["Lecture Notes in Computer Science, Springer Verlag. 10. Moensp Marc and Marc Steedman. 1988 \"Temporal Ontology and Temporal Reference\""]},{"title":"Computational Linguistics.","paragraphs":["Vol. 14:2:15-28. 11. Pustejovsky, James. 1991. \"The Syntax of Event Structure\""]},{"title":"Cognition","paragraphs":["Vol. 41:103:47-82. 12. Pustejovsky, James and Bran Bognrnev. to appear. \"Lexical Knowledge l~.epreaentation and Natural Language Processing\""]},{"title":"IBM Journal of Research and Development.","paragraphs":["13. Quirk, Randolph, Sidney Greenbaum,"]},{"title":"Geof-","paragraphs":["frey Leech, Jan Svartvik. 1972."]},{"title":"A Comprehensive Grammar of the English Language,","paragraphs":["Longman: London. 14. Teany, Carol Lee. 1987. \"Grnmmatlcalizing Aspect and Affectedness\", PhD Dissertation, De~ par*men* of Linguistics. M.I.T., Cambridge: Massachusetts. 15. Vendler, Zeno. 1967."]},{"title":"Linguistics iu Philoso. phy,","paragraphs":["Coruell University Press: Ithaca, New York. ACTES DE COLING-92, NAgrES, 23-28 ho~rr 1992 1 1 3 1 PROC. oF COLING.92, NANTES. AUG. 23-28, 1992"]}]}