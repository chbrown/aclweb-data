{"sections":[{"title":"A Similarity-Driven Transfer System Hideo W~t~n~})c","paragraphs":["IBM Research~ Tokyo"]},{"title":"Research","paragraphs":["Laboratory","5-19 Sitnbancbo, Chiyoda-ku, Tokyo 102 Japan e-math watanabe@trl.vnet.ibm.cmn"]},{"title":"Abstract","paragraphs":["The transfer phase in machine translation (MT) systems has been considered to be more complicated titan analysis and generation~ since it is inherently a conglomeration of individual lexical rules. Currently some attempts are being made to use case-based reasoning in machine translation, that is, to make decisions on the basis of translation examples at appropriate pohtts in MT. This paper proposes a new type of transfer system, called a"]},{"title":"Similarity-driven Trans-","paragraphs":["fer'"]},{"title":"System (SimTi'ao),","paragraphs":["for use in such case-based MT"]},{"title":"(CBMT). 1 Introduction","paragraphs":["The transfer process in macbine translatiou systems is, in general, more complicated than the processes of analysis and generatimt. One reasmt for this is that it relies heavily on human heuristic knowledge or the linguistic intuition of the rule writers. Unfortunately, linguistic intuition tends to be unable to control the process properly for a wide variety of inputs, because of the huge amount of data and the huge number of situations that need to be considered. However, rule writers must rely on their linguistic intuition to some extent, because there is no linguistic theory on lexieal transfer [7]. Another reason [81113 ] is that tile transfer task is inherently a conglomeration of individual lexical rules. Therefore, the transfer process can be said to fall into a class of problem that cannot easily be controlled by the linguistic intuition of rule writers. In accordance with these observations, various attempts have been made to overcome the problems of transfer; they include knowledge-based MT [12], bilingual signs [13], and Tags for MT[1]. One such approacb is case-based or example-based MT [4] [9] [10] [11]. The essential idea behind all case-based MT (CBMT) methods is that tile system chooses the case (or example) most similar to tile given input from the case base, and applies the knowledge attached to the chosen case to the input. 1 Supposing that there is a corpus of parsed translation examples in which corresponding parts are linked to each other~ we can regard those parsed transla-1 This approach can be regarded as an application of case-baaed tea.sorting [3] to ntttural language translation. tion examples as translation rules. A promising ~rpproach is therefore to make a transfi~r process that (1) chooses a set of translation examples, each source part of which is similar to a part of the input~ attd all source parts of which overlap the whole input~ and (2) constructs an output by combining the target parts of those translation examples chosen. However, this does ]tot mean that existing transfer knowledge should be abandoned. Rather, such transfer knowledge should be used ms a fail-safe mechanism if there are no appropriate examples. In the"]},{"title":"similarity-dr~iven t,unsfer system (Simlmn)","paragraphs":["we have developed, both translation examples and existing transfer knowledge are treated uniformly as trauslation pattern% and are called translation rules. In Figure 1, for example, (a) is tile parsed dependency structure of an inpnt Japanese sentence, \"kare ga kusuri wo numu.\" Suppose that (b) is selected as the most similar translation rule for the part \"kare ga ... nomu\" frmn the translation rule-base, and that (c) is selected as the most similar translation rule for the part \"kusuri wo nomu~\" even though there are several translation candidates for the Japanese verb \"nomu.\" This figure illustrates what we would like to do; that is, to construct (d), the translated structure by combining the target structures of the selected translation rules. To develop this kind of system, we must consider the following issues: (a) a metric for similarity, (b) a mecbanism for combining target parts of rules, and (c) correspondence between the source part anti the target part of a rule. To handle the last two issues, I developed a model called"]},{"title":"Rules Combination Transfer (RUT)","paragraphs":["[14]."]},{"title":"SimTran","paragraphs":["is RCT coupled with a similarity calculation method. In tbis paper, I will introduce RCT and the similarity calculation method used in"]},{"title":"SimTran.","paragraphs":["The next section defines the data structure for graphs, aud the format of a translation rule. Section 3 presents a method for calculating the similarity between an input and the source part of a translation rule. Section 4 describes the flow of the transfer process in RCT. Section 5 gives examples of translation using"]},{"title":"SimTran,","paragraphs":["and Section 6 discusses related work. Some concluding remarks bring the paper to an end. AcrEs DE COLING-92, NAN2T~, 23-28 AOI~T 1992 7 7 0 PROC. OF COLING-92, NANTES, AUG. 23-2fl, 1992 .....-\"...... .... ........ .. l:igure 1: Sample Japanestv4o.English tr~u,s[ation"]},{"title":"2 Translation Rules","paragraphs":["A basic type ,ff gra.ph used in this paper is a labeled directed graph, or art Ida. 2 At, ldg G consists of a set of nodes N, and a set of arcs A. Further, each node and art: has a label, ht particular, node labels are unique. Each node consists tff features, each of which is a pair of a feature name attd a feature v~lue. If an ldg lta.~ only one root node, then it is called ~n rldg, and if an Ida has no cyclic pr~th, then it is called an idag. s Therefore~ an ridag denotes an Ida that h~-s only one root node and no cyclic path. A translation rnle 4 r consists of the folk,wing three corrtpo,leots: r = (G,,,,M,G~) where Gm is a matching gr~rph, G~ is a construction graph, e.nd M is a set of mappings between Gm and A matching graph G',,, and a construction graph G~ must be at lea.st an rldag. 5 Further, nodes in (~,, must be labeled uniqnely; that is, each node in G,,, mnst hz~ve only one unique label, and the l~bel of the node n~ in G~ is determined to be the label of the","~The term qabeled' means that nodes and arcs are labeled, and the term ~directed' means that each arc has a direction. Further, an Ida in this paper refers to a connected graph unless otherwise specified. ZThe term dag is often used in the NLP world, and usually denotes a rooted connected labeled (as functional) directed graph. But in this paper, dag denotes a direct,:d acycllc graph that may have multiple toots, is not necessarily a connected graph, and does not necessarily itave labels. 4In this paper, the term rule does not mean a procedure, but rather a pattern of translation knowledge. bSudl graphs are sufficient to express almost MI lingu~atlc strsct ures. Figure 2: Samph. rule for translation between Japanese ~tnd English node nm in G,. such that n:. = M(nm). Mat)ping between (:.,~ and G~ designates tile cor-. respondences be,wee. ,,[}des in G,. and (;.. l'})r instance, in Figure 2, tim Japanese word \"nagai\" (\"tong\") should c.rrespond to both of the English words \"have\" and"]},{"title":"~[(lll~111 bl!cal,se","paragraphs":["if am),her word g.ow~rn.~ the word \"nagai\" then its English ,re,rela-tion should be connected to the word \"h~Lve.\" On the other hand, if the Japanese word \"to,elan\" (\"very\") modifies \"nagai\" then its English translation \"very\" should be connected to \"long.\" This shows tllat fi)r node in ~ source languag% two kinds of connection point, for translations of both governing structures attd governed structures of the node, are needed in its translated structure. This implies that there shouht be two kinds of correspondence between G',, and (7~, namely, (I) a mapping from a G,, node n,, to a G~ node nc that is to be a node connected to translations ACq'ES DE COLING-92, NANqT!S, 23-28 AOUq\" 1992 7 7 1 PP.OC. OF COLING-92, NAtWrES, AUG. 23-28, 1992 of structures governing nm, and (2) a mapping from n,, to a G~ node n'~ that is to be a node connected to translations of structures governed by n,~. We call the former an upward mapping and the latter a downward mapping, and denote these twn kinds of mapping as follows: where M T is upward mapping, and M ~ is downward mapping. Not all kinds of mapping should be permitted as M [ and M 1. A translation rule r=( Gm,M,Gc ) must satisfy the following conditions: (1)M T and M I are both injections, (2) there are no two distinct nodes x aml y in G.~ such that M(x)=M(y), e and (3) M l(root(G,,,)) .... t(a~). Condition (1) ensures that there is only one c()nnection point in G~ for each translation of gow~rn ing structures and governed structures, coudition (2) ensures that the label of a G'~ node is determined uniquely, and condition (3) ensures that the result of this transfer model becomes a rooted graph (see [15] for details). A rule sat.isying these conditions is said to be sound."]},{"title":"3 Similarity Calculation","paragraphs":["This section desribes how a similarity is calcuhm~d."]},{"title":"3.1 Graph Distance","paragraphs":["The shnilarity between a Gm and an input graph Gi,, is defined as the inverse of the graph distance 7 between thenL First, the simple graph distance D; between Gi,, and G~ is given ;ks follows:"]},{"title":"D',(G~, a..) = o=(n~., R.,)","paragraphs":["+ E,,, min(D'a(VS(Ri ..... ),GS(t~,, .... ))) where R/, and /~ are roots of Gi~ and Gm, respectlvely~ D,, is a node distance, a= is an arc in G,n such that its source node is R.m, and GS(n~ a) denotes a subgraph that is related to an arc a from n. Briefly, a simple distance is the sum of the node distance between two roots and the sum of the minimal simple distances between Gin subgraphs and Gm subgraphs that, far each arc a outgoing from the GmmOt node, are related to the all arcs a from the root nodes. ~This means that either M ~(x) or M l(x) is equal to either M T(Y) or M .~(y) rDistltnces defined in this section are not actual distances in the mathematical sense. However, the larger Gm is, the larger this simple distance becomes. Therefore~ when normalized by the number of nodes in G,,,, the graph distance Dg is given as follows:","D;(Gin,G,,,) Dg(Gin, am) -- N","where N is the number of nodes in G~."]},{"title":"3.2 Node Distance","paragraphs":["When considering the distance between two words (nodes), we usually think of their semantic distance in a semantic hierarchy. In general, no matter what semantic hierarchy we use, it is inevitable that there will be some sort of distortion. Further, ,as stated be> fi)re, a node consists of several features and may not have a lexica[ form that is a pointer to a semantic hierarchy. Therefore, a promising approach to calculating distances between nodes is to use both a semantic hierarchy and syntactic features~ that is, to use syntactic features to correct the distortion contained in the semantic hierarchy to some extent. The node distance between a Gin node n i and a G,,, node nm is detined ms follows:","Dn (hi, nm ) D/+ D, * 6, N S"]},{"title":"+a.","paragraphs":["where DI is a feature node distance, D, is a semantic no(h.\" distance, N I is the number of features in nm for DI, and 6, is the weight of a semantic distance. The semantic distance D, between a Gi,~ word wi,~ and a G,, word wm is given by the following equation. In SimTran, Bunrul Goi Hyou [5] code (or bghcode s) is used for calculating the smnantlc distance between Japanese words. Do(wln, wm) = 0 Win ~ Wm 0.5 wiT~ or wm is unknown 1 win and w,,, are unknown I~°h(~')-@h(~')l+~ otherwise","bghmax-F~","where bgh(w) is the fraction part of the bghcode of","w, bghmax is the mammal difference between two","bghcode fraction parts, and 6b is a penalty incurred","if two words are not identlcM. The feature distance l)f between a Gi~ node hi,, and a Gm nmle nm is given ms follows:"]},{"title":"D:(n~ ........ ) = E:~., d:(n.,, f)","paragraphs":["df(nin, fn : fv) =","1 fi~(fnin : fvi,,) whose fni,~ = fn, and","fv is consistent with fVln","0 otherwise s A bgheode is a fraction of number. Its integer part roughly","corresponds to a syntactic c~tegory, and therefore, only its frac-","tion part is used. ACRES DE COLING-92, NANTES, 23-28 AOm\" 1992 7 7 2 PROC. OF COLING-92, NANTES, AUG. 23-28, 1992"]},{"title":".//\"","paragraphs":["Each matching pivot in ~t simibtr i-cover rule set must have M I or M 1, to ensure that tim"]},{"title":"Gcs","paragraphs":["of the i cover rllle set pr(lduce a t:ounected graph a~s a result. If there atre rules in the given i-cover rule set that do not s~ttlsfy this condition, they are renloved from the set of ruh, camlidates~ and the cover search method is executed until an i cover rule set th~.t satisfies this conditinn is found. Such as, i-cover rule set is called a proper rule set. Next, for each projection nf the given i-cover, we nmst make ;t copy of its origin rule~ m\" rule instance, be> C;-LUSe one ride IEay make lllort • thgn oue project(tin un (~in ' Figure 3: An isomorphic cover In the ~bove equatiolb tile consistency checking de pends on a feature."]},{"title":"4 Rules Combination Transl~r","paragraphs":["In this section, I present tile tlow of the transduction process by using RCT formalism."]},{"title":"4.1 Rule Selection","paragraphs":["A transfer process rnust first find a set of rules whose Gins' matching parts (called projections) totally overlap all input structure, and which is the most similar to the intmt. We call a uuimi of projections a cover, and a cower identical to the input an isomorphic cover (or i-cover). In or(her words, wha'~ we want here is the i-cover th;~t is the most similar to the input. Further, if a G., make ~L llrojection"]},{"title":"pj on a Gi~,","paragraphs":["then tile G,a is called the origin graph of the"]},{"title":"pj.","paragraphs":["A pivot is a node of (;~,~ that has more than one origin graph, attd a matching pivot is the origin node of a pivot. For instance, in Figure 3~ A and D are pivots. There may be some methods for tinding such an i-cover rule set. One method is to pick up a rule whose projection does not have any arc ow~rlapped by cover by other selected rules until there ~tre no uncovered arc% if it is desirable that a rule set should }lave few overlaps as possible. We h;tve Klso developed auotlmr method using dynamic programmiug: which can choose the most similar rule set from cttndidate rule sets. Briefly, it stores the most similar rule set for each combination of arcs of each node from Ice.yes up to the root~ and the most similar rule set stored in the root node is tile one for the input structure (see [6] for details),"]},{"title":"4.2 Prc-Lexicalization","paragraphs":["It may It~qqlen that ~ lexit:al-hIrm of a 6'~ in the given rub! iust~tnce is lint ~t [uuldldat~! translation word of its correspoudiltg word in the input, because a lexica] form in a. l,~tci,iug node it, its G,. is not necessarily the same as the input word. hl this (:~e, such a node is lexlcMized by c~L.dida.te tr~tnslation words."]},{"title":"4.3 Node Labeling","paragraphs":["The label of a (d,,, node becomes tit(.\" I~bel of its mateillng nude in (;~,,. Since"]},{"title":"(;i,,","paragraphs":["nodes are labeled uniquely, (¢,..odes are idso I~}mled uniquely. On the uther h;md, the label of a (7,: nude n~ becomes the tttbel of a (,',,, node (n,,~) such that ~'z~ = M T(nm) or '['here nlay 1 h(lWeVl~r I be twn nodes ill"]},{"title":"(Jc","paragraphs":["ill ;¢ rule inst~ulce that are mapped by ;t node in (;,~ with M ] ~.nd M ~, respectiwdy. In the succeeding process, (1~ nodes with the same bLbel are merged into one node in order to gener~.te an mltpul structure, lu this phase, tim transferred hdmls of these two nodes shoulcl be dif ferent~ becnuse the two (lodes should not be merged f.r this rule. We must therefore relabel G~nodes of rule it|stances as follows: G~ Node Relabeling: for any label l i,, G~, if l is distrilmted t[) twt) distinct uoch!s of (;~ by troth M [ and M ~ fronl a node (,f (;,,,, then a I~bel l iu a G~ tulde, which is mallped only by M ], or is mapped by both M [ ~tnd M .{ ~tnd has no descendants, is Cil[tUg{!d to I ' I"]},{"title":"4.4 Gluing Unificatior~","paragraphs":["is ~t well-known c(unput~tiuual tool for c(mm.cting gra.phs, and is widely used in natural language l)rocessing. Usually, unitlcation uses two func-AcrEs DE COLING-92. NANTES. 23-28 Ao~'rr 1992 7 7 3 P~oc. oF COLING-92. NANTI~S. AUG. 23-28. 1992"]},{"title":"y (a) ( x ( (b) (e) Gluing of (a) and (b)","paragraphs":["Figure 4: Example of gluing lionel rldags as data and unifies them front the root node down to the leaves. In RCT, however, we want to merge those nodes of two graphs that have the same labels, even if their root nodes are different and they are not functiona L as shown in Figure 4. Unifi: cation, however, cannot proceed in this manner, because it unifies two nodes that occupy the same p+ sition, and always starts from the root node. For instance, in Figure 4, even if unification starts from node B then it fails, since it tries to unify node D of (a) and node C of (b) for arc y. In Graph Grammars, this method of connecting two graphs is called gluing [2]. The ghfing used in Graph Grammars is not concerned with the content of a node, so it must be extended in order to check the consistency among the nodes to be glued. in SiraTi'an, if two features conflict then the feature whose rule is more simi[ar to the input is taken. Briefly, gluing is performed as followsg: ICivst, nodes with the same label are me~yed if they are consistent. If arty nodes fail to be merged , then the ghdn 9 also fails. If all the me~ges succeed, all ares are reatlached to the original nodes, which may or may not be me~yed. As a result, some ares with the same labels and attached to the same nodes may be me~ed, if they are consistent. A glued graph is not nece~arily a cmmeeted, rooted, or acyclic graph, but we usually need a connected rldag iu natural language processing. Several constralnts satisfying such requirements are described in previous papers [14][15]. After the G~s have been labeled and relabeled, the target structure is built by gluing the G~s. ODetMls of tire algorithm are given iu previous papers [141115]."]},{"title":"4.5 Post-Lexicalization","paragraphs":["The constructed target structure is still bnperfect; there might be a G~ node thai. has no lexical-form, because there are some rules made froul transfer knowledge that have no lexlcal-forms. Therefore, as in the pre-lexicalizatiou phase, non-lexical G: nodes are lex: icalized."]},{"title":"5 Examples","paragraphs":["This sectimt gives examples of translation by SimTcan. Figure 5 shows how the Japanese sentmme \"Kauojo no me ga totemo kireina no wo sitteiru\" is translated blto the English sentence \"(1) know that she has very beautiful eyes.\" In this figure, (a) is an input sentence structure, (b),(c), and (d) are rules (precisely, rule instances), and (e) is the output structure produced. In these rules, a mapping line not marked M ~ and M ~ has both M ~ and M ~. Dotted lines designate matching or gluing correspondences between rule nodes and input or output nodes, respectively. I:'urther, numbers prefixed by '*' denote node labels. In this example, we assume type hierarchies in which, for instance, 'yougen(predicate)' is a super-category of 'keiynu(axlj)', and \"kaut6o(she)\" is an instance of :hnmau'. Note that the node labels of both \"have\" in rule instance (c) and lower 'pred' in rule instance (b) are changed from that of the corresponding Japanese word \"kirei(beautiful)\" by the G¢ node relabeling procedure. Another example is shown in Figure 6, which shows how the Japanese sentence \"US ga ... wo fusegu tame ni buhit/ul kanzei wo kakeru\" is translated into the English sentence \"US imposes tax on parts in order to blockade .... \" In this example, (a) is an input structure, (b), (c) and (d) are matched rules, and (e) is the output structure produced. The Japanese verb \"kakeru\" has several trauslation candidates as sociated with different governing words, as shown in the following +~able: Similarity dapaues+Eng/ish","5.988 (meishi) ni zeikiu wo kakeru","impose tax on (noun)","3,077 (meishi) wo salban ni kakeru","take (noun) to court","2.717 (meishi) wo mado ni kakeru","hang (noun) in window","2.545 (meishi) wo sutoobu ui kakeru","put (noun) on stove haukati ui kousui wo kakeru","2.040 spray perfume on handkerchief This table lists the top live similar rules for the part \"buhin ni kanzei wo kakeru\" of the input. As shown ACTI~ DE COLING-92. NANTES, 23-28 AOt~q\" 1992 7 7 4 PROC. OF COLING-92, NANTES, AUG. 23-28, 1992"]},{"title":"., £+..--- --.. \"r'+","paragraphs":["*3 lit \"LI' hive ~'"]},{"title":"~I !-\\o, ,,T\",. ,~/<.~ ...... >~.---7'-~xt ..~£.i Z-~ \"~',,. ,--L-/')-% -\" ~.+-,~L<, I \\,t.--? tz-'.9\" t_7.9 \",'U ,,I \"i~:...>. ~\" ,~r ~ t'3..-,7_L.,. ........... ~: ........... +_\"~ \"~I.~ \\ \"~I I \"*~ i\" ..........","paragraphs":["('~"]},{"title":"~....:.,..~-r~, fSb,7. .......","paragraphs":["Figure 5: Exami~le 1 of translation by SimTi'~n",",.-\"[\" \"2 ~.z ~_d'2 \" .... ///\" [ (b) ~',,.\\."]},{"title":"\",..,. I,} \"/\" \" '2 / '5 \", 'l \\ \"6","paragraphs":["t ! t+ 4 _MI ~ \" -\" *3 / t '4 [ / '3 / ~ 4 mort 'x ', ..~\" / ~..\" : / : '~'e '.. >~ .. \" F ' / \",/-\" .. .. ........ .-.\"~ ! i / ' ,/\" \",....-.:<i ................ \"., /"]},{"title":"/ i i \\--~\" .,. ....... :::~':(L~ f~ /","paragraphs":["\" / / \"\" /\" 'x\" , B';'~\") ~ pr }pr,~l ,! \" i '{l(,,t,~L..j .............."]},{"title":"/..d.,F..~,","paragraphs":["i \", .5\" \" '~ ,' (d) (c) Figure 6: Example 2 of transl;~tiou by Sim!l'~n A~l.:s BE COLING-92, Nnlqi~;~;, 23-28 Ôt~T 1992 7 7 5 PROC. OF COLING-92, NANTES, AUG, 23-28, 1992 in this table, rule (c) is the most similar one. Note that this similarity calculation was done for all rules, including non-lexical translation rules. There were no appropriate example rules for the part \"US ga kakeru,\" and a non-lexical rule (b) was timrefore selected. Further, note that the lexical forms in *3 nodes of (c) and (el are different, and that *4 node of (el has no lexical form other than a preposition, whereas \"4 node of (el has a lexical form. The for-met was obtained by pre-lexicalization, and the latter by post-lexicaiizatiml."]},{"title":"6 Related Work","paragraphs":["Although there were several early experimental projects on CBMT [4][9][11], MWF-H [10] is the first working prototype of a case-based transfer systern~ and demonstrates the promise of the CBMT alrproadL It uses Japanese-to-English translation exanlples as translation rules: chooses the source trees of examples that are most similar to the iuput tree from the root node down to the leaves, and assembles those target trees to produce an output tree, With respect to the transducing mechanism, MBT-II is a tree-to-tree transducer adopting one--to-one correspondeuce. MT by LTAGs [1], although it is not an attempt of CI3MT, proposed a similar mechanism to RCT described in this paper. It uses paired derivation trees of English and French as translation rules. An input sentence is parsed by the source grammar, and at the same time, its output tree is generated by derivation pairs of trees used in the parsing. As a trausdueer~ this mechanism is also a tree-to-tree transducer adopting one-to-one correspondence. In contrast, the RCT employed in SimTran is a rldag-to-rldag transducer adopting upward and downward correspondences. These extended correspondences are desirable for expressing the structural discrepancies that often occur in translation. Moreover, this transducing model is a parallel production system [2] that Call produce an output structure in one execu-tion of gluing if all the G~s required to produce an output are supplied,"]},{"title":"7 Conclusion","paragraphs":["In this paper: 1 described a cas~based transfer system, SimTran, which combines I~CT with a similarity calculation method. RCT has powerful correspondences between the source structure and the target structure of a translation rule, which can express most structural discrepancies between two languages. As a transducing mechanism, RCT is a parallel nondestructive rldag-to-rklag transducing system. I also propose a similarity calculation method for graphs whose nodes consist of syntactic and semantic features, and show that a translation rule th~tt has no [exical forms can he used ms a default rule, that is, that such rules can provide a fail-sMe mechanism if there are no appropriate translation examples."]},{"title":"References","paragraphs":["[1] Aheilld, A., Schabes, Y., and Joshi, A. K., \"Using l,exiealized Tags f,~r Machine qYanslation,\" Prec. of Coling 90, 1990.","[2] Ehrig, 11., \"Introduction to the Algebraic Theory of Graph Grammars,\" Prec. of Inle,'national Workshop on Graph Grammars, LNCS 73, 1-69, 1979.","[3] l(olodner, J. and ILiesbeck, C., \"Cmse-Bmscd Reasonings\" tutorial textbook of llth IJCAI, 1989.","[41 Nagao, M., \"A Framework of a MechanicM Translation between Japanese and English by Analogy Principle,\" Elittmrn, A. and Banerji, R. (eds.) : Arlificisl and Human lntelhgence, NATO 1984.","[5] National Language ltesoarch Institute: Bunrui Got Hyou (in Japanese), Syuuei Syuppan, 1964.","[6] Marnyama, ft. and Watanabe, l-l., \"Tree Cover Search Algorithm for Example-Based Translation,\" Prec. of 4th 1st. Conf. on Theoretical and Melhodological 1ssues in Machine Translation, 1992.","[7] Melhy, A. K., \"l,exical Transfer: A Missing Element in Linguistic Theories,\" Prec. of Coting 86, pp. 104 - 106, 1986.","[8] Nitro, Y., \"Idiosyncratic Gap: A Tough Problem to Structure-hound Machine q~'anslation,\" Prec. of Col-in~ 86, pp. 107--111, 1986.","[9] Sadler, V., \"Working with Analogical Semantics,\" Forts Publications, 1989.","[10] Sate, S. and Nagao, M., \"Toward Memory-based Translations\" Cohn9 90, 1990.","[11] Sumita, E., lida, 11., attd Kohyama, 11., \"Translating with Examples: A New Approach to Machine 'l~'anslotion,\" l'roc, of lnfo Japan 90, 1990.","[12] Tomita, M. and Carbonell, J.G., \"Another Stride Towards Knowledge-Ba~qed Machine Translation,\" Prec. of Coling 86, 1986","[13] Tsujii, J. and Fujita, K., \"bexical ~lYansfer bmsed on bilingual signs: Towards interaction during transfer,\" Prec. of Seoul Int Conf. on NLP, 1990.","[14] Watanabe~ ll., \"A Model of a Transfer t'roccss Using Combinations of Translation Rules,\" Proc. of Pacific Rim of Int. Conf. on AI '90, 1990.","[15] Watanabe, tt., \"A Formal Model of Transfer Using Rules Combination,\" submitted to Machine Translation, 1991. AcrEs DE COLlNG-92, NANTEs, 23-28 AOt'Zr 1992 7 7 6 PROC. OF COLlNG-92, NANTES, AUG. 23-28, 1992"]}]}