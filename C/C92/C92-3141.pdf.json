{"sections":[{"title":"HIGH-PROBABILITY SYNTACTIC LINKS Leonid Mitjushin Institute for Problems of Information Transmission Russian Academy of Sciences 19 Ermolovoy Street, 101447 GSP-4, Moscow, Russia 1 Introduction","paragraphs":["In this paper we consider syntactic relations between words of a sentence that can be strongly predicted by local mechanisms. For instance, if a sentence contains a pair of words ... red block .... then the reader immediately makes a conjecture that red is an adjective modifier for the noun block. The same is true for semantically abnormal pairs such as ... green ideas ....","Other examples of strong prediction are provided by pairs ... authors describe .... ... problem is..., for which a \"subject - verb\" relation takes place with high probability.","In most cases, such simple hypotheses prove to be correct. However, sometimes they lead to errors, as for the pair problem is in the sentence (I) The solution of this problem is very simple. In this example, however, by the moment the word is has been read, the word problem is already engaged in other strongly predicted constructions, namely the prepositional phrase of\" this problem and even the whole noun phrase the solution of this problem. A conflict arises, and plausibility of the new hypothesis becomes much lower.","Such syntactic relations may concern not only adjacent words. For instance, in (1) it is for the pair solution ... is that the \"subject - verb\" relation will be conjectured.","In this paper, slrong prediction of syntactic relations is modeled within the framework of dependency syntax (see Mel'~uk 1974, 1988). According to this theory, (surface) syntactic structure of a sentence is an oriented tree whose nodes are the words of the sentence (more precisely, their lexico-morphological interpretations). The arcs of the tree represent syntactic links between words and are labeled by names of syntactic relations. The result of strong prediction is a partial parse of the sentence, in which high-probability syntactic links are established.","In our opinion, dependency structures are better adapted to partial parsing than constituent structures. The reason is that the dependency structure of a segment is the same both when the segment is considered as isolated and when it is considered as a part of some sentence (by \"segment\" we understand any sequence of words). Generally, this is not true for constituent structures. For instance, the segment l saw a man has the dependency structure * (2) l-compl pred [ det 1 I ~ SOW O ~ man both as a complete sentence and as a part of the sentence I saw a man with a telescope. The fact that the latter sentence is ambiguous does not hamper anything, as both its structures contain subtree (2) (and differ only in arcs that go into the word with): (3) l-comp[ prep pred [ del] attr l, det l I ~ saw a ~man ~wi~n a ~ telescope. (4) nov pred I ~saw l-compl [~_ prep d¢t ] dnt"]},{"title":"[","paragraphs":["a ~man with a ~ telescope. On the other hand, the constituent structure of the segment I saw a man is not fully inherited in the constituent structures of the longer sentence. In our opinion, this comparison demonstrates that, in a certain sense, dependency structures reflect the in-cremental nature of sentence comprehension from left to right better than constituent structures do.","In this paper we describe a bottom-up, left-to-right algorithm of partial parsing that establishes high-probability syntactic links. It is implemented on a VAX 11/750 computer as a subsystem of a multipurpose linguistic processor developed in the Laboratory of Computational Linguistics of the Institute for Problems of Information Transmission, the Russian Academy of Sciences (Apresjan et al. 1992). The partial parser is employed as a preprocessing unit before the operation of the main filter-type parser. It can also be used for automatic indexing and lemmatization. The algorithm is language-independent: all language-specific information is recorded in the dictionaries and the rules that establish links. * Full names of English syntactic relationS that appear in example= are: predicative, determinative, lsl completive, prepositional, at-tributive, adverbial. The number of relations used In complete models of English and Ru~tan syntax varies from 40 to 55 (Mel'~uk 1974; Mel'~.uk and Pertsov 1987; Apresjan et al. 1989, 1992). AcrEs DE COLING-92, NANT~, 23-28 AOtJT 1992 9 3 0 PROC. OF COLING-92. NANTES, AUG. 23-28. 1992 Experiments with Russian sentences have given promising results: on average, the algorithm establishes 70 - 80 ~o of syntactic links of a sentence; processing speed (exclusive of morphological analysis) is about 10 words per CPU second. The error rate is less than 1% (stable estimates have not been obtained yet). 2 Bottom-up Parsing The processing of a sentence begins with morphological analysis. As a result, each word is given a set of its possible lexico-morphological interpretations, henceforth called \"homonyms\". A homonym is a list that includes a lexeme identifier, a part-of-speech marker, and morphological features of the wordform. For instance, the morphological module of the ETAP-2 system (Apresjan et al. 1989) will give for the word sawtbe following three homonyms: SEE, V, pt (-past tense); SAWl, V, mf (-main form); SAW2, N, sg.","All morphological data are concentrated in a special morphological dictionary. The key role in parsing proper is played by a combinatorial (syntactic) dictionary that contains versatile information on syntactic properties of lexemcs, i.e. on their ability to participate in various syntactic constructions (for details see Mel'~uk 19\"/4, 1988; Apresjan et al. 1989, 1992).","The general scheme of parsing is as follows. After the morphological analysis, for each word there appears one or more homonyms. By \"fragment\" we shall understand a set of homonyms occupying one or more successive positions in the sentence (one homonym in each position) plus a tree of syntactic links defined on these homonyms as nodes. For instance, an isolated homonym is a trivial fragment; the whole dependency tree of a sentence is also a fragment. It should be noted that in trees (2) - (4) each word is represented by a certain homonym (for example, saw is represented by SEE, V, pt).","Lejkina and Tsejtin (1975) described a bottom-up process for constructing dependency trees. It is based on the operation of adjunction. This operation is applied to two adjacent fragments and consists in establishing a link, marked by a certain syntactic relation, from a certain node of one fragment to the root of the other. The result of adjunction is a new fragment on the union of segments occupied by the initial fragments. This action is similar to generation of a new constituent from two adjacent constituents. However, unlike constituents, fragments at the moment of adjunction may be \"incomplete\", i.e. they need not contain all the nodes that will be direct or indirect dependents of their roots in the structure of the sentence. These nodes may be added to them later (also by the operation of adjunction). Mitjushin (1985) described the class of trees that can be constructed from isolated homonyms by repeated adjunction, i.e. that can be built by the bottom-up process. Consider a tree with an ordered set of nodes. Let a \"tangle\" be a quadruple of nodes (a, b, c, d) with the following properties: 1) a<b<c<d; 2) a and c are linked by an arc (in any direction); 3) b and d are linked by an arc (in any direction); 4) the path between a and d contains neither b nor","c (here, orientation of arcs is ignored, so the","path always exists). The following criterion is true: a tree can be con-","structed from its nodes by repeated adjunction if and","only if it contains no tangles. The simplest tangle looks as follows:","a b c d (direction of the arcs does not matter; there can be other nodes between a, b, c, and d). According to the criterion, a tree that contains such a subtree cannot be built by the bottom-up process.","The class of trees obtainable by adjunction is much wider than the class of so-called projective trees (on projectivity see, for example, Gladkij 1985; Mel't~uk 1988). For the model of Russian syntax presented by Mel'~uk (1974) and Apresjan et al. (1992), this class includes all syntactic structures permissible in scientific, technical, and business texts (however, it is not so for spoken language and poetry). We suppose all the structures considered below to belong to this class. 3 Rules In our system, in contrast to those based on forulal grammars, the rules are not a tool for the exhaustive description of the set of correct syntactic structures. We suppose that the correspondence between sentences and their syntactic structures is defined by some other means. The task of the parsing algorithm and the rules it employs is to build, for a given sentence, some set of its syntactic structures or their fragments, without losing the semantically correct ones.","The concrete function of the rules is to check whether the given case of adjunction is feasible and, if so, to perform the operation of adjunctioa. Some additional operations can also be performed. The rules have access to any information about the structure of fragments to be adjoined and the homonyms they contain (their lexeme names, morphological features, and syntactic properties stated in the combinatorial dictionary). The rules may also use data on punctuation and limited data on homonyms not belonging to the given two fragments; they have no access to information about fragments built by the algorithm earlier. While formally the rules could be strongly context-sensitive within the limits of two given fragments, in most cases they only use information on nodes X and Y (those to be linked) and their nearest syntactic Context. In fact, the rules currently emloyed do not ACTES DE COLING-92, NANTES. 23-28 Am~'r 1992 9 3 1 PROC. OF COLING-92, NANTES, AUG. 23-28. 1992 consider nodes for which distance from X or Y exceeds 3 (where distance is the number of links in the path connecting two nodes in the dependency tree of a fragment).","A rule is a program written in the form of a transilion graph, with an elementary predicate or operation associated with each arc. The rule interpreter performs ordered search to find a path along \"true\" arcs that starts at a fixed entry node and ends at one of fixed exit nodes. No backtracking is used: if forward motion from some node proves to be impossible, interpretation is terminated. The fact that backtracking is not necessary has been discovered empirically; it is connected with the nature of syntactic events considered by the rules. On the other hand, when desirable, an explicit return may be made to a point passed earlier, with simple measures taken against infinite cycling.","Each rule contains at least one operation LINK(X, Y,R) that establishes a link marked by a certain syntactic relation R between the given node X of one fragment and the root Y of the other (that is, performs the adjunction). The corpus of rules covers only those situations for which the probability that the established links are correct is estimated as close to 1. For instance, the rules do not establish links like alter and ad~v in structures (3) and (4) because altachment of prepositional postmodifiers is known as a \"classical\" case of structural ambiguity.","It should be noted that the probability close to 1 characterizes here not individual links (it would be too strong a demand) but all complex of links established for the given words. This can be illustrated by the segment 1 saw, for which two fragments will be built with different homonyms for the word saw: pred pred I~-- SEE V.pt, I~ SAWI V,mf. Both these alternatives are syntactically correct. At the same time, they are mutually exclusive, and it is only their disjunction that has probability close to 1. This ambiguity is also inherited by larger fragments. (As a result, the sentence 1 saw a man with a telescope has four different parses, two of which are semantically abnormal.) Thus, high probability is a \"rollerfive\" and not an \"individual\" property of links. Rigorous definitions can be found in the paper by Miljushin (1988). 4 The Parsing Algorithm The simplest method of bottom-up parsing is to consider all opportunities for adjunction, starting from adjacent one-element fragments. We employ a faster algorithm, in which certain heuristics are used to reduce search (Mitjushin 1988).","The algorithm builds a growing sequence A of fragments. At any moment of time A contains some homonyms of the sentence and certain fragments constructed of these homonyms. The algorithm moves from the beginning of the sequence A to its end and tries to perform adjunction between the current fragment F E A and the fragments that appear in A earlier than F. New fragments are added to the end of the sequence.","The fragment cmtsidered at the given moment is called active. All fragments of A (including isolated homonyms) become active successively, without leaps or returns.","While the algorithm moves along the sequence A, tile sequence grows longer because of the addition of newly built fragments. Nevertheless, a moment will necessarily come when the active fragment is the last in A and further motion is impossible. In this case, the next homonym of the sentence is added to the sequence; it becomes active and the work is continued. When a new deadlock arises, another homonym is added, and so on. If in such a situation it turns out that all homonyms of the sentence are exhausted, then the work is finished.","Homonyms are added to the sequence in the order they are arranged in the sentence from left to right (which is essential), and those occupying the same position are added in an arbitrary order (in this case, the order has no influence m~ the results). At the initial moment A contains a single element, namely one of the homonyms occupying the leftmost position of the sentence, and it is declared active.","For each active fragment Flhe algorithm selects in A its left neighbors, i.e. fragments thai are adjacent to F on its left. A preference relation is defined between tile neighbors of F: fragments of greatter length are preferred, and lhose of equal length are considered equivalent.","For the given F, the algorithm considers its left neighbors E in order of their preference, and for each E tries to adjoin it to F. If for some E adjunclion is successful, subsequent search is limited to the neighbors of F equivalent to E; less preferred fragments are not considered. An attempt to adjoin E to F is made as follows. IJnks are considered that connect a certain node X of fragment E with the rightmost node Y of fragment F. A preference relation is defined between the links: those of greater length are less prefen'ed, and those of equal length are equivalent. In other words, more preferred are links X -- -Y and X ~ Y with nodes X that are nearer to the Jight end of E; links with the same X are equivalent.","For the given E and F, nodes X ~E are considered from right to left (i.e. in order of the preference of links between X and Y), and for each X the rules applicable to these X and Y are activated. The list of such rules is determined by parts of speech of X and Y, and by possible direction of fhe link. If during interpretation of a rule an operation LINK(X, Y, .) or LINK(Y,X, .) is performed then a new fragment is built which is the ~'esult of joining X and Y with the given link. It is placed at the end of tile sequence A. After flint, for these E and F the search is limited to the links equivalent to the established one; less preferred links are not considered. When the sequence A is built, its subset C of maximal fragments is formed. A fragment is called maximal if its segment is not a proper part of the segment of any other fragment belonging to A. The set C is the final result of partial parsing. Below, when speaking ACTES DE COLING-92, NANTES, 23-28 AO(ZI' 1992 9 3 2 PROC. OI' COLING 92, NANI KS. AUG. 23-28. 1992 about fragments built by the algoritlnn, we shall al.- ways mean exactly tim set C.","The first experiments with this algorithm have shown titbit, tit sonte c;.tses, the preferences attd restrictions adopted arc too strong and pvtme away semantically correct parses. To intprove tire situation, special operations were defined that made it possible to cancel (from inside lhc rule) priority of longer neighbors or shorter links, and also to make the algm'ithm cmrsider not only the rightmost node of tire right fragment. ()wing to them, the search can be made exhaustive in all cases when the rule \"considers it desirable\". In tile real process of pursing, these operations are fired not too often, so tile main part of search remains limited. 5 Experimcn|s At present, after preliminary debugging and tuning of tile rules, we have begun to carry out regahn' experi~ merits with it homogeneous flow of Russian texts. The experiments make use of a Coluputer-olicnted conlbinatorial dictionary of Russian compiled by a group of linguists under ttle guidance of Ju.D.Apresjan (see Apresjan et al. 1992). It contains over' 10,000 entries, mainly general scicnlific vcxzabulary and terms horn computer science and e]tx:trical engineering. The number of rules in lhc system is now about 100. Total number of arcs in their transition graphs is about 2,000. As a source of texts, we have taken several issues of the journal Computer Science Abstracts (Referativnyj zhurnal Vyehislitel'nyje Nauki, in Russian). Sentences are chosen at raodom. Sentences with formulas, occasional abbreviations, and non-Cyrillic words are excluded. Words absent in the dictionaries (aboul 8% of all word occureuces in these texts) are replaced by \"dummy\" words that have syntactic properties most probable for the given category. At present, about 300 sentences have been processed. On the average, fraginr:nts produced by partial parsing include 3 - 4 words. It is not infrequent that they have 8 - 10 or store words, or present complete structures of sentences. On the other hand, a substantial parl of fragments are isolated homonyms. For instance, subordinate conjunctions remain isolated in most eases because, as a rule, their links wilh other words are not considered having high probability.","Frequently enough morphoh~gieal, lexical, and structural ambiguity results ill building 2 - 4 different fragments on tile same segnlellt, Sometimes their number is 8 - 12 and more, but such cases are relatively rare. The record is now equal to 72 fragments on a segment of 9 words. For such cases, packing techniques can be developed similar to those described by Tomita (1987). Another possible method is to employ ntnnelical estimates of syntactic preference (set, for example, Tsejtin 1975; Kulagiua 1987, 1990; Tsujii et al. 1988).","On the avecage, the nmubcr of established links is 70 - 80 % of the total nunlber of syntactic links in tile sentence. These figm'es include links present both in the fragmenls built ;trl0 ill tile semantically COl r¢ct structm'e of the sentence; \"extra\" links that arise due to ambiguity of fragments are not included. Sometimes the fragments overlap, that is, their segments intersect. It happens approximately in one tenth of sentences. As a rule, in such cases the correct resnlt is a combination of one of the overlapping fragments with its \"truncated\" competitor. A fragment is called correct for a given sentence if it is a subtree of the semantically correct dependency trek of this sentence (or of one of such trees, in the rare cases of real semantic ambiguity like (3) - (4)). A h'agment is called feasible if it is a subtree of some dependency tree of some sentence of the given language. The algmSthm makes an error in the following lwo cases: (a) if a non-feasible fragment is built; (b) if all fragments built on some segment are feasible but none is correct. (Here we do not take into account semantically abnormal sentences or the possibility of overlapping; these situations would require more accurate definitions.) hi roost cases, all error means that some link of a fragment is established erroneously, while all the others arc correct. Ttre experiments have shown that tile frequency of errors for the algorithm described is fairly snmll. For tile lasl 100 sentences, 12 errors were nmde (9 of the first type and 3 of the second), which is less than 1% of the total number of links eslablished in correct fragments. A stable estimate is not yet obtained because at this stage of experiments tuning of tire rules is emllinued, and the error frequeocy decreases steadily.","Error s of tire first type are caused by inaccuracy of the lexicographic descriplious and imperfection of the rules. In the presence of adequate lexicographie information, these errors in principle are avoidable, as the rules may fully control internal properties of the fragments being created.","The second type of error is intrinsic to our approach. The rules employed are local in two respects: they take no (or almost no) account of the context outside the fragments being adjoined, and they take no account of a very large part of syntax that concerns less probable links. The first restrictiou means that fragments may appear which are grammatically feasible but do not agree with the context. The second one implies that wc do not intend to obtain complete structures of sentences, and therefore shall no[ be able to reject a fragment for the reason that it is not engaged in any complete structure.","In general, it is not at all snrprising that a certain part of syntactic links can be reliably revealed by local mcchanisrns. Any flow of texts in any language must contain chains of words the parse of which weakly depends on the context (\"weakly\" can be understood here in the statistical sense: the share of those occurences for which tile parse differs from the most probable one is small). The possibility of examining fragments in any detail permits to avoid situations iu which the risk of creating a non-feasible fragment is too large. A more surprising fact is that the number of reliably established links is rather high ~ about 75 %. For the most part, these are links typical of the basic, most frequent syntactic constructions such as \"adjec-ACIES DI,;COLlN(l-92, NANIV;S, 23-28 AOt-ll 1992 93 3 l'aoC. OV COLING-92, NAhqES, AUG, 23-28, 1992 tire + noun\", \"preposition + noun\", \"numeral + noun\", \"adverb + verb\", and also a large group of links connecting predicate words with their arguments. As regards the last type, preference for the predicate-argument interpretation of word combinations was orlon noted in the literature (this preference is a particular case of the Most Restrictive Context Principle proposed by Hobhs and Bear (1990)).","Observations show that the number of established high-probability links noticeably depends on the type of text. The general trend is as follows: the more \"for-mal\" the text is, the more links are established. From this point of view, the language of scientific abstracts suits the given approach quite well.","As regards comparative frequency of high-probability links in different languages, it would be natural to expect these links to be more typical of languages with rich morphology than of analytical ones (such as English). Nevertheless, preliminary experiments have shown no substantial difference in this respect between English and Russian scientific texts.","We suppose that in case of high-probability links, the efficiency of local approach is additionally augmented due to factors \"of the second order\" concerning general mechanisms of text comprehension and generation. This opinion is based on the following as-sumptions. If someone reading a text sees that a high-probability link is possible between certain words and this link is compatible with the previous part of the text, then he makes a conjecture that this link is correct; such conjecture is abandoned only if some counter-evidence is obtained. When people generate texts, they take into account this property of the comprehension mechanism and tend not to disap-point expectations of the readers. In other words, they are careful not to create high-probability links that would prove to be incorrect. This can be regarded as an instance of cooperation in language performance (cf. the Cooperative Principle in pragmatics formulated by Grice (1975))."]},{"title":"References","paragraphs":["Apresjan, Ju.D., I.M.Boguslavskij, L.L.Iomdin, A.V.Lazurskij, N.V.Pertsov, V.Z.Sannikov, and L.L.Tsinman. 1989. Lingvisticheskoje Obespechenije Sistemy ETAP-2. Nauka, Moscow. ('The linguistics of the ETAP-2 system', in Russian) Apresjan, Ju.D., I.M.Boguslavskij, L.L.Iomdin, A.V.Lazurskij, LG.Mitjushin, V.Z.Sannikov, and L.LTsinman. 1992 (forthcoming). Lingvisticheskij Protsessor dlja Slozhnykh Informatsionnykh Sistern. Nauka, Moscow. ('A linguistic processor for complex information systems', in Russian)","Gladkij, A.V. 1985. Sintaksicheskije Struktury Estestvennogo Yazyka v Avtomatizirovannykh Sistemakh Obshchenija. Nauka, Moscow. ('Syntactic structures of natural language in automatic dialogue systems', in Russian)","Grice, H.P. 1975. Logic and Conversation. In P.Cole, J.L.Morgan, editors. Syntax and Semantics, Vol. 3, Academic Press, New York, pp. 41 - 58. Hobbs, .LR. and J.Bear. 1990. Two Principles of Parse Preference. In Proceedings of COLING-90, Vol. 3, Helsinki, pp. 162 - 167. Kulagina, O.S. 1987. Ob Avtomaticheskom sintaksicheskom Analize Russkikh Tekstov. Preprint No. 205, Institute for Applied Mathematics, Moscow. ('On automatic parsing of Russian texts', in Russian) Kulagina, O.S. 1990. O Sintaksicheskom Analize na Osnove Predpochtenij. Preprint No. 3, Institute for Applied Mathematics, Moscow. ('On preference-based parsing', in Russian) Lejkina, B.M. and G.S.Tsejtin. 1975. Sintaksicheskaja Model' s Dopushchenijem Ogranichennoj Neprojectivnosti. In Meztulunarodnyj Seminar po Mashinnomu Perevodu, Moscow, pp. 72 - 74. ('A syntactic model allowing limited non-projectivity', in Russian) Mel'~uk, I.A. 1974. Opyt Teorii Lingvisticheskikh Modelej \"Smysl ,,* Tekst\". Nauka, Moscow. ('Toward a theory of Meaning ~--, Text linguistic models', in Russian) Mel'tfuk, I.A. 1988. Dependency Syntax: Theory and Practice. State University of New York Press, Albany. Mel'~uk, I.A. and N.V.Pertsov. 1987. Surface Syntax of English.\" A Formal Model within the Meaning --- Text Framework. John Benjamins, Amsterdam. Mitjushin, L.G. 1985. Dlina Sintaksicheskikh Svjazej i Induklivnyje Struktury. In Semiotika i Informatika, No. 26, Moscow, pp. 34 - 51. ('Length of syntactic links and the class of inductive structures', in Russian) Mitjushin, LG. 1988. O Vysokoverojatnykh Sintaksicheskikh Svjazjakh. In Problemy Razrabotki Formal'noj Modeli Jazyka (series \"Voprosy Kibernetiki\", No. 137), Moscow, pp. 145 - 174. ('On high-probability syntactic links', in Russian)","Tomita, M. 1987. An Efficient Augmented-Context-Free Parsing Algorithm. Computational Linguistics, Vol. 13, No. 1 - 2, pp. 31 - 46.","Tsejtin, G.S. 1975. Metody Sintaksicheskogo Analiza, Ispol'zujushchije Predpochtenije Jazykovykh Konstruktsij: Modeli i Eksperimenty. In Mezhdunarodnyj Seminar po Mashinnomu Perevodu, Moscow, pp. 131 - 133. ('Parsing methods based on preference of the language constructions: models and experiments', in Russian)","Tsujii, J., Y.Muto, Y.Ikeda, and M.Nagao. 1988. How to Get Preferred Readings in Natural Language Analysis. In Proceedings of COLING-88, Vol. 2, Budapest, pp. 683 - 687. ACRES DE COLING-92, NANTES, 23-28 ÔI~T 1992 9 3 4 PROC. OF COLING-92, NANTES, AUO. 23-28, 1992"]}]}