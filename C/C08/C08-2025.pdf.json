{"sections":[{"title":"","paragraphs":["Coling 2008: Companion volume – Posters and Demonstrations, pages 99–102 Manchester, August 2008"]},{"title":"On the weak generative capacity of weighted context-free grammars","paragraphs":["∗"]},{"title":"Anders Søgaard University of Potsdam soegaard@ling.uni-potsdam.de Abstract","paragraphs":["It is shown how weighted context-free grammars can be used to recognize languages beyond their weak generative capacity by a one-step constant time extension of standard recognition algorithms."]},{"title":"1 Introduction","paragraphs":["Weighted context-free grammars (WCFGs) are used to disambiguate strings and thus filter out subsets of the tree languages of the underlying context-free grammars (CFGs). Weights can either be used as probabilities, i.e. higher weights are preferred, or as penalities, i.e. lower weights are preferred. The first convention, also followed by Smith and Johnson (2007), is followed here. The subsets of the tree languages that consist of the heaviest tree for each yield are called the Viterbi tree languages. String languages are the yields of tree languages, and Viterbi string languages are the yields of Viterbi tree languages.","Infante-Lopez and de Rijke (2006) show that the Viterbi tree languages strictly extend the tree languages.","The idea explored in this paper is simple. If trees must have particular weights for their yields to be recognized, weights can be used to encode non-local dependencies. Technically, the {r1, . . . , rn}-language is defined as all the strings for which the heaviest, i.e. most probable, tree has weight ri ∈ {r1, . . . , rn}. It is shown that this class of languages includes common classes","∗","Thanks to Mark Hopkins, Daniel Quernheim and the anonymous reviewers for helpful comments.","∗","c⃝ 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. of context-sensitive languages. In other words, standard Viterbi-style recognition algorithms for WCFGs can be used to recognize these classes by a one-step look-up that checks if the weight of the heaviest tree is in {r1, . . . , rn}. We say that {r1, . . . , rn}-languages are {r1, . . . , rn}- recognized.","Sect. 1.1 presents formal preliminaries and a Viterbi-style recognition algorithm for WCFGs. Note that for simplicity we restrict weights to be rational numbers.","Sect. 2 defines {r1, . . . , rn}-languages and presents some examples of WCFGs that {r1, . . . , rn}-recognize context-sensitive languages. Sect. 3 gives a rough characterization of the class of languages that can be {r1, . . . , rn}- recognized by WCFGs.","Cortes and Mohri (2000) introduced a similar idea in the context of weighted finite-state automata (WFSAs) and showed that WFSAs can be used to {r1, . . . , rn}-recognize context-free languages. Their results are extended in Sect. 4. It is shown that WFSAs can also be used to {r1, . . . , rn}-recognize context-sensitive languages. It is shown, however, that the noncontext-free languages that can be {r1, . . . , rn}- recognized by WCFGs strictly extend the noncontext-free languages that can be {r1, . . . , rn}- recognized by WFSAs.","Sect. 5 discusses a more exact characterization of the weak generative capacity of WCFGs in this view. Coprime WCFGs (CWCFGs), i.e. a subclass of WCFGs where the weights can be partitioned into reciprocal coprimes, are introduced. It is conjectured that the infinite hierarchy of k-CWCFGs is non-collapsing, and the classes of languages that can be {r1, . . . , rn}-recognized by k-CWCFGs are characterized in terms of an untraditional modifi-99 cation of indexed grammars. 1.1 Preliminaries A CFG is a 4-tuple G = ⟨N, T, P, S⟩ where N, T are finite and disjoint sets of nonterminal and terminal symbols, P a finite set of production rules of the form A → φ where A ∈ N and φ ∈ (N ∪ T )∗",", and S ∈ N is the start symbol. A WCFG is a 2-tuple G′","= ⟨G, π⟩ where G = ⟨N, T, P, S⟩ is a CFG and π : P → { m","n | m ∈ Z+",", n ∈ Z+",", m, n ̸= 0} a (total) weight function.","A left-most derivation t(ω) for some CFG G = ⟨N, T, P, S⟩ is a sequence of production rules ⟨p1, . . . , pm⟩ with 1 ≤ i ≤ m : pi ∈ P such that S p1 =⇒ φ1 . . . φm−1 pm =⇒ ω","ω is called the yield of t(ω). The tree language T (G) is the set of all left-most derivations licensed by the production rules of G. The string language of G is the set of yields: L(G) = {ω | t(ω) ∈ T (G)}","The accumulated weight of a derivation of a string ω π(t(ω)) is the product of the weight of all the productions in t(ω). The Viterbi tree language of a WCFG then is:","V (G) = {t(ω) | t(ω) ∈ arg max t′ (ω)∈T (G)","(π(t′ (ω)))} A simple Viterbi recognition algorithm for WCFGs is presented in Figure 1 for further reference."]},{"title":"2 Our extension","paragraphs":["For a set of n many rational numbers {r1, . . . , rn}, the language that is {r1, . . . , rn}-recognized by the WCFG G, L{r1,...,rn}(G), is defined:","L{r1,...,rn}(G) = {ω | t(ω) ∈ V (G), π(t(ω)) ∈ {r1, . . . , rn}}","Call the class of all languages that can be {r1, . . . , rn}-recognized by a WCFG for all finite and non-empty sets of rational numbers {r1, . . . , rn} for balanced weighted context-free languages (BWCFLs). In all our examples {r1, . . . , rn} will be a singleton set.","Note that all there is needed to do to recognize the BWCFLs is to change line 7 of the Viterbi algorithm in Figure 1 to: if (S, ri) ∈ t(0, n), ri ∈ {r1, . . . , rn} then . . ."]},{"title":"3 Bounds on weak generative capacity","paragraphs":["The first result of this paper is the following: Theorem 3.1. The BWCFLs strictly extend the context-free languages. Proof. It is not difficult to see that any context-free language is a BWCFL. Simply construct a WCFG G = ⟨G′",", π⟩ for any CFG G′","= ⟨N, T, P, S⟩ such that the weight associated with each production rule in P is 1","1 . It then holds that L{ 1","1 }(G) = L(G′",").","The other direction is not very difficult either. It is shown that {an","bn","cn","| n ≥ 0}, which is non-context-free by the Bar-Hillel lemma, is a BWCFL. The language is, for instance, the set of strings L{ 1","1 }(G) for the WCFG G = ⟨⟨{S, S′","}, {a, b, c}, P, S⟩, π⟩ where P is the following set of production rules, and π assigns the weights in the left column to the items in the right column: 1 2 : S → Sc 2 1 : S → S’ 2 1 : S’ → aS’b 1 2 : S’ → ε","L{ 1","1 } = {an","bn","cn","| n ≥ 0}. Some example","derivations are presented in Example 3.2. Example 3.2. Consider the only and thus heaviest tree for abc, resp. ab: S ","","  S S’ ","","  a S’ ε b c S S’ ","","  a S’ ε b The weight of the left tree, whose yield is abc,","is 1 1 . The weight of the left tree is 2","1 . Consider also the { 1","1 }-language of G =","⟨{S, D, T, T ′","}, {a, b, c, d}, P, S⟩ with production","rules P : 1 1 : S → TD 1 2 : D → dD 1 1 : D → ε 1 1 : T → aTc 1 1 : T → T’ 2 1 : T’ → bT’ 1 1 : T’ → ε 100","BUILD(t, [w1 . . . wn])","1 for j ← 1 to n","2 do t(j − 1, j) ← {(A, α) | A → wj ∈ P, log(π(A → wj)) = α}","3 for k ← (j − 1) to 0","4 do t(k, j) ← {(A, α + β) | A → B ∈ P, log(π(A → B)) = α,","(B, β) ∈ t(k, j), if (A, α′",") ∈ t(k, j) then α > α′","}","5 for i ← (j − 2) to 0","6 do t(i, j) ← {(A, α + β + κ) | A → BC ∈ P, log(π(A → BC)) = α,","∃k.(B, β) ∈ t(i, k), (C, κ) ∈ t(k, j), if (A, α′",") ∈ t(i, j) then α > α′","}","7 if (S, ri) ∈ t(0, n) then return success else failure Figure 1: A Viterbi recognition algorithm for WCFGs","It should be relatively easy to see that L(G) = {an","bm","cn","dm","| n ≥ 0}.","It is not difficult to see that the BWCFLs are a subset of the context-sensitive languages. This follows from the fact that the left-most derivations in the Viterbi tree languages of WCFGs are linear in the length of the input string; in other words, BWCFLs can be recognized in nondeterministic linear space and thus by a linear bounded automaton. Since any language that can be represented by a linear bounded automaton is context-sensitive, the BWCFLs must be a subset of the context-sensitive ones.","The set of BWCFLs is also a subset of the range concatenation languages (Boullier, 1998) by the observation made in the introduction that they can be recognized in polynomial (i.e. cubic) time by standard algorithms and a one-step inspection of the weight of the heaviest tree; and by the fact that the range concatenation languages are exactly the languages that can be recognized in polynomial time (Boullier, 1998)."]},{"title":"4 Weighted finite-state automata","paragraphs":["Cortes and Mohri (2000) showed, in similar work, that WFSAs can be used to recognize context-free, i.e. non-regular, languages. Example 4.1. The weighted finite-state automaton T = ⟨{q0, q1}, {a, b}, δ, q0, {q1}⟩ with the following δ-transitions { 1","1 }-recognizes the language","L{ 1","1 }(T ) = {an","bn","| n ≥ 0}: 1 2 : δ(q0, a) = q0 1 1 : δ(q0, λ) = q1 2 1 : δ(q1, b) = q1 It is not difficult to see that the strings ab, aabb, . . . have derivations with weights 1","1 , whereas the string aab, for example, only has a","derivation with weight 1","2 . Since 1","2 /∈ { 1","1 }, aab /∈","L{ 1 1 }(T ).","Cortes and Mohri (2000) also formulated an extension of WFSAs over cross-products of semirings that recognized certain context-sensitive, i.e. non-context-free languages, but their results can be considerably extended. The automaton in Example 4.2, for example, even recognizes a language conjectured to be outside the linear indexed languages, namely the MIX language (Gazdar, 1988). Example 4.2. The weighted finite-state automaton T = ⟨{q0, q1, q2, q3}, {a, b, c}, δ, q0 , {q0}⟩ with the following δ-transitions { 1","1 }-recognizes","the MIX language: 1 8 : δ(q0, a) = q1 1 8 : δ(q1, a) = q2 1 8 : δ(q2, a) = q3 1 125 : δ(q0, b) = q1 1 125 : δ(q1, b) = q2 1 125 : δ(q2, b) = q3 1 729 : δ(q0, c) = q1 1 729 : δ(q1, c) = q2 1 729 : δ(q2, c) = q3 903 1 : δ(q3, λ) = q0 This example is a bit more complicated. Note","that 8 × 125 × 729 = 903",". The strings","cab, bcabac, . . . have derivations with weights 1","1 ,","since 903 8×125×729 = 1","1 , whereas the string cababa,","for instance, has no derivations with weight 1","1 . The","string cababa has exactly one derivation whose","weight is 903","82","×125 ."]},{"title":"5 Coprime WCFGs","paragraphs":["A 2-CWCFG is a WCFG over subsets of the ratio-","nal numbers C = { 1","n | n ∈ Σ} ∪ { n","1 | n ∈ Σ} 101 B. (2000) WCFGs","{an 1 . . . an","k | n ≥ 0} ✓ ✓","MIX ✓ ✓","{an bm","cn","dm","| m, n ≥ 0} ✓ ✓","{wcw | w ∈ {a, b}∗","} ✓ ✓ Figure 2: Classes of languages {r1, . . . , rn}- recognized by WCFGs and recognized by the extension in Boullier (2000). where Σ is an arbitrary set of coprimes (Σ ⊆ N∗",") such that there is a bijection from the production rules onto themselves such that if a production rule has weight 1","1 it is projected onto itself, and otherwise, i.e. if it has weight 1","m with m ̸= 1 it is projected onto a production rule with weight m","1 . A k-CWCFG for k ≥ 1 is now the extension of CWCFG where the sets of production rules the product of whose weights is 1, can be of size at most k, e.g. the WFSA in Example 4.2 is a 3-CWCFG.","The infinite hierarchy of k-CWCFGs seems to be non-collapsing. A k-CWCFG {r1, . . . , rn}- recognizes the language {an","1 . . . an","2k | n ≥ 0}, but not {an","1 . . . an","2k+1 | n ≥ 0}. It has this property in common with k-multiple context-free grammars (Seki et al., 1991). 2-CWCFG can be shown to be weakly equivalent with the extension of linear indexed grammars (LIGs) (Gazdar, 1988) where the stack is a multiset or a bag that is globally accessible and not just along spines. The universal recognition problem for this extension of LIGs can be shown to be NP-complete by reduction of the vertex cover problem, similar to Søgaard et al. (2007). The generalization to k-CWCFG requires stacks of stacks, but is otherwise relatively straight-forward."]},{"title":"6 Conclusions","paragraphs":["It was shown how weighted context-free grammars can be used to recognize languages beyond their weak generative capacity by a one-step constant time extension of standard recognition algorithms. The class of languages that can be recognized this way strictly extends the context-free languages, but is included in the cubic time recognizable ones.","Boullier (2000) defines what he calls a “cubic time extension of CFG” that recognizes generalizations of the copy language that are beyond WCFG. It remains to be seen if the set of BWCFLs is a strict subset of the set of languages that can be recognized by this formalism. They all recognize the classes of languages in Figure 2."]},{"title":"References","paragraphs":["Boullier, Pierre. 1998. Proposal for a natural language processing syntactic backbone. Technical report, IN-RIA, Le Chesnay, France.","Boullier, Pierre. 2000. A cubic time extension of context-free grammars. Grammars, 3(2–3):111– 131.","Cortes, Corinna and Mehryar Mohri. 2000. Context-free recognition with weighted automata. Grammars, 3(2–3):133–150.","Gazdar, Gerald. 1988. Applicability of indexed grammars to natural languages. In Reyle, Uwe and Christian Rohrer, editors, Natural language parsing and linguistic theories, pages 69–94. Reidel, Dordrecht, the Netherlands.","Infante-Lopez, Gabriel and Maarten de Rijke. 2006. A note on the expressive power of probabilistic context free grammars. Journal of Logic, Language and In-formation, 15(3):219–231.","Seki, Hiroyuki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. 1991. On multiple context-free grammars. Theoretical Computer Science, 88(2):191–229.","Smith, Noah and Mark Johnson. 2007. Weighted and probabilistic context-free grammars are equally expressive. Computational Linguistics, 33(4):477– 491.","Søgaard, Anders, Timm Lichte, and Wolfgang Maier. 2007. On the complexity of linguistically motivated extensions of tree-adjoining grammar. In Proceedings of Recent Advances in Natural Language Processing 2007, Borovets, Bulgaria. 102"]}]}