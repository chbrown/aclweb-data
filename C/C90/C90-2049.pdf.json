{"sections":[{"title":"Dependency Analyzer: A Knowledge-Based Approach to Structural Disambiguation","paragraphs":["Katashi Nagao","IBM Research, Tokyo Research Laboratory","5--19 Sanbancho, Chiyoda-ku, Tokyo 102, Japan","E-mail: nagao@jpntscvm.bitnet"]},{"title":"Abstract","paragraphs":["To resolve structural ambiguities in syntactic analysis of natural language, which are caused by prepositional phrase attachment, relative clause attachment, and so on, we developed an experimental system called tile Dependency Anal!lzcr. The system uses instances of dependency structures extracted froth a terminology dictionary as a knowledge ba.~e. Structural (attachment) ambiguity is represented"]},{"title":"by","paragraphs":["showing that a word has several words as c;tndidate modiliees. Tim system resolves such ambiguity as follows. First, it searches the knowledge base for modification relationships (dependencies) between the word and each of its possible modifiees, then assigns an order of preference to these relationships, and finally seieets the most preferable deper.dency. The knowledge base can be constructed semi-automatically, since the source of knowledge exists in the form of texts, and these sentences can be analyzed by the parser and transformed into dependency structures by the system. We are realizing knowledge bootstrapping by adding the outputs of the system to its knowledge base."]},{"title":"1 Introduction","paragraphs":["The bottleneck of sentence analysis, structural ambiguity, occurs when a sentence has several alternatives for modifier-modifiee relationships (dependencies) between words or phrases. This kind of ambiguity cannot be resolved merely by applying grammatical knowledge: there is a need for semantic processing. Resolution of structural ambiguities seems to be a problem of selecting the most preferable dependency from several candidates by using large-scale knowledge on dependencies among words. There are two problems in realizing practical semantic processing: one is that knowledge must be large-scale, and must be constructed automatically or semi-automatically; the other is that the mechanism for utilizing knowledge, inference, must be efficient or tractable. We developed a system called the Dependency Analyzer that resolves these problems.","The Dependency Analyzer is a systenl fl)r structural disambignation. One of its characteristics is that it selects the most preferabledependency by using a knowledge base containing terminological knowledge in the form of dependency trees. The knowledge base can be constructed semi-automatically, as described in Section 2. The inputs of this system are parse trees, which are outputs of the PEG parser, a broad coverage English parser [5]. The system translates the phrase structures into dependency strut-"]},{"title":"282","paragraphs":["tures that explicitly represent modifier-modifiee relationships between words. The main processes of the system are executed if attachment ambiguities are included in the phrase structures. In the dependency structures, attachment ambiguities are represented by showing that some words have several candidate modiliees. From these depe.ndency structures, several candidate dependencies are extracted. The system decides which of these should be adopted by using background knowledge an,l context. The decision is made via tim mechanisms of path search and distance calculation. A precise description of path search is given in Section 3. An explanation of distance calculation is given in Section 4. Another problem for disambiguation, namely interaction (or constraints) between attachment ambiguities, is discussed in Section 5."]},{"title":"2 Knowledge Base","paragraphs":["The knowledge must be large=scale, since natural language semantics should have a broad coverage of lexical items. Since dependency structures are built by analyzing sentences and by tra:nsforming phr~e structures in a straightforward way, if knowledge is assumed to consist of dependency structures, a knowledge base is easily constructed by using already-existing on-line dictionaries. This idea of using on-line dictionary definitions as a knowledge base was originally proposed by Karen Jensen and Jean-Louis Binot [6]. Jun-ichi Nakamura and Makoto Nagao"]},{"title":"[101","paragraphs":["evaluated tile automatic extraction of semantic relationships between words from the on-line dictionary. We emphasize that a data structure for representing knowledge should be as simple as possible, because it must be easy to construct and efficient.","We selected the tree structure as a means of representing knowledge, because it is a very simple and manageable data structure, and because tree structures are suitable for describing dependency structures.","Tile tree structure is defined as follows. A Tree consists of a Node and reeursions (or null) of Tree, and a Node consists of repetitions of a paired attribute name and u.ttribute value.","For example, Figure 1 shows a tree (dependency) strncture for the clause \"the operating system stores the files in the disk.\" In this tree, \"WORD,\" \"POS (part of speech),\" and \"CASE\" are att,qbute names, and \"store,\" \"VERB,\" and \"AGENT\" are attribute values.","In our system, the knowledge can be extracted fi:om dictionaries of terminology, and is of two types: (1) dependency structures and (2) synonym and taxonym relation-","( ((WORD . \"store\") (POS . VERB)) (((WORD . \"operating system\")","(CASE . AGENT) (POS . NOUN))) (((WORD . \"file\") (CASE , PATIENT)","(POS . NOUN))) (((WORD . \"disk\") (CASE . LOCATION)","(POS . NOUN))) ) Table h Tree Index Table","d synonym and taxonyra trees to(O)-qo(o) t~2(0) tsO) t~(o) tea(o) t~(0) t ~(0) tn(1) ts0) t25(1) t82(o) dependency trees tlol(O 1) tlso(1 O) tu(1) trio(t) tlOl(1 1) t350(0 2 3) tas(1 O) tllo(1 1 O) lqgure h Tree structure for the clause \"the operating system stores the files in the disk\" ships.","The process of knowledge extraction is as follows. First, dictionary statements are rewritten manually as simple :~entences. Next, sentences are parsed into phrase struetm'es by tile PEG parser. Then. phrase structures are transformed into dependency structm'es by the Depende'nc:q Str~zctu're Builder, which is a component of tile Dependency Analyzer. Finally, sernantie case markers are manually added to the modification links in dependency .structures. Synonym and taxollym relationships are extracted from sentences of the form \"X is a synonynt for Y\" and \"X is a Y\" respectively. These sentences are automatically transformed into tree structures each of which has two nodes R)r tile words \"X\" and \"Y\" and a link from \"X\" to \"Y\" with the label \"isa.\" In the case of \"X is a synonym for Y,\" since \"Y\" is also a synonym for \"X,\" \"Y'\" is connected with \"X\" at the same time by a link with the label \"isa.'\" \\Ve developed an interactive tree management tool, the Tree Editor. which makes it easy for users to deal with trees.","Another problem of natural language processiug is the knowledge acquisition bottleneck. Some ideas on how to a.cquire knowledge fi'om a!ready-existing dictionaries automatically or semi-automatically haw~ be.en proposed [10,41. But it is still difficult to develop a knowledge base hilly automatically because of ambiguities in the natural language analysis of dictionary definitions. A more practical way, to overcome the t)otthmeck is so-called kno'wledge bootstraptn'a~.]. By knowledge bootstrapping, the Dependency Analyzer extends its knowledge automatically by using a eor'e knowledge base that includes mammllv edited dependency .~;truetures. Since the De.pendency Analyzer uses dependency structures as knowledge and outputs a dependency structure with no ambiguity (case ambiguity is also resolved by the system), tile output can be added to the knowledge base. Of course we still need to evaluate the automatically constructed knowledge base. But the reliability (performance) of the knowledge base is rising gradua[ly, so it is expected that human interw,ntion wilI be greatly reduced in the near future."]},{"title":"\"t Path Search An EtIicient Algorithm","paragraphs":["Path search is a process for finding relationships between the words in a candidate dependency by using a knowledge base. Since relationships between words in these candidates do not always exist in the knowledge base, relation-"]},{"title":"/\\","paragraphs":["(3 (o) (?O (2) t.5 (2 1 0) Figm'e 2: Tree and Node Location ships between synonyms and taxouyms of these words eau also /)e targets. Path search is done ill the following steps:","1. Synonyms and t~u,:onyms of words in the candidate dependencies are found by using the knowledge base. In the knowledge base, synonym and taxonym relationships are also defined in the form of trees. All the synonyms and taxonyms can be collected by transiting relationships.","2. Dependencies between elements of each synonym and taxonym set (including the original words) are also found by using the knowledge base.","We developed an efficient algorithm for path search, using the table of indices shown in Table 1. In this table, t~, represents the pointer of the tree in which the word on the same line appears, and the numbers in parentheses represent the node location of the word in the tree. Relation-ships between the numbers amt the node are shown in Figure 2. The left side of tile table shows trees in which a synonym or a taxonym of the word on the same line appears as its parent node. For example, in the tree to, the word a is on the node of location (0), and by traversing to up by one node fl'om location (0) we can find that the word b is on the node of location (), so b is a synonym or a taxonym of a, as shown in Figure 3. Thus, in order to find a synonym or a taxonym of a word, we just traverse up tile tree on the left side of the table by one node. We assume that synonym and taxonym relationships are transitive, that is. that a synonym/taxonym of one of the synonyms/taxonyms of a word is also a synonym/taxonym of the word itself. We can to ~ b"]},{"title":"l synonym/tmxonym (isa) a","paragraphs":["Figure 3: Synonym/Taxonym Tree 283"]},{"title":"tl. tO 0/0~ / b","paragraphs":["d \"keep\" .~,.. \"VM/SP .... information\" / \"virtual disk\" Figure 6: Ambiguous Dependency Structure Figure 4: Dependency Tree ~110"]},{"title":"~ O~","paragraphs":["to ~ b q.,, -. d"]},{"title":"A","paragraphs":["C Figure 5: Path collect all its synonyms/taxonyms by iteration of that process. The next stage of"]},{"title":"path search","paragraphs":["is to find whether there are dependencies between words within each set of synonyms/taxonyms. This process searches trees that involve both words and checks whether there is a"]},{"title":"path","paragraphs":["from one word to the other. In the dependency trees, the words' locations show whether there is a dependency between them.","For example, we can see that tile word b is a dominator of the word d frmn the locations of these words in the emnmou tree tH0 (shown in Figure 4), which is included in both the set of dependency trees that include b. {ttl, ttl0}, and that of dependency trees that include d, {tas, t110}. In the tree structures, if the node a is an ancestor of the node b, then there is a unique"]},{"title":"path","paragraphs":["front b to a. Thus, finding dependency between words is equivalent to checking their node locations in the dependency trees. A"]},{"title":"path","paragraphs":["between words wl and w2 is found by the following processes:","1. The synonym/taxonym sets of these words, S~,~ and S~, are collected. \"keep\""]},{"title":"I","paragraphs":["on \"virtual disk\" Figure 7: Candidate Dependency"]},{"title":"4 Distance Calculation - A Heuristic Process for Selection of the Most Preferable Dependency","paragraphs":["Several conditions are added to"]},{"title":"path.s,","paragraphs":["and the ch)seness of dependevcy in a"]},{"title":"path","paragraphs":["is computed according to these conditions. The degree of closeness of dependenc.y is called the"]},{"title":"dependency distance.","paragraphs":["This is calculated by using the number of dependencies inclnded in a"]},{"title":"path","paragraphs":["and the values of the conditions. Three conditions are used to calculate the"]},{"title":"dependency distartce: I. Case","paragraphs":["consistency For example, in the sentence \"VM/SP kceps the information on the virtual disk,\" there is a prepositional phrase attachment ambiguity, as shown in Figure 6. If the"]},{"title":"path","paragraphs":["shown in Figure 8 is found together with the candidate dependency shown in Figure 7, then tile semantic case of the"]},{"title":"path's","paragraphs":["dependency between \"store\" and \"disk\" must be consistent with the grammatical case of the"]},{"title":"sentence's","paragraphs":["dependency between \"keep\" and \"virtual disk.\" lIere, the case consistency between the sentence and the"]},{"title":"path","paragraphs":["holds, since the grammatical case \"on\" call have the role of the semantic case \"location.\" If this consistency holds, then the value of case consistency is 1; otherwise, it is 0."]},{"title":"2. Co-occurrence","paragraphs":["consistency This is the consistency between the other modifiers of the modifiee of tile candidate dependency, called the"]},{"title":"co-occurrent modifiers,","paragraphs":["and those of a"]},{"title":"path.","paragraphs":["2. The common trees tz... that involve both elenmnts, ei 6 Swl and ej ~ Sw2, of each set are found. 3. Tile node locations of"]},{"title":"ei","paragraphs":["and"]},{"title":"ej","paragraphs":["in t~... are checked. For example, a"]},{"title":"path","paragraphs":["between the words a and c is shown in Figure 5. \"store\" \"keep .... disk\"","lisa \"virtual disk\" Figure 8: Path"]},{"title":"284 3.","paragraphs":["\"keep\""]},{"title":"\"VM/SP\"","paragraphs":["'~virtual disk\" Figure 9: Co-Occurrence \"operating system\" \"file .... disk\" Figure 10: Dependency Tree In tile example sentence, for instance, there is a cooccurrent modifier \"VM/SP\" of the candidate dependency between \"keep\" and \"virtual disk,\" as shown in Figure 9. In this case, \"VM/SP\" has the grammatical case"]},{"title":"subject.","paragraphs":["On the other hand, if the"]},{"title":"path","paragraphs":["is given by the dependency tree shown in Figure 10, then there is also a eo-oceurrent modilicr \"operating systenf' that has the semantic ease of"]},{"title":"agent.","paragraphs":["In addition, there is a tmxonym relationship between \"VM/SP\" and \"operating system\" in the knowledge base, as shown in Figure ].I. In this case, the co-occurrence consistency between \"VM/SP\" and \"operating systenf' holds, since there is a relationship between the words and both case,; are consistent (the grammatical case"]},{"title":"subject","paragraphs":["call have a semantic case"]},{"title":"agent),","paragraphs":["as shown in Figure 12. The vahm of co-occurrence consistency is tile number of co-oceurrent modifiers that are consistent between the"]},{"title":"path","paragraphs":["and the sentence. Here, the value is 1, since only one co-oecurrent modifier \"VM/SP\" is consistent."]},{"title":"Context","paragraphs":["consistency Context consistency holds if dependencies in a"]},{"title":"path","paragraphs":["already exist in previous sentences. For example, if the sentence \"the data is stored in the storage device\" comes before tile above sentence, then the dependency structure shown in Figure 13 is in the context base in which the dependency structures of previous sentences are stored. Then the other"]},{"title":"path","paragraphs":["(shown in Figure 14), which corresponds to the dependency between \"store\" and \"disk\" in the \"path,\" is found by using the context base. Thus the dependency between \"store\" and \"disk\" is defined by the context. The vahn', of context consistmmy is the number of dependencies in the"]},{"title":"path","paragraphs":["that are. defined by tile context. In this case, the wflue \"operating system\""]},{"title":"l","paragraphs":["isa \"VM/SP\" Figure lh Taxonym Relationship","agent location \"operating system\" ~ \"store\" .i .... \"disk\"","subject on \"VM/SP\" \" * \"keep\" ~ \"virtual disk\" Figure 12: Diagram of Co-Occurrence Consistency \"store\""]},{"title":"St-->","paragraphs":["\"data .... storage device\" Figure 13: Dependency Tree in tile Context Base is 1, since there is one dependency in the"]},{"title":"pa&","paragraphs":["and it is de.fined in the context. The"]},{"title":"dependency distance","paragraphs":["is computed from the following formula:"]},{"title":"Distance = [Depl","paragraphs":["+ ~c'o,,, x (n- 1) (t~, ..... + 1) x (l@oo~ + 1) ' where"]},{"title":"]Dep]","paragraphs":["represents the number of dependencies included in the"]},{"title":"palh,","paragraphs":["i\"c ..... is the value of case consistency, 1 ~'oo~. is that of co-occurrence cm~sistency, and l'C,o,,t is that of context consistency. This formula assumes that case and co-occurrence consistency affect the distance of the whole"]},{"title":"path,","paragraphs":["but that context consistency affects the distance of each dependency in the"]},{"title":"path.","paragraphs":["n is a real number in tile range 0 < n < 1; it is a heuristic parameter that represents the degree of unimportance of context consistency.","The"]},{"title":"dependency distance","paragraphs":["between \"keep\" and \"virtual disk\" that is calculated by using the"]},{"title":"path","paragraphs":["in the example is 0.125, because the number of depenttencies is 1, the value of case consistency is 1, that of co-occurrence consistency is 1, and that of context consistency is 1 (n is defined 0.5).","The ambiguity of an attachment is resolved by selecting the candidate dependency that is separated by the shortest distance. \"store\""]},{"title":"-..<","paragraphs":["storage device \"disk\" Figure 14: Path of Context"]},{"title":"285","paragraphs":["Table 2: Constraint Tables Constraint Table T5.6 Constraint Table 7~5,7 Cons~r~dnt Table T6.r"]},{"title":"tl'~ 0 I l I 0 1 ~","paragraphs":["6/7 3 6","1 0 1","3k~__~l_L2 o V3 fl i 212o0 [5 ~ 1","0 Ic~0 I m I1 2~ m"]},{"title":",o ):% _'7_'7 ,0 / ,Q/~ \"-- , / 7 ~\\0~,~) I ~O/{3,s}","paragraphs":["Figure 15: Ambigu,ms Dependency Slructure"]},{"title":"5 Planning, Constraint Propagation, and Process of Disambiguation","paragraphs":["When there are several attachment ambiguities in one sentence, the relationships of each pair of ambiguities are represented by a constraint network [91. The idea that am-Mguous syntactic structures can be represented by a data structure of constraint network was originally developed by Hiroshi Maruyama [7 t. A constraint network consists of constraint tables.","For example, the constraint tables shown in Table 2 are constructed from tile ambiguous dependency structure shown in Figure 15. In this dependency structure, words 5, 6, and 7 have attachment ambiguities, so their possible modifiees are {1,3}, {1,5}, and {3,6} respectively. The constraint table is a two-dimensional matrix that represents the. possibility of simultaneous modification of two ambiguous attachments. The rows and columns of the matrix show the candidate modifiees of each modifier, and an element in the matrix means the possibility (1 or 0) that both dependencies can exist simultaneously. For example, constraint table T5.7 indicates that if word 5 modifies word 1, then word 7 cannot modify word 3 because of the rule of no-crossing.","By using the constraint tables, the system decides which ambiguity should be resolved first. This process is called planning. In the above example, words 5, 6, and 7 have two candidate modifiees each. But from the constraint tables, we can see that if word 7 modifies word 3, then words 5 and 6 cannot modify word 1. Thus, in this case, the ambiguity concerning the modification of word 7 should be resolved first. The algorithm for plauning consists of the following steps:","1. On each row of the constraint table Ti.j, sum up the element values (Ai in Table 2), and subtract the sum from the size of the row (Bi). Then sum up the results on all rows (Ci). The result is the value of merit of 286 the ambiguity of word i.","2. Do the same in each cohmm. The result is the value of merit of the ambiguity of word j.","3. In all the constraint tables, sum up all the values of merit of each ambiguity, and divide each of these values by the number of their candidate modifiees.","4. The expected values of meTit of all ambiguities are given by the above process. Select the ambiguity that has the highest expected value. When an ambiguity is resolved, the system updates the constraint tables by tile filtering algorithm called constraint propagation. We apply Mohr and Henderson's AC-4 algorithm [8] for constraint propagation. We reduce the computational cost of disambiguation by using planning and constraint propagation.","Structural disambiguation of a sentence is done as follows. The PEG parser tmrses a sentence and constructs its phrase structure. The Dependency Stracturc Builder transhttes the phrase structure int.o the dependency strm:ture, and constructs the constraint tables when the phrase structure contains sew~ral structural ambiguities. The Planner, which is the component for planning, gives the Disambiguator the information on an ambiguous dependency and its candidate modifiees. The Disambiguator decides which modifiee is the most preferable by doing path search and distance calculation. After resolving one ambiguous attachment, it calls the constraint propagation routine to filter the other ambiguities' candidates. After filtering, the Transformer transforms the dependency structure into one that has correc t dependencies for all resolved attachments. These processes are iterated until no ambiguity remains."]},{"title":"6 Related Work","paragraphs":["There are several approaches to structural disambiguation, including resolution of prepositional phrase attachment. Wilks et al. [12] discussed some strategies for disambiguation based on preference semantics. Our framework is closely related to their ideas. While their strategies need hand-coded semantic formulas called preplates to decide preferences, our system can construct dependency knowledge semi-automatically. Dahlgren and Mc-Dowell [2] proposed another preference strategy for prepositional phrase disambiguation. It is based on ontological knowledge, which is manually constructed. Whereas this framework (and also that of Wilks et al.) was aimed at disambiguating single prepositional phrases in sentences, our approach can handle the attachments of multiple prepositional phrases in sentences, ttirst [3] developed a mechanism for structural disambiguation, called the Semantic Enquiry Desk, which is based on Chraniak's marker passing paradigm [1]. Our path Search is partially equivalent to marker passing. While marker passing involves a high computational cost and finds ninny meaningless relations, our path search is restricted and finds only paths that in-elude synonym/taxonym relationships and dependencies. Our system can reduce the computational cost by using a limited knowledge search. Jensen and Binot [6] developed a heuristic method of prepositional phrase disambiguation usinp, on-line dictionary definitions. Our approach is sire-- liar t,o theirs in the sense that both use dictiouaries as knowledge sources. The differences are in tile ways in which dictionary definitions are used. While their method sear{:hes for knowledge by phrasal pattern matching and calculates certainty factors by complex procedures, ours uses knowledge it: a simt)le and efficient way, searching tree:: and traversing nodes, and calculates t)referenees by afe, w simplified processes. Wernlter [11] t)rop{}sed a e:}nneeliol:ist approach to 8lrllctllra.[ disan:biguation of noun phrases. He integrated syntaclic and semantic conslraints on lhe relaxation network. ~el:laI:tic {2OllS'{l'ailltS ol: prepositional reh:tionshil)s betweetl words are learned by a backl}ro]}agation algorithm. Learned semantics is often very t:seful for natural language processing, when sexnantic rehtti,mshit)s cannot be represented explicitly. \\\\2: represm:t semantic relationships between words by explicit relationship chains, al:d therefore do not need learning by backpropagation. We integrate sem.mti{: preferences and syntactic eonstrailllS t}y using e(mstraint t}ropagathm. }n:t it is a sequential {:o::ue{'tion and does not allow their iilterac-. ti{m. \\\\k! are thii:king of desigIfinp a frau:ework that deals wilh both syntactic and semanli{: constraints simultam'- ousty."]},{"title":"7 Concluding Remarks","paragraphs":["We deveh)ped the DepeT~dcrtcy Anal:/zer to re:olve structural ambiguity by sen:antic processing. It aims t<~ overcome two serious problems in realizing pr:'a'tical semantic pr,~,cessing: ::en::@u'::nm:ie conslru{tion of knowledge and efficient use nf that knowledge. The key ideas, path. .sea~'ch and distance calcuiatiora, ~~e.re shown to be feasible.","\\Ve now have a knowledge base constructed by using defi:,.itions giver~ in the \"IBM Dictionary of Computing/' which inch:des about 20.009 instance.s of dependency :trueturc'.s, h: addilion, we evaluated the system by disan:- biguat.ing the prepositional phrase attachment of about 2,0()0 sentence.':. The results were as follows: (1) :he number of arzflJiguou:-; prepositio::al phrases wa> 4.290, (2) the numbe, of correctly (lisanfi}iguat.ed a'~ta{:hm{'n:s was 3,569, and (3) the success ratio of disambiguatio:: was 83.2%.","Further enhancement plans arc listed be.low:",",, ~,¥~'. are exploring the formalization of dependency distar, ce with reference to graph theory. I)epe.ndeney distMlee is aSsllnled to be a score lbr the (:OIlSistel~cy of a dependency with tim background knowledge and context. The background knowledge and context are represented as trees (special ca.~es of graphs), and c(msistency might be defined by a degree of matching between trees.",",L. We are planning to enhance tile system for other problems such as adverb attachment and scope of eonj'unction.s. To resolve general struetmal ambiguity problems, we must design a general ambiguity-packed syntactic strncture, since the system can deal wilh locally packed ambiguities."]},{"title":"Acknowledgements","paragraphs":["i would like to thank members of the IBM Tokyo Research Laboratory, Karen Jensen of the IBM Thomas J. Watson Research Ceqter, and tile reviewers for their vainable comments on a draft of this paper, Hiroshi Nomiyama for his help in implementing tile system, Mizuho Tanaka, ~%hko Kobayashi, Mitsuyo Sadohara, and Xbmoko Uehida for their kind support it: constructing the knowledge base and evaluating the system, and Michael McDonakl for his helpful adviee on the wordi[:g of this paper. References","[1] Charniak, E., \"A Neat Theory of Marker Pressing,\" Procec.dirzgs of AAAI-86, 584-588, 1986.","[2] Dahlgren. K. and McDowe!l, J., \"Using Commonsense Km~wledge to Disambiguate Prepositional Phr~u~e Xiodifiers,\" Proceedin.q.s of A.4A[-a< 589-593, !986.","[3] tlirst, G., Scmanlic hlterpre.t,Ltion and Zhe Rc.s,)hLtio.n of A'mbiguity, Cambridge University Press, 1!357.","[.1] Jacob:, P. and Zernik. U., \"Acquiring Lexical K'aowledge from Text: A Case Study,\" Proceedings (;f AAAL 88, 739-7-1.1, 1988.","[5] Jensen, K., HeMorn, G.E., Richardson, S.D., and Haas, N., \"PLNLP, PEG, and CRYI'IQUE: Th,'ee Contribntions to Computing in the Humanities.\" IBM Research Report, EC 11841. 1986.","[6] Jensen, K. and Binot J-L., \"Disambiguating Prep(> sitional Phrase Attachments by Using On-Line Dictionary Definitions,\""]},{"title":"Coraputational Ling'u£stics~ 13:251-260, 1987.","paragraphs":["[7] Maruyama, H., \"Structural Disambiguation with Constrain~, Propagation,\" Proceedings o/ ~l~e 28th Annual Meeting of the A CL, 1990.","[8] Mohr, E. and Henderson, T.. \"Are and Path Consiste.ney IIevisited.\" Artificial Intelligence, 28:225-233. 1986.","[9] Montanari, U., \"Networks of Constraints: Fundamental Properties and Applications to Picture Processing,\""]},{"title":"Inf~imation Sciences, 7:95-132, 1974. [10] Nakamura, J.","paragraphs":["and Nagao, M., \"Extraction of Semantic information from an Ordinary English Dictionary and its Evaluation.\" Proceedings of COLING-88. 459-46,1, 1!)88.","[ll] Wermter, S., \"Integration of Semantic and Syntactic Constraints for Structural Noun Phrase t)isambiguation,\" P'roceedirLgs of IJCA[-89, 1-186-1491, 1989.","[i[2] Wilks, Y., Huang, X., and Fass, D., \"Syntax, Prefluence and Right Attachment,\" Proceedings of I.ICAL85, 779 78.1, ]!)85."]},{"title":"287","paragraphs":[]}]}