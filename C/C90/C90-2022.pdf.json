{"sections":[{"title":"Generating from a Deep Structure * Claire Gardent Universitfi Blaise Pascal- Clermont Ferrand (France) and University of Edinburgh 2 Buccleuch Place Edinburgh EH8 9LW (Scotland) Agnes Plainfossfi Laboratoires de Marcoussis Route de Nozay 91460 Marcoussis (France)","paragraphs":["ABSTRACT: Noncanonical semantic representations are representations which cannot be derived by some grammar G although they are semanticMly equivalent to representations which can be derived by G. This paper presents a generation Mgorithm which deals with non-canonical input. The proposed approach also enhances portability and language independence in that (i) linguistic decisions made by independent modules (e.g., planner, transfer component) can be communicated to the generater in a naturM way and (ii) the same algorithm coupled with different grammars will yield sentences in the corresponding languages."]},{"title":"1 Introduction","paragraphs":["not derivable under G. Representations that cannot be derived under a grammar G are said to be noncanonical with respect to G. In this paper, we present a generation algorithm for Unification Categorial Grammar [6] (,ca) which addresses the problem raised by non-canonicM input (section 2 and 3). An interesting upshot of the strategy we propose is that it allows :['or language independent generation. Section 4 illustrates this point by considering how, starting from one semantic representation, two sentences can be generated: one in English and one in French. Section 5 relates our work to previous proposals by Van Noord and Shieber. Two major requirements on a generator is that it be correct and complete. A generator is said to be correct if given two semantic representations R1 and R.~ which are not semantically equivalent, R1 and R2 do not generate the same string. A generator is said to be complete if any two senmn tically equivalent representations generate the same set of strings. An obvious case of incompleteness occurs when the generator fails to terminate on some well-defined input. An-other less obvious cause for incompleteness can be explMned as follows. Consider a grammar G and its as-sociated semantic representation language L. It is often the case that syntactically different strings of L will have equivalent semantics. A simple case in point is the semantic equivalence holding between ¢ A ¢ and ¢ A ¢ in e.g. propositional logic. On the other hand, it is also often the case that the same grammar G will not derive for a given string all the formulae which may represent its meaning. From the point of view of generation, this means that given two semanticMly equivalent representations R1 and R2 there is always a possibility that R1 generates a string S but that R2 doesn't because R2 is","*The work reported here has been carried out ,as part of the ESPRIT project P393 ACORD on \"The Construction and In-terrogation of Knowledge-B~es using Natural Language Text and Graphics\". It is the result of joint work with Michael Reape of the Center for Cognitive Science, University of Edinburgh (Scotland, UK)."]},{"title":"2 Generating from a deep structure","paragraphs":["It is sometimes the case that a grammar will assign to a string several possible derivations with equivalent sementies. This phenomena is particularly acute in categorial grammars [2] and is referred to in the literature as that of spurious ambiguity. In grammars where the semantics is built by unification, the syntactic differences holding between these equivalent semantics resides in the relative ordering of the subformulae within the formula. That is, there is a direct relationship between the syntactic shape of a semantic formula and the derivational history of the corresponding string. Consequently, a given formula will be non-canonk:al wrt to a particular grammar G if the relative sequencing of its subformulae does not reflect a possible derivation in C. Hence, to allow for generation from non-canonical input, we need to abstract away from the derivational information reflected in the linear ordering of the input formula. Three major alternatives come to mind. First, we could try to generate all sentences whose semantics are logically equivalent to the input semantics. In uc(~, this means that generation is carried out with the two additional logical axioms of associativity and commutativity. However, this solution produces a search space factorial in the number of conjunction s and must thus be rejected as computationally intractable. 1 127 The second possibility is to define a semantic representation language for which all well-formed formulas are in normal form. This approach is essentially unavailable to any grammar framework in which the semantics of a given expression results from the unification of partially specified semantic representations because normal forms can only be defined on languages with fully instantiated formulae. A third possibility consists in generating from an alternative representation i.e. one that is related to but not identical with the semantic representation used by the grammar. This is what we chose to do. The alternative representation we adopted is closely related to"]},{"title":"D-structure","paragraphs":["in cn theory where"]},{"title":"D-structure","paragraphs":["is a level of syntactic structure which mirrors semantic functor-argument dependencies. Syntactic information is encoded in terms of schematic X theory familiar from modern generative grammar. The deep structures (DS) we generate from consist of four types:"]},{"title":"heads, complements, modifiers","paragraphs":["and"]},{"title":"specifiers","paragraphs":["(we follow LEG f-structure and ucc subcategorisation structure in treating subjects as ordinary complements rather than specifiers of clauses) whereby"]},{"title":"Specifiers","paragraphs":["are of the form: specifier(Semantics, Head). That is, they specify their own semantics and the properties of their head. In contrast,"]},{"title":"Heads","paragraphs":["are of the form: head(Semantics, ArgList, AdjunctList). That is, they specify their own head semantics and a list of arguments and adjuncts which are also either specifier or head structures. All of these structures also allow the encoding of syntactic requirements on arguments and adjuncts. The use of DSs has two other consequences. First, by allowing for the association of syntactic with semantic information,"]},{"title":"D-structures","paragraphs":["offer a way to mediate the results of linguistic decisions made by an eventual planner to the generator. This may be useful. For instance, NP planning could be accounted for. In the present context, a planner is any system which given some information about"]},{"title":"what","paragraphs":["to say will return some decision about"]},{"title":"how","paragraphs":["to say it. For instance, if we want to expre,~s the fact that Jon runs, the planner will have to decide on"]},{"title":"how","paragraphs":["to refer to Jon, i.e. it could decide to describe him using a complex NP as in"]},{"title":"'the man with the red scarf who stands negt to Irene',","paragraphs":["or a pronoun e.g."]},{"title":"'he'","paragraphs":["or simply his name i.e."]},{"title":"'.Ion'.","paragraphs":["The point is that the syntactic decision made by the planner must be communicated to the generator. Since DSs contain syntactic information, they are a good candidate for the necessary interface between planner and generator. A second advantage of DSs is that because they are language independent, they allow for language independent generation. That is, for any acceptable input deep structure, the algorithm presented below will generate e.g., a French sentence if coupled with a UCG grammar for French and an English sentence if coupled with a coo grammar for English. This is only possible because the input deep structure the generation algorithm relies on is both sufficiently abstract to be language-independent and general enough that it can be mapped onto language dependent surface syntactic structures. Language independent generation is discussed in more detail in section 4. In relation with the problem raised by non-canonical input, an important property of DSs is that they contain no indication of either surface syntactic order of the complements and adjuncts or of the relative scope of quantifiers occurring in either complements or modifiers. In-stead, thematic dependencies between subformulae are kept track of by the X schema where no reference is made to derivational history. The generator is thus free to realize both scope and surface syntactic structure in any way which is consistent with the deep structure specification and the particular grammar used. The reader might object to this elimination of scope distinctions. However, within UOG any scope distinctions which are produced by the individual grammars or as a result of some semantics construction process are in fact artefactual. Further-more, it might reasonably be argued that it should be possible to generate all possible scopes. This is typically done with"]},{"title":"quantifier shifting","paragraphs":["rules. Our solution is simply not to specify scope. An immediate consequence of using DSs is that non-canonical input is no longer a problem. The reason for this simply is that the generation algorithm no longer relies on the assumption that the input semantic representation i8 canonical i.e. derivable under the grammar used. Rather, the assumption is that the input will be some well-formed DS that will contain all the information contained in the corresponding semantics but none of the information embodied in the linear ordering of the formula about the derivational history of the corresponding string."]},{"title":"3 The basic algorithm 3.1 A brief introduction to UCG","paragraphs":["In UOO the basic linguistic unit is a"]},{"title":"sign","paragraphs":["which includes phonological, syntactic, semantic and ordering information. In the sequel, a sign will be represented either by a complex feature structure or as Pho :Synt :Sera: Drder. The phonological field of a sign contains its orthographic string. The syntactic field is categorial i.e. it can be either basic (e.g s,np,n etc) or complex in which case, it will be of the form"]},{"title":"C/Sign","paragraphs":["where C is a syntactic field and"]},{"title":"Sign","paragraphs":["is a sign. Moreover, any basic category can be assigned some morphosyntactic information. For instance"]},{"title":"s[fin]","paragraphs":["denotes the category"]},{"title":"sentence","paragraphs":["with morpholog-y feature value:"]},{"title":"finite.","paragraphs":["The semantic field contains the semantics of the expression whereby the semantic representation language is a linear version of Discourse Rep-resentation Theory in which each condition is preceded by a sorted variable called the index. As in most unification based grammars, the semantics of any expression results from the unification of the semantics of its subparts. Finally, the Order field is a binary feature with value either"]},{"title":"pre","paragraphs":["or"]},{"title":"post","paragraphs":["which constrains the applicability of grammar rules. Grammar rules in uco are of two types: binary and"]},{"title":"128 2","paragraphs":["unary. Binary rules include forward and backward functional application. These are stated below.","Pho:(Synt/Sign):Sem:0rder, Sign","--> Pho:Synt:Sem:Order if the order value of Sign is pro","Sign, Pho:(Synt/Sign):Sem:Order","--> Pho:Synt:Sem:0rder if the order value of Sign i8 post Unary rules are of the form c~ --+ fl where c, and fl are signs. Unary rules are used for the treatment of unbounded dependencies, syntactic forms of type-raising and subcategorlsation for optional modifiers. aetive(SignO,Active), apply(SignOoActive,Result), retrleve(DS,SubDS,NewDS), generate(SubDS, Active), reduee(Result,Sign,NewDS). The algorithm presented above makes many simplifying assumptions which are incompatible with a wide coverage uoc grammar. To produce a complete generator with respect to uoo we need to extend the basic algorithm to account for type-raised NPs, identity semantic functors, lexical modifiers and unary rules. For more details on the general content of these extensions see Ill. For their implementation cf. the listing of the generation algorithm given in the appendix."]},{"title":"3.2 A sketch of the algorithm","paragraphs":["Following work by [11, [5] and [3], the algorithm we present here follows a mixed top-down and bottom-up strategy. The generation process starts with a deep structure DS and a sign Sign whose syntax embodies the goal category (e.g. sentence(finite)), get deepstr info extracts from the deep structure some semantic (Sere) and syntactic (Synt) information on the next sign to be generated. create sign creates a new sign Sign0 on the basis of Sem and Syn~. Lexlcal look-up on Sign0 returns a sign with instantiated syntax and phonology. The call to reduce ensures that this lexical sign is reduced to the goal sign Sign in the process instantiating the generated string.","generate(DS. Sign) :- get_dsepstr_info(DS,[Synt,Sem],RestQfDS), create sign(Synt,Sem,SignO), lexical(SignO), reduce(SignO,Sign0Rest0fDS). There are two main ways of reducing a sign Sign0 to a goalsign Sign. The base case occurs when Sign0 unifies with Sign and the deep-structure is empty i.e. all the input semantic material has been made use of in generating the result string. The recursive case occurs when Sign0 is a syntactic functor. If the syntax of Sign0 is of the form Result/Active, we apply Result/Active to Active thus getting a new sign Result. retrieve nondeterministically retrieves from the current deep structure DS, a substructure SubDS and returns the remaining deep-structure NewDS. The argument Active is then generated on the basis of the extracted sub..structure SubDS with a new goal sign whose syntax is that predicted by the syntactic functor Sign0. The resulting sign Result is recursively reduced to the original go,~l sign Sign. reduce (Sign. Sign, [ [] 0 [] ] ) . reduce (SignO, Sign, DS) :-"]},{"title":"4 Bilingual Generation","paragraphs":["Consider the following synonymous sentences. a The mou.,m misses the cat b Le chat manque ~l la souris","(Lit. the cat misses to the mouse)"]},{"title":"(1)","paragraphs":["There are two main differences between (la) and (lb). First, a NP (the mouse) translates to a PP ( g~ la souria). Second, a structural transfer occurs i.e. the object NP in (la) becomes a subject in (lb) and vice-versa. For the generator described above, this poses no particular problem. Because DSs encode thematic rather than grammatical dependencies, structural transfer is no issue. Further, since at DS all arguments are represented as NPs x, the generation of (la) is straightforward. Generating (lb) is a little more intricate but results naturally from the interaction of the generator with the grammar =. Note that if the PP were represented as such in the DS, then generation would fail for the English sentence. This suggests that the deep structures we generate from offer the right level of abstraction for generation to be possible in several languages. The case of structural transfer illustrated in (1) is a good example of the problems that occur with generators that are unable to deal with non-canonical input. To illustrate this consider the following situation. Suppose that given two grammars, one for Engllsh(G~) and one for French (GF), (la) and (lb) each have one unique derivation with resulting semantics as in (2). a The(mouse(m), the(cat(c), miss(re,c)) b The(cat(c), the(mouse(m), tulsa(re,c)))"]},{"title":"(2)","paragraphs":["Furthermore, suppose (3a) is non-canonlcal with respect to C,~ (i.e. (an) is not derivable under C,~) and (3b) is non-canonic.M wrt GE. For any generator G that cannot deal with non-canonical input, this means that G cannot be used in a system where parsing occurs on one language IThis is in accordance with the view that prepositions oc° curing within argumental PPs have no semantic content. 2For more details on the generation of subcategorised PPs within UCG see [1}. 3 129 ' and generation on another. More to the point, if G is coupled with the grammar GE, then it will fail to generate when given (2b) as input - and similarly when coupled with GF and given input (2a). To understand why deep structures allow for grammar independent generation, let us first examine why traditional top-down/bottom-up generators such as the one described in [1] fail on non-canonical input. 3 Consider the case where we try to generate under Gs the English sentence in (la) from the semantic (2b) and- as already mentioned- (2b) is non-canonical wrt GE. The main steps of the generation process will be as follows. 4 Suppose the goal sign is"]},{"title":"SignO","paragraphs":["with category"]},{"title":"s[fin].","paragraphs":["First, a sign"]},{"title":"Sig~l","paragraphs":["is created whose semantics is as in (2b). Lexical access on"]},{"title":"Signl","paragraphs":["returns the sign for"]},{"title":"'the'.","paragraphs":["On the basis of the syntactic and semantic predictions made by"]},{"title":"Signl,","paragraphs":["the sign"]},{"title":"Sign2","paragraphs":["for"]},{"title":"'cat'","paragraphs":["is then generated. Reduction of"]},{"title":"Signl","paragraphs":["with"]},{"title":"Sign2","paragraphs":["yields a new sign"]},{"title":"Sign3","paragraphs":["with phonology"]},{"title":"'the cat'and","paragraphs":["syntax"]},{"title":"C/(C/np) 5.","paragraphs":["In turn,"]},{"title":"Sign3","paragraphs":["makes some predictions which lead to the generation of a new sign"]},{"title":"Sign4","paragraphs":["with syntax"]},{"title":"C/(C/np)","paragraphs":["and phonology"]},{"title":"'the mouse'.","paragraphs":["Finally, on the basis of"]},{"title":"Sign4,","paragraphs":["the sign"]},{"title":"Sign5","paragraphs":["for"]},{"title":"'miss'","paragraphs":["is generated. At this point in generating, the two signs in (3) must combine to reduce to a sign with category"]},{"title":"C/np.","paragraphs":["pho:~i~) synt : C/ pho : Wa synt:C/ pho:themouse syat:np sem :m.mouse(m) order:Of sem:VP order:Of order:02 pho : misses I pho : Wa","synt :s/ synt : np[nom] sere : m.NPI order : pre sem : m.miss(m,c) order : 03 pho : Wb"]},{"title":"/ sr t: npb ]","paragraphs":["sere : c.NP2 order : post But under ti~e UCG rules of combination (see 3.1), these two signs cannot combine because of the unification clash occuring between the semantics of the accusative NP in the verbal sign (c.NP2) and that of the NP sign within","aNote that in this case, reduction to normal form is no longer a possible solution even if we were able to define a normal form for our semantic representation language. For suppose that (2a) is the normal form, then (lb) is not derivable and if (2b) is, then (la) is not derivable.","4For more information on the details of the generation procedure, see [1].","~For the sake of clarity, the syntactic part of"]},{"title":"Sign3","paragraphs":["is here simplified in that non-syntactic fields (Phonology, Semantics etc.) are omitted. Note also that in UCG, NPs are typeraised i.e they are assigned the syntactic category"]},{"title":"C/(C/np)","paragraphs":["as opposed[ to just"]},{"title":"np.","paragraphs":["the sign for"]},{"title":"'the mouse'","paragraphs":["(m.mouse(m)). Hence generation fails. Consider now how the problem is dealt with when generating from deep structures. Rather than being as indicated in (2b), the input to the generator is 6"]},{"title":"head(miss(m, e), [specifier(the, head(moose(m), [], [])), specifier(the, head(cat(e), [l, [l))] []) (3)","paragraphs":["Roughly, generation will proceed as follows. Suppose the goal sign"]},{"title":"SignO","paragraphs":["has category"]},{"title":"s[fin].","paragraphs":["First, the semantics corresponding to the head of the clause (i.e."]},{"title":"mi,Js(m, c))","paragraphs":["is extracted from (3) and a sign"]},{"title":"Signl","paragraphs":["is created with semantics"]},{"title":"miss(re, c).","paragraphs":["Lexical access on"]},{"title":"Signl","paragraphs":["returns the sign given in (3) above."]},{"title":"Signl","paragraphs":["must then be reduced to"]},{"title":"SignO","paragraphs":["with category"]},{"title":"s[fin].","paragraphs":["At this stage, the remaining DS is"]},{"title":"[specifler(the, head(mouse(m),","paragraphs":["[], [])),"]},{"title":"speci/ier(the, head(cat(c), [l, []))] To generate the first argument","paragraphs":["of"]},{"title":"Signl,","paragraphs":["we then have the choice between generating on the basis of"]},{"title":"specifier(the, head(mouse(m),","paragraphs":["[], [])) or of"]},{"title":"specifier(the, head(cat(c),","paragraphs":["[], [1)) 7 As demonstrated above, if we generate the sign for"]},{"title":"'the mouse'","paragraphs":["first, reduction cannot apply and generation will fail. But here, failure is only temporary and on backtracking, the sign for"]},{"title":"'the cat'","paragraphs":["will eventually be generated; it will then reduce with"]},{"title":"Signl","paragraphs":["to generate"]},{"title":"Sign2","paragraphs":["with phonology"]},{"title":"'misses the cat'.","paragraphs":["At this point, the remaining DS will be"]},{"title":"[specifier(the, head(mouse(m),","paragraphs":["[], []))]. This will trigger the generation of"]},{"title":"Sign3","paragraphs":["with phonology"]},{"title":"'the mouse'","paragraphs":["which will then combine with"]},{"title":"Sign2","paragraphs":["to reduce to"]},{"title":"SignO","paragraphs":["with resulting phonology"]},{"title":"'the mouse misses the cat'.","paragraphs":["To generate the French sentence"]},{"title":"'Is chat manque h la 8ouris ',","paragraphs":["the same generation process applies but this time in connection with GF and in a reverse order i.e. the sign for"]},{"title":"'Is souris'(the","paragraphs":["mouse) is generated before the sign corresponding to the NP"]},{"title":"'Is chat'","paragraphs":["(the cat). Further, because in the French lexicon"]},{"title":"'manque'","paragraphs":["(miss) subcategorises for a dative NP, the preposition ~ is generated and combined with the sign for"]},{"title":"'Is souris'","paragraphs":["before reduction of the thus obtained PP with the verb. Because DSs make no assumption about the linear ordering of the constituents to be generated, the problem raised by non-canonicity simply does not arise."]},{"title":"5 Comparisons with Re][ated Research","paragraphs":["To compare our algorithm with previous work, we first show how it can be amended to phrase structure grammars. Consider the following extension to reduce.","reduce(SignO, Sign, DS) :- rule(Morn, SignO, Kids), 6For the sake of simplicity, the syntactic information usually contained in the deep structures input to the generator is here omitted. 7cf. the non-determinism of the retrieve predicate. 130 4 generate_sisters (Kids,"]},{"title":"DS, NewDS),","paragraphs":["reduce(gem, Sign, NewDS). gene:t:'ate_sisters([] , DS, DS)."]},{"title":"gene:t:afie_sisfiers([HIT], DS, NewDS)","paragraphs":[":- index (tI, Idx), me I; eh (Idx, DS, SubDS, NewDS 1 ), generate(SubDS, H), generate sisters(T, NewDS1, llewDS). This clause is very similar in structure to the second clause of reduce, the main difference being that the new claus(, makes fewer assumptions about the feature struotures being manipulated, rule enmnerates rules of the grammar, its first argument representing the mother con. stitu~ut, its second the head daughter and its third a list of non-head daughters which are to be recursively generated by the predicate generate sisters. The behaviour of this clause is just like that of the clause for reduce which implements the uc(; rules of function application. On tire basis of the generated lexical sign Sign0 an applical.ion of the rule is hypothesised and we then attempt to prove that ru]e application will lead to a new sign gem whiel, reduces to the original goal Sign. Having generalised our basic algorithm to phrase structure ~ran]mars, we can now compare it to previous work by [5} and [3] Van Iqoord's Bottom-Up Generator (BUG) is very similar in structure to our basic algorkhm. Closer examination of the. two programs however reveals two differences. The first is that daugthers in a rule are separated into those that })recede the semantic head and those that follow it. The ,'.econd more meaningful difference involves the use of a 'link' predicate implementing the transitive closure of the semantic head relation over the grammar rules. The link predicate is similar in purpose to reachibility table~ in parsing algorithms and contributes to reducing the search space by producing some syntactic information on the sign to be generated. Itowever, such a predicate is of litt.le use when generating with a categorial grammar in particular and with any strongly lexicalist linguistic theory in general since in these, the grammar rules are extremely schematised. Their information content is so impoverished that the computation of and resort to a link predicate cannot be expected to reduce the search space in an/meaningflfl way. In the algorithm presented above however~ this shortcoming is redressed by exploiting the syntactic information contained in the deep-structure we start from. In [5], Shieber et al. present a \"semantic-head-driven\" generation algorithm that is closely related to van Noord's. In contrast to Van Noord's algorithm however, this ~dgorithm also operate on grammars violating the sema~dic head con.~traint (SHC) according to which any sema~tic representation is a further instantiation of the semantic representation of one of i~s constituents called the semantic head. This is achieved as follows. First, a distlnction is made between chain--rules and non-chain-rules whereby non-chain-rules are used to introduce semantic material syncategorematically. The distinction between the two types of rules can be sketched as follows. i. Chain-rule (Sem, lhs --> Head(Sem), Sisters) 2. Non-Chain-rule (Sem, lhs(Sem) --> Daughters) (1) indicates that given a semantic Sere, a chain rule will be such that Sere unifies with the head daughter's semantics whilst (2) shows that non-chMn-rules are such that the input semantics must unify with the semantics of the lhs of the rule. The intuition is that non-chain-rules will help find the lowest node in the derivation tree whose semantics unify with the input semantics. Furthermore, the top-down base case for non-chain-rules corresponds to the case in which the lhs of the rule has no non-terminal daughters i.e. to lexieal look up. Consider now the top call to"]},{"title":"generate.","paragraphs":["generate(Root) :- non_chain rule(Root,Pivot,P.hs), generate rhs(Rhs)0 connect(Pivot,Root). Two cases obtain with regard to the applicatlon of the non- chain-rule predicate. Either the base case occurs and lexical look-up takes place exactly as in our algorithm or a non-chain-rule is triggered top-down before the conatituents in the rhs are generated by a recursive call to generate. Hence the solution to the introduction of syncategorematic material is essentially a reintroduc-tion of the top-down generation strategy. The result is that there is no guarantee that the algorithm will terminate. This point seems to have been overlooked in [5 t . Therefore, the extension may be of less utility than it appears to be at first sight although it may well be the case for linguistically motivated grammars that termination problems never arise."]},{"title":"6 Further Research","paragraphs":["The general backtracking reghne characterising the algorithm presented in this paper means that failure at a first attempt to generate might induce the recomputa-tion of partial results. Perhaps the use of a chart could contribute to enhance generation efficiency. Ii1 relation to [4] where chart edges contain no ordering information, it would be interesting to investigate whether during the generation process some ordering information can be recovered. That is, whether the chart could be constructed in such a way that t:he relative positioning of edges mirrors the knowledge embodied in the grammar about linear precedence within and between constituents. In this way, only the relevant part of the chart would need to be looked up before attempting to build a new edge. The algorithm described above is implemented ill CProlog on a Sun4 and constitutes part of the generation cola-5 131 ponent in the ACORD prototype. The generator can be coupled with either a UCG grammar for French or one for English thus generating either French or English sentences."]},{"title":"References","paragraphs":["[l] Calder, J., Reape, M. and Zeevat, H. [1989] An Algorithm for Generation in Unification Categorial Grammar. In"]},{"title":"Proceedings of the Fourth Conference of the European Chapter of the Association for Computational Linguistics,","paragraphs":["University of Manchester Institute of Science and Technology, Manchester, England, 10-12 April, 1989, 233-240."]},{"title":"[2] Gardent, C.,","paragraphs":["Bes,"]},{"title":"G., Jurle,P.F. and","paragraphs":["Baschung, K. [1989] Efficient P;~rsing for French. In"]},{"title":"Proceedings of the 27th annual meeting of the Association for Computational Linguistics,","paragraphs":["University of British Columbia. Vancouver, 26-29 June 1989, 280-287.","[3] van Noord, G. [1989] BUG: A Directed Bottom Up Generator for Unification Based Formalisms. Manuscript. Department of Linguistics, University of Utrecht, M~rch 14, 1989.","[4] Shieber, S. [1988] A Uniform Architecture for Parsing and Generation. In"]},{"title":"Proceedings of the 12th International Conference on Computational Linguistics,","paragraphs":["Budapest, 22-27 August, 1988, 614-619.","[5] Shieber, S., van Noord, G., Moore, R. and Pereira, F.C.N. [1989] A Semantic-Head-Driven Generation Algorithm for Unification-B,nsed For-malisms. In"]},{"title":"Proceedings of the","paragraphs":["27th"]},{"title":"Annual Meeting of the Association/or Computational Linguistics.","paragraphs":["University of British Columbi.% Vancouver, British Columbia, Canada, 26-29 June, 1989, 7-17.","[61 Zeevat H., Klein, E. and Calder, J. [19871 An Introduction to Unification C~tegorial Grammar. In Haddock, N.J., Klein, E. and Morrill, G. (eds.)"]},{"title":"Edinburgh Working Papers in Cognitive Science, Volume 1: Categorial Grammar, Unification Grammar and Parsing.","paragraphs":["Listing of the whole program (Low level procedures have been omitted)"]},{"title":"generate(DeepStro Sign) :- get_deepstr_info(DeepStr°[Synt. Sem],RestOfDeepStr). create_sign(Synt°Sem°SignO), lexical(Sign0), reduce(SignO,Sign,Rest0fDeepStr). reduce(SignoSigno [ [] o [] ] ). reduce(SignO°Sign° DeepStr) :- active(SignO,Active), apply(SignO°Active,Reault), retrieve(DeepStr,SubDeepStr,NewDeepStr)° generate(SubDeepStr, Active), reduce(ResultoSign°NewDeepStr). reduce(SignO, Sign. DeepStr) :- transform(SignO, Signl, DeepStr, NewDeepStr) reduce(Signl° Sign, NewDeepStr). Identity Semantic Fun(torn transform(Sign,NewSign,DeepStr,DeepStr) :- not_idsign(Sign). create_id_functor(IdSemFctor, Sign), identity(IdSemFctor), apply(NewSign. IdSemFctor0Sign)° defreeze_order(AdjSign, Sign, NewSign) % Lexical Adjtmcts traneform(Sign,NewSign0DS,NewDS) :- create_lexical_adjunct(Sign, ASign0DS,NewDS,DS2) o generer(DS2, ASign), apply(NewSign, ASign, Sign). Type-raise Verbs to C/(C/NP) transform(Sign,NewSign,DS,NewDS) :- type_raise vb to_np(Sign, RaisedSign), getjub deepstr(Sign0 DS, SubDS, NewDS) generer(SubDS, RaisedSign), apply(NewSign, RaisedSign, Sign) 132 Unary rules transform(Sign,NewSign°DeepStr,DeepStr) unary_rule(NewSign,Sign). Identity Semantic Functor (Case marking Prepositions) transform(Sign,NewSign,DeepStr,DeepStr) active(Sign,VB), active(VB, NP), category(NP, np) o create_id_prep(Np,PREP)° identity(PREP),","paragraphs":[]}]}