{"sections":[{"title":"SUMMARY OF SESSION 2: Spoken Language Systems I","paragraphs":["Chairperson- P. Price This session included descriptions of Spoken Language Systems under development at BBN Systems and Technologies, Carnegie Mellon University, Massachusetts Institute of Technology and Unisys. The topics covered a variety of issues including semantic interpretation (BBN), modeling \"noise words\" for spontaneous (vs. read) speech (CMU), dialogue management (Unisys) and systems issues (MIT and Unisys). Dave Stallard presented a survey of the natural language understanding effort at BBN. The principal topic presented was the change in formalism for semantic interpretation from a Montague-style rule-for-rule mirror of syntax to a unification framework, as has been used at various sites, including SRI and TI. Wayne Ward presented results in dealing with \"noise\" in speech. The \"noise\" in question included pause-filler words, mouth sounds, paper rustling, etc. The technique for dealing with the noise was simply to model these noises as words and to train them as other words are trained in the CMU SPHINX system. The result did not seem to affect performance much for \"clean\" speech (speech without these \"words\") and dramatically reduced the error rates for speech containing these \"words\". These are encouraging results for spoken language systems. The MIT Voyager system was presented principally in the form of a videotape that showed a complete SLS system for getting directions concerning the Harvard-MIT area: a subject speaks a sentence which is recognized by the SUMMIT system, sent to TINA for interpretation and then sent to the VOYAGER backend for execution. The system is not yet real-time, but represents an important first step in developing spoken language systems. Lynette Hirschman presented an analysis of the Unisys experience in porting the PUNDIT system, originally designed for message processing, to a query-answering system for the VOYAGER application. The resulting architecture includes a general dialogue manager which can be used for a variety of interactive applications to maintain and control discourse coherency. Lynette also presented the last paper in the session: Computational Requirement for a Spoken Language System, in which she presented ways of parallelizing parsing steps and the resulting effects on computation. 37"]}]}