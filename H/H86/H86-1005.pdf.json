{"sections":[{"title":"RESEARCH IN NATURAL LANGUAGE PROCESSING University of Pennsylvania Department of Computer and Information Science","paragraphs":["This a brief report publications. FACULTY STUDENTS FACILITIES summarizing our work to date, our intermediate and long term goals, and a summary of some of our Aravind Joshi, Tim Finin, Dale Miller, Lokendra Shastri, and B°nnie Webber Brant Cheikes, John Dowding, Amy Felty, Ellen Hays, Robert Kass, Ron Katriel, Sitaram Lanka, Megan Moser, CGopalan Nadathur, MaryAngela Papalaskaris, Martha Pollack, Robert Rubinoff, Yves Schahes, Ethel Schuster, Sunil Shende, Jill Smudski, Vijayshankar, David Weir, Blair Whitaker LINC (Langauge, Information, and Computation) laboratory, which consists of a dedicated VAX 11/785, I0 Symbolics Lisp machines, 7 HP 68020 based AI workstations, a SUN workstation, several Macintoshes, and a laser printer. These machines are networked together and to other research facilities in the department."]},{"title":"MAJOR THRUST","paragraphs":["Natural language interfaces providing support for many different communicative functions. • Providing definitions of concepts * Recognizing and correcting user misconceptions * Providing explanations • Offering to provide information later, when known • Verifying and demonstrating understanding • Exploiting and enriching the context of natural language discourse between user and system."]},{"title":"WORK-TO-DATE","paragraphs":["• Integration of RUS-TEXT-MUMBLE (RTM) - This effort involves integrating three natural language system components (BBN's RUS parser-interpreter, McKeown's TEXT system (developed at Penn), and McDonald's MUMBLE system (received from U. Mass in January 1985). This integration of three independently developed systems has required substantial effort. The version of RTM (to be completed in May 1986) [1] accepts a limited number of English language requests for definitions of, descriptions of, or comparisions between terms in the ONR database used by Kathy MeKeown in her development of TEXT; [2] formulates appropriate reponses using TEXT and outputs those responses in English using MUMBLE; and [3] runs on a SYMBOLICS Lisp machine. This work has been done by Moser, Whitaker and Rubinoff. • Initial work on incorporating a sense of relevance in monitor offers. Mays' dissertation work on monitor offers was limited to issues of competancy. This work is being done by Cheikes and Schabes. • Completion of McCoy's dissertation work on correcting certain types of object-related misconceptions and implementation of a system called ROMPER which generates such corrections. (MUMBLE is used as the tactical generation component of this system as well.) • Completion of Hirsehberg's dissertation work on scalar implicatures and their use in constructing non-misleading responses. • Completion of Pollack's dissertation work on plan inference in which user's and system's beliefs about actions and plans is dccoupled. • Continuation of work on integrating scalar-implicature-based reasoning within a general framework of circumscription-based non-monotonic reasoning. • Development of methods for converting proofs in a system akin to first-order resolution into natural deduction (ND) • proofs, which are then reorganized into cohesive paragraphs using Chester's 1976 algorithm."]},{"title":"30","paragraphs":["• Development of methods of converting modal resolution proofs into modal ND proofs and higher-order resolution proofs into higher-order ND proofs. • Initial development of domain-independant tools for expressing and reasoning about user models - in particular, for defining hierachies of stereotypical users, representing individual users, and drawing inferences about them using a default logic. • Continuation of basic research on local coheLeuce of discourse using the notions of centering and syntax, semantics, and parsing of tree adjoining grammars. FUTURE PLANS Having gained the experience of integrating three natural language systems and carrying out some of the basic research as described in the previous section, we have now developed the plan described below, which summarizes the near term and long term goals. Near Term Goals","We have three tangible goals for the next year: • Completing the RTM demonstration system (using the existing domain and knowledge representation) and producing a videotape which explains and demouslrates it. • Developing TEXT into a more modular tool for defining and comparing terms, on the order of RUS and MUMBLE. This will eliminate its tie to a particular knowledge representation and increase its portability. • Acquiring familiarity with the PENMAN approach to NL generation through acting as a beta-test site for NIGEL. Long Term Goals Support for NL Definitions - Enriched Knowledge Representation In our original proposal, we stated our intention of employing a richer knowle.xlge representation as the basis for our work on text generation, especially for constructing definitions. Our original idea was to make use of BBN's NIKL systenx In the past year though, we have become aware of some of NIKL's limitations, which essentially make it non-optimal, even as a next step, for our text generation work. On the other hand, we have identified several features with which a NIKL-like language could be enriched to make it more suitable for our work:","• associating non-definitional information with concepts in a way that maintains the underlying structure of that"]},{"title":"information, without","paragraphs":["interferring with NIKL's automatic classification"]},{"title":"mechanism.","paragraphs":["• associating \"evidential\" information with concepts, especially frequency information - how often the concept is known to display particular features. • allowing for what appears to be conflicting information coming down through inheritance - e.g., information that is contrary to expectations grounded in an alternative perspective on a concept • allowing mutual definition of concepts - each being defined with reference to the others in a set • incorporating notions of time and change - allowing the defming properties and evidential properties of concepts to include how they change over time • allowing assertions about usual relations between properties of subtypes Work on an enriched knowledge representation that includes all these features in a well-motivated way will take several years. However one that includes at least the first three of them can probably be developed over the next two years, with work on employing it in text generation beginning after the first six months to a year after the start of that work. Support of NL Definitions - Use of Discourse and User Models The TEXT system, as it is currently structured, will produce the same definition for a concept (or comparison between two concepts) whenever it is asked. It does not take into account what the user may have already found out about the concept, or what it is implicitly being contrasted with (e.g., some other concept the user has recently asked about), or what the user's goal is in making the request. Hence, other directions in which we would like to take this definitional/clarificational capability is to increase its sensitivity to (1) the discourse history, to avoid repetition and possibly to take advantage of the additional clarity brought by contrasting a new term to one explained before; (2) the user's level of expertise, to avoid either stating the obvious or going more deeply into a concept than the user can understand; and (33) the user's goals, to focus on those aspects of the concept being defined (or concepts being compared) which are significant to the current tasL (The latter is related to the notion of \"perspective\" used in Kathy McCoy's recent thesis here.) For both these apects of user modelling (in contrast with the first point, which can be developed using the current discourse alone), we will draw on the other work being done here on domain-independent user-modelling mechanisms. This proposed work must be done in a domain in which tasks can be characterized and recognized. Thus we plan to do this initially in investment advising dmnain that we have started to develop. Work on 31 incorporating and using discourse history will involved about a one-year effort, once the knowledge base is built. Work on incorporating and using a model of a user's expertise and goals will take more time, on the order of two to three years. Explanations Again in our original proposal, we proposed work on constructing natural language explanations - more specifically, on ways to loosen the current tight coupling between the form of the system's proof of some statement to the form of its explanation of why the statement is true. This coupling has kept systems which should be able to explain their reasoning from employing stronger proof methods which do not have a natural, understandable form of presentation to their human users.","Our immediate goals involve: * developing a demonstration system which responds to NL queries posed to RUS by doing an efficient first-order resolution-based proof, transforming that proof into an ND proof, organizing that proof according to an improved version of the Chester algorithm, and then producing an English version of the text using MUMBLE or NIGEL. • abstracting from the three separate sets of proof conversion methods (noted under WORK-TO-DATE) into general methods of transforming any resolution-style proof in any logic into its corresponding ND proof. • determining whether existing methods of organizing fwst-order ND proofs into paragraphs are applicable to ND proofs in these stronger logics or whether more must be done to produce high-quality, cohesive, understandable text. Our loog-term goals remain as stated in our original proposal - the production of explanations sensitive to users' beliefs, expertise, desired level of detail and expectations. In this long-term research, we see taking expertise and desired level of detail into account in determining how much of the ND proof is made explicit. Of more interest is how users' beliefs and expectations should affect the explanations. Work on scientific explanation has shown that central to the explanation of what is the case is a set of alternative situations which are not the case. One explains what is in contrast to what is not. However, this requires additional work. to prove of each of the alternatives (which may be given explicitly by the user - \"why this and not thatT - or inferred from the system's model of the user's expectations) that it is not true. Our planned approach involves guiding the (failing) proof of each alternative against the successful prooL The point is that although there may be many failing proofs of each alternative, the most relevant of these in the current situation is the one which is analogous - up to the point of failure - to the original successful proof not only should this technique provide relevant information, but is should also be efficient in reducing the search space. We expect this work to take on the order of two to three years, provided we have enough resources to pursue it in parallel with our more near-term goals. Natural Language Parsing and Generation While continuing to use the RUS system, we will continue our work on tree adjoining grammar (TAG) both from the parsing and generation points of view. TAGs lead to some attractive approaches to parallelizing parsing and also seem to provide natural planning units for generation. This work will be integrated with our future work on parsing and generation. Our first language generator (used by TEXT) was one based on Kay's Functional Unification Grammar. While theoretically elegant, it was unacceptably slow (in its straightforward implementation), leading us last year to import the MUMBLE generator from McDonald at University of Massachusetts and adapt it to work with TEXT. Using MUMBLE has produced a 60-fold speed-up in generation time. However, adapting MUMBLE to work with TEXT and, independently, with two other systems has made us aware of MUMBLE's limitations, primarily its lack of knowledge of words or grammar. EssentiaUy, MUMBLE's knowledge is limited to how to realize particular message units (i.e., to choose an acceptable one from an a priori specified set of choices), given constraints already imposed by message units that have already been realized. The large amount of work that must be invested in building a MUMBLE lexicon and the lack of inter-application portability of anything but the control structure comes from this fact - that one has to completely specify each set of choices beforehand for each message unit and the sets are completely application specific. We propose to work on the development of a new architecture, including our work on tags, that avoids these limitations by having more knowledge of syntax and words and hence is more portable between applications. The time frame for this project is approximately three years. Anaphora Resolution The RUS parser/interpreter we received from BBN uses a limited method of resolving definite pronouns and noun phrases that is only a bit more advanced than the one originally developed for BBN's LUNAR system back in 1971. Since then, there have been major theoretical advances in our understanding of discourse anaphora (in the works of Grosz (at SRI), Joshi, Sidner (at BBN), Webber, and Weinstein), but these theoretical advances have not yet found their way into natural language understanding systems. We feel strongly qualified to undertake this work, having two of the major participants (Joshi and Webber) here at Penn already, and want to do so. For us, it is both of research interest and of practical importance, since it can mean a major improvement in system's understanding abilities. We will also integrate our work on tags with this effort as it relates to parsing and generation. This work wiU also complement additional work being done here on a theoretical and computational account of anaphoric reference to actions and events. We see this work as taking about two to two and a half years. 32"]},{"title":"User Modeling","paragraphs":["The need for systems to model the knowledge and beliefs of their users has already been pointed out. We plan to address a number of issues which underly the succesful development and encorporation of explicit user models. Our current domain-independent user-modelling system, GUMS, provides mechanisms for defining hierachies of stereotypical users, representing individual users, and drawing inferences about them using a rich default logic. We will continue to develop this system as a tool which will support the user modeling needs of various applications. We also plan to study the problem of bow new knowledge of individual users can be derived from their regular interaction - that is, how relevent information about users can be inferred from their queries and responses. In other situations it may become necessary for the system to explicitly pose a few crucial questions to the user to determine what he or she does and does not know."]},{"title":"System Integration","paragraphs":["Finally, we plan to begin work on system integration. In recent years, we have identified many types of behavior that interfaces to database systems and expert systems should demonstrate. Beginning with Kaplan's work on recognizing and responding to existential presupposition failures in his COOP system, we have developed and produced several modules, each demonslrating another type of desired behavior. These include the ability to recognize and respond to type failures, the ability to respond to object-related misconceptions, the ability to calculate and offer competant database monitors, the ability to use scalar implicatures to convey additional information, and the ability to respond to a class of \"inappropriate\" queries, and various paraphrase abilities. Following the publication of Kaplan's thesis, the features of his COOP system were soon incorporated into several database interfaces (both natural slanguage and formal query language). This gave the resulting systems the ability to give two types of responses: either a direct answer, ff there was one, or a statement concerning the abscnse of individuals satisfying some description in the given query. Now we plan to tackle the more significant problem related to this: Given a system that is able to call upon a variety of response strategies, how does it decide what to do in a given circumstance? This is the issue we plan to explore by investigating the integration of multiple communicative behaviors. Given a system with several different types of useful behaviors, which can be combined in various ways, can one efficiently and effectively coordinate a response that is better (i.e., more useful, more helpful and more understandable) than simply a (direct) answer. While we speculate that it will be the case that identifying what one might consider the best response might take complex reasoning about the user's goals, level of expertise and need-to-know with respect to what the answer (if any) actually is, we also plan to look at how, with more limited resuurees, we can still improve system behavior. This aspect of our future plans is the most long term, involving both the actual component integration itself (in which, in many cases, it is only the basic ideas that can be carried over, where the component must be re-programmed entirely to fit into the integrated system) and the development of that part of the total system that reasons about what kind of response(s) to give. The time frame here is approximately four years."]},{"title":"Architecture","paragraphs":["We plan to investigate parallel and connectionist architectures and algorithms for realizing our systems, especially those for knowledge representation, reasoning, explanations, and integrated parsing and generation."]},{"title":"Abstracts of Recent Technical Reports INTERACTIVE CLASSIFICATION A Technique for the Aquisition and Maintenance of Knowledge Bases,","paragraphs":["Tim Flnln and David Silverman, MS-CIS-84-17. The practical application of flame-based knowledge-based systems, such as in expert systems, requires the maintenance of potentially very large amounts of declarative knowledge stored in their knowledge bases (KBs). As a KB grows in size and complexity, it becomes more difficult to maintain and extend. Even someone who is familiar with the representation and the contents of the existing KB may introduce inconsistencies and errors whenever an addition or modification is made. This paper describes an approach to thisproblem based on a tool called an interactive classifier. An interactive classifier uses the contents of the existing KB and knowledge about its representation to assist the person who is maintaining the KB in describing new KB objects. The interactive classifier will identify the ~ppmpriate taxonomic location for the newly described object and add it to the KB. The new object is allowed to be a generalization of existing KB objects, enabling the system to learn more about existing objects. The ideas have been tested in a system call KuBIC, for Knowledge Base Interactive Classifier, and are being extended to a more complete knowledge representation language."]},{"title":"Correcting Object-Related Misconceptions: How Should The System Respond?,","paragraphs":["Kathleen F. McCoy, MS-CIS-84-1& This paper describes a computational method for correcting users' misconceptions concoming the objects modeled by a computer system. The method involves classifying object-related nnsconceptions according to the knowledge-base feature involved in..the incorrect information. For each resulting class sub-types are identified, according to the structure of the knowledge base, wmcn indicate what information may be supporting the misconception and, therefo.re, what informatio 9 to tnelufle .m the rysponse. Such a characterization, along with a model of what the user knows, enables IRe system to reason m a aomam-moepenoent way about how best to correct the user."]},{"title":"33 Default Reasoning in Interaction,","paragraphs":["Aravind"]},{"title":"Joshi, Bonnie Webber,","paragraphs":["and Ralph Welschedel, MS-CIS-84-58 Nonmonotonic reasoning is usually studied in the context of a logical system in its own right or as reasoning done by an agent, in which the agent reasons about the world from partial information andhence may draw conclusions unsupported by traditional logic. The main point of departure here is looking at nonmonotonic reasoning in the context of interacting with another agent. This information is partial, in that the other agent neither will not can make everything explicit. Knowing this, the agent may attempt to derive more from the interaction than what has been made explicit, by. reasoning by default about what has been m~£te explicit (often by contrast with what he assumes would have been made explicit, were something else the case). Thus there can be rules for default reasoning that are operative m~'d~'~'~-ac~\"~ situation Cinteractional defaults\") that are not operative with only a single agent."]},{"title":"Preventing False Inferences,","paragraphs":["Aravind Josh[, Bonnie Webber, and Ralph M. Weischec~e!, MS..CIS.84-5~ In cooperative man-machine interaction, it is taken as necessary that a system truthfully and informatively respond to a user's question. It is not, however, sufficient. In particular, if the system has reason to believe that its planned response might lead the user to draw an inference that l~ows to be false, then it must block it by modifying or adding to its response. The problem is that a system neither can nor should explore all conclusions a user might possibly draw: its re~oning must be constrained in some systematic and weU motivated way."]},{"title":"Living Up To Expectations: Computing Expert Responses","paragraphs":["Aravind"]},{"title":"Josh[, Bonnie","paragraphs":["Webber, and Ralph Weischedel, MS-CIS-84-60 In cooperative man-machine interaction, it is necessary"]},{"title":"but not suJJiclent","paragraphs":["for a sustem to respond truthfully and informatively to a user's question. In particular, if the system has reason to believe that its planned response might mislead the user, then it must block that conclusion by modifying its response. This paper focusses on identifying and avoiding potentially misleading responses by acknowledging types of \"informing behavior\" usually expected of an expert. We air.erupt to give a formal account of several types of assertaUons that should be included in response to questions concerning the achievement of some goal (in addition to the simple answer), lest the questioner otherwise be misled."]},{"title":"A Modal Temporal Logic for Reasoning About Changing Databases with Applications to Natural Language Question Answering,","paragraphs":["Eric Mays, Aravind Joshl, Bonnie Webber, MS-CIS-85-01. A database which models a changing world must evolve in correspondence to the world. Previous work on natural language UeStion answering systems for databases has largely ignored the issues which arise when the database is viewed as a dynamic ather than a static) object. We investigate the question answering behaviors that become possible with the ability to represent and reason about thepossible evolution of a database. These behaviors include offering to monitor for a possible future state of the database as an indirect response to a query, and directly answering questions about prior and futare possibility. We apply a propositional modal temporal logic that captures possibility and temporality to represent and reason about dynamic databases, and present a sound axiomatization and proof and proof procedure."]},{"title":"Explaining Concepts in Expert Systems: The CLEAR System,","paragraphs":["Robert Rublnoff, MS-CIS-85-06, LINC LAB 02 Existing expert systems provide limited explanatory ability. They can explain the specific reasoning the system uses, but if the user is confused about the concepts and terms the system is using, no help is available. The CLEAR system allows users to ask for explanations of specific concepts. The system generates the explanaU~ns by examining the rule base, selecting rules that are relevant to the concept asked about. These rules are then turned into Engfish by various simple translation schemes and presented to the user, providing an explanation of how the concept is used by the system."]},{"title":"The Linguistic Relevance of Tree Adjoining Grammars,","paragraphs":["Anthony S. Kroch, Department of Linguistics, and Aravind K. Joshl, Department of Computer and Information Science, MS-CIS-85-16, LINC LAB 03 In this paper the linguistic significance of the Tree Adjoining Grammar (TAG) has been investigated. An important property of TAG is that it defines a constrained theory of syntactic embedding, one requiring that embedded structures be composed out of elementary structures in a fixed way, and one which forces co-occurence relations between elements that are separated in surface constituent structures to be stated broadly as constraints on elementary trees in which those elements are copresent. The extra generative power of TAG beyond context-free grammar emerges as a corollary of factoring recursion and co-occurence relations. The linguistic details specifically discussed are raising constructions, passive, and WH-movements."]},{"title":"A Computational Logic Approach to Syntax and Semantics","paragraphs":["Dale A. Miller and Gopalan Nadathur, MS-CIS-85-17 It is well known that higher-order logics are very expensive, and for this reason have been used to represent many problems in mathematics and theoretical computer science. In the latter domain, higher-order logics are often used to describe the semantics of first-order logics, natural languages, or programs, since the formalization of such semantics needs a recourse to quantification over the domain of functions and sets. In these settings, higher-order logic has generally been limited to a descriptive role. Once the formalization is made little has been made of it computationally, largely because there is abundant evidence that theorem proving in higher-order logics is very difficult. In this paper we shall look at a sublogic of a particular higher-order logic that is derived from Church s Theory of Types, and examine its representational power and its computational tractability. This sublogic can also be described as Horn clauses logic extended with quantifications over function variables and R-contraction. We shall present a sound and complete theorem prover for this logic, which uses higher-order unification and may be described as an extension of a unification procedure for the typed R-calculus. There are at least three ways in which this logic is different from the first-order logic that it generalizes. First l't possesses function variables which can be mstantiated with ~.-terms and evaluated through ~.-contractions. This provides the logic with a new source of computation. Second, since Z-terms do not have most general unifiers, the process off'mding appropriate unifiers must branch, and hence involves real search. This facet provides a new source of noncteterminism in specifying computations. Finally, this log.ic can directly encode f'trst-order logic m its term stucture and can manipulate such terms in logically meaningful ways. We illustrate this with examples taken from knowledge representation and natural language parsing."]},{"title":"The Role of Perspective In Responding to Property Misconceptions,","paragraphs":["Kathleen F. McCoy, MS-CIS-85-31, May 1985 In order to ad.ecluately respond to misconceptions involving an object's properties, we must have a ccontext-sensitive method for determining object similarity. Such a method is intrnduced here. Some of the necessary contextual information is captured by a new notion of"]},{"title":"object perspective","paragraphs":["It is shown how object perspective can be used to account for different responses to a given"]},{"title":"34","paragraphs":["misconception in different contexts."]},{"title":"Some Computational Properties of Tree Adjoining","paragraphs":["Grammars, ViJayshenkar and Joshl, MS-CIS-85-07 Tree Adjoining Grammar (TAG) is a formalism for natural language grammars. Some of the basic notions of TAG's were introduced in [Joshi,Levy, and Takahashi 1975] and by [Joshi, 1983]. A detailed investigation of the linguistic relevance of TAG's has been carried out in [Kroch and Joshi,1985]. In this paper, we will describe some new results for TAG's, especially in the following areas: (1) parsing complexity of TAG's, (2) some closure results for TAG'S, and (3) the relationship to Head grammars."]},{"title":"Grammar, Phrase Structure,","paragraphs":["Aravtnd K. Josht, MS-CIS-85-45 Phrase-slructure trees (phrase-markers) provide structural descriptions for sentences. Phrase-structure trees can be generated by"]},{"title":"phrase-structure grammars.","paragraphs":["Phrase-structure trees can be shown to be appropriate to characterize structural descriptions for sentences, including those aspects which are usually characterized by transformational grammars, by making certain amendations to CFG's, without increasing their power, or by generating them from elementary trees (phrase-markers) by a suitable rule of composition, increasing the ~powcr only mildly beyond that of CFG's. Structural descriptions provided by phrase-structure trees are used explicitly or implicltly in natural language processing systems."]},{"title":"Uestion, Answer and Responses: Interacting with Knowledge Base Systems,","paragraphs":["Bonnie Lynn Webber, MS-CIS-85-50, LINC"]},{"title":"O4","paragraphs":["The purpose of this chapter is to examine the character of information-seeking interactions between a user and a knowledge base system (KBS). In doing so, I advocate that a clear distinction be made between an answer to a c.luestion and a response. The chapter characterizes questions, answers, and responses, the role they play in effective information interchanges, and what is involved in facilitating such interactions between user and KBS."]},{"title":"A Theory Of Scalar Implicature,Julla","paragraphs":["Bell Hlrschberg, MS-CIS-85-56. The"]},{"title":"Relationship Between Tree Adjoining Grammars And Head","paragraphs":["Grammars, K. ViJay-Shanker, David J. Weir and Aravind K. Joshl, MS-CIS-86-01, LINC LAB 06 Tree Adjoining Grammars (TAG) and Head Grammars (HG) were introduced to capture certain structural properties of natural languages. These formalisms, which were developed independently, appear to be quite different notationaliy. In this paper we discuss the formal relationship between the class of languages generated by TAG's (TAL) and the class of languages generated by HG's (HL). In particular, we show that HL's are included in TAL's andthat TAG's are equivalent to a modification of HG:s called Modified Head Grammars (MHG's). The inclusion of MHL in HI.,, and thus the equivalence of HG's and TAG's, in the most general case remains to be established. We show that this relationship is very close both linguistically and formally, the difference hinging on the status of heads of empty swings and whether one deals with heads directly or with the left and right wrapping positions around the head."]},{"title":"Natural Language Interactions With Artflcial Experts,","paragraphs":["Tim Finin, Aravlnd K. Jeshl and Bonnie Lynn Webber, MS-CIS-86-16, LINC LAB 08). The aim of this paper is to justify why Natural Language (NL) interaction, of a very rich functionality, is critical to the effective"]},{"title":"]","paragraphs":["se of Expert Systems and to describe what is needed and what has been done to support such interaction. Interactive functions iscussed here include defining terms, paraphrasing, correcting misconceptions, avoiding misconceptions and modifying questions."]},{"title":"Higher.Order Logic Programming,","paragraphs":["Dale A. Miller and Gopalan Nadathur, MS-CIS-86-17 In this paper we consider the problem of extending Prolog to include predicate and function variables and typed ~.-terms. For this purpose, we use a higher-order logic to describe a generalization to first-order Horn clauses. We show that this extension possesses certain desirable computational properties. Specifically, we show that the familiar operational and least fixpoint semantics can be given to these clauses. A language, ~.Prolong that is based on this generalization is then presented, and several examples of its use are provided. We also discuss an interpreter for this language in which new sources of branching and backtracking must be accommodated. An experimental interpreter has been constructed for the language, and aLl the examples in this paper have been tested using it. Some Uses of"]},{"title":"Higher.Order Logic in Computational Linguistics,","paragraphs":["Dale A. MiLler and Gopalan Nadathur, MS-CIS-86-31, LINC LAB 08 Consideration of the question of meaning in the framework of linguistics often requires and allusion to sets and other higher-order notions. The traditional approach to representing and reasoning about meaning in a computational setting has been to use knowledge representation systems that are either based on first-order logic or that use mechanisms whose formal justifications are to be provided after the fact. In this paper we shall consider the use of a higher-order logic for this task. We first present a version of definite clauses (positive Horn clauses) that is based on this logic. Predicate and function variables may occur m such clauses the terms in the language are the typed/-terms. Such term structures have a richness that may be exploited in representing meanings. We also describe a higher-order logic programming language, called /Prolog, which represents programs as hijgher-order definite clauses and interprets them using a depth-first interpreter. A virtue of this language is that it is possible to write programs in it that integrate syntactic and semantic analyses into one computational paradigm. This is to be cont~'asted ~vith the more common pFactice of using two entirely different computation paradigms, such as DCGs or ATNs for parsing ann frames or semantic nets for semantic processing. We illustrate such and integration in this language by considering a stmple example, and we claim that its use makes the task of providing formal justifications for the computations specified much more airect. . Some"]},{"title":"Aspects Of Default Reasoning In Interactive Discourse,","paragraphs":["Aravlnd K. Joshl, Bonnie L. Webber and Ralph M. Weischedel, MS-CIS-86-27 (revised version of MS-CIS-84-58) In cooperative inter.action_, it is taken as necessary that a system truthfully and informatively respond to a user's question. It is not, however, sur.nClent. In par~cuiar, ff the system has reason to befieve that its planned response might lead the user to draw an inference mat it knows to be false, then it must block it by modifying or adding to its response. In this paper we investigate several aspects of such reasoning in interactive discourse. 35 Adapting MUMBLE: Experience with N~tuml Language Generation, Robert Rublnoff, MS-CIS-86-32, LINC LAB 09} This paper describes the construction of a MUMBLE-based [McDonald 83b tactical component for the TEXT text generation system [McKeown 85]. This new component, which produces fluent English sentences from the sequence of structured message units output from TEXT's strategic component, has produced a 60-fold speed-up in sentence production. Adapting MUMBLE required work on each of the three parts of the MUMBLE framework: the interpreter, the grammar, and the dictionary.. It also provided some insight into the generation process and the consequences of MUMBLE's commitment to a determlmsttc model. GUMS 1 : A General User Modeling System, Tim Finin and David Drager, MS-CIS-86-35 This paper describes a general architecture of a domain independent system for building and maintaining long term models of individual users. The user modeling system is intended toprovide a well defined set of services for an application system which is interacting with various users andhas a need to build andmaintain models of the-re. As the application system interacts with a user, it can acquire knowledge of him and pass that knowledge on to the user model maintenance system for incorporation. We describe a prototype general user modeling system which we have implemented in Prolog. This system satisfies some of the desirable characteristics we discuss. Breaking the Primitive Concept Barrier, Robert Kass, Ron Katrlel, and Tim Finln, MS-CIS-86-36 Building and maintaining a large knowledge base of general information requires a knowledge representation system with ]?recise semantics and an easy knowledge acquisition procedure. Systems such as KL-ONE meet these criteria by using a classifier to install new concepts into a taxonomic sWacture. These systems use a formal notion of a definition for concepts. Unfortunately, many concepts do not seem to have such precise definittons, and end up represented as primitive concepts. Primitive concepts form a barrier to classification, forcing the user to manually classify a new concept with respect to all primitive concepts in the knowledge base. We propose an extension to ~NE which retains its soundness and greatly reduces the burden on the user during knowledge acquisition. This extension consists of adding an explicit definitional component to concepts and relaxing the strictness of concept definitions themselves. The relaxed definition reduces the number primitive concepts in a knowledge base, enables the classifier to handle concepts that do not have complete definitions and enhances the usefulness of an interactive classifier. 36"]}]}