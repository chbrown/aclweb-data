{"sections":[{"title":"STATISTICAL SIGNIFICANCE OF MUC-6 RESULT S","paragraphs":["Nancy Chinchor, Ph.D ."]},{"title":"Science Applications International Corporatio n 10260 Campus Point Drive, M/S A2- F San Diego, CA 9212 1 chinchor@gso.saic .co m (619) 458-261 4 INTRODUCTIO N","paragraphs":["The results of the MUC-6 evaluation must be analyzed to determine whether close scores significantl y distinguish systems or whether the differences in those scores are a matter of chance. In order to do such an analysis , a method of computer intensive hypothesis testing was developed by SAIC for the MUC-3 results and has been use d for distinguishing MUC scores since that time . The implementation of this method for the MUC evaluations was firs t described in [1] and later the concepts behind the statistical model were explained in a more understandable manne r in [2] . This paper gives the results of the statistical testing for the three MUC-6 tasks where a single metric could b e associated with a system's performance ."]},{"title":"STATISTICAL SIGNIFICANCE TESTING Method","paragraphs":["The general method employed to analyze the MUC-6 results is the Approximate Randomization method described in [3] . It is a computer intensive method which approximates the entire sample space in such a way as t o allow us to determine the significance of the differences in F-Measures between each pair of systems and th e confidence in that significance . The general method was applied on the basis of a message-by-message shuffling of a pair of MUC systems' responses to rule out differences that could have occurred by chance and to give us a picture o f the similarities of the systems in terms of performance .","The method sorts systems into like and unlike categories . The results are shown in the following three table s for Named Entity, Template Element, and Scenario Template . These three all use the F-Measure as the single measur e for systems as defined in [4] and in the MUC-6 Test Scores appendix to this proceedings . The parameters in the F - Measure used are such that recall and precision scores are combined with equal weighting . Note that Coreference was not characterized by F or any other unified measure because of the linkages that were being evaluated . Of course, an F-Measure is calculable, but more research is necessary before we can conclude that it will combine recall an d precision in a way that is meaningful for these evaluations .","The statistical results reported here are based on the strictest cutoff point for significance level (0 .01) an d high confidence in the assigned level (at least 99%) . What this method does not tell us is a numerical range withi n which F is not a significant distinguisher (such as plus or minus 3%) . Instead it provides lists of similar systems . We have to be careful to not confuse the numerical order of the F-Measures with a ranking of systems and to instead loo k at the groupings on these charts . If a group or a single system is off by itself, then that group or single system i s significantly different from its non-members . However, if there is overlap (and there is a lot of it in these results), the n the ranking of the grouped systems is impossible. In addition, two similarly acting systems could use very differen t approaches to data extraction, so there may be some other value that distinguishes these systems that has not been measured in MUC-6 ."]},{"title":"Processing","paragraphs":["To prevent human error, the entire process of doing the statistical analysis is automated . An awk program extracts tallies that appear in the score report output by the scoring software and puts them in a file to be fed to the C program for approximate randomization . The C program re-calculates F-measure, recall, and precision from raw 39 tallies for higher accuracy than during the approximate randomization comparisons . The scoring program is slow i n emacslisp and would be slowed further by calculations with higher accuracy . The statistical program outputs th e significance and confidence levels in a matrix format for the analyst to inspect . Although 10,000 shuffles are carried out, the C program is fast . Results are depicted in lists of systems that are all equivalent, i .e ., the differences in thei r scores were due to chance ."]},{"title":"Results","paragraphs":["The results are reported in a tabular format . The row headings contain the F-Measures for the systems an d the rows are ordered from highest to lowest F. The columns are ordered in the same way as the rows and the header s contain the numerical order of the F values rather than the F value itself because of the size of the table on the page .","To use the table, you first determine which system you are interested in and identify its F-Measure in the left column, then look across the row or down the corresponding column to see which systems' F-Measures its F-Measure is not significantly different from . The systems that make up that group can be considered to have gotte n their different F-Measures just by chance .","You can see, for instance, that among the Named Entity systems, the two lowest scoring systems ar e significantly different from each other and all of the all of the other systems . The two systems above them form a group which are significantly different from the other systems, but not from each other . A similar case appears i n Template Element at the low and high end of the scores . However, the important thing to note is that there is a larg e amount of overlap otherwise . The Scenario Template test shows even more overlap than the other two tasks ."]},{"title":"CONCLUSION S","paragraphs":["The groupings in these tables allow an ordering that is less clean than we would like, but that is realistic a t this point in the evaluation methodology research . In addition to looking at the scores, evaluation research on a mor e granular level is needed to understand the differences in the systems' performance . Such research could revea l strengths and weaknesses in extracting certain information and lead to test designs that focus research in areas tha t will directly impact operational value . Also, other factors that are of interest to consumers, such as speed , development data requirements, and so on, need to be considered when making comprehensive comparisons o f systems .","The entire community would benefit from more refined measured values and a better understanding of ho w the differences in human performance influence the results . Distinguishing systems at such a strict cutoff as we use i n the statistics may only be justified if variations in human performance are smaller . After all, it is the human interpretation of the task definitions that informs the systems during development . Especially in Named Entity where machine performance and human performance are close, we would expect to see inherent human differences i n interpreting language during both system and answer key development to be a considerable factor holding th e machines back ."]},{"title":"REFERENCES","paragraphs":["[1] Chinchor, N., Hirschman, L ., and D . Lewis (1993) \"Evaluating Message Understanding Systems : An Analysi s of the Third Message Understanding Conference (MUC-3) \" Computational Linguistics 19(3) .","[2] Chinchor, N . (1992) . \"The Statistical Significance of the MUC-4 Results\" Proceedings of the Fourth Messag e Understanding Conference (MUC-4) . Morgan Kaufmann, Publishers . San Mateo, CA . [3] Noreen, W. (1989) Computer Intensive Methods for Testing Hypotheses : An Introduction . John Wiley & Sons . [4] Van Rijsbergen, C .J . (1979) Information Retrieval. London : Butterworths . 40"]},{"title":"NE Statistical Result s","paragraphs":["Similar System s"]},{"title":"T 96 .42","paragraphs":["1 3 2 3 3 3"]},{"title":"4","paragraphs":["5 6 7 8 9"]},{"title":"10 11 12 13","paragraphs":["14 15"]},{"title":"16","paragraphs":["17 18"]},{"title":"19","paragraphs":["2 0 95 .66 3 3 3 3 3 94 .92 3 3 3 3 3 3 3 3 3 3 94 .00"]},{"title":"k 3 3 3 3 3 3 3 3 3 3 93 .65","paragraphs":["3 3 3 3 3 3 3 3 3 3 93 .33 3 3 3 3 3 3 3 3 3 3 3 92 .88 3 3 3 3 3 3 3 3 3 3 92.74 3 3 3 3 3 3 3 3 3 3"]},{"title":"92.61 3 3 3 3 3 3 3 3 3 3 3 91 .20 3 3 3 3 3 3 3 3 3 3 90 .84","paragraphs":["3 3 3 3 3 3 3 3 3 3 3 3 3 3 89 .06 3 3 3 3 3 3 3 3 3 3 3 3 88 .19 3 3 3 3 3 ' 3 3 3 85 .82 3 3 3 3 3 3 85 .73 3 3 3 3 3 3 84 .95 3 3 3 3 3 3 67 .62 3 3 59 .38 3 3 35 .46 3 2.38 3 4 1"]},{"title":"TE Statistical Result s Similar System s 79 .99 1 6/ 2 6/ 3 5 6 7 8 9 LO 11 1 2 79 .85 3 6/","paragraphs":["3 3"]},{"title":"77 .31 s/ 3 3 3 77 .24 6/","paragraphs":["3 3 3 3"]},{"title":"76 .29 3 3 3 3 3 3 3 74 .96 3 6/","paragraphs":["3 3 3 3"]},{"title":"74 .32 3 3 6/","paragraphs":["3"]},{"title":"71 .97 3 3 6/","paragraphs":["k"]},{"title":"3","paragraphs":["3 6/"]},{"title":"71 .16 3 k V 3 3 69 .80 k V 6/","paragraphs":["3"]},{"title":"61 .17 3 53 .80 3 4 2 ST Statistical Results Similar","paragraphs":["System s F 56 .40 1 3 2 3 3 3"]},{"title":"4 3","paragraphs":["5 6/ 6 6/ 7 8 6/ 9 10 1 1 54 .39 6/ 3 3 3 3 3 6/ 6/ 53 .27 3 3 3 3 3 3 3 3"]},{"title":"51 .63 3 3 6/ t/ 6/ 6/","paragraphs":["3 3 3 50 .98 3 3 3 6/ ' s/ 3 3 3 3 50 .96 3 3 3 3 e/ 3 3 6/ 6/ 48 .96 3 3 3 6/ 3 3 3 3"]},{"title":"48 .14 3 3 6/","paragraphs":["3 3 3 3 3 3 3 43 .24 6/ 3 6/ 3 A 6/ 3 6/ 40 .35 s 6/ 3 s/ 3"]},{"title":"33 .44 3 3","paragraphs":["4 3"]}]}