{"sections":[{"title":"BBN : Description of the PLUM System as Used for MUC- 5 The PLUM System Group * BBN Systems and Technologies 70 Fawcett Stree t Cambridge, MA 0213 8 weischedel@bbn .co m APPROACH","paragraphs":["Traditional approaches to the problem of extracting data from texts have emphasized hand-crafted linguisti c","knowledge . In contrast, BBN's PLUM system (Probabilistic Language Understanding Model) was developed as par t","of an ARPA-funded research effort on integrating probabilistic language models with more traditional linguisti c","techniques . Our research and development goals are : • more rapid development of new applications , • the ability to train (and re-train) systems based on user markings of correct and incorrect output , • more accurate selection among interpretations when more than one is found, an d • more robust partial interpretation when no complete interpretation can be found .","We began this research agenda approximately three years ago . During the past two years, we have evaluated muc h of our effort in porting our data extraction system (PLUM) to a new language (Japanese) and to two new domains ."]},{"title":"KEY SYSTEM FEATURES","paragraphs":["Three key design features distinguish PLUM : statistical language modeling, learning algorithms and partia l understanding . The first key feature is the use of statistical modeling to guide processing . For the version of PLUM used in MUC-5, part of speech information was determined by using well-known Markov modeling technique s embodied in BBN's part-of-speech tagger POST [5] . We also used a correction model, AMED [3], for improvin g Japanese segmentation and part-of-speech tags assigned by JUMAN . For the microelectronics domain, we used a probabilistic model to help identify the role of a company in a capability (whether it is a developer, user, etc .) . Statistical modeling in PLUM contributes to portability, robustness, and trainability . The second key feature is our use of learning algorithms both to obtain the knowledge bases used by PLUM' s processing modules and to train the probabilistic algorithms . We feel the key to portability of a data extractio n system is automating the acquisition of the knowledge bases that need to change for a particular language o r application . For the MUC-5 applications we used learning algorithms to train POST, AMED, and the template - filler model mentioned above . We also used a statistical learning algorithm to learn case frames for verbs fro m examples (the algorithm and empirical results are in [4]) .","A third key feture is partial understanding, by which we mean that all components of PLUM are designed t o operate on partially interpretable input, taking advantage of information when available, and not failing whe n information is unavailable . Neither a complete grammatical analysis nor complete semantic interpretation i s required. The system finds the parts of the text it can understand and pieces together a model of the whole from thos e part and their context ."]},{"title":"PROCESSING STAGE S","paragraphs":["The PLUM architecture is presented in Figure 1 . Ovals represent declarative knowledge bases ; rectangles represen t processing modules . A more detailed description of the system components, their individual outputs, and thei r knowledge bases is presented in Ayuso et al ., [1] . The processing modules are briefly described below . * Ralph Weischedel (Principal Investigator), Damaris Ayuso, Sean Boisen, Heidi Fox, Robert Ingria, Tomoyosh i Matsukawa, Constantine Papageorgiou (BBN), Dawn MacLaughlin, Masaichiro Kitagawa, Tsutomu Sakai (Bosto n University), June Abe, Hiroto Hosihi, Yoichi Miyamoto (University of Connecticut), and Scott Miller (Northeaster n University) 93 Message Message Reader","Morphological Analyzer Part of Speech requency Data Concept-based Pattern Matcher \\tCBasic Patterns Grammar Rules Fast Partial Parser Semantic Interpreter y \\t Domain Model I \\t","Discourse \\t '\\t<\\tEvent"]},{"title":"Rule Template Generator \\t Application Constraints Outpu t Figure 1 : PLUM System Architecture :","paragraphs":["Rectangles represent domain-independent, language-independen t algorithms ; ovals represent knowledge bases ."]},{"title":"Message Reade r","paragraphs":["This module is like the \"text zoner\" of Hobbs' description of generic data extration systems . PLUM ' s specification of the input format is a declarative component of the message reader, allowing the system to be easil y adapted to handle different formats . The input to the PLUM system is a file containing one or more messages . The message reader module determines message boundaries, identifies the message header information, and determine s paragraph and sentence boundaries . To date, we have designed format specifications for about half a dozen domains ."]},{"title":"Morphological Analyze r","paragraphs":["The first phase of processing is assignment of part-of-speech information, e .g., proper noun, verb, adjective, etc . In BBN's part-of-speech tagger POST [5], a bi-gram probability model, frequency models for known words (derive d from large corpora), and probabilities based on word endings for unknown words are employed to assign part of speech to the highly ambiguous words and unknown words of the corpus . POST tags each word with one of 47 possible tags with 97% accuracy for known words . For the Japanese domains, JUMAN is used to propose wor d segmentation and part-of-speech assignments, which are then corrected by AMED [3] before being handed to POS T for final disambiguation . Below are the part-of-speech tags produced by POST for the first sentence of the EJV walkthrough article 0592 :","\"BRIDGESTONE SPORTS CO . SAID FRIDAY IT HAS SET UP A JOINT VENTURE IN TAIWAN WITH A LOCAL CONCERN AND A JAPANESE TRADING HOUSE TO PRODUCE GOLF CLUBS TO BE SHIPPED TO JAPAN .\" (BRIDGESTONE NP) (SPORTS NPS) (CO . NP) (SAID VBD) (FRIDAY NP) (IT PP) (HAS VBZ ) (SET UP VBN) (A DT) (JOINT VENTURE NN) (IN IN) (TAIWAN NP) (WITH IN) (A DT) (LOCAL JJ) (CONCERN NN ) (AND CC) (A DT) (JAPANESE JJ) (TRADING HOUSE NN) (TO TO) (PRODUCE VB) (GOLF NN) (CLUBS NNS) (TO TO ) (BE VB) (SHIPPED VBN) (TO TO) (JAPAN NP) (. .)"]},{"title":"Concept-Based Pattern Matche r","paragraphs":["The Concept-based Pattern Matcher was developed after MUC-4 to deal with grammatical forms, such a s corporation names . It applies finite state patterns to the input, which consists of word tokens with part-of-speec h and semantic concept information . In particular, word groups that are important to the domain and that may b e detectable with only local syntactic analysis can be treated here . When a pattern is matched, a semantic form i s Lexicon entente Patterns7 94 assigned by the pattern . In both joint ventures and microelectronics, patterns were used to group proper nouns int o company names, organization names, and person names . Continuing with the example sentence discussed above, a pattern recognized the sequence (BRIDGESTONE NP) (SPORTS NPS) (CO . NP) as a company ; the pattern' s action substituted the single token (BRIDGESTONE SPORTS CO . CORP), with semantics of corporation ."]},{"title":"Fast Partial Parser (FPP)","paragraphs":["The FPP is a near-deterministic parser which generates one or more non-overlapping parse fragments spanning th e input sentence, deferring any difficult decisions on attachment ambiguities . When cases of permanent, predictabl e ambiguity arise, the parser finishes the analysis of the current phrase, and begins the analysis of a new phrase . Therefore, the entities mentioned and some relations between them are processed in every sentence, whether syntactically ill-formed, complex, novel, or straightforward . Furthermore, this parsing is done using essentiall y domain-independent syntactic information . FPP averages about 6 fragments for sentences as complex as in the EJV corpus ; this number is inflated since punctuation usually results in an isolated fragment. Continuing with the same example sentence, Figure 2 show s nine parse fragments as generated by FPP . The Japanese grammar produces smaller fragments by design ."]},{"title":"Semantic Interprete r","paragraphs":["The semantic interpreter contains two sub-components : a rule-based fragment interpreter and a pattern-base d sentence interpreter. The first was used in MUC-3 and MUC-4 . The rule-based fragment interpreter applies semanti c rules to each fragment produced by FPP in a bottom-up, compositional fashion . Semantic rules are matched based on general syntactic patterns, using wildcards and similar mechanisms to provide robustness . A semantic rul e creates a semantic representation of the phrase as an annotation on the syntactic parse . A semantic formula includes a variable (e .g ., ?l3), its type, and a collection of predicates pertaining to that variable . There are three basic types of semantic forms : entities in the domain, events, and states of affairs . Each of these can be further categorized a s known, unknown, and referential . Entities correspond to the people, places, things, and time intervals of the domain . These are related in various ways, such as through events (who did what to whom) and states of affairs (properties o f the entities) . Entity descriptions typically arise from noun phrases ; events and states of affairs are often described i n clauses .","The rule-based fragment interpreter encodes defaults so that missing semantic information does not produce errors , but simply marks elements or relationships as unknown . Partial understanding is critical to text processin g systems ; missing data is normal . For example, the generic predicate PP-MODIFIER indicates that two entities are connected via a certain preposition . In this way, the system has a \"placeholder\" for the information that a certai n structural relation holds, even though it does not know what the actual semantic relation is . Sometime s understanding the relation more fully is of no consequence, since the information does not contribute to the template - filling task . The information is maintained, however, so that later expectation-driven processing can use it i f necessary .","F4: \"AND \" (CONJ \"AND\")","F5: \"A JAPANESE TRADING HOUSE \" (NP (DETERMINER \"A\" )","(ADJP (ADJ \"JAPANESE\") )","(N 'TRADING HOUSE\"))","F6: \"TO PRODUCE GOLF CLUBS \" (VP (AUX (TO \"TO\"))","(VP (V \"PRODUCE\" )","(NP (N \"GOLF\") (N \"CLUBS\"))) )","F7: \"TO \" (PREP \"TO\" )","F8: \"BE SHIPPED TO JAPAN\" (VP (AUX (V \"BE\") )","(VP (V \"SHIPPED\" )","(PP (PREP \"TO\" )","(NP (N (NAME \"JAPAN\"))))))","F9 : (PUNCT \" .\") for the example sentence .","Fl : \"BRIDGESTONE SPORTS CO . SAID FRIDAY IT HAS","SET UP A JOINT VENTURE \"","(S (NP (N (NAME \"BRIDGESTONE SPORTS CO .\")) ) (VP (AUX )","(VP (V \"SAID\" )","(NP (MONTH \"FRIDAY\"))","(S","(S (NP (PRO-DET-SPEC \"IT\"))","(VP (AUX (V \"HAS\")) (VP (V \"SET UP\")","(NP (DETERMINER \"A\")","(N \"JOINT VENTURE\")))))))))","F2: \"IN TAIWAN\"","(PP (PREP \"IN\" ) (NP (N (NAME \"TAIWAN\"))))","F3: \"WITH A LOCAL CONCERN \"","(PP (PREP \"WITH \" ) (NP (DETERMINER \"A\")","(ADJP (ADJ \"LOCAL\"))","(N \"CONCERN\")))","Figure 2. Parser Output : Partial parse foun d 95","An important consequence of the fragmentation produced by FPP is that top-level constituents are typically mor e shallow and less varied than full sentence parses . As a result, a fairly high level of semantics coverage can b e obtained quite quickly when the system is moved to a new domain . This would not be possible if the semantic rule s were required to cover a wider variety of syntactic structures before it could achieve reasonable performance . In thi s way, semantic coverage can be added gradually, while the rest of the system is progressing in parallel . The second sub-component of the semantic interpreter module is"]},{"title":"a","paragraphs":["pattern-based sentence interpreter which applies semantic pattern-action rules to the semantics of each fragment of the sentence . This replaces the fragment combining component used in MUC-4 . The semantic pattern matching component employs the same core engine as the concept-based pattern matcher . These semantic rules can add additional long-distance relations between semanti c entities in different fragments within a sentence . For example, in the English joint-venture domain, we have define d a rule which looks for a sequence of [<ENTITY> \"capitalized at\" <MONETARY-AMOUNT>] . This rule's actio n creates an OWNERSHIP semantic form, where <ENTITY> is related via the OWNERSHIP-OWNED role an d <MONETARY-AMOUNT> via the OWNERSHIP-CAPITALIZATION role . The semantic lexicon is separate from the parser's lexicon and has much less coverage . Lexical semantic entries indicate the word's semantic type (a domain model concept), as well as predicates pertaining to it . For example, here is the lexical semantics for the noun collocation \"joint venture\" . This entry indicates that the semantic type i s JOINT-VENTURE, and that a \"with\" or \"between\" PP argument whose type is ENTITY should be given the rol e PARENT-OF, and a \"for\" PP argument of type ACTIVITY should be given the role ACTIVITY-OF .","(defnoun \"joint venture \" (JOINT-VENTURE ( :CASE ((\"with\" \"between\") ENTITY PARENT-OF) (\"for\" ACTIVITY ACTIVITY-OF))) )","We used an automatic case frame induction procedure to construct an initial version of the lexicon [4] . Word senses in the semantic lexicon have probability assignments . For MUC-5 probabilities were (automatically) assigne d so that each word sense is more probable than the next sense, as entered in the lexicon . Event : JOINT-VENTURE JOINT-VENTURE-CO-OF: Unknown-role : Entity : CORPORATIO N NAME-OF: \"Bridgestone Sports Taiwan Co . \" Entity: OWNERSHI P OWNERSHIP-CAPITALIZATION : Entity: MONETARY-AMOUNT UNIT: \"TWD\" SCALAR : 20000000 Figure 3 . Semantic Structure : The semantic representation for the first fragment in Figure 2 . In Figure 3 we show the semantic representation that is built for the phrase \"THE JOINT VENTURE , BRIDGESTONE SPORTS TAIWAN CO ., CAPITALIZED AT 20 MILLION NEW TAIWAN DOLLARS\" i n EJV walkthrough article 0592 (this phrase is parsed within a single fragment by FPP) . Notice that the JOINT-VENTURE is linked to the OWNERSHIP information via an unknown role, because the interpreter was unable t o determine a specific relationship between the NP \"THE JOINT VENTURE, BRIDGESTONE SPORTS TAIWA N CO .,\" and the participial modifier \"CAPITALIZED AT . . .\" The discourse component will further refine the relationship between these two semantic objects to the JV-OWNERSHIP-OF relation ."]},{"title":"Discourse Processin g","paragraphs":["PLUM's discourse component [2] performs the operations necessary to create a meaning for the whole messag e from the meaning of each sentence . The message level representation is a list of discourse domain objects (DDOs) for the top-level events of interest in the message (e .g ., JOINT-VENTURE events in the joint-venture domain o r CAPABILITY events in the microelectronics domain) . The semantic representation of a phrase in the text onl y includes information contained nearby in a sentence ; in creating a DDO, the discourse module must infer other long-distance or indirect relations not explicitly found by the semantic interpreter, and resolve any references in the text . 96 The discourse component creates two primary structures : a discourse predicate database and the DDOs . The database contains all the predicates mentioned in the semantic representation of the message . When references are resolved , corresponding semantic variables are unified . Any other inferences are also added to the database . To create the DDOs, the discourse component processes each semantic form produced by the interpreter, adding it s information to the database and performing reference resolution for pronouns and anaphoric definite NPs . Set- an d member-type references may be treated . When a semantic form for an event of interest is encountered, a DDO i s generated, and any slots already found by the interpreter are filled in . The discourse processor then tries to merge th e new DDO with a previous DDO, in order to account for the possibility that the new DDO might be a repeate d reference to an earlier one .","Once all the semantic forms have been processed, heuristic rules are applied to fill any empty slots by looking a t the text surrounding the forms that triggered a given DDO . Each filler found in the text is assigned a confidence scor e based on distance from trigger . Fillers found nearby are of high confidence, while those farther away receive wors e scores (low numbers represent high confidence ; high numbers low confidence ; thus 0 is the \"highest\" confidenc e score) . Following is the DDO for the first JOINT-VENTURE in EJV walkthrough article 0592 : DDO: JOINT-VENTURE Trigger fragments : \"BRIDGESTONE SPORTS CO. SAID FRIDAY IT HAS SET UP A JOINT VENTURE\" \"THE JOINT VENTURE, BRIDGESTONE SPORTS TAIWAN CO ., CAPITALIZED AT 20 MILLION","NEW TAIWAN DOLLARS, WILL START PRODUCTION IN JANUARY 1990 \" ------------------------------------------------------------------------------------------------------------------------------- - JOINT-VENTURE-CO-OF : \\t \"BRIDGESTONE SPORTS TAIWAN CO .\" (score = 0) JV-PARENT-OF: \\t \"BRIDGESTONE SPORTS CO.\" (score =1 ) \"A LOCAL CONCERN\" (score = 2) \"A JAPANESE TRADING HOUSE\" (score = 2) \"GOLF CLUBS\" (score = 2) \"CLUBS\" (score = 2 ) JV-ACTIVITY-OF : \\t \"start production\" (score = 1 ) \"produce golf clubs\" (score = 2) \"be shipped to Japan\" (score = 2) \"with production of 20,000 iron\" (score = 2)","JV-OWNERSHIP-OF: \"capitalized at 20 million new Taiwan dollars\" (score =1 )","Each trigger fragment contains one or more words whose semantics triggered this DDO . A DDO can have multipl e trigger fragments if the discourse component determines that the triggers corefer . In this example, a \"joint venture \" in the first fragment co-refers with \"the joint venture\" in the second fragment. A score of 0 indicates the filler was found directly by the semantics ; 1 that it was found in the same fragment as a trigger form ; and 2 in the same sentence."]},{"title":"Template Generation","paragraphs":["The template generator takes the DDOs produced by discourse processing and fills out the application-specifi c templates . Clearly, much of this process is governed by the specific requirements of the application, consideration s which have little to do with linguistic processing. The template generator must address any arbitrary constraints, a s well as deal with the basic details of formatting . The template generator uses a combination of data-driven and expectation-driven strategies . First the DDOs foun d by the discourse module are used to produce template objects . Next, the slots in those objects are filled usin g information in the DDO, the discourse predicate database, or other sources of information such as the message heade r (e .g ., document number, document source, and date information), statistical models of slot filling (e .g ., as in th e microelectronics domain to choose among the slots : purchaser/user, developer, distributor, and manufacturer), o r from heuristics (e .g ., the status of an equipment object is most likely to be IN_USE, or the status of a joint ventur e object is most likely to be EXISTING) . 97"]},{"title":"Parameters in PLU M","paragraphs":["Many aspects of PLUM's behavior can be controlled by simply varying the values of system parameters . For example, PLUM has parameters to control aspects of tagging, parsing, pattern matching, event merging and slo t filling by discourse, and template filling . An important goal has been to make our system as \"parameterizable\" a s possible, so that the same software can meet different demands for recall, precision, and overgeneration ."]},{"title":"TRAINING DATA AND TECHNIQUE S","paragraphs":["The entire development corpus was used in various ways as training data . PLUM was run over all messages t o detect, debug, and correct any causes of system breaks . The entity name slot for all messages was used to quickl y add names to the domain-dependent lexicon . For both microelectronics applications, statistics on the co-occurrenc e of particular entities in various roles (developer, manufacturer, etc .) were used as a fall-back model for low-confidenc e relationships detected in the texts .","The TIPS 1 and TIPS2 sets for all applications were used as blind test sets to measure our progress at least once a week . Throughout, we used the summary output from the scoring procedure to guide our development, rather tha n adding to the lexicon or debugging the system based on particular messages."]},{"title":"DEALING WITH MULTIPLE LANGUAGES AND MULTIPLE DOMAIN S","paragraphs":["Any system that participated in more than one domain in MUC-5 and/or in more than one language ha s demonstrated domain independence and language independence. In PLUM, the text zoner, morphological processing , parsing, and semantic interpretation employ language-independent and domain-independent algorithms driven by dat a (knowledge) bases . Similarly, the discourse algorithms and template generation algorithms are domain- an d language-independent, and are driven by knowledge that is predominantly declarative .","The issue (or the goal) that all systems must address further is greater automation of th e porting process. Our approach has been to rely on probabilistic learning algorithms . Based on our experience i n the last two years, several conclusions have emerged : 1. Porting PLUM to a new domain, even in multiple languages, takes much less effort now . Table 1 show s the effort expended in porting PLUM to the microelectronics domain . In 52 person-days, PLUM was processin g microelectronics articles in both English and Japanese, obtaining reasonable performance . Had we run PLUM at that time on the TIPS3 test sets, scores would already have been impressive in English (an ERR of 74) . For Japanese , performance was 73 on test set TIPS2 . (We quote the score for TIPS2, because it covered only the capabilities fo r which there was data at the time of the TIPS2 version of PLUM . ) Tasks Person-Days Language Domain Pair Person-Months","Language-independent 14 English Joint Venture 4-5 English 19 Japanese Joint Venture 2 Japanese 12 English Microelectronics 3 TOTAL 52 Japanese Microelectronics 3 .5 Table 1 : Effort to Port to Microelectronics \\t Table 2 : Total Effort in Each Domai n Table 2 lists our estimated effort in each domain ; Figure 4 portrays the data graphically . The effort in each language was largely balanced ; the performance of the system across languages and domains was also remarkably balanced, a s shown graphically in Figure 5 . 2. Annotating data for PLUM's probabilistic model of a new language, even with little language - specific resources, proved easier than anticipated . The only resource available to us at the start was the JUMA N system from Kyoto University, which hypothesizes word segmentation and part of speech for Japanese text . . Ou r Japanese speakers were able to annotate part of speech and word boundaries at about 1,000 words per hour, and wer e able to annotate syntactic structure at about 750 words per hour . Initial annotation and testing were performed usin g only I6,(XX) words plus the JUMAN lexicon ; therefore, the initial port to Japanese required only about a person - week of annotation effort . 9 8 Figure 4 : Distribution of Effort across Domains : Effort across languages was about equal . S O 7 0 6 0 5 0 4 0 3 0 2 0 10 0\\tI\\t1\\t1\\tI","EJV \\t JJV \\t EME \\t JME","Figure 5 : Performance Based on ERR : Across language-domain pairs, there was remarkable consistency i n PLUM's performance. 3. Building lexical resources for a new language or a new domain took only a few person days usin g heuristics . In Japanese, a three step process for hypothesizing proper names reduced the labor involved . First, we ran JUMAN + POST over the training corpus to find the sequence of words and their most likely part of speech i n context. Then, a finite-state process with a handful of language-specific patterns was run on the result t o hypothesize (previously unknown) proper nouns in the corpus . The patterns were designed for high recall of names , at the expense of low precision ; we measured the effectiveness of the technique as 90% recall at 20% precision . Lastly, a person ran through the hypothesized proper names using KWIC as a resource to quickly eliminate ba d hypotheses . The resulting list of names was made available to all the participants in JJV . A simple manual technique also enabled fast semantic categorization of the nouns and verbs of each domain in bot h languages . Using a KWIC index and the frequency of each noun and each verb in the corpus, we could define abou t 125 words per hour into categories such as HUMAN, CORPORATION, OFFICER, GOVERNMENT-ORGANIZATION, etc. The process could go so quickly by organizing the categories into small menus of at most 12 items, so that a perso n need only make simple discriminations in any pass through a list of words . 4. Training new staff to use PLUM effectively proved easier than anticipated . Our team faced trainin g new staff two months before the MUC-5 test, as our single Japanese programmer needed to reduce his involvemen t substantially . Starting at the beginning of June, two Japanese computer science majors, who had just complete d their junior year at college came to BBN . They had had no training in computational linguistics, but had had on e course in artificial intelligence and one in LISP . In June, they learned about data extraction, the joint venture and microelectronics tasks, and how to use PLUM . Since the Japanese articles on packaging and lithography had arrive d much later than the other data, and since we had not touched that data, they focussed on those two capabilitie s starting July 1 . Initially, of course, PLUM had near 100 as an ERR on sets composed primarily of thos e","El English Joint Ventur e","O Japanese Join t Ventur e","D Englis h Microelectronic s","n Japanes e Microelectronic s 99 microelectronics capabilities . As evident in Figure 6, the progress was rapid and dramatic, as the error rate droppe d by 25% in all cases and by almost 50% in some cases .","Figure 6 : Progress in JME : For development messages involving packaging and lithography, progress o f new staff with minimal training was rapid and dramatic ."]},{"title":"CONCLUSION S","paragraphs":["We began our research agenda approximately three years ago when we build PLUM for MUC-3 . During the past two years, we have focused much of our effort on techniques to facilitate porting our data extraction system (PLUM ) to new languages (Japanese) and to two new domains (joint ventures and microelectronics), as well as infrastructur e development .","Some of the lessons we learned during our work include the following : Automatic training and acquisition of knowledge bases can yield relatively good performance at reduced labor, a s evidenced, for example, by a quick port to the microelectronics domain (in 2 languages) in 2 person-month s (after which further refinements were made) . Domains dominated by jargon (sub-language) may be easier than domains of normal vocabulary because there i s less ambiguity and more predictability . For TIPSTER this means that the microelectronics domain was easier than joint ventures . Japanese was easier to process than English because of strong clues provided by case-markers, and a less varie d linguistic structure in the articles .","• Availability of a large text corpus was invaluable for quick knowledge acquisition . A smaller number of filled templates should still be adequate .","• Our algorithms were already largely language- and domain-independent ; an important goal remains to further automate the porting process .","• Finite-state pattern matching is a useful complement to linguistic processing, offering a good fall-back strateg y for addressing language constructions that are hard to treat via general linguistically-based approaches .","• Continued work on discourse processing is important to improving performance . Reliably determining whe n different descriptions of events or objects in fact refer to the same thing remains one of the hardest problems i n data extraction .","• Improving syntactic coverage is a priority . Increased coverage normally leads to greater perceived ambiguity i n the system ; we hope to counter this through the use of probabilistic models . 100","We plan to continue our research agenda emphasizing the use of probabilistic modeling and learning algorithms fo r data extraction in order to continue improving robustness and portability ."]},{"title":"SYSTEM WALKTHROUGH S","paragraphs":["No development was done on the walkthrough messages for any of the domains, prior to the MUC-5 test ."]},{"title":"EJV Walkthrough (Message 0592 ) Questions","paragraphs":["to Address:","(1) Coreference determination:","• Which coreferences did your system get ?","[a] : \\t","\"LOCAL CONCERN\",","\"UNION PRECISION CASTING CO. OF TAIWAN\"","PLUM did not find this coreference . The system misanalyzed \"Union Precision Casting Co .\" such that the name","was split across 2 fragments . System Response Template for 0592 :","<TEMPLATE-0592-1> : = DOC NR : 059 2 DOC DATE: 24118 9 DOCUMENT SOURCE: \"Jiji Press Ltd . \" CONTENT: \\t <TIE_UP_RELATIONSHIP-0592-1 > <TIE UP - _RELATIONSHIP-0592-2> <TIE_UP -","_RELATIONSHIP-0592-3>","<fIE_UP_RELATIONSHIP-0592-1 > TIE-UP STATUS : EXISTING ENTITY: <ENTITY-0592-1 >","<ENTITY-0592-2> JOINT VENTURE CO : <ENTITY-0592-2> OWNERSHIP: <OWNERSHIP-0592-1 > ACTIVITY : <ACTIVITY-0592-1 >","<TIE_UP_RELATTONSHIP-0592-2> := TIE-UP STATUS : EXISTING JOINT VENTURE CO : <ENTITY-0592-3> OWNERSHIP: <OWNERSHIP-0592-1 > ACTIVITY: \\t","<ACTIVITY-0592-1 >","<ACTIVITY-0592-2> <TIE_UP_RELATIONSHIP-0592-3> : = TIE-UP STATUS: EXISTING ENTITY : \\t","<ENTITY-0592-1 >","<ENTITY-0592-2>","<ENTITY-0592-4> OWNERSHIP : <OWNERSHIP-0592-1 > <ENTITY-0592-1> : = NAME: BRIDGESTONE SPORTS CO ALIASES : \"BRIDGESTONE SPORTS \" TYPE: COMPANY ENTITY RELATIONSHIP:","<ENTITYRELATIONSHIP-0592-1>","<ENTITY_RELATIONSHIP-0592-3 > <ENTITY-0592-2> : = NAME: TAIWAN TYPE: COMPAN Y NATIONALITY: JAPAN (COUNTRY) ENTITY RELATIONSHIP:","<ENTITYRELATIONSHIP-0592-1>","<ENTITY_RELATIONSHIP-0592-3> <ENTITY-0592-3> :_ NAME : BRIDGESTONE SPORTS TAIWAN C O TYPE : COMPANY ENTITY RELATIONSHIP:","<ENTITY_RELATIONSHIP-0592-2> <ENTITY-0592-4> : _ NAME: TAGA CO TYPE : COMPANY ENTITY RELATIONSHIP:","<ENTITY_RELATIONSHIP-0592-3 > <ENTITY_RELATIONSHIP-0592-1> : = ENTITY 1 : \\t","<ENTITY-0592-1 >","<ENTITY-0592-2> ENTITY2: <ENTITY-0592-2> REL OF ENTITY2 TO ENTITY I : CHILD STATUS : CURRENT","<ENTITY_RELATIONSHIP-0592-2> :_ ENTITY2 : <ENTITY-0592-3 > REL OF ENTITY2 TO ENTITY 1 : CHILD STATUS : CURRENT <ENTITY_RELATIONSHIP-0592-3> := ENTITY! : \\t","<ENTITY-0592-1 >","<ENTITY-0592-2>","<ENTITY-0592-4> REL OF ENTITY2 TO ENTITY 1 : CHIL D STATUS: CURRENT","<ACTIVITY-0592-l> : = INDUSTRY: <INDUSTRY-0592-1 >","<ACTIVITY-0592-2> : = INDUSTRY : <INDUSTRY-0592-2>","<INDUSTRY-0592-1> : = INDUSTRY-TYPE: PRODUCTION PRODUCT/SERVICE: (- \"GOLF CLUBS\" )","<INDUSTRY-0592-2> : = INDUSTRY-TYPE: PRODUCTION PRODUCT/SERVICE : (- \"20,000 IRON\" ) <OWNERSHIP-0592-1> := OWNED: <ENTITY-0592-2> OWNERSHIP-% : \\t (<ENTITY-0592-l> 75 ) ( <ENTITY-0592-1> 15 ) 101","[b]: \"A JAPANESE TRADING HOUSE\", \"TAGA CO ., A COMPANY ACTIVE IN TRADING WITH TAIWAN \"","[c]: \"A JOINT VENTURE\", \"THE JOINT VENTURE, BRIDGESTONE SPORTS TAIWAN CO .\", \"THE NEW COMPANY, BASED IN KAOHSIUNG, SOUTHERN TAIWAN\", \"THE TAIWAN UNIT \"","PLUM did not find any of these coreference relations .","[d]: \"BRIDGESTONE SPORTS CO . \",","\"BRIDGESTON SPORTS\",","\"BRIDGESTONE SPORTS\",","\"THE JAPANESE SPORTS GOODS MAKER \"","PLUM found \"Bridgestone Sports Co\" and \"Bridgestone Sports\" as being coreferential . PLUM did not recogniz e","the \"typo\" alias, or the Japanese sport goods maker coreferences .","• Of those, which could it have gotten 6 months ago (at the previous evaluation) ? [a] & [b] : PLUM could not recognize these 6 months ago . [c]: 6 months ago, PLUM did find coreference between \"a joint venture\" and \"the joint venture\" . [d]: PLUM could not get any of these 6 months ago . • How can you improve the system to get the rest ?","[a]: The phrase \"local concern\" is assigned a semantic type that is a superconcept of CORPORATION. If the discourse module allowed merging of a subconcept event into a superconcept event (something which i s allowed in the microelectronics domain but not currently in the joint venture domain), then PLUM could potentially find this coreference via discourse event merging . However, PLUM's company name recognize r would need to be adapted so that it would not misanalyze the company name \"Union Precision Casting Co . \"","[b]: This is a harder case . In order to find this coreference, PLUM would probably need to recognize that bot h mentions are involved in trading .","[c]: A more explicit treatment of definite references would help with these cases . Also, better recognition of locations would aid in establishing coreference between the two mentions of the Taiwan company .","[d]: In order to recognize the other Bridgestone references, PLUM would need to try to treat misspellings, as wel l as treat the definite reference explicitly . (2) Did your system get the OWNERSHIPs, in particular from \". . . THE REMAINDER BY TAGA CO.\"? ,","PLUM did produce an ownership object with 75 and 15 % ownership percentages ; however, the system filled in the owning entities incorrectly . PLUM did not attempt to handle phrases like \"the remainder . . .\" . PLUM also missed the capitalization information in this example . Other comments on walkthrough performance :","The PLUM system found 3 tie-up objects instead of 1 . One of the spurious tie-ups resulted from the discours e event triggered by \"the new company\" not being correctly merged with the earlier mention of the joint ventur e company . The reason for the second spurious tie-up stems from PLUM having identified \"Taiwan\" (in the phrase \"i n Taiwan \" ) as a corporation, and more precisely, as a joint venture company .","The lexical entry for \"Taiwan\" incorrectly lists it as a corporation, as well as a country . Once \"Taiwan\" wa s identified as a corporation, the pattern [\"set up\" . . . <company> with <company>] matched the text \"set up a join t venture in Taiwan with a local concern and . . .\", and \"Taiwan\" was identified as the joint venture company . Since this joint venture company was found to be different from \"Bridgestone Sports Taiwan Co .,\" which was als o identified as a joint venture company by the system, 2 separate tie-ups were generated .","After the test was run, we removed the definition of \"Taiwan\" as a corporation . With this change, the syste m generated I less tie-up object, and it correctly found the reference between \"a joint venture\" and \"the joint venture .\" This correction is reflected in the sample event given in the discourse component description section .","\"UNION PRECISION CASTING CO\" was missed because it was not recognized as a possible company name : capitalization information was not available to help with name recognition (the article was fully capitalized), and the tagging component tagged \"casting\" as a V, a category which is not allowed to be taken as part of a company name. 102","Although PLUM did not recognize the typo \"Bridgeston Sports\", this did not cause any processing problem . I t only resulted in PLUM's missing this alias . PLUM produced 2 activity objects, triggered by the verb \"produce\" (golf clubs) and the noun \"production\" (o f 20,000 iron and \"metal wood\" clubs) . The first was correct, but the second was spurious .","PLUM recognized some ownership information, including the 75 and 15 percentage shares in the venture . Because PLUM failed to identify Union Precision Casting Co, this entity was not represented in the ownership information . PLUM did not attempt to treat the information conveyed by the phrasing \"and the remainder by Taga Co . \""]},{"title":"EME Walkthrough (Article 2789568 )","paragraphs":["Questions to Address: (1) What information triggers the instantiation of each of the two LITHOGRAPHY objects ?","The PLUM system generated 3 lithography objects, all of type UNKNOWN (the key contains 1 LASE R lithography and 1 UNKNOWN lithograpy) . The three triggering phrases are : \"a new stepper,\" \"the stepper,\" an d \"latest stepper\" (2) What information indicates the role of Nikon Corp. for each Microelectronics Capability ?","The PLUM system initially finds Nikon Corp . as the manufacturer of each of the 3 capabilities (in the key, Niko n is the manufacturer of the LASER lithography and the manufacturer and distributor of the UNKNOWN lithography) . Nikon was associated with each of the three capabilities because it occurred in the same sentence . Our statistica l model of entity<->capability relationships indicated that Nikon was most likely to be a manufacturer, so it wa s placed in this role . We actually found Nikon as a distributor of all 3 capabilities, but we removed this relation as it was determined t o be unlikely by our statistical model . Nikon was thought to be a distributor because of the trigger verbs \"market\" an d \"sell .\" The discourse rule then picked up Nikon Corp . (at score I) as the agent of this verb . (3) Explain how your system captured the GRANULARITY information for \"The company's latest stepper . \"","The granularity phrase \"a resolution of 0 .45 micron\" was correctly understood by the semantics component an d was associated with the appropriate lithography object via a discourse rule. However, the granularity filler was ruled out by the template generator because its confidence score fell outside the threshold set for this slot (the threshol d setting is tailored to provide the best overall system performance) . Consequently, the granularity information did no t appear in the response template . System Response Template :","<TEMPLATE-2789568-1> :_ DOC NR : 2789568 DOC DATE : 191090 DOCUMENT SOURCE : \"Comline Electronics\" CONTENT:","<MICROELECTRONICS_CAPABILITY-2789568-1 >","<MICROELECTRONICS_CAPABILITY-2789568-2>","<M ICROELECTRON ICS_CAPAB ILITY-2789568-3>","<MICROELECTRONICS_CAPABILITY-2789568-1> : _ PROCESS : <LITHOGRAPHY-2789568-l > MANUFACTURER : <ENTITY-2789568-1 >","<MICROELECTRONICS_CAPABILITY-2789568-2> PROCESS : <LITHOGRAPHY-2789568-2> MANUFACTURER : <ENTITY-2789568-1 >","<MICROELECTRONICS_CAPABILITY-2789568-3> : = PROCESS : <LITHOGRAPHY-2789568-3> MANUFACTURER : <ENTITY-2789568-1 >","<LITHOGRAPHY-2789568-I> :_ TYPE : UNKNOWN DEVICE: <DEVICE-2789568-1> EQUIPMENT : <EQUIPMENT-2789568-I >","<LITHOGRAPHY-2789568-2> := TYPE: UNKNOWN EQUIPMENT: <EQUIPMENT-2789568-1 >","<LITHOGRAPHY-2789568-3> := TYPE: UNKNOWN EQUIPMENT: <EQUIPMENT-2789568-1 >","<ENTITY-2789568-l> : = NAME: Nikon CORP TYPE: COMPANY","<DEVICE-2789568-I> : = FUNCTION: DRAM","<EQUIPMENT-2789568-1> : = MANUFACTURER : <ENTITY-2789568-I > MODULES: <EQUIPMENT-2789568-2> EQUIPMENT TYPE: STEPPER STATUS : IN_USE <EQUIPMENT-2789568-2> : _ MANUFACTURER : <ENTITY-2789568-I > EQUIPMENT TYPE: RADIATION_SOURCE STATUS : INUSE"]},{"title":"103","paragraphs":["(4) How does your system determine EQUIPMENT TYPE for \"the new stepper\"? \"the company's latest stepper\" ?","Equipment types are defined hierarchically in PLUM 's domain model . The word \" stepper\" is linked to the concep t STEPPER in the domain model and triggers a STEPPER discourse event . The template generator translate s STEPPER events into equipment objects of type STEPPER . So the equipment_type is based on the domain mode l concept that is associated with the trigger phrase.","(5) How does your system determine the STATUS of each equipment object ? The equipment status is defaulted to IN_USE. (6) Why is the DEVICE object only instantiated for LITHOGRPAHY-I ?","PLUM's discourse heuristic for finding a process's device only looks within the same sentence . In this article, the 64-mbit DRAM device is in the same sentence as the first lithography object, but no other . Other comments on walkthrough performance: The PLUM system found 3 microelectronics capabilities instead of the 2 in the answer key . The spurious capability results from a discourse referencing problem : the lithography object triggered by the definite phrase \"th e stepper\" was not found to be coreferential with the lithography object triggered by \"a new stepper\" in the previous sentence . PLUM's definite referencing mechanism is controlled by a parameter When this parameter is turned on , PLUM correctly resolves the definite reference in this example, and only 2 lithography capabilities are generated . However, turning the parameter on negatively affects scores overall, so it was off for the MUC-5 test . The walkthrough article exemplifies our use of the entity relation statistical model . The PLUM system, throug h discourse processing, had hypothesized Nikon Corp as both the distributor and manufacturer of <LITHOGRAPHY - 2789568-1>, as the distributor of <LITHOGRAPHY-2789568-2>, and as the distributor and purchaser/user o f <LITHOGRAPHY-2789568-3>. However, these relations were found at a fairly low confidence by a discourse search rule looking around within the sentence . On the other hand, the statistical model (derived from training data ) indicated that Nikon is most likely to be a manufacturer . So the template generator removed the unlikely relation s (distributor and purchaser/user) and entered the likely relation of manufacturer . Compared against the key, th e statistical model was correct in removing the purchaser/user relation but incorrect in removing one of the distributo r relations .","The PLUM system incorrectly generated only 1 stepper equipment object . This was because the discourse even t triggered by \"the company's latest stepper\" was incorrectly merged with the earlier stepper events . If PLUM coul d have recognized the two granularities and associated them with the 2 different stepper objects (at a high level o f confidence), this over-merging error could have been prevented . The device size information was missed because PLUM failed to correctly analyze the sequence \"64- mbit dram . \" Since running the walkthrough message for the MUC-5 test, this problem has been fixed, so the device siz e information in this article is now reported ."]},{"title":"JJV Walkthrough (Article 0002)","paragraphs":["appearing on the next pag e Questions to Address:","(I) How does your system determine whether there is a reportable tie-up ? A tie-up is generated whenever a teikei sentence pattern is matched .","(2) In Article 0002, how many tie-ups were found? What strategies are used to determine the number of tie-ups in","Sentence 2 ? PLUM found 4 tie-ups, the results after merging those which matched sentence patterns . (3) How does your system determine the entities in a tie-up ?","Some entities are picked up directly in the semantics when parsed within a fragment, or via lexical clues an d syntactic/semantics contexts within phrases . Others are picked up via discourse rules .","(4) How many discourse entities were identified anywhere in the text, and how did the system determine which o f","these were reportable ? The template generator's parameters were set to only output objects directly related to a tie-up . 104 System Response Template :","<5- 7 T L — I- -0002-1> : - {t \\t : \\t 000 2 \\t {T # II n : \\t 85010 8 \\t 1.—ZIIPh : \\t -aJnlIIM 4lli+l - IRI \\t : \\t <l1 I% -0002-1 > < \\t","-0002-2 > <Ili It -0002-3 > <N M t -0002-4 > 2 T 4Iin : \\t 93081 1 <Vi f!t -0002-1 > 5 -, \\t (4 — : it 4k \\t","<x i T 4 T 4--0002-1 > <.1 i 7' 4 T 4 - -0002-2 >","<{ f%-0002-2> : - lli \\t it \\t",": I ' - 1 4 — : < x i =r 4 7' !--0002-1 > <x i 4 7' 4 - -0002-2 >","<Ilt flt -0002-3> : - NfR]tiR : \\t","It17 • ' 4 4 - : < x i 7' 4 4--0002-3 > <x i 4 4--0002-4 >","<lk l* -0002-4> : - Iii f!t #f; iR : \\t","7R {7 i 7' 4 7 4 — : <X : /5-45-4-- 0 0 0 2 - 4 >","c]:. i T 4 \\t","4 - -0002-1> • - x> 5-4-7-4—A : \\t *71f.0ifk ifltfll£ 5IJ : \\t","\" *7tii .l ± 1: i 7' 4 7' 4 — flIf : \\t i It .7: i T 4 \\t — lVl f;= : \\t","<x > T 4 7 4 — I!!1 Ift -0002-1 > <T i 7' 4 7' 4- t f;+ -0002-2 >","<x i 7' 4 4 - -0002-2> xi-7-4 5-4—A : *1OliE * • \\t","i5 -44- : i t • 4 7 ' 4 — I R ) : <x > i 4 -Y 4 — IRI f -0002-1 > <x i t 4 =r 4— IR1 f.-0002-2 >","<x T 4 7' 4 - -0002-3 > x i 7' 4 T 4 — pi : \\t I\"I fi1 :/: )k 1 \\t f t I+ xiT 4 4 — ~ If : x \\t 44- : < \\t 4 j 4 \\t 0 0 0 2 - 3 >","<x T 4 4--0002-4> x i4-7 -4— : \\t","Ill — 18 xiT 4 T4 — It : Silk x i T 4 T 4 — M I f 'tI : < > 4 j 4 \\t . 0 0 0 2 - 3 > <x i T 4 Y 4 IIb f, -0002-4 >","<x T 4 7 ' 4 — A!I (• ̀e -0002-1 > x : /5-4'5-4-Z, \\t < > 1 \\t 4 - -0 0 0 2 -1> <x i T 4 T 4- -0002-2> \\t R~#lZIIC(;~ : \\t","it","— tt:","<x r 4 7 - 4 - (RI f-0002-2> : - x i 7' 4'7. 4 — Z. : <x i T 4 7' 4 - -0002-1 > <x i t 4 7 4--0002-2 > \\t FlI #Z. I : \\t !t— F t — #R iR : P 4","<x i 7 ' 4 7 ' 4 - IfC f + -0002-3 > .2 > - 1 \\t 1 — Z , :. : \\t","<X.5. 4-7. 4--0 0 0 2 - 3> <x i T 4 7' 4 - -0002-4> f Z. MI : i t— F 1 — ~tR : \\t","Atfr","<x i T 4 7 ' 4 - IR1 f-0002-4 > :/5-45-4 — Z. : \\t <x i 7' ! 7' ! - -0002-4 > \\t fZl ;tlfn : \\t Pe– Ft — yR : \\t J l #t","(5) Explain any difficulties you had in identifying the following:","a) the correct number of reportable entities Since the system doesn't handle conjunction of company names well, it missed one company . b) the correct number of tie-ups (correct, for the sake of this walk-through allows BOTH interpretation s","described in b) above, even though the key template does not. )","There was some overgeneration due to under-merging by the discourse component .","c) the correct links between reportable entities and reportable tie-ups. Since entities are only hypothesized through tie-up patterns, this is not a problem . (6) How does your system determine aliases for entities ? The system tests all noun phrases and their parts for concatenations of substrings of a company name . (7) What problems were there in detecting the alias for the ENTITY named Toukyou Kaijou Kasai Hoken ? 105 There was no problem .","(8) Sentence 2 ends with a general statement about products developed in tie-ups between insurance companies an d","securities companies. How would your system determine that this is a generic, not a specific reference ? No tie-up is generated when no proper names of companies are mentioned . (9) Discuss any specific analysis your system does to handle terms like \" ryousha\", which appears in Sentence 2 .","How does your system deal with the usage of the particle \"no\" that precedes it ? Currently, our system does not deal with conjunctions like \"ryousha\" ."]},{"title":"JME Walkthrough (Article 000452 ) System Response Template for 000452 :","paragraphs":["<i- i 1 I. – 1- -000452-1> : _ E , \\t : \\t 00045 2 ii. \\t 11 C1 : \\t 89080 4 - .~1l1 : \\t"]},{"title":"\"n \\t trrl \"","paragraphs":["Nl , \\t","< ' 4 7 q T L 7 I- q = 7 2 lit -000452-1 > < ;' 4 7 q i 1. 7 1- q \\t x It U-000452-2 > T 411 19 : \\t","93081 1","4( 7 q m 1 7 q . 7 ,7,1K 11t -000452-1> : =","<1-","4 ' 9 > f-000452-1 > A t : <L , ;- r 5- 4 - -000452-1>","<x > r 5- r - - 000452-2 > l( : \\t","< X > 5• r 5- r - - 000452-1 > <1 > 5' 4","5' r - - 000452-2 > -(7 q r L 7 h q 7 ? llt lit; -000452-2> : - h"]},{"title":"a \\t","paragraphs":["<1, 4 A' > l - 000452-2 > }'̀.. jn t : \\t","< 1' > 5' r 5- 4 - -000452-1 >","<1 > -) ! T r - - 000452-2 > .t : \\t","<1 > r T r - - 000452-1> <X Y 5- 4 i- •4 - -000452-2 >","<L 4"]},{"title":"r","paragraphs":["I"]},{"title":".","paragraphs":[") > 7' -000452-1> : = S g : \\t CVD S : \\t <g."]},{"title":"a","paragraphs":["-000452-1 >","<1. 4 A' 1.1 i 7' - 000452-2> : _ 51 11 \\t CVD <0."]},{"title":"a","paragraphs":["-000452-2 >","< :L' > 5- 4 5- 4 - - 000452-1 >"]},{"title":"<1","paragraphs":["> 5- 4 5- 4 -"]},{"title":"-","paragraphs":["000452-2> : _ 1 > 5-45-4–A : \\t","Lt T U •4 Y - -1-i a 1-16 t.t x. r i- 4 — Y9 : 4i"]},{"title":"< a","paragraphs":["-000452-1> : _ 11 i .t : \\t","< 5- 4 ;- 4 - -000452-1 >","<.1. > r 4 ;-","r - - 000452-2 >","5.111 : \\t cVD R iR : \\t I'1 144 t"]},{"title":"< a","paragraphs":["-000452-2> : _ A t : < 2 > T r j- r - - 000452-1 > g Rq : CVDR"]},{"title":"a","paragraphs":["4i R : \\t 91H4 106 Questions to Address : (1) How does the system determine the existence of a reportable microelectronics capability ? If a sentence includes equipment and a verb expressing an ME activity, and it matches a sentence pattern, then a ME capability object is created .","(2) Three entities are mentioned in this article. How did your system determine which were involved in the M E","capability? (If the joint venture company was not selected, was it rejected because its activity was in die . future,","or some other basis?) Only company names which fit the ME capability patterns are considered . Our system did not select the join t","venture company, since it did not match any company name patterns . (3) How does the system identify company names? How does it associate locations with entities ? Locations are associated with entities by using patterns lik e","\" . . .-maker, XXXX ( headquarters YYYY . . .\" and","\" . . .America's biggest . . . company, XXXX \" where XXXX is a company name and YYYY is a location . (4) How does your system associate film type with each ME capability? (In this article \"CVD\" is immediatel y","preceded by \"metal film.\" Will your present strategy allow more remote references? )","First, film names are extracted by means of clue words . Then, if these names match the sentence patterns, they ar e matched with film types according to the domain model . The order of <film>, <equipment>, and <verb> is not fixe d in the system, but currently must be within the same sentence . (5) How does you system determine the existence of reportable equipment? How is equipment type determined ?","(Would the determination of a new equipment type generate a new ME capability?)","Equipment names are extracted by means of clue words . Their types are decided according to a hierarchy o f equipment types. A new equipment type would not by itself generate a new capability . Equipment objects are onl y reported if some slot besides STATUS is filled ."]},{"title":"ACKNOWLEDGMENT S","paragraphs":["The work reported here was supported in part by the Defense Advanced Research Projects Agency and was monitored by the Rome Air Development Center under Contract No . F30602-91-C-0051 . The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing th e official policies, either expressed or implied, of the Advanced Research Projects Agency or the United State s Government ."]},{"title":"REFERENCE S","paragraphs":["[1] Ayuso, D .M., Boisen, S ., Fox, H ., Ingria, R ., and Weischedel, R . \"BBN : Description of the PLUM System as Used for MUC-4\", MUC-4 Proceedings, 1992. [2] Iwanska, et.al ., \"Computational Aspects of Discourse in the Context of MUC-3\", Proceedings of the Third Message Understanding Conference (MUC-3), 1991 . [3] Matsukawa, T., Miller, S ., and Weischedel, R. \"Example-Based Correction of Word Segmentation and Part of Speech Labelling\", to appear in Proceedings of the ARPA Workshop on Human Language Technology, 1993 . [4] Weischedel, R ., Ayuso, D .M ., Bobrow, R., Boisen, S ., Ingria, R., and Palmucci, J., \"Partial Parsing, A Report on Work in Progress\", Proceedings of the Fourth ARPA Workshop on Speech and Natural Language, 1991 . [5] Weischedel, R., Meteer, M ., Schwartz, R ., Ramshaw, L ., and Palmucci, J . \"Coping with Ambiguity an d Unknown Words through Probabilistic Models\", Computational Linguistics (Special Issue on Using Large Corpora : II) 19, 359-382, 1993 . 107"]}]}