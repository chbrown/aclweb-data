{"sections":[{"title":"TRW : DESCRIPTION OF THE DEFT SYSTEM AS USED FOR MUC- 5","paragraphs":["WILLIAM W. NOAH, Ph .D. ROLLIN V. WEEKS","TRW SYSTEMS DEVELOPMENT DIVISION","ONE SPACE PARK","REDONDO BEACH, CA 9027 8","R2/218 6 BACKGROUN D For the past three years, TRW has been developing a text analysis tool called DEFT- - Data Extraction from Text . Based on the Fast Data Finder (I'D I . ), l)EF'l' processes larg e volumes of text at very high speeds, identifying patterns which serve as indicator s for the presence of relevant objects, relationships, or concepts in the data . Thes e indicators are processed by a series of system-supplied utilities or custom-writte n functions which refine the data and re-formulate it into frames which can b e presented to a user for review, editing, and submission to a downstream applicatio n or database . Superficially, DEFT resembles a Natural language Understanding (NLUI) system ; however, there are key differences . DEFT entertains very limited goals in th e processing of natural language input . Although DEF\"1' processes unconstraine d input, it is looking for textual entities which are tightly constrained and presented t o the system as a list of expressions or in a powerful pattern specification language . i t exploits expectations about how a small set of entities will he expressed to reduce th e amount of computation required to locate those-- and only those-- entities . Th e broader question of the \"meaning\" of the text in the document is bypassed in favor o f rapid, robust processing that can he readily moved from domain to domain . As lon g as the input for a particular domain is sufficiently predictable, data extraction with a satisfactory level of recall and precision for many applications can be achieved . We are currently installing three DEFT systems for a United States government agency ; initial reviews have been highly favorable . Our involvement in MUC-5 derives from a request by the government to turn DEFT t o a COTS product, with the intent of having a fully-supported version of the system by the end of the year . An analysis of the broader commercial and government marke t for text extraction suggested that the scope of problems that DEI'\"I' should he able t o address needed to be expanded ; however, it was established that replication of the on - going research and development work in the NLU community was an inappropriat e role for our development group . Rather, we wanted DEFT to he able to integrate wit h systems already developed or in development for functionality which falls outsid e the narrow boundaries of DEFT's pattern-based capabilities . At the same time, DEFT' s ability to express patterns needed to be extended from it's current, highly effectiv e means for defining \"atomic\" patterns to the definition of patterns in relationship t o each other, permitting simple syntactic information to be added to DEFT's lexica l knowledge . Thus, DEli' would have the potential to find entities not expressly define d 237 in a lexicon, improve its ability to correctly determine the relation between entities , and decrease the overgeneration that tends to be associated with approaches that rel y exclusively on pattern matching . A mechanism was selected for enhancing pattern specification which was felt to b e compatible with the notion of integrating DEFT with third-party systems . As will b e described in some detail, DEFT is intrinsically an engineering shell which is intende d to facilitate such integration while making its rapid pattern-matching service s available to the other system components . Unfortunately, the softwar e implementing this concept was not available at the time of the final MUC- 5 evaluation, the results of which therefore serve only to confirm our expectation s that the recognition of \"simple\" (i .e . isolated) patterns is woefully insufficient fo r complex data extraction problems . While we regret that the capabilities of the extended version of DEFT could not b e demonstrated for MUC-5, we feel that the outcomes justify our belief that real-worl d message understanding problems necessitate an engineering solution that can pit a choice of technologies against the specific problem at hand-- different technologie s being optimum for different tasks . We believe that DEFT's success in handling simpl e data extraction problems can be extended, and that DEFT is well-suited to a role as an integrator of text analysis capabilities . It is toward this end that we are focusing ou r on-going productization efforts . SYSTEM DESCRIPTIO N It is convenient to envision DEFT as a pipeline, as shown in Figure 1 . At the head is a standardized document interface to message handling systems . At the tail is a proces s which generates frames and distributes these to the appropriate destinations on th e basis of content . In between is a series of text analysis \"filters\" which apply DEF T lexicons (pattern searches) against the text (using the FDF) and call specifi c extraction functions to process the textual fragments located by the lexicons . Al l processes are controlled by means of external configuration files and a \"workbench \" which contains tools for interacting with DEFT and the data DEFT extracts . We wil l describe each of these major components in turn . The Document Interface : Message Queuing . It is assumed that DEFT will be embedde d in an existing automated message handling (AMIl) system . DEFT's interface wit h these systems is called Message Queuing (MQ) . Text is typically disseminated to M Q (e .g . by a messaging system like TRW's EL,CSS or KOALA that receives governmen t cables, wire service input, etc .) on the basis of subject matter, source, structure, o r other characteristic with salience for how the message's language will he analyzed . MQ can also accommodate documents loaded from other sources, such as native wir e services, an existing full-text database, CD-ROM, OCR, and so on . Text is assumed to b e in ASCIi or extended ASCII ; in the near-future, DEFT will build on work currentl y underway to allow the FDF to accommodate Unicode for foreign character sets, suc h as Japanese . Structural features, such as document boundaries, sentence boundaries , paragraphs, tahularization, encoded tags (such as SGMI .), embedded non-textual media, etc . can he defined for a particular document class using DEFT specificatio n files . MQ utilizes a configuration file to assign a processing thread tailored to the proble m domain to each category of document classified by the dissemination system or by whatever means (including manual) is used to route documents to DEFT . Document s 238 are associated with a processing thread by placing them in a particular 1\\IQ \"in - basket\" (a standard Unix directory) . Each in-basket is polled periodically, using a se t of criteria (time and number of messages since the last processing thread wa s initiated) defined in the configuration file . fx \\t lvi ~oo-;v;wsa ."]},{"title":"'Meow \\t x ;ti- . . Formatted portion s Knowledge Base an Messag Management Tools","paragraphs":["wr ,"]},{"title":"Messag e receipt","paragraphs":["Figure 1 : DEFT Functional Architectur e Extracting Data : Text Analysis [liters . When (\\9Q assigns a document to a processin g thread, it is subjected to a sequence of procedures which operate on the text to locat e patterns of interest and use these patterns as a guide to extract the data required for a particular problem domain . This sequence of processes determines what is extracted and how it is extracted . The sequence is defined as an ordered list of \"extractio n phases\" in a configuration file . This list can be changed at any time to substitute o r add new extraction phases to refine a text processing thread . New threads can h e modeled on existing ones, facilitating transitions to new problem areas . Each extraction phase is an executable program . The behavior of a phase i s dependent on the order in which it is called (i .e . its relationship to the phases tha t have been executed before it) and on parameters which are supplied in th e configuration file . In this Way, a generalized extraction phase can be configured fo r a specific analytic objective . DEFT has a library of extraction phases that perform th e most elementary analytic processes ; new phases are be written on a problem-specifi c basis . DEFT provides an application programming interface (API) in the form of a library of utilities which allows a custom extraction phase to interact with the dat a structure which is common to all extraction phases, and which is used t o communicate between phases . This structure is the DEFT \"Tag File. \" The Tag File is a cumulative record of the processing performed by each extractio n phase . Each phase receives the Tag File from the preceding phase, and passes it t o 239 the next . A \"tag\" represents a textual pattern identified by DEFT in the text or dat a created by an extraction function . Much of the power of DEFT comes from the ability w apply a mixture of extractio n phases that is optimally suited for a given class of document and extraction problem . For example, one extraction phase might reason about the relative time o f occurrence of events located in the text, basing its analysis on the occurrence o f various forms of date/time indicators as well as the presence of such modifiers a s \"last week,\" or \"three years ago .\" Another phase might construct corporate name s on the basis of the occurrence of a known name or the presence of a designator (e .g . \"Inc .\" or \"S .A .\") . Yet another phase might act upon these names to reason about thei r potential relationship in a joint venture . Locating Data : DEFT Lexicons. The patterns that DLI°T uses to locate data of interest i n the text arc contained in DE .FF's lexicons . Lexicons serve various purposes : t o identify potential frames, to determine the \"scope\" of a frame in the text (i .e . th e boundaries to be used to find data to fill the frame slots), to find the contents for a slo t in a frame, to determine structural elements (e .g . sentences, paragraphs, heade r information), and to set the attributes of a text object (e .g . classification level) . Lexicons are of two types : list and pattern . The list lexicon associates a set o f synonyms (or spelling variants) with a given object . It is useful when the complet e set of strings associated with an object can be specified . The pattern lexicon is use d when the textual variations associated with an object cannot be specified . For example, all possible monetary values cannot he conveniently enumerated, but a single pattern describing monetary values in terms of digits, punctuation, an d denomination strings can he constructed . Associated with lexicon entries are attributes, representing the semantics of th e problem domain . An attribute is a characteristic of the object represented in th e text by its synonym list or pattern . It might he the normalized form of a name o r other data about an object which is useful to map into a frame, such as the countr y associated with a corporate name . In a list lexicon, these attributes are know n explicitly when an entry is created ; they are not inferred from the text . In a patter n lexicon, however, the attributes cannot be known in advance because it is not know n what exact value will hit against the pattern . For this reason, attributes must b e extracted for a pattern lexicon . Attribute extraction is handled by a C or C++ progra m referred to as an \"extraction function .\" For example, given the location of a corporate designator, a function might reconstruct the corporate name . The success of a data extraction system that relics on pattern matching and strin g finding depends on how exhaustively it can search for the variations expected i n input language . DEFT has proved successful in its current applications in par t because its lexicons can be extremely large, thanks to the capabilities (in terms o f both functionality and performance) of the FDF . Searching Te .xt for Lexicon Entries : The PM DEFT uses the TRW-developed Fast Dat a Finder to rapidly locate instances of a potentially enormous set of patterns in th e input text. The power of the FDF originates in two ways : the hardware architectur e and the expressiveness of its Pattern Specification Language (PSI .) . The current generation FDF-3, nc,a~• a COTS product manufactured by Paracel, inc . , uses a massively parallel architecture to stream text past a search pattern at dis k speeds (currently 3 .5-million characters/second using a standard SCSi disk) . 240 Searches are compiled into micro code for a proprietary chip set which ca n accommodate up to 3,600 simultaneous character searches or Boolean operations . Lexicons are broken into \"pipelines\" which fully fill the chip set ; each pipeline i s run against all of the text in the set of documents currently being processed . MO_ batches messages as they come in so as to optimize the use of the 1 . 1) 1 .-- larger message sets are processed more efficiently than several smaller ones . The tradeoff betwee n batching and \"real-time\" processing can he independently balanced in the W I configuration file for each in-basket and processing thread . Search patterns are specified in PSI,. Because the l l)f uses a streaming approach , PSL is not dependent on word boundaries . Extremely complex patterns can h e expressed, which can include such features as error tolerance, sliding windows , multiple wildcard options, nested macros, character masking, ranging, and the usua l Boolean operations. Features that support \"fuzzy matching,\" like error tolerance, ar e extremely important for handling \"noisy\" input . Output Generation : Frame Assemhi) and Rowing . When the filters that comprise a processing sequence have executed, the 'fag File is passed to the \"Frame Assembly an d Region Routing\" (FARR) module . This program, which constitutes the \"tail\" of th e DEFT pipeline, assembles the data elements generated during the analysis thread int o frames based on an external definition file . This file specifies which slots ar e associated with which frames, how to transform a data value for display to the use r (e .g . normalize \"England\" to \"United Kingdom\"), how to transform a value for storag e in a downstream database (e .g . abbreviate \"England\" as \"UK\"), how to validate a dat a value, whether a data type can he multiply-occurring, and so on . One issue that arises during frame assembly is when to associate a data value with a n instance of the frame class for which it is defined . In DEFT, this operation i s associated with \"scoping .\" Scoping is the process of determining the extent in th e text of a concept associated with a pattern . For example, if a pattern of word s indicative of a joint venture is found, the scope of the \"tie-up\" frame might be take n to be the location of the pattern plus or minus two sentences . The unit of scoping (i n this case, sentence) need not he a syntactic unit-- it can be any pattern stored in a special type of lexicon used exclusively for determining frame scope . The unit o f scoping and its extent (e .g ., \"plus or minus n\") can he determined independently fo r each frame class . When a pattern that gives rise to a slot value of a type defined for a given frame clas s is found in the text, the slot is automatically mapped by I ARR to any frame whos e scope encompasses the location of the pattern . \"thus, if the name of a corporatio n were to occur within the two sentence range of the tic-up frame in our example, i t would appear in that frame . Of course, this may not he accurate-- DEFT has a tendency to overgenerate slots through bogus associations that arise because of thi s weak scoping mechanism . Another issue that is encountered is overlapping frames . The \"best available \" resolution can he specified in the frame definition file . One alternative is simply t o accept both frames, since they may be describing separate concepts . If the frame s are of different classes, FARR supports the attribution of a priority to each class, an d only the frame with the highest priority need be retained . If the frames are of th e same class, FARR supports a \"non-multiply occurring\" attribute, which optionall y suppresses all but one of the frames . Unfortunately, the action taken is generalize d to all situations-- the specifics of a given case cannot be taken into account . Thus , DEFT tends to either overgenerate or lose frames . 241 When a message's frames have been generated and ambiguities resolved (to th e extent that DEFT can resolve them), the frames (and the message) are routed to a destination directory on the basis of their content . Routing instructions are define d in a rule base using a normalized conjunctive form of field-value pairs . It should b e kept in mind that although DEFT's primary mission is extraction, not dissemination , the routing capability (since it is based on knowledge representation) provides a sensitive mechanism for determining the destination of a message and the structure d representation of its contents . Controlling the System : DEI .T' lbois and Specification Management . in order to make DEFT portable to different computing environments and problem domains, th e definition of user-modifiable system characteristics has been exported to a set o f external specification files . These files govern the interface with the surroundin g message handling system, the output data model, FDF configuration, and othe r \"housekeeping\" functions . Specification files are maintained using any convenien t text editor . The most important system specifications from the standpoint of the end-user are the lexicons and the frame routing rules . To facilitate lexicon development an d maintenance, a lexicon editor is bundled with DEFT that provides a graphic use r interface (under X/[Motif) for interactively defining lexicons and entering/editin g lexicon entries . Lexicons can also he created/updated from databases or externa l machine-readable files (e .g . gazetteers, corporate name lists) using a hatch loa d protocol . Like the lexicon editor, the routing rule manager provides a GUI for maintainin g routing rules . It uses a spreadsheet metaphor to minimize the user's exposure to th e potentially complex Boolean logic that the rules can involve . Menus of valid value s and conditions tests are automatically provided . Another important Dlil°l' tool is frame review . D1:1'1' was developed under th e assumption that a user would always he in the loop ; it was not intended to ru n autonomously . 'Phis package therefore supports simultaneous display of message s and the frames derived from them, providing highlights that show where slot value s were extracted . Menus of valid values drawn from the lexicons assist the user i n filling slots that were omitted by\" Dl't Features for selectively deleting superfluou s slots and frames are particularly important, since l)I :F I' (like other pattern-base d approaches to text analysis) tends to overgenerate data . A mechanism is als o provided to facilitate manually linking frames of different classes into higher-leve l logical aggregations, since Dlil'l' was not originally designed with an automate d linking capability . Clearly, these two design assumptions-- human interaction an d manual frame linking-- had an impact on working with the iM11C-5 data . DEFT as an Engineering Shell Phis description of the DEFT system has emphasized that analysis threads ar e composed of independent components \\ n 'hich communicate through a common dat a structure using a library of utilities that constitute an API . It is our contention tha t 242 DEFT's strengths are: • A powerful pattern searching capability, which we are extending .","• The ability to integrate COTS, CO'T'S, and custom-written program s within the DEFT architecture . We believe that there will probably not he a single text analysis or NI .0 system tha t meets the requirements of all conceivable applications . There will always be a tradeoff between such factors as speed, depth of analysis, breadth of coverage , portability, robustness, and analysis methodology that will favor one technolog y over another for a particular problem . The real question is not \"What is the bes t system?\", but \"What is the best system at this moment? \" Our current development work on DEFT is chiefly targeted at its usefulness as a n integration tool . DEFT provides a high-speed pattern searching capability which ca n successfully extract data from structured or tightly constrained textual inputs, whil e providing pre-processing services (e .g . tagging words with part of speech o r semantic attributes)"]},{"title":"for","paragraphs":["third-party software which performs more extensive natura l language processing for unconstrained textual inputs . This approach should h e especially efficient for applications in which messages are mixed (formatted an d unformatted), text analysis tasks are varied in complexity, and throughput is a majo r consideration ."]},{"title":"Inherent Limitations in DEFT's Pattern-Matching Approac h","paragraphs":["Because DEFT was not originally intended for problems of the scope of MC-5, it s simplistic approach posed some major problems . Among the most fundamental were: Syntactical Patterns. DEFT has very powerful mechanisms for specifying \"atomic \" patterns-- a corporate name, a place name, a scat of words that indicate a join t venture, etc . DEFT was not designed to have the capability of expressin g relationships among the patterns in its lexicons and providing for the assignment o f values defined with respect to these patterns to variables . These are essentia l capabilities for the implementation of the most rudimentary semantic grammar . Fo r example, DEFT had no way to express : \"Look for a corporate name followed by a join t venture formation phrase and take the following corporate name as the partner i n the joint venture . \" Frame Scoping. DEFT was designed to interpret the scope of a frame as a function o f proximity to the \"hit location\" of the pattern that resulted in a frame's instantiation . The boundaries are determined by a pre-defined number of repetitions of a patter n contained in a scope lexicon . An upper ceiling determined by a fixed number o f characters can also be specified, in case the scoping pattern is not detected a \"reasonable\" distance from the site of the hit . All occurrences of slots defined for a frame within these boundaries are automatically included in the frame when it i s assembled by FARR . For highly formatted text (e .g . messages in Military \"Text Format), such a mechanis m is adequate . For free-text, it is not . in the MIIC-5 evaluation, DLF'l' failed to repor t valid objects that it located (notably entities) because they were not within the scop e of a tic-up, as DEFT measured scope . 243 /Tame Linking . The original DEFT design assumed that a human operator woul d perform this task . Automated linking is obviously needed for \"unattended\" operatio n and is clearly useful even if there is a human-in-the-loop . Solution s Current internal research and development work aimed at resolving each of thes e problems for the eventual DIET product adheres to the constraint that architectura l extensions must be philosophically compatible with the pattern-based approach , while avoiding significant overlap with NI. .0 (which we prefer to view as a n integratable component in a complex system) . As noted earlier, key software bein g developed under IR&D was not available for the MtlC-5 final evaluation ; however , work continues and will be tested on the NIIIC-5 corpus in the near future to validat e the approach . Syntactical Patterns . This is the specific area that was not developed in time for th e evaluation ; unfortunately, it is also the most critical for dealing with even the simpl e aspects of the NIt1C problem . The approach we selected is intended to be compatibl e with the integration of more powerful text understanding components in the future , while extending the range of problems DEFT can solve by itself . it exploits DEFT' s atomic pattern-recognition capabilities while separating the definition of a semanti c grammar into an independent extraction phase . This phase could easily be replace d (or supplemented) with an NE,tl system which can optionally take advantage of th e D1 :1'I' lexical pre-processing while performing deep syntactic and semantic analyses . This separation is in part intended to provide an initial test of our belief that th e integration of Dl]']' with an Nl .tl component creates a symbiotic association wit h better performance characteristics than either system by itself . To stay within the (admittedly loosely defined) hounds of pattern matching, ou r approach to exploiting syntax consists of providing DEFT with a simple mechanis m for expressing \"meta-patterns\"-- that is, patterns whose components may be th e atomic patterns (and, by reference, their attributes) located by the DEFT lexicons . W e decided to use a l~Nl specification to define a semantic grammar based on a combination of' literal strings and DEFT'-identified tokens . The key issue was how to pass the results of DEFT pattern-matching to the parser . An integrated NE,tl component within the 1)1 :1'I' shell could interface directly with th e DEFT Tag File through the All ; the component could also interface with the frame s generated by DLI I', providing a preliminary level of analysis on which to build . Fo r our prototype, however, we chose to mark terms in the text with SGML-like tags t o indicate their properties . The grammar directly references these tags, and routine s were provided within the parser for assigning text strings to slots by extracting DEF T lexicon attributes (e .g . normalized values or semantic characteristics) or collectin g words intervening between two tags (of the same or different class) . Additiona l primitives for manipulating the strings prior to slot assignment were also built int o the parser infrastructure to control frame generation and the assignment of slot s (including pointers to other frames) to frames . This significantly improves on th e primitive scoping capability provided with the current version of DEFT . The approach selected thus provides a vocabulary for expressing both the expected contents of documents and the rules for instantiating and linking templates . At th e 244 same time, its intermediate product is human-readable (and, in fact, could he used as a general-purpose \"tagger\") and easily interpreted by other programs . Frame Scoping . Fundamental changes in the I)I :I'I' frame-scoping mechanism are planned which will exploit domain knowledge as well as limited syntactic (from th e meta-patterns) and semantic (from lexicon attributes) data . For MUC-5, the basi c DEFT mechanism was retained, with its inherent limitations . Frame Linking. A primitive frame linking capability was added to DE R' . It was base d on frame scoping, however, and therefore suffered from the same limitations . Th e DEFT frame definition file format was extended to accommodate hierarchica l relationships ; any frame defined as a child of another frame had its generated fram e ID automatically included as a slot value in the parent frame if its \"hit location\" fel l within the scope of the parent frame . Of course, multiple and spurious association s are easily generated in this way . In the future, frame linking will be improved b y combining syntactic and domain knowledge in a final extraction phase to resolv e inter-object relations . RESULT S The results of the final MUC evaluation were strongly influenced by th e unavailability of the parser, which was an essential component of the DEFT approac h to MUC-5 . The resulting scores indicate the magnitude of the problems inherent in a simple pattern-matching strategy which is not informed with even a crude semanti c grammar . It should be noted that a decision Was made to focus only on a subset o f templates and slots required for the preliminary run . These were the documen t template, tie-up-relationship, and entity . The F-measures for the final evaluatio n were: P&R \\t 2P&R \\t P&2 R 1 .15 \\t 2 .64 \\t 0 .7 4 Not surprisingly, these were the lowest scores for any system in the evaluation . A detailed analysis of the run is of little utility, however there are some points o f interest seen in the walk-through sample document ."]},{"title":"Walkthrough Documen t","paragraphs":["The identifying data (document number, source, and date) were correctly extracted . Some simple atomic patterns were defined in a l)I :I \"I' lexicon for tie-up relations . These were to be factored into a semantic grammar ; as noted, the parser was no t available at the time of the run . \"Therefore, the patterns were run as a simple search . It correctly identified the presence of a joint venture in the sample document , incorrectly instantiating two tie-up templates (one for each of two out of thre e references to the venture) and entering their ll)s in the content slot of th e document template . DEFT currently does not determine that multiple references hav e a common object unless the frames overlap . A single entity was mis-identified, \"Jiji Press Ltd .,\" which is actually the documen t source . This entity was incorrectly associated with the first tie-up . The foregoin g explanation of the DEFT scoping mechanism makes it clear why this false associatio n 245 took place . The name of the \"BRiDGIS'TONE SPORTS CO .\" was correctly reconstructed from the corporate designator (\"CO .\") and assigned to the first tie-up . The name of th e joint venture, \"BRIDGESTONE SPORTS TAIWAN CO .,\" was also constructed and associate d with the second tie-up instance . No other features were correctly identified . Among the other corporate names, the algorithm used by DEFT would not hav e identified \"UNION PRECISON CAS'T'ING CO .,\" but did identify \"\"I'AGA CO .\" However, thi s entity was considered out of scope of the tie-up templates and was (incorrectly) no t attached to one . DEFT had no facility for recognizing \"BRIDGESTONE SPORTS\" nor for tracking the reference to \"TI IL NEW COMPANY . \""]},{"title":"What Worke d","paragraphs":["DEFT was effective at recognizing literal strings and 'patterns contained in it s lexicons . DEFT frequently generated correct entity names that were not in th e corporate name lexicon using a set of heuristics that reasoned backwards from a designator . For example, \"BRIDGESTONE SPORTS CO .\" was constructed . DEFT of cours e had little problem with the tagged items for the document template . These ar e precisely the kinds of elemental functions that DEFT is expected to perform well . DEFT recognized the occurrence of sonic of the joint ventures, based on a very limite d set of patterns that were originally defined for use in connection with a semanti c grammar . This set could have been extended to produce improved recall had w e known the parser would not he available . \"These few successes indicate that even a simple pattern-based approach can recognize concepts of this type in restricte d cases ."]},{"title":"What Faile d","paragraphs":["The lexicons and ext raction phases that were rapidly developed for MtJC-5 containe d some hugs that were not observed during training ; some corporate names wer e missed, for example, that should have been constructed . The chief failings wer e inadequate lexicons for identifying joint ventures and inadequate scoping . Thes e two problems combined to suppress the instantiation of the many valid entities tha t DEFT found, but could not associate with a tie-up relation and therefore did no t report . In general, the system was configured to reduce the anticipate d overgeneration, with the expectation that tie-ups and entity relations would b e identified and scoped by the semantic grammar ; in the absence of the parser , undcrgeneration became severe ."]},{"title":"System Training and Resources Expende d","paragraphs":["The effort expended on MUC-5 testing and documentation was approximately tw o person-weeks . System development activities undertaken independently of MUC- 5 were exploited for the Mt1C-5 evaluation run . These included : • Analysis : 1 person-mont h • lexicon Development and Data Definitions : 1 .25 person-month s • Extraction Phases and Functions : 3 person-month s I'he total level of effort for all actin ities impacting M1,1C-5 c\\\"as therefore roughly 5 . 5 person-months . 246 As we have noted, key system components were ultimately unavailable for the MUC- 5 evaluation . Although we won't know \"how we would have done\" until th e components are completed and our internal tests against the MUG data are repeated, i t is our expectation that significant improvement will he obtained with a littl e additional effort-- although performance is neither expected nor required t o approach that of true NM systems, given our view of DEFT as an integratio n environment . Most of the effort in creating a new DEFT application usually centers on lexico n development . For MUC-5, most lexicons were batch loaded from the data supplied vi a the Consortium for Lexical Research . A few lexicons for joint venture identificatio n and scoping were developed manually . These were quite simple and their actua l creation required minimal time . Much of the time on MUG-5 was occupied with writing C-code for extraction routines , particularly for corporate names . The need to write so much code for a ne w application is a current weakness in DEFT which will he remedied to a degree whe n the parser becomes available . Of course, a key activity was the analysis of the test corpus and development of a semantic grammar appropriate to the IiJV problem . The results of this analysis wer e manifested in the tie-up relation lexicon and the BNF grammar for the parser . Onl y the former was ready in time for the evaluation . Analysis was a cyclical, iterativ e process ; refinement continued during system training . DEFT system training consisted of a series of runs against samples of the trainin g corpus, utilizing the frame review tool to examine the results . Lexicons wer e manually refined as a result of missed objects and false hits . Early runs resulted i n changes to the hatch loading sequence for some of the lexicons (e .g . the corporat e designators) . Feedback into the grammar would also have been derived from thi s process, had the parser been available and time permitted . As it was, time wa s insufficient even for lexicon refinement ; for example, a few key errors in th e corporate designator lexicon resulting from a hug in the program that prepared th e file provided through the Consortium for hatch uploading were noted only after th e final evaluation run was analyzed . This was partially responsible for some of th e undergeneration . What We Learned It came as no surprise that simple patterns are inadequate to extract the complex ideas expressed in the IiJV documents . We view the results as validating the concep t that DEFT, operating as a standalone system, is best qualified to perform on problem s involving well-defined, constrained sets of text objects to be extracted, even with th e addition of a \"meta-pattern\" or grammatical capability . DEFT should excel on suc h problems when throughput is a major consideration . The selection (and on-going implementation) of a mechanism for expressing meta - patterns that is compatible with all of the goals discussed earlier is a major outcom e of our MUC work, even though it was not available in time . We believe that thi s approach will significantly empower DEFT and broaden the range of applications fo r which it is a suitable tool, while increasing the flexibility with which it can b e integrated with other text analysis tools . This will prove highly valuable to ou r 247 current government customers, as well as future DL F1' users in the government o r commercial sector . DEFT's potential as an integration environment was underscored by the fact that w e successfully ran documents through : • A complex set of extraction phase s • With extremely large lexicon s that are beyond the scope of anything that has been tried in existing DEF T applications . The robustness of the architecture and efficiency of the patter n searches were our major consolation in the MUG-5 evaluation . We therefore look .fo r opportunities to combine DEFT's system engineering and search capabilities with th e sophisticated analytical power of NI .U-based solutions when real-world problems ar e encountered which are out of scope of DEFI\"s simple extraction mechanisms . 248"]}]}